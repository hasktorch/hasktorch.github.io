<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-3"></span><span>
</span><span id="line-4"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Functional</span><span>
</span><span id="line-5"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">module</span><span> </span><span class="annot"><a href="Torch.Functional.html"><span class="hs-identifier">Torch.Functional</span></a></span><span>
</span><span id="line-6"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#acos"><span class="hs-identifier">Internal.acos</span></a></span><span>
</span><span id="line-7"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#addmv"><span class="hs-identifier">Internal.addmv</span></a></span><span>
</span><span id="line-8"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#addr"><span class="hs-identifier">Internal.addr</span></a></span><span>
</span><span id="line-9"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#allclose"><span class="hs-identifier">Internal.allclose</span></a></span><span>
</span><span id="line-10"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#argmin"><span class="hs-identifier">Internal.argmin</span></a></span><span>
</span><span id="line-11"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#asin"><span class="hs-identifier">Internal.asin</span></a></span><span>
</span><span id="line-12"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#atan"><span class="hs-identifier">Internal.atan</span></a></span><span>
</span><span id="line-13"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#baddbmm"><span class="hs-identifier">Internal.baddbmm</span></a></span><span>
</span><span id="line-14"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#bmm"><span class="hs-identifier">Internal.bmm</span></a></span><span>
</span><span id="line-15"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#conj"><span class="hs-identifier">Internal.conj</span></a></span><span>
</span><span id="line-16"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#det"><span class="hs-identifier">Internal.det</span></a></span><span>
</span><span id="line-17"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#dot"><span class="hs-identifier">Internal.dot</span></a></span><span>
</span><span id="line-18"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#einsum"><span class="hs-identifier">Internal.einsum</span></a></span><span>
</span><span id="line-19"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#expm1"><span class="hs-identifier">Internal.expm1</span></a></span><span>
</span><span id="line-20"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#ger"><span class="hs-identifier">Internal.ger</span></a></span><span>
</span><span id="line-21"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#logdet"><span class="hs-identifier">Internal.logdet</span></a></span><span>
</span><span id="line-22"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#lstsq"><span class="hs-identifier">Internal.lstsq</span></a></span><span>
</span><span id="line-23"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#mv"><span class="hs-identifier">Internal.mv</span></a></span><span>
</span><span id="line-24"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html#sumWithDimnames"><span class="hs-identifier">Internal.sumWithDimnames</span></a></span><span>
</span><span id="line-25"></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-26"></span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier">all</span></span><span>
</span><span id="line-28"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">any</span></span><span>
</span><span id="line-29"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">sin</span></span><span>
</span><span id="line-30"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">sinh</span></span><span>
</span><span id="line-31"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">cos</span></span><span>
</span><span id="line-32"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">cosh</span></span><span>
</span><span id="line-33"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">tan</span></span><span>
</span><span id="line-34"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">tanh</span></span><span>
</span><span id="line-35"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">asin</span></span><span>
</span><span id="line-36"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">asinh</span></span><span>
</span><span id="line-37"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">acos</span></span><span>
</span><span id="line-38"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">acosh</span></span><span>
</span><span id="line-39"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">atan</span></span><span>
</span><span id="line-40"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">atanh</span></span><span>
</span><span id="line-41"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">max</span></span><span>
</span><span id="line-42"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">min</span></span><span>
</span><span id="line-43"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">exp</span></span><span>
</span><span id="line-44"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">log</span></span><span>
</span><span id="line-45"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">round</span></span><span>
</span><span id="line-46"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">isNaN</span></span><span>
</span><span id="line-47"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">floor</span></span><span>
</span><span id="line-48"></span><span>                      </span><span class="hs-special">,</span><span> </span><span class="hs-identifier">ceil</span><span>
</span><span id="line-49"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">P</span></span><span>
</span><span id="line-51"></span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign.ForeignPtr</span></span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign.C.Types</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">CBool</span></span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Dimname.html"><span class="hs-identifier">Torch.Dimname</span></a></span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Scalar</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tuple</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Const</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Cast</span></a></span><span>
</span><span id="line-64"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Functional.Internal.html"><span class="hs-identifier">Torch.Functional.Internal</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Internal</span></span><span>
</span><span id="line-65"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span>
</span><span id="line-66"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span>
</span><span id="line-67"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Int</span></span><span>
</span><span id="line-68"></span><span>
</span><span id="line-69"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Scalar.html"><span class="hs-identifier">Torch.Scalar</span></a></span><span>
</span><span id="line-70"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span>
</span><span id="line-71"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.DType.html"><span class="hs-identifier">Torch.DType</span></a></span><span>
</span><span id="line-72"></span><span class="hs-comment">-- import Torch.Functional.Internal hiding (argmax, clamp, cosh, conv1d, linear, softmax)</span><span>
</span><span id="line-73"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.TensorFactories.html"><span class="hs-identifier">Torch.TensorFactories</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.TensorFactories.html#onesLike"><span class="hs-identifier">onesLike</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.TensorFactories.html#ones%27"><span class="hs-identifier">ones'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>
</span><span id="line-75"></span><span class="annot"><a href="Torch.Functional.html#kOne"><span class="hs-identifier hs-type">kOne</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Scalar</span></a></span><span>
</span><span id="line-76"></span><span id="kOne"><span class="annot"><span class="annottext">kOne :: ForeignPtr Scalar
</span><a href="Torch.Functional.html#kOne"><span class="hs-identifier hs-var hs-var">kOne</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (ForeignPtr Scalar) -&gt; ForeignPtr Scalar
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (ForeignPtr Scalar) -&gt; ForeignPtr Scalar)
-&gt; IO (ForeignPtr Scalar) -&gt; ForeignPtr Scalar
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">CInt -&gt; IO (ForeignPtr Scalar)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.newScalar_i</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-77"></span><span>
</span><span id="line-78"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Num</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-79"></span><span>  </span><span id="local-6989586621679881082"><span class="annot"><span class="annottext">+ :: Tensor -&gt; Tensor -&gt; Tensor
</span><span class="hs-operator hs-var hs-var hs-var hs-var">(+)</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#add"><span class="hs-identifier hs-var">add</span></a></span><span>
</span><span id="line-80"></span><span>  </span><span id="local-6989586621679881079"><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="hs-special">)</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sub"><span class="hs-identifier hs-var">sub</span></a></span><span>
</span><span id="line-81"></span><span>  </span><span id="local-6989586621679881077"><span class="annot"><span class="annottext">* :: Tensor -&gt; Tensor -&gt; Tensor
</span><span class="hs-operator hs-var hs-var hs-var hs-var">(*)</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mul"><span class="hs-identifier hs-var">mul</span></a></span><span>
</span><span id="line-82"></span><span>  </span><span id="local-6989586621679881074"><span class="annot"><span class="annottext">negate :: Tensor -&gt; Tensor
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">negate</span></span></span><span> </span><span id="local-6989586621679881073"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679881073"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.neg_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881073"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-83"></span><span>  </span><span id="local-6989586621679881070"><span class="annot"><span class="annottext">abs :: Tensor -&gt; Tensor
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">abs</span></span></span><span> </span><span id="local-6989586621679881068"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679881068"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.abs_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881068"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-84"></span><span>  </span><span id="local-6989586621679881066"><span class="annot"><span class="annottext">signum :: Tensor -&gt; Tensor
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">signum</span></span></span><span> </span><span id="local-6989586621679881064"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679881064"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sign_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881064"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-85"></span><span>  </span><span id="local-6989586621679881062"><span class="annot"><span class="annottext">fromInteger :: Integer -&gt; Tensor
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">fromInteger</span></span></span><span> </span><span id="local-6989586621679881061"><span class="annot"><span class="annottext">i :: Integer
</span><a href="#local-6989586621679881061"><span class="hs-identifier hs-var">i</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorLike Int =&gt; Int -&gt; Tensor
forall a. TensorLike a =&gt; a -&gt; Tensor
</span><a href="Torch.Tensor.html#asTensor"><span class="hs-identifier hs-var">asTensor</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Tensor) -&gt; Int -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679881061"><span class="hs-identifier hs-var">i</span></a></span><span>
</span><span id="line-86"></span><span>
</span><span id="line-87"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679881057"><span class="annot"><span class="hs-identifier hs-type">Eq</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-88"></span><span>    </span><span id="local-6989586621679881055"><span class="annot"><span class="annottext">== :: Tensor -&gt; Tensor -&gt; Bool
</span><span class="hs-operator hs-var hs-var hs-var hs-var">(==)</span></span></span><span> </span><span id="local-6989586621679881054"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679881054"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span id="local-6989586621679881053"><span class="annot"><span class="annottext">t' :: Tensor
</span><a href="#local-6989586621679881053"><span class="hs-identifier hs-var">t'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Bool
</span><a href="Torch.Functional.html#all"><span class="hs-identifier hs-var">all</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881054"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#eq"><span class="hs-operator hs-var">`eq`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881053"><span class="hs-identifier hs-var">t'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>
</span><span id="line-90"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Fractional</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-91"></span><span>  </span><span id="local-6989586621679881045"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679881045"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679881044"><span class="annot"><span class="annottext">/ :: Tensor -&gt; Tensor -&gt; Tensor
</span><span class="hs-operator hs-var hs-var hs-var hs-var">/</span></span></span><span> </span><span id="local-6989586621679881042"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679881042"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.div_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881045"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881042"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-92"></span><span>  </span><span id="local-6989586621679881039"><span class="annot"><span class="annottext">recip :: Tensor -&gt; Tensor
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">recip</span></span></span><span> </span><span id="local-6989586621679881037"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679881037"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.reciprocal_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679881037"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-93"></span><span>  </span><span id="local-6989586621679881035"><span class="annot"><span class="annottext">fromRational :: Rational -&gt; Tensor
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">fromRational</span></span></span><span> </span><span id="local-6989586621679881034"><span class="annot"><span class="annottext">i :: Rational
</span><a href="#local-6989586621679881034"><span class="hs-identifier hs-var">i</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorLike Float =&gt; Float -&gt; Tensor
forall a. TensorLike a =&gt; a -&gt; Tensor
</span><a href="Torch.Tensor.html#asTensor"><span class="hs-identifier hs-var">asTensor</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="annot"><span class="annottext">(Float -&gt; Tensor) -&gt; Float -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Rational -&gt; Float
forall a. Fractional a =&gt; Rational -&gt; a
</span><span class="hs-identifier hs-var">fromRational</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="annot"><span class="annottext">Rational
</span><a href="#local-6989586621679881034"><span class="hs-identifier hs-var">i</span></a></span><span>
</span><span id="line-94"></span><span>
</span><span id="line-95"></span><span class="hs-comment">-- Return upper or lower triangular matrices</span><span>
</span><span id="line-96"></span><span class="hs-keyword">data</span><span> </span><span id="Tri"><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-var">Tri</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="Upper"><span class="annot"><a href="Torch.Functional.html#Upper"><span class="hs-identifier hs-var">Upper</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="Lower"><span class="annot"><a href="Torch.Functional.html#Lower"><span class="hs-identifier hs-var">Lower</span></a></span></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679881028"><span id="local-6989586621679881030"><span class="annot"><span class="annottext">Tri -&gt; Tri -&gt; Bool
(Tri -&gt; Tri -&gt; Bool) -&gt; (Tri -&gt; Tri -&gt; Bool) -&gt; Eq Tri
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: Tri -&gt; Tri -&gt; Bool
$c/= :: Tri -&gt; Tri -&gt; Bool
== :: Tri -&gt; Tri -&gt; Bool
$c== :: Tri -&gt; Tri -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679881022"><span id="local-6989586621679881024"><span id="local-6989586621679881026"><span class="annot"><span class="annottext">Int -&gt; Tri -&gt; ShowS
[Tri] -&gt; ShowS
Tri -&gt; String
(Int -&gt; Tri -&gt; ShowS)
-&gt; (Tri -&gt; String) -&gt; ([Tri] -&gt; ShowS) -&gt; Show Tri
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [Tri] -&gt; ShowS
$cshowList :: [Tri] -&gt; ShowS
show :: Tri -&gt; String
$cshow :: Tri -&gt; String
showsPrec :: Int -&gt; Tri -&gt; ShowS
$cshowsPrec :: Int -&gt; Tri -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>
</span><span id="line-98"></span><span class="hs-comment">-- Reductions, used by BCE loss, see -</span><span>
</span><span id="line-99"></span><span class="hs-comment">-- https://github.com/pytorch/pytorch/blob/3762cf9cc63e2032410d50f218c1406668177c23/aten/src/ATen/core/Reduction.h</span><span>
</span><span id="line-100"></span><span class="hs-keyword">data</span><span> </span><span id="Reduction"><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-var">Reduction</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ReduceNone"><span class="annot"><a href="Torch.Functional.html#ReduceNone"><span class="hs-identifier hs-var">ReduceNone</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ReduceMean"><span class="annot"><a href="Torch.Functional.html#ReduceMean"><span class="hs-identifier hs-var">ReduceMean</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ReduceSum"><span class="annot"><a href="Torch.Functional.html#ReduceSum"><span class="hs-identifier hs-var">ReduceSum</span></a></span></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679881014"><span id="local-6989586621679881016"><span class="annot"><span class="annottext">Reduction -&gt; Reduction -&gt; Bool
(Reduction -&gt; Reduction -&gt; Bool)
-&gt; (Reduction -&gt; Reduction -&gt; Bool) -&gt; Eq Reduction
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: Reduction -&gt; Reduction -&gt; Bool
$c/= :: Reduction -&gt; Reduction -&gt; Bool
== :: Reduction -&gt; Reduction -&gt; Bool
$c== :: Reduction -&gt; Reduction -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679881008"><span id="local-6989586621679881010"><span id="local-6989586621679881012"><span class="annot"><span class="annottext">Int -&gt; Reduction -&gt; ShowS
[Reduction] -&gt; ShowS
Reduction -&gt; String
(Int -&gt; Reduction -&gt; ShowS)
-&gt; (Reduction -&gt; String)
-&gt; ([Reduction] -&gt; ShowS)
-&gt; Show Reduction
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [Reduction] -&gt; ShowS
$cshowList :: [Reduction] -&gt; ShowS
show :: Reduction -&gt; String
$cshow :: Reduction -&gt; String
showsPrec :: Int -&gt; Reduction -&gt; ShowS
$cshowsPrec :: Int -&gt; Reduction -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>
</span><span id="line-102"></span><span class="hs-keyword">data</span><span> </span><span id="Dim"><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="Dim"><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-103"></span><span>
</span><span id="line-104"></span><span class="hs-keyword">data</span><span> </span><span id="KeepDim"><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-var">KeepDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="KeepDim"><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-var">KeepDim</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="RemoveDim"><span class="annot"><a href="Torch.Functional.html#RemoveDim"><span class="hs-identifier hs-var">RemoveDim</span></a></span></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679881001"><span id="local-6989586621679881003"><span class="annot"><span class="annottext">KeepDim -&gt; KeepDim -&gt; Bool
(KeepDim -&gt; KeepDim -&gt; Bool)
-&gt; (KeepDim -&gt; KeepDim -&gt; Bool) -&gt; Eq KeepDim
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: KeepDim -&gt; KeepDim -&gt; Bool
$c/= :: KeepDim -&gt; KeepDim -&gt; Bool
== :: KeepDim -&gt; KeepDim -&gt; Bool
$c== :: KeepDim -&gt; KeepDim -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880995"><span id="local-6989586621679880997"><span id="local-6989586621679880999"><span class="annot"><span class="annottext">Int -&gt; KeepDim -&gt; ShowS
[KeepDim] -&gt; ShowS
KeepDim -&gt; String
(Int -&gt; KeepDim -&gt; ShowS)
-&gt; (KeepDim -&gt; String) -&gt; ([KeepDim] -&gt; ShowS) -&gt; Show KeepDim
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [KeepDim] -&gt; ShowS
$cshowList :: [KeepDim] -&gt; ShowS
show :: KeepDim -&gt; String
$cshow :: KeepDim -&gt; String
showsPrec :: Int -&gt; KeepDim -&gt; ShowS
$cshowsPrec :: Int -&gt; KeepDim -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>
</span><span id="line-106"></span><span class="hs-keyword">data</span><span> </span><span id="CeilMode"><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-var">CeilMode</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="Ceil"><span class="annot"><a href="Torch.Functional.html#Ceil"><span class="hs-identifier hs-var">Ceil</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="Floor"><span class="annot"><a href="Torch.Functional.html#Floor"><span class="hs-identifier hs-var">Floor</span></a></span></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880989"><span id="local-6989586621679880991"><span class="annot"><span class="annottext">CeilMode -&gt; CeilMode -&gt; Bool
(CeilMode -&gt; CeilMode -&gt; Bool)
-&gt; (CeilMode -&gt; CeilMode -&gt; Bool) -&gt; Eq CeilMode
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: CeilMode -&gt; CeilMode -&gt; Bool
$c/= :: CeilMode -&gt; CeilMode -&gt; Bool
== :: CeilMode -&gt; CeilMode -&gt; Bool
$c== :: CeilMode -&gt; CeilMode -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880983"><span id="local-6989586621679880985"><span id="local-6989586621679880987"><span class="annot"><span class="annottext">Int -&gt; CeilMode -&gt; ShowS
[CeilMode] -&gt; ShowS
CeilMode -&gt; String
(Int -&gt; CeilMode -&gt; ShowS)
-&gt; (CeilMode -&gt; String) -&gt; ([CeilMode] -&gt; ShowS) -&gt; Show CeilMode
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [CeilMode] -&gt; ShowS
$cshowList :: [CeilMode] -&gt; ShowS
show :: CeilMode -&gt; String
$cshow :: CeilMode -&gt; String
showsPrec :: Int -&gt; CeilMode -&gt; ShowS
$cshowsPrec :: Int -&gt; CeilMode -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>
</span><span id="line-108"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-type">CeilMode</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">CBool</span></span><span> </span><span class="hs-keyword">where</span><span> </span><span class="hs-comment">-- Word8 == CBool</span><span>
</span><span id="line-109"></span><span>  </span><span id="local-6989586621679880979"><span class="annot"><span class="annottext">cast :: CeilMode -&gt; (CBool -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="annot"><a href="Torch.Functional.html#Ceil"><span class="hs-identifier hs-type">Ceil</span></a></span><span> </span><span id="local-6989586621679880977"><span class="annot"><span class="annottext">f :: CBool -&gt; IO r
</span><a href="#local-6989586621679880977"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">CBool -&gt; IO r
</span><a href="#local-6989586621679880977"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-110"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#Floor"><span class="hs-identifier hs-type">Floor</span></a></span><span> </span><span id="local-6989586621679880976"><span class="annot"><span class="annottext">f :: CBool -&gt; IO r
</span><a href="#local-6989586621679880976"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">CBool -&gt; IO r
</span><a href="#local-6989586621679880976"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span>
</span><span id="line-111"></span><span>  </span><span id="local-6989586621679880975"><span class="annot"><span class="annottext">uncast :: CBool -&gt; (CeilMode -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span class="hs-number">0</span><span> </span><span id="local-6989586621679880973"><span class="annot"><span class="annottext">f :: CeilMode -&gt; IO r
</span><a href="#local-6989586621679880973"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">CeilMode -&gt; IO r
</span><a href="#local-6989586621679880973"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">CeilMode
</span><a href="Torch.Functional.html#Floor"><span class="hs-identifier hs-var">Floor</span></a></span><span>
</span><span id="line-112"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="hs-number">1</span><span> </span><span id="local-6989586621679880972"><span class="annot"><span class="annottext">f :: CeilMode -&gt; IO r
</span><a href="#local-6989586621679880972"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">CeilMode -&gt; IO r
</span><a href="#local-6989586621679880972"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">CeilMode
</span><a href="Torch.Functional.html#Ceil"><span class="hs-identifier hs-var">Ceil</span></a></span><span>
</span><span id="line-113"></span><span>
</span><span id="line-114"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int64</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-115"></span><span>  </span><span id="local-6989586621679880969"><span class="annot"><span class="annottext">cast :: Reduction -&gt; (Int64 -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679880969"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="annot"><a href="Torch.Functional.html#ReduceNone"><span class="hs-identifier hs-type">ReduceNone</span></a></span><span> </span><span id="local-6989586621679880968"><span class="annot"><span class="annottext">f :: Int64 -&gt; IO r
</span><a href="#local-6989586621679880968"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int64 -&gt; IO r
</span><a href="#local-6989586621679880968"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span>
</span><span id="line-116"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#ReduceMean"><span class="hs-identifier hs-type">ReduceMean</span></a></span><span> </span><span id="local-6989586621679880967"><span class="annot"><span class="annottext">f :: Int64 -&gt; IO r
</span><a href="#local-6989586621679880967"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int64 -&gt; IO r
</span><a href="#local-6989586621679880967"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-117"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#ReduceSum"><span class="hs-identifier hs-type">ReduceSum</span></a></span><span> </span><span id="local-6989586621679880966"><span class="annot"><span class="annottext">f :: Int64 -&gt; IO r
</span><a href="#local-6989586621679880966"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int64 -&gt; IO r
</span><a href="#local-6989586621679880966"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span>
</span><span id="line-118"></span><span>  </span><span id="local-6989586621679880965"><span class="annot"><span class="annottext">uncast :: Int64 -&gt; (Reduction -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679880965"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span class="hs-number">0</span><span> </span><span id="local-6989586621679880964"><span class="annot"><span class="annottext">f :: Reduction -&gt; IO r
</span><a href="#local-6989586621679880964"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Reduction -&gt; IO r
</span><a href="#local-6989586621679880964"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="Torch.Functional.html#ReduceNone"><span class="hs-identifier hs-var">ReduceNone</span></a></span><span>
</span><span id="line-119"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="hs-number">1</span><span> </span><span id="local-6989586621679880963"><span class="annot"><span class="annottext">f :: Reduction -&gt; IO r
</span><a href="#local-6989586621679880963"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Reduction -&gt; IO r
</span><a href="#local-6989586621679880963"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="Torch.Functional.html#ReduceMean"><span class="hs-identifier hs-var">ReduceMean</span></a></span><span>
</span><span id="line-120"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="hs-identifier">_</span><span> </span><span id="local-6989586621679880962"><span class="annot"><span class="annottext">f :: Reduction -&gt; IO r
</span><a href="#local-6989586621679880962"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Reduction -&gt; IO r
</span><a href="#local-6989586621679880962"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="Torch.Functional.html#ReduceSum"><span class="hs-identifier hs-var">ReduceSum</span></a></span><span>
</span><span id="line-121"></span><span>
</span><span id="line-122"></span><span class="hs-keyword">data</span><span> </span><span id="Diag"><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-var">Diag</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="Diag"><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-var">Diag</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-123"></span><span>
</span><span id="line-124"></span><span id="isUpper"><span class="annot"><span class="annottext">isUpper :: Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var hs-var">isUpper</span></a></span></span><span> </span><span class="annot"><a href="Torch.Functional.html#Upper"><span class="hs-identifier hs-type">Upper</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-125"></span><span class="annot"><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#Lower"><span class="hs-identifier hs-type">Lower</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-126"></span><span>
</span><span id="line-127"></span><span class="hs-comment">-- | Returns the mean value of all elements in the input tensor.</span><span>
</span><span id="line-128"></span><span class="annot"><a href="Torch.Functional.html#mean"><span class="hs-identifier hs-type">mean</span></a></span><span>
</span><span id="line-129"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-130"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-131"></span><span id="mean"><span class="annot"><span class="annottext">mean :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mean"><span class="hs-identifier hs-var hs-var">mean</span></a></span></span><span> </span><span id="local-6989586621679880958"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880958"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mean_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880958"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-132"></span><span>
</span><span id="line-133"></span><span>
</span><span id="line-134"></span><span class="hs-comment">-- | Returns the standard deviation of all elements in the input tensor.</span><span>
</span><span id="line-135"></span><span class="annot"><a href="Torch.Functional.html#std"><span class="hs-identifier hs-type">std</span></a></span><span>
</span><span id="line-136"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-137"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-138"></span><span id="std"><span class="annot"><span class="annottext">std :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#std"><span class="hs-identifier hs-var hs-var">std</span></a></span></span><span> </span><span id="local-6989586621679880955"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880955"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.std_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880955"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-139"></span><span>
</span><span id="line-140"></span><span class="hs-comment">-- | Returns the variance of all elements in the input tensor.</span><span>
</span><span id="line-141"></span><span class="annot"><a href="Torch.Functional.html#var"><span class="hs-identifier hs-type">var</span></a></span><span>
</span><span id="line-142"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-143"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-144"></span><span id="var"><span class="annot"><span class="annottext">var :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#var"><span class="hs-identifier hs-var hs-var">var</span></a></span></span><span> </span><span id="local-6989586621679880952"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880952"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.var_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880952"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-145"></span><span>
</span><span id="line-146"></span><span class="hs-comment">-- | Returns the sum of all elements in the input tensor.</span><span>
</span><span id="line-147"></span><span class="annot"><a href="Torch.Functional.html#sumAll"><span class="hs-identifier hs-type">sumAll</span></a></span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-150"></span><span id="sumAll"><span class="annot"><span class="annottext">sumAll :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sumAll"><span class="hs-identifier hs-var hs-var">sumAll</span></a></span></span><span> </span><span id="local-6989586621679880949"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880949"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sum_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880949"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-151"></span><span>
</span><span id="line-152"></span><span class="hs-comment">-- | Computes the element-wise absolute value of the given input tensor.</span><span>
</span><span id="line-153"></span><span class="annot"><a href="Torch.Functional.html#abs"><span class="hs-identifier hs-type">abs</span></a></span><span>
</span><span id="line-154"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-155"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-156"></span><span id="abs"><span class="annot"><span class="annottext">abs :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#abs"><span class="hs-identifier hs-var hs-var">abs</span></a></span></span><span> </span><span id="local-6989586621679880946"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880946"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.abs_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880946"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-157"></span><span>
</span><span id="line-158"></span><span class="hs-comment">-- | Computes the fractional portion of each element in input.</span><span>
</span><span id="line-159"></span><span class="hs-comment">-- out_i = input_i - (floor . abs) input_i * (sign input_i)</span><span>
</span><span id="line-160"></span><span class="annot"><a href="Torch.Functional.html#frac"><span class="hs-identifier hs-type">frac</span></a></span><span>
</span><span id="line-161"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-162"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-163"></span><span id="frac"><span class="annot"><span class="annottext">frac :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#frac"><span class="hs-identifier hs-var hs-var">frac</span></a></span></span><span> </span><span id="local-6989586621679880944"><span class="annot"><span class="annottext">_self :: Tensor
</span><a href="#local-6989586621679880944"><span class="hs-identifier hs-var">_self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.frac_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880944"><span class="hs-identifier hs-var">_self</span></a></span><span>
</span><span id="line-164"></span><span>
</span><span id="line-165"></span><span id="keepdim"><span class="annot"><span class="annottext">keepdim :: KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var hs-var">keepdim</span></a></span></span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-166"></span><span class="annot"><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#RemoveDim"><span class="hs-identifier hs-type">RemoveDim</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-167"></span><span>
</span><span id="line-168"></span><span class="hs-comment">-- | Returns the indices of the maximum value of all elements in the input tensor.</span><span>
</span><span id="line-169"></span><span class="annot"><a href="Torch.Functional.html#argmax"><span class="hs-identifier hs-type">argmax</span></a></span><span>
</span><span id="line-170"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ the dimension to reduce</span><span>
</span><span id="line-171"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-comment">-- ^ whether the output tensor has dim retained or not</span><span>
</span><span id="line-172"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-173"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-174"></span><span id="argmax"><span class="annot"><span class="annottext">argmax :: Dim -&gt; KeepDim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#argmax"><span class="hs-identifier hs-var hs-var">argmax</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880940"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880940"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880939"><span class="annot"><span class="annottext">k :: KeepDim
</span><a href="#local-6989586621679880939"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span id="local-6989586621679880938"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880938"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.argmax_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880938"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880940"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><span class="annottext">KeepDim
</span><a href="#local-6989586621679880939"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-175"></span><span>
</span><span id="line-176"></span><span class="hs-comment">-- | Each element of the tensor other added to each element of the tensor input. The resulting tensor is returned.</span><span>
</span><span id="line-177"></span><span class="annot"><a href="Torch.Functional.html#add"><span class="hs-identifier hs-type">add</span></a></span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-179"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-180"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-181"></span><span id="add"><span class="annot"><span class="annottext">add :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#add"><span class="hs-identifier hs-var hs-var">add</span></a></span></span><span> </span><span id="local-6989586621679880935"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880935"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880934"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880934"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; ForeignPtr Scalar -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_tts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880935"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880934"><span class="hs-identifier hs-var">b</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Scalar
</span><a href="Torch.Functional.html#kOne"><span class="hs-identifier hs-var">kOne</span></a></span><span>
</span><span id="line-182"></span><span>
</span><span id="line-183"></span><span class="hs-comment">-- | Multiplies each element of the tensor other to each element of the input tensor and returns a new resulting tensor.</span><span>
</span><span id="line-184"></span><span class="annot"><a href="Torch.Functional.html#mul"><span class="hs-identifier hs-type">mul</span></a></span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-186"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-188"></span><span id="mul"><span class="annot"><span class="annottext">mul :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mul"><span class="hs-identifier hs-var hs-var">mul</span></a></span></span><span> </span><span id="local-6989586621679880932"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880932"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880931"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880931"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880932"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880931"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-189"></span><span>
</span><span id="line-190"></span><span class="hs-comment">-- | Element wise subtraction of other tensor from input tensor and returns a new resulting tensor</span><span>
</span><span id="line-191"></span><span class="annot"><a href="Torch.Functional.html#sub"><span class="hs-identifier hs-type">sub</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-193"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-194"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-195"></span><span id="sub"><span class="annot"><span class="annottext">sub :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sub"><span class="hs-identifier hs-var hs-var">sub</span></a></span></span><span> </span><span id="local-6989586621679880929"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880929"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880928"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880928"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; ForeignPtr Scalar -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_tts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880929"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880928"><span class="hs-identifier hs-var">b</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Scalar
</span><a href="Torch.Functional.html#kOne"><span class="hs-identifier hs-var">kOne</span></a></span><span>
</span><span id="line-196"></span><span>
</span><span id="line-197"></span><span class="hs-comment">-- | Element wise division of input tensor by other tensor and returns a new resulting tensor</span><span>
</span><span id="line-198"></span><span class="annot"><a href="Torch.Functional.html#div"><span class="hs-identifier hs-type">div</span></a></span><span>
</span><span id="line-199"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-200"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-201"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-202"></span><span id="div"><span class="annot"><span class="annottext">div :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#div"><span class="hs-identifier hs-var hs-var">div</span></a></span></span><span> </span><span id="local-6989586621679880925"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880925"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880924"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880924"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.div_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880925"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880924"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-203"></span><span>
</span><span id="line-204"></span><span class="hs-comment">-- | ceil</span><span>
</span><span id="line-205"></span><span class="annot"><a href="Torch.Functional.html#ceil"><span class="hs-identifier hs-type">ceil</span></a></span><span>
</span><span id="line-206"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-207"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-208"></span><span id="ceil"><span class="annot"><span class="annottext">ceil :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#ceil"><span class="hs-identifier hs-var hs-var">ceil</span></a></span></span><span> </span><span id="local-6989586621679880922"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880922"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.ceil_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880922"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-209"></span><span>
</span><span id="line-210"></span><span class="hs-comment">-- | floor</span><span>
</span><span id="line-211"></span><span class="annot"><a href="Torch.Functional.html#floor"><span class="hs-identifier hs-type">floor</span></a></span><span>
</span><span id="line-212"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-213"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-214"></span><span id="floor"><span class="annot"><span class="annottext">floor :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#floor"><span class="hs-identifier hs-var hs-var">floor</span></a></span></span><span> </span><span id="local-6989586621679880919"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880919"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.floor_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880919"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-215"></span><span>
</span><span id="line-216"></span><span class="hs-comment">-- | min</span><span>
</span><span id="line-217"></span><span class="annot"><a href="Torch.Functional.html#min"><span class="hs-identifier hs-type">min</span></a></span><span>
</span><span id="line-218"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-219"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-220"></span><span id="min"><span class="annot"><span class="annottext">min :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#min"><span class="hs-identifier hs-var hs-var">min</span></a></span></span><span> </span><span id="local-6989586621679880916"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880916"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.min_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880916"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-221"></span><span>
</span><span id="line-222"></span><span class="hs-comment">-- | max</span><span>
</span><span id="line-223"></span><span class="annot"><a href="Torch.Functional.html#max"><span class="hs-identifier hs-type">max</span></a></span><span>
</span><span id="line-224"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-225"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-226"></span><span id="max"><span class="annot"><span class="annottext">max :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#max"><span class="hs-identifier hs-var hs-var">max</span></a></span></span><span> </span><span id="local-6989586621679880913"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880913"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.max_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880913"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-227"></span><span>
</span><span id="line-228"></span><span class="hs-comment">-- | median</span><span>
</span><span id="line-229"></span><span class="annot"><a href="Torch.Functional.html#median"><span class="hs-identifier hs-type">median</span></a></span><span>
</span><span id="line-230"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-231"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-232"></span><span id="median"><span class="annot"><span class="annottext">median :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#median"><span class="hs-identifier hs-var hs-var">median</span></a></span></span><span> </span><span id="local-6989586621679880910"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880910"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.median_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880910"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-233"></span><span>
</span><span id="line-234"></span><span class="hs-comment">-- | Adds each element of the input input with the scalar and returns a new resulting tensor.</span><span>
</span><span id="line-235"></span><span id="local-6989586621679880908"><span class="annot"><a href="Torch.Functional.html#addScalar"><span class="hs-identifier hs-type">addScalar</span></a></span><span>
</span><span id="line-236"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679880908"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-237"></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679880908"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-comment">-- ^ summand</span><span>
</span><span id="line-238"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-239"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span></span><span>
</span><span id="line-240"></span><span id="addScalar"><span class="annot"><span class="annottext">addScalar :: a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#addScalar"><span class="hs-identifier hs-var hs-var">addScalar</span></a></span></span><span> </span><span id="local-6989586621679880905"><span class="annot"><span class="annottext">a :: a
</span><a href="#local-6989586621679880905"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880904"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880904"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; a -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880904"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679880905"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-241"></span><span>
</span><span id="line-242"></span><span class="hs-comment">-- | Subtracts each element of the input input with the scalar and returns a new resulting tensor.</span><span>
</span><span id="line-243"></span><span id="local-6989586621679880902"><span class="annot"><a href="Torch.Functional.html#subScalar"><span class="hs-identifier hs-type">subScalar</span></a></span><span>
</span><span id="line-244"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679880902"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-245"></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679880902"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-comment">-- ^ subtrahend</span><span>
</span><span id="line-246"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-247"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span></span><span>
</span><span id="line-248"></span><span id="subScalar"><span class="annot"><span class="annottext">subScalar :: a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#subScalar"><span class="hs-identifier hs-var hs-var">subScalar</span></a></span></span><span> </span><span id="local-6989586621679880900"><span class="annot"><span class="annottext">a :: a
</span><a href="#local-6989586621679880900"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880899"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880899"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; a -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880899"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679880900"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-249"></span><span>
</span><span id="line-250"></span><span class="hs-comment">-- | Multiplies each element of the input input with the scalar and returns a new resulting tensor.</span><span>
</span><span id="line-251"></span><span id="local-6989586621679880897"><span class="annot"><a href="Torch.Functional.html#mulScalar"><span class="hs-identifier hs-type">mulScalar</span></a></span><span>
</span><span id="line-252"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679880897"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-253"></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679880897"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-comment">-- ^ multiplier</span><span>
</span><span id="line-254"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-255"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span></span><span>
</span><span id="line-256"></span><span id="mulScalar"><span class="annot"><span class="annottext">mulScalar :: a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mulScalar"><span class="hs-identifier hs-var hs-var">mulScalar</span></a></span></span><span> </span><span id="local-6989586621679880895"><span class="annot"><span class="annottext">a :: a
</span><a href="#local-6989586621679880895"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880894"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880894"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; a -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880894"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679880895"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-257"></span><span>
</span><span id="line-258"></span><span class="hs-comment">-- | Divides each element of the input input with the scalar and returns a new resulting tensor.</span><span>
</span><span id="line-259"></span><span id="local-6989586621679880892"><span class="annot"><a href="Torch.Functional.html#divScalar"><span class="hs-identifier hs-type">divScalar</span></a></span><span>
</span><span id="line-260"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679880892"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-261"></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679880892"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-comment">-- ^ divisor</span><span>
</span><span id="line-262"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-263"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span></span><span>
</span><span id="line-264"></span><span id="divScalar"><span class="annot"><span class="annottext">divScalar :: a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#divScalar"><span class="hs-identifier hs-var hs-var">divScalar</span></a></span></span><span> </span><span id="local-6989586621679880890"><span class="annot"><span class="annottext">a :: a
</span><a href="#local-6989586621679880890"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880889"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880889"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; a -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.div_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880889"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679880890"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-265"></span><span>
</span><span id="line-266"></span><span class="hs-comment">-- |  Matrix product of two tensors.</span><span>
</span><span id="line-267"></span><span class="hs-comment">--</span><span>
</span><span id="line-268"></span><span class="hs-comment">-- The behavior depends on the dimensionality of the tensors as follows:</span><span>
</span><span id="line-269"></span><span class="hs-comment">--</span><span>
</span><span id="line-270"></span><span class="hs-comment">-- If both tensors are 1-dimensional, the dot product (scalar) is returned.</span><span>
</span><span id="line-271"></span><span class="hs-comment">-- If both arguments are 2-dimensional, the matrix-matrix product is returned.</span><span>
</span><span id="line-272"></span><span class="hs-comment">-- If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.</span><span>
</span><span id="line-273"></span><span class="hs-comment">-- If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.</span><span>
</span><span id="line-274"></span><span class="hs-comment">-- If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N &gt; 2), then a batched matrix multiply is returned. If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after. If the second argument is 1-dimensional, a 1 is appended to its dimension for the purpose of the batched matrix multiple and removed after. The non-matrix (i.e. batch) dimensions are broadcasted (and thus must be broadcastable). For example, if input is a (j \times 1 \times n \times m)(j&#215;1&#215;n&#215;m) tensor and other is a (k \times m \times p)(k&#215;m&#215;p) tensor, out will be an (j \times k \times n \times p)(j&#215;k&#215;n&#215;p) tensor.</span><span>
</span><span id="line-275"></span><span class="annot"><a href="Torch.Functional.html#matmul"><span class="hs-identifier hs-type">matmul</span></a></span><span>
</span><span id="line-276"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ first tensor for matrix multiplication</span><span>
</span><span id="line-277"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ second tensor for matrix multiplication</span><span>
</span><span id="line-278"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-279"></span><span id="matmul"><span class="annot"><span class="annottext">matmul :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#matmul"><span class="hs-identifier hs-var hs-var">matmul</span></a></span></span><span> </span><span id="local-6989586621679880886"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880886"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880885"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880885"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.matmul_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880886"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880885"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-280"></span><span>
</span><span id="line-281"></span><span class="hs-comment">-- | A simple lookup table that looks up embeddings in a fixed dictionary and size.</span><span>
</span><span id="line-282"></span><span class="hs-comment">-- This module is often used to retrieve word embeddings using indices. The input to the module is a list of indices, and the embedding matrix, and the output is the corresponding word embeddings.</span><span>
</span><span id="line-283"></span><span class="annot"><a href="Torch.Functional.html#embedding"><span class="hs-identifier hs-type">embedding</span></a></span><span>
</span><span id="line-284"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ whether or not to scale the gradient by the frequencies</span><span>
</span><span id="line-285"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ whether or not the embedding is sparse</span><span>
</span><span id="line-286"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weights</span><span>
</span><span id="line-287"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-288"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ indices</span><span>
</span><span id="line-289"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-290"></span><span id="embedding"><span class="annot"><span class="annottext">embedding :: Bool -&gt; Bool -&gt; Tensor -&gt; Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#embedding"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span id="local-6989586621679880882"><span class="annot"><span class="annottext">scaleByGradFreq :: Bool
</span><a href="#local-6989586621679880882"><span class="hs-identifier hs-var">scaleByGradFreq</span></a></span></span><span> </span><span id="local-6989586621679880881"><span class="annot"><span class="annottext">sparse :: Bool
</span><a href="#local-6989586621679880881"><span class="hs-identifier hs-var">sparse</span></a></span></span><span> </span><span id="local-6989586621679880880"><span class="annot"><span class="annottext">weights :: Tensor
</span><a href="#local-6989586621679880880"><span class="hs-identifier hs-var">weights</span></a></span></span><span> </span><span id="local-6989586621679880879"><span class="annot"><span class="annottext">paddingIdx :: Int
</span><a href="#local-6989586621679880879"><span class="hs-identifier hs-var">paddingIdx</span></a></span></span><span> </span><span id="local-6989586621679880878"><span class="annot"><span class="annottext">indices :: Tensor
</span><a href="#local-6989586621679880878"><span class="hs-identifier hs-var">indices</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-291"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Int -&gt; Bool -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.embedding_ttlbb</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880880"><span class="hs-identifier hs-var">weights</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880878"><span class="hs-identifier hs-var">indices</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880879"><span class="hs-identifier hs-var">paddingIdx</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880882"><span class="hs-identifier hs-var">scaleByGradFreq</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880881"><span class="hs-identifier hs-var">sparse</span></a></span><span>
</span><span id="line-293"></span><span>
</span><span id="line-294"></span><span class="annot"><a href="Torch.Functional.html#embedding%27"><span class="hs-identifier hs-type">embedding'</span></a></span><span>
</span><span id="line-295"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weights</span><span>
</span><span id="line-296"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ indices</span><span>
</span><span id="line-297"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-298"></span><span id="embedding%27"><span class="annot"><span class="annottext">embedding' :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#embedding%27"><span class="hs-identifier hs-var hs-var">embedding'</span></a></span></span><span> </span><span id="local-6989586621679880874"><span class="annot"><span class="annottext">weights :: Tensor
</span><a href="#local-6989586621679880874"><span class="hs-identifier hs-var">weights</span></a></span></span><span> </span><span id="local-6989586621679880873"><span class="annot"><span class="annottext">indices :: Tensor
</span><a href="#local-6989586621679880873"><span class="hs-identifier hs-var">indices</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-299"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Int -&gt; Bool -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.embedding_ttlbb</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880874"><span class="hs-identifier hs-var">weights</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880873"><span class="hs-identifier hs-var">indices</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-301"></span><span>
</span><span id="line-302"></span><span class="hs-comment">-- | A one hot encoding of the given input. The encoding is based on the given number of</span><span>
</span><span id="line-303"></span><span class="hs-comment">-- classes.</span><span>
</span><span id="line-304"></span><span class="annot"><a href="Torch.Functional.html#oneHot"><span class="hs-identifier hs-type">oneHot</span></a></span><span>
</span><span id="line-305"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ number of classes</span><span>
</span><span id="line-306"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-307"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ </span><span>
</span><span id="line-308"></span><span id="oneHot"><span class="annot"><span class="annottext">oneHot :: Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#oneHot"><span class="hs-identifier hs-var hs-var">oneHot</span></a></span></span><span> </span><span id="local-6989586621679880871"><span class="annot"><span class="annottext">numClasses :: Int
</span><a href="#local-6989586621679880871"><span class="hs-identifier hs-var">numClasses</span></a></span></span><span> </span><span id="local-6989586621679880870"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880870"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.one_hot_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880870"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880871"><span class="hs-identifier hs-var">numClasses</span></a></span><span>
</span><span id="line-309"></span><span>
</span><span id="line-310"></span><span class="hs-comment">--</span><span>
</span><span id="line-311"></span><span class="hs-comment">-- element-wise transformations / non-linearities</span><span>
</span><span id="line-312"></span><span class="hs-comment">--</span><span>
</span><span id="line-313"></span><span>
</span><span id="line-314"></span><span class="hs-comment">-- | Computes the error function of each element</span><span>
</span><span id="line-315"></span><span class="annot"><a href="Torch.Functional.html#erf"><span class="hs-identifier hs-type">erf</span></a></span><span>
</span><span id="line-316"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-317"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-318"></span><span id="erf"><span class="annot"><span class="annottext">erf :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#erf"><span class="hs-identifier hs-var hs-var">erf</span></a></span></span><span> </span><span id="local-6989586621679880867"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880867"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erf_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880867"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-319"></span><span>
</span><span id="line-320"></span><span class="hs-comment">-- | Computes the complementary error function of each element of input</span><span>
</span><span id="line-321"></span><span class="annot"><a href="Torch.Functional.html#erfc"><span class="hs-identifier hs-type">erfc</span></a></span><span>
</span><span id="line-322"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-323"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-324"></span><span id="erfc"><span class="annot"><span class="annottext">erfc :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#erfc"><span class="hs-identifier hs-var hs-var">erfc</span></a></span></span><span> </span><span id="local-6989586621679880864"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880864"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erfc_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880864"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-325"></span><span>
</span><span id="line-326"></span><span class="hs-comment">-- | Computes the inverse error function of each element of input. The inverse error function is defined in the range (-1, 1)(&#8722;1,1) as: erfinv(erf(x)) = x</span><span>
</span><span id="line-327"></span><span class="annot"><a href="Torch.Functional.html#erfinv"><span class="hs-identifier hs-type">erfinv</span></a></span><span>
</span><span id="line-328"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-329"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-330"></span><span id="erfinv"><span class="annot"><span class="annottext">erfinv :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#erfinv"><span class="hs-identifier hs-var hs-var">erfinv</span></a></span></span><span> </span><span id="local-6989586621679880861"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880861"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erfinv_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880861"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-331"></span><span>
</span><span id="line-332"></span><span class="hs-comment">-- | Computes the logarithm of the gamma function on input.</span><span>
</span><span id="line-333"></span><span class="annot"><a href="Torch.Functional.html#lgamma"><span class="hs-identifier hs-type">lgamma</span></a></span><span>
</span><span id="line-334"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-335"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-336"></span><span id="lgamma"><span class="annot"><span class="annottext">lgamma :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#lgamma"><span class="hs-identifier hs-var hs-var">lgamma</span></a></span></span><span> </span><span id="local-6989586621679880858"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880858"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lgamma_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880858"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-337"></span><span>
</span><span id="line-338"></span><span class="hs-comment">-- | Computes the logarithmic derivative of the gamma function on input.</span><span>
</span><span id="line-339"></span><span class="annot"><a href="Torch.Functional.html#digamma"><span class="hs-identifier hs-type">digamma</span></a></span><span>
</span><span id="line-340"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-341"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-342"></span><span id="digamma"><span class="annot"><span class="annottext">digamma :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#digamma"><span class="hs-identifier hs-var hs-var">digamma</span></a></span></span><span> </span><span id="local-6989586621679880855"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880855"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.digamma_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880855"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-343"></span><span>
</span><span id="line-344"></span><span class="hs-comment">-- | Computes the nth derivative of the digamma function on input. n \geq 0n&#8805;0 is called the order of the polygamma function.</span><span>
</span><span id="line-345"></span><span class="annot"><a href="Torch.Functional.html#polygamma"><span class="hs-identifier hs-type">polygamma</span></a></span><span>
</span><span id="line-346"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ n</span><span>
</span><span id="line-347"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-348"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-349"></span><span id="polygamma"><span class="annot"><span class="annottext">polygamma :: Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#polygamma"><span class="hs-identifier hs-var hs-var">polygamma</span></a></span></span><span> </span><span id="local-6989586621679880852"><span class="annot"><span class="annottext">n :: Int
</span><a href="#local-6989586621679880852"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679880851"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880851"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Int -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.polygamma_lt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880852"><span class="hs-identifier hs-var">n</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880851"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-350"></span><span>
</span><span id="line-351"></span><span class="hs-comment">-- | Computes the multivariate log-gamma function with dimension pp element-wise. All elements must be greater than (p-1)/2, otherwise an error would be thrown.</span><span>
</span><span id="line-352"></span><span class="annot"><a href="Torch.Functional.html#mvlgamma"><span class="hs-identifier hs-type">mvlgamma</span></a></span><span>
</span><span id="line-353"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ p</span><span>
</span><span id="line-354"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-355"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-356"></span><span id="mvlgamma"><span class="annot"><span class="annottext">mvlgamma :: Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mvlgamma"><span class="hs-identifier hs-var hs-var">mvlgamma</span></a></span></span><span> </span><span id="local-6989586621679880848"><span class="annot"><span class="annottext">p :: Int
</span><a href="#local-6989586621679880848"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679880847"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880847"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mvlgamma_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880847"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880848"><span class="hs-identifier hs-var">p</span></a></span><span>
</span><span id="line-357"></span><span>
</span><span id="line-358"></span><span class="hs-comment">-- | Returns a new tensor with the exponential of the elements of the input tensor input.</span><span>
</span><span id="line-359"></span><span class="annot"><a href="Torch.Functional.html#exp"><span class="hs-identifier hs-type">exp</span></a></span><span>
</span><span id="line-360"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-361"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-362"></span><span id="exp"><span class="annot"><span class="annottext">exp :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#exp"><span class="hs-identifier hs-var hs-var">exp</span></a></span></span><span> </span><span id="local-6989586621679880844"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880844"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.exp_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880844"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-363"></span><span>
</span><span id="line-364"></span><span class="hs-comment">-- | Returns a new tensor with the natural logarithm of (1 + input).</span><span>
</span><span id="line-365"></span><span class="annot"><a href="Torch.Functional.html#log1p"><span class="hs-identifier hs-type">log1p</span></a></span><span>
</span><span id="line-366"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-367"></span><span id="log1p"><span class="annot"><span class="annottext">log1p :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#log1p"><span class="hs-identifier hs-var hs-var">log1p</span></a></span></span><span> </span><span id="local-6989586621679880841"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880841"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log1p_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880841"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-368"></span><span>
</span><span id="line-369"></span><span class="hs-comment">-- | Returns a new tensor with the logarithm to the base 2 of the elements of input.</span><span>
</span><span id="line-370"></span><span class="annot"><a href="Torch.Functional.html#log2"><span class="hs-identifier hs-type">log2</span></a></span><span>
</span><span id="line-371"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-372"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-373"></span><span id="log2"><span class="annot"><span class="annottext">log2 :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#log2"><span class="hs-identifier hs-var hs-var">log2</span></a></span></span><span> </span><span id="local-6989586621679880838"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880838"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log2_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880838"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-374"></span><span>
</span><span id="line-375"></span><span class="hs-comment">-- | Returns a new tensor with the natural logarithm of the elements of input.</span><span>
</span><span id="line-376"></span><span class="annot"><a href="Torch.Functional.html#log"><span class="hs-identifier hs-type">log</span></a></span><span>
</span><span id="line-377"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-378"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-379"></span><span id="log"><span class="annot"><span class="annottext">log :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#log"><span class="hs-identifier hs-var hs-var">log</span></a></span></span><span> </span><span id="local-6989586621679880835"><span class="annot"><span class="annottext">_self :: Tensor
</span><a href="#local-6989586621679880835"><span class="hs-identifier hs-var">_self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880835"><span class="hs-identifier hs-var">_self</span></a></span><span>
</span><span id="line-380"></span><span>
</span><span id="line-381"></span><span class="hs-comment">-- | Returns a new tensor with the logarithm to the base 10 of the elements of input.</span><span>
</span><span id="line-382"></span><span class="annot"><a href="Torch.Functional.html#log10"><span class="hs-identifier hs-type">log10</span></a></span><span>
</span><span id="line-383"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-384"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-385"></span><span id="log10"><span class="annot"><span class="annottext">log10 :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#log10"><span class="hs-identifier hs-var hs-var">log10</span></a></span></span><span> </span><span id="local-6989586621679880832"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880832"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log10_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880832"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-386"></span><span>
</span><span id="line-387"></span><span class="hs-comment">-- | Takes the power of each element in input with exponent and returns a tensor with the result.</span><span>
</span><span id="line-388"></span><span id="local-6989586621679880830"><span class="annot"><a href="Torch.Functional.html#pow"><span class="hs-identifier hs-type">pow</span></a></span><span>
</span><span id="line-389"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679880830"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-390"></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679880830"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-comment">-- ^ exponent</span><span>
</span><span id="line-391"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-392"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span></span><span>
</span><span id="line-393"></span><span id="pow"><span class="annot"><span class="annottext">pow :: a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#pow"><span class="hs-identifier hs-var hs-var">pow</span></a></span></span><span> </span><span id="local-6989586621679880828"><span class="annot"><span class="annottext">s :: a
</span><a href="#local-6989586621679880828"><span class="hs-identifier hs-var">s</span></a></span></span><span> </span><span id="local-6989586621679880827"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880827"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; a -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880827"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679880828"><span class="hs-identifier hs-var">s</span></a></span><span>
</span><span id="line-394"></span><span>
</span><span id="line-395"></span><span class="hs-comment">-- | Takes the power of each element in input with exponent and returns a tensor with the result.</span><span>
</span><span id="line-396"></span><span class="hs-comment">-- Exponent is a tensor with the same number of elements as input.</span><span>
</span><span id="line-397"></span><span class="annot"><a href="Torch.Functional.html#powt"><span class="hs-identifier hs-type">powt</span></a></span><span>
</span><span id="line-398"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-399"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ exponent</span><span>
</span><span id="line-400"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-401"></span><span id="powt"><span class="annot"><span class="annottext">powt :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#powt"><span class="hs-identifier hs-var hs-var">powt</span></a></span></span><span> </span><span id="local-6989586621679880824"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880824"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span id="local-6989586621679880823"><span class="annot"><span class="annottext">t' :: Tensor
</span><a href="#local-6989586621679880823"><span class="hs-identifier hs-var">t'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880824"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880823"><span class="hs-identifier hs-var">t'</span></a></span><span>
</span><span id="line-402"></span><span>
</span><span id="line-403"></span><span class="hs-comment">-- | Applies the rectified linear unit function element-wise.</span><span>
</span><span id="line-404"></span><span class="annot"><a href="Torch.Functional.html#relu"><span class="hs-identifier hs-type">relu</span></a></span><span>
</span><span id="line-405"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-406"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-407"></span><span id="relu"><span class="annot"><span class="annottext">relu :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#relu"><span class="hs-identifier hs-var hs-var">relu</span></a></span></span><span> </span><span id="local-6989586621679880820"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880820"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.relu_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880820"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-408"></span><span>
</span><span id="line-409"></span><span class="hs-comment">-- | Applies Exponential linear unit function element-wise, with alpha input, \(\text{ELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x) - 1))\)</span><span>
</span><span id="line-410"></span><span id="local-6989586621679880818"><span class="annot"><a href="Torch.Functional.html#elu"><span class="hs-identifier hs-type">elu</span></a></span><span>
</span><span id="line-411"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679880818"><span class="hs-identifier hs-type">s</span></a></span><span>
</span><span id="line-412"></span><span>    </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679880818"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="hs-comment">-- ^ alpha value for ELU formulation</span><span>
</span><span id="line-413"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-414"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span></span><span>
</span><span id="line-415"></span><span id="elu"><span class="annot"><span class="annottext">elu :: s -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#elu"><span class="hs-identifier hs-var hs-var">elu</span></a></span></span><span> </span><span id="local-6989586621679880816"><span class="annot"><span class="annottext">a :: s
</span><a href="#local-6989586621679880816"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880815"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880815"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; s -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.elu_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880815"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679880816"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-416"></span><span>
</span><span id="line-417"></span><span class="hs-comment">-- | Applies exponential linear unit function element wise with default alpha value = 1</span><span>
</span><span id="line-418"></span><span class="annot"><a href="Torch.Functional.html#elu%27"><span class="hs-identifier hs-type">elu'</span></a></span><span>
</span><span id="line-419"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-420"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-421"></span><span id="elu%27"><span class="annot"><span class="annottext">elu' :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#elu%27"><span class="hs-identifier hs-var hs-var">elu'</span></a></span></span><span> </span><span id="local-6989586621679880812"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880812"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.elu_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880812"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-422"></span><span>
</span><span id="line-423"></span><span class="hs-comment">-- | Applies element-wise, \(\text{SELU}(x) = scale * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1))\) , with &#945;=1.6732632423543772848170429916717 and scale=1.0507009873554804934193349852946.</span><span>
</span><span id="line-424"></span><span class="annot"><a href="Torch.Functional.html#selu"><span class="hs-identifier hs-type">selu</span></a></span><span>
</span><span id="line-425"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-426"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-427"></span><span id="selu"><span class="annot"><span class="annottext">selu :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#selu"><span class="hs-identifier hs-var hs-var">selu</span></a></span></span><span> </span><span id="local-6989586621679880809"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880809"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.selu_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880809"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-428"></span><span>
</span><span id="line-429"></span><span class="hs-comment">-- | Applies element-wise, \(\text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))\).</span><span>
</span><span id="line-430"></span><span class="annot"><a href="Torch.Functional.html#celu"><span class="hs-identifier hs-type">celu</span></a></span><span>
</span><span id="line-431"></span><span>   </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ alpha</span><span>
</span><span id="line-432"></span><span>   </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-433"></span><span>   </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-434"></span><span id="celu"><span class="annot"><span class="annottext">celu :: Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#celu"><span class="hs-identifier hs-var hs-var">celu</span></a></span></span><span> </span><span id="local-6989586621679880806"><span class="annot"><span class="annottext">_alpha :: Float
</span><a href="#local-6989586621679880806"><span class="hs-identifier hs-var">_alpha</span></a></span></span><span> </span><span id="local-6989586621679880805"><span class="annot"><span class="annottext">_self :: Tensor
</span><a href="#local-6989586621679880805"><span class="hs-identifier hs-var">_self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.celu_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880805"><span class="hs-identifier hs-var">_self</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880806"><span class="hs-identifier hs-var">_alpha</span></a></span><span>
</span><span id="line-435"></span><span>
</span><span id="line-436"></span><span class="hs-comment">-- | Applies the element-wise function sigmoid.</span><span>
</span><span id="line-437"></span><span class="annot"><a href="Torch.Functional.html#sigmoid"><span class="hs-identifier hs-type">sigmoid</span></a></span><span>
</span><span id="line-438"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-439"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-440"></span><span id="sigmoid"><span class="annot"><span class="annottext">sigmoid :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sigmoid"><span class="hs-identifier hs-var hs-var">sigmoid</span></a></span></span><span> </span><span id="local-6989586621679880802"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880802"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sigmoid_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880802"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-441"></span><span>
</span><span id="line-442"></span><span class="hs-comment">-- | Applies a softmax function.</span><span>
</span><span id="line-443"></span><span class="hs-comment">-- It is applied to all slices along dim, and will re-scale them so that the elements lie in the range [0, 1] and sum to 1.</span><span>
</span><span id="line-444"></span><span class="annot"><a href="Torch.Functional.html#softmax"><span class="hs-identifier hs-type">softmax</span></a></span><span>
</span><span id="line-445"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-446"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-447"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-448"></span><span id="softmax"><span class="annot"><span class="annottext">softmax :: Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#softmax"><span class="hs-identifier hs-var hs-var">softmax</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880799"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880799"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880798"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880798"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; DType -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.softmax_tls</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-449"></span><span>    </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880798"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880799"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor -&gt; DType
</span><a href="Torch.Tensor.html#dtype"><span class="hs-identifier hs-var">dtype</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880798"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-450"></span><span>
</span><span id="line-451"></span><span class="hs-comment">-- | Applies a softmax followed by a logarithm.</span><span>
</span><span id="line-452"></span><span class="hs-comment">-- While mathematically equivalent to log(softmax(x)), doing these two operations separately is slower, and numerically unstable. This function uses an alternative formulation to compute the output and gradient correctly.</span><span>
</span><span id="line-453"></span><span class="annot"><a href="Torch.Functional.html#logSoftmax"><span class="hs-identifier hs-type">logSoftmax</span></a></span><span>
</span><span id="line-454"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-455"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-456"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-457"></span><span id="logSoftmax"><span class="annot"><span class="annottext">logSoftmax :: Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#logSoftmax"><span class="hs-identifier hs-var hs-var">logSoftmax</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880794"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880794"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880793"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880793"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; DType -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log_softmax_tls</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-458"></span><span>    </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880793"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880794"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor -&gt; DType
</span><a href="Torch.Tensor.html#dtype"><span class="hs-identifier hs-var">dtype</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880793"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-459"></span><span>
</span><span id="line-460"></span><span class="hs-comment">-- | Thresholds each element of the input Tensor.</span><span>
</span><span id="line-461"></span><span class="annot"><a href="Torch.Functional.html#threshold"><span class="hs-identifier hs-type">threshold</span></a></span><span>
</span><span id="line-462"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ threshold</span><span>
</span><span id="line-463"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ value</span><span>
</span><span id="line-464"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-465"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-466"></span><span id="threshold"><span class="annot"><span class="annottext">threshold :: Float -&gt; Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#threshold"><span class="hs-identifier hs-var hs-var">threshold</span></a></span></span><span> </span><span id="local-6989586621679880790"><span class="annot"><span class="annottext">threshold :: Float
</span><a href="#local-6989586621679880790"><span class="hs-identifier hs-var">threshold</span></a></span></span><span> </span><span id="local-6989586621679880789"><span class="annot"><span class="annottext">value :: Float
</span><a href="#local-6989586621679880789"><span class="hs-identifier hs-var">value</span></a></span></span><span> </span><span id="local-6989586621679880788"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880788"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-467"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Float -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.threshold_tss</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880788"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880790"><span class="hs-identifier hs-var">threshold</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880789"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-468"></span><span>
</span><span id="line-469"></span><span class="hs-comment">-- | Returns a new tensor with the sine of the elements of input.</span><span>
</span><span id="line-470"></span><span class="annot"><a href="Torch.Functional.html#sin"><span class="hs-identifier hs-type">sin</span></a></span><span>
</span><span id="line-471"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-472"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-473"></span><span id="sin"><span class="annot"><span class="annottext">sin :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sin"><span class="hs-identifier hs-var hs-var">sin</span></a></span></span><span> </span><span id="local-6989586621679880785"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880785"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sin_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880785"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-474"></span><span>
</span><span id="line-475"></span><span>
</span><span id="line-476"></span><span class="hs-comment">-- | Returns a new tensor with the cos of the elements of input.</span><span>
</span><span id="line-477"></span><span class="annot"><a href="Torch.Functional.html#cos"><span class="hs-identifier hs-type">cos</span></a></span><span>
</span><span id="line-478"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-479"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-480"></span><span id="cos"><span class="annot"><span class="annottext">cos :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#cos"><span class="hs-identifier hs-var hs-var">cos</span></a></span></span><span> </span><span id="local-6989586621679880782"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880782"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cos_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880782"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-481"></span><span>
</span><span id="line-482"></span><span class="hs-comment">-- | Returns a new tensor with the tangent of the elements of input.</span><span>
</span><span id="line-483"></span><span class="annot"><a href="Torch.Functional.html#tan"><span class="hs-identifier hs-type">tan</span></a></span><span>
</span><span id="line-484"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-485"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-486"></span><span id="tan"><span class="annot"><span class="annottext">tan :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#tan"><span class="hs-identifier hs-var hs-var">tan</span></a></span></span><span> </span><span id="local-6989586621679880779"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880779"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tan_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880779"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-487"></span><span>
</span><span id="line-488"></span><span class="hs-comment">-- | Returns a new tensor with the hyperbolic sine of the elements of input.</span><span>
</span><span id="line-489"></span><span class="annot"><a href="Torch.Functional.html#sinh"><span class="hs-identifier hs-type">sinh</span></a></span><span>
</span><span id="line-490"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-491"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-492"></span><span id="sinh"><span class="annot"><span class="annottext">sinh :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sinh"><span class="hs-identifier hs-var hs-var">sinh</span></a></span></span><span> </span><span id="local-6989586621679880776"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880776"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sinh_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880776"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-493"></span><span>
</span><span id="line-494"></span><span class="hs-comment">-- | Returns a new tensor with the hyperbolic cosine of the elements of input.</span><span>
</span><span id="line-495"></span><span class="annot"><a href="Torch.Functional.html#cosh"><span class="hs-identifier hs-type">cosh</span></a></span><span>
</span><span id="line-496"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-497"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-498"></span><span id="cosh"><span class="annot"><span class="annottext">cosh :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#cosh"><span class="hs-identifier hs-var hs-var">cosh</span></a></span></span><span> </span><span id="local-6989586621679880773"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880773"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cosh_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880773"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-499"></span><span>
</span><span id="line-500"></span><span class="hs-comment">-- | Returns a new tensor with the hyperbolic tangent of the elements of input.</span><span>
</span><span id="line-501"></span><span class="annot"><a href="Torch.Functional.html#tanh"><span class="hs-identifier hs-type">tanh</span></a></span><span>
</span><span id="line-502"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-503"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-504"></span><span id="tanh"><span class="annot"><span class="annottext">tanh :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#tanh"><span class="hs-identifier hs-var hs-var">tanh</span></a></span></span><span> </span><span id="local-6989586621679880770"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880770"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tanh_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880770"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-505"></span><span>
</span><span id="line-506"></span><span class="hs-comment">-- | Returns a new tensor with the square-root of the elements of input.</span><span>
</span><span id="line-507"></span><span class="annot"><a href="Torch.Functional.html#sqrt"><span class="hs-identifier hs-type">sqrt</span></a></span><span>
</span><span id="line-508"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-509"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-510"></span><span id="sqrt"><span class="annot"><span class="annottext">sqrt :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sqrt"><span class="hs-identifier hs-var hs-var">sqrt</span></a></span></span><span> </span><span id="local-6989586621679880767"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880767"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sqrt_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880767"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-511"></span><span>
</span><span id="line-512"></span><span class="hs-comment">--</span><span>
</span><span id="line-513"></span><span class="hs-comment">-- infix operators</span><span>
</span><span id="line-514"></span><span class="hs-comment">--</span><span>
</span><span id="line-515"></span><span>
</span><span id="line-516"></span><span class="hs-comment">-- | Computes input &gt; other element-wise.</span><span>
</span><span id="line-517"></span><span class="hs-comment">-- The second argument can be a number or a tensor whose shape is broadcastable with the first argument.</span><span>
</span><span id="line-518"></span><span class="annot"><a href="Torch.Functional.html#gt"><span class="hs-identifier hs-type">gt</span></a></span><span>
</span><span id="line-519"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-520"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-521"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-522"></span><span id="gt"><span class="annot"><span class="annottext">gt :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#gt"><span class="hs-identifier hs-var hs-var">gt</span></a></span></span><span> </span><span id="local-6989586621679880764"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880764"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880763"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880763"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.gt_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880764"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880763"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-523"></span><span>
</span><span id="line-524"></span><span id="%3E."><span class="annot"><span class="annottext">&gt;. :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#%3E."><span class="hs-operator hs-var hs-var">(&gt;.)</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#gt"><span class="hs-identifier hs-var">gt</span></a></span><span>
</span><span id="line-525"></span><span>
</span><span id="line-526"></span><span class="hs-comment">-- | Computes input &lt; other element-wise.</span><span>
</span><span id="line-527"></span><span class="hs-comment">-- The second argument can be a number or a tensor whose shape is broadcastable with the first argument.</span><span>
</span><span id="line-528"></span><span class="annot"><a href="Torch.Functional.html#lt"><span class="hs-identifier hs-type">lt</span></a></span><span>
</span><span id="line-529"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-530"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-531"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-532"></span><span id="lt"><span class="annot"><span class="annottext">lt :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#lt"><span class="hs-identifier hs-var hs-var">lt</span></a></span></span><span> </span><span id="local-6989586621679880759"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880759"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880758"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880758"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lt_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880759"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880758"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-533"></span><span>
</span><span id="line-534"></span><span id="%3C."><span class="annot"><span class="annottext">&lt;. :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#%3C."><span class="hs-operator hs-var hs-var">(&lt;.)</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#lt"><span class="hs-identifier hs-var">lt</span></a></span><span>
</span><span id="line-535"></span><span>
</span><span id="line-536"></span><span class="hs-comment">-- | Computes input &gt;= other element-wise.</span><span>
</span><span id="line-537"></span><span class="hs-comment">-- The second argument can be a number or a tensor whose shape is broadcastable with the first argument.</span><span>
</span><span id="line-538"></span><span class="annot"><a href="Torch.Functional.html#ge"><span class="hs-identifier hs-type">ge</span></a></span><span>
</span><span id="line-539"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-540"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-541"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-542"></span><span id="ge"><span class="annot"><span class="annottext">ge :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#ge"><span class="hs-identifier hs-var hs-var">ge</span></a></span></span><span> </span><span id="local-6989586621679880754"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880754"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880753"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880753"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.ge_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880754"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880753"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-543"></span><span>
</span><span id="line-544"></span><span id="%3E%3D."><span class="annot"><span class="annottext">&gt;=. :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#%3E%3D."><span class="hs-operator hs-var hs-var">(&gt;=.)</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#ge"><span class="hs-identifier hs-var">ge</span></a></span><span>
</span><span id="line-545"></span><span>
</span><span id="line-546"></span><span class="hs-comment">-- | Computes input &lt;= other element-wise.</span><span>
</span><span id="line-547"></span><span class="hs-comment">-- The second argument can be a number or a tensor whose shape is broadcastable with the first argument.</span><span>
</span><span id="line-548"></span><span class="annot"><a href="Torch.Functional.html#le"><span class="hs-identifier hs-type">le</span></a></span><span>
</span><span id="line-549"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-550"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-551"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-552"></span><span id="le"><span class="annot"><span class="annottext">le :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#le"><span class="hs-identifier hs-var hs-var">le</span></a></span></span><span> </span><span id="local-6989586621679880749"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880749"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880748"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880748"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.le_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880749"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880748"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-553"></span><span>
</span><span id="line-554"></span><span id="%3C%3D."><span class="annot"><span class="annottext">&lt;=. :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#%3C%3D."><span class="hs-operator hs-var hs-var">(&lt;=.)</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#le"><span class="hs-identifier hs-var">le</span></a></span><span>
</span><span id="line-555"></span><span>
</span><span id="line-556"></span><span class="hs-comment">-- | Computes input == other element-wise.</span><span>
</span><span id="line-557"></span><span class="hs-comment">-- The second argument can be a number or a tensor whose shape is broadcastable with the first argument.</span><span>
</span><span id="line-558"></span><span class="annot"><a href="Torch.Functional.html#eq"><span class="hs-identifier hs-type">eq</span></a></span><span>
</span><span id="line-559"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-560"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-561"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-562"></span><span id="eq"><span class="annot"><span class="annottext">eq :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#eq"><span class="hs-identifier hs-var hs-var">eq</span></a></span></span><span> </span><span id="local-6989586621679880745"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880745"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880744"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880744"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.eq_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880745"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880744"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-563"></span><span>
</span><span id="line-564"></span><span id="%3D%3D."><span class="annot"><span class="annottext">==. :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#%3D%3D."><span class="hs-operator hs-var hs-var">(==.)</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#eq"><span class="hs-identifier hs-var">eq</span></a></span><span>
</span><span id="line-565"></span><span>
</span><span id="line-566"></span><span class="annot"><a href="Torch.Functional.html#isclose"><span class="hs-identifier hs-type">isclose</span></a></span><span>
</span><span id="line-567"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ rtol</span><span>
</span><span id="line-568"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ atol</span><span>
</span><span id="line-569"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ equal_nan</span><span>
</span><span id="line-570"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-571"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-572"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-573"></span><span id="isclose"><span class="annot"><span class="annottext">isclose :: Double -&gt; Double -&gt; Bool -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#isclose"><span class="hs-identifier hs-var hs-var">isclose</span></a></span></span><span> </span><span id="local-6989586621679880740"><span class="annot"><span class="annottext">rtol :: Double
</span><a href="#local-6989586621679880740"><span class="hs-identifier hs-var">rtol</span></a></span></span><span> </span><span id="local-6989586621679880739"><span class="annot"><span class="annottext">atol :: Double
</span><a href="#local-6989586621679880739"><span class="hs-identifier hs-var">atol</span></a></span></span><span> </span><span id="local-6989586621679880738"><span class="annot"><span class="annottext">equalNan :: Bool
</span><a href="#local-6989586621679880738"><span class="hs-identifier hs-var">equalNan</span></a></span></span><span> </span><span id="local-6989586621679880737"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880737"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679880736"><span class="annot"><span class="annottext">other :: Tensor
</span><a href="#local-6989586621679880736"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Double -&gt; Double -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; CDouble
-&gt; CDouble
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.isclose_ttddb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880737"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880736"><span class="hs-identifier hs-var">other</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880740"><span class="hs-identifier hs-var">rtol</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880739"><span class="hs-identifier hs-var">atol</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880738"><span class="hs-identifier hs-var">equalNan</span></a></span><span>
</span><span id="line-574"></span><span>
</span><span id="line-575"></span><span class="annot"><a href="Torch.Functional.html#isnan"><span class="hs-identifier hs-type">isnan</span></a></span><span>
</span><span id="line-576"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-577"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- a new tensor with boolean elements representing if each element is NaN or not.</span><span>
</span><span id="line-578"></span><span id="isnan"><span class="annot"><span class="annottext">isnan :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#isnan"><span class="hs-identifier hs-var hs-var">isnan</span></a></span></span><span> </span><span id="local-6989586621679880733"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880733"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.isnan_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880733"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-579"></span><span>
</span><span id="line-580"></span><span class="annot"><a href="Torch.Functional.html#isNonzero"><span class="hs-identifier hs-type">isNonzero</span></a></span><span>
</span><span id="line-581"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-582"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-583"></span><span id="isNonzero"><span class="annot"><span class="annottext">isNonzero :: Tensor -&gt; Bool
</span><a href="Torch.Functional.html#isNonzero"><span class="hs-identifier hs-var hs-var">isNonzero</span></a></span></span><span> </span><span id="local-6989586621679880730"><span class="annot"><span class="annottext">_self :: Tensor
</span><a href="#local-6989586621679880730"><span class="hs-identifier hs-var">_self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool) -&gt; Tensor -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.is_nonzero_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880730"><span class="hs-identifier hs-var">_self</span></a></span><span>
</span><span id="line-584"></span><span>
</span><span id="line-585"></span><span class="annot"><a href="Torch.Functional.html#isSameSize"><span class="hs-identifier hs-type">isSameSize</span></a></span><span>
</span><span id="line-586"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-587"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-588"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-589"></span><span id="isSameSize"><span class="annot"><span class="annottext">isSameSize :: Tensor -&gt; Tensor -&gt; Bool
</span><a href="Torch.Functional.html#isSameSize"><span class="hs-identifier hs-var hs-var">isSameSize</span></a></span></span><span> </span><span id="local-6989586621679880727"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880727"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679880726"><span class="annot"><span class="annottext">other :: Tensor
</span><a href="#local-6989586621679880726"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor -&gt; Tensor -&gt; IO Bool
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.is_same_size_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880727"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880726"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-590"></span><span>
</span><span id="line-591"></span><span class="annot"><a href="Torch.Functional.html#isSigned"><span class="hs-identifier hs-type">isSigned</span></a></span><span>
</span><span id="line-592"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-593"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ True if the data type of input is a signed type</span><span>
</span><span id="line-594"></span><span id="isSigned"><span class="annot"><span class="annottext">isSigned :: Tensor -&gt; Bool
</span><a href="Torch.Functional.html#isSigned"><span class="hs-identifier hs-var hs-var">isSigned</span></a></span></span><span> </span><span id="local-6989586621679880723"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880723"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool) -&gt; Tensor -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.is_signed_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880723"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-595"></span><span>
</span><span id="line-596"></span><span class="hs-comment">-- | Computes input /= other element-wise.</span><span>
</span><span id="line-597"></span><span class="hs-comment">-- The second argument can be a number or a tensor whose shape is broadcastable with the first argument.</span><span>
</span><span id="line-598"></span><span class="annot"><a href="Torch.Functional.html#ne"><span class="hs-identifier hs-type">ne</span></a></span><span>
</span><span id="line-599"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-600"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-601"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-602"></span><span id="ne"><span class="annot"><span class="annottext">ne :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#ne"><span class="hs-identifier hs-var hs-var">ne</span></a></span></span><span> </span><span id="local-6989586621679880720"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880720"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679880719"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880719"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.ne_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880720"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880719"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-603"></span><span>
</span><span id="line-604"></span><span id="%2F%3D."><span class="annot"><span class="annottext">/=. :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#%2F%3D."><span class="hs-operator hs-var hs-var">(/=.)</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#ne"><span class="hs-identifier hs-var">ne</span></a></span><span>
</span><span id="line-605"></span><span>
</span><span id="line-606"></span><span class="hs-comment">-- | Casting to given 'Dtype', where 'Dtype' is an object that represents the data type of a tensor in hasktorch.</span><span>
</span><span id="line-607"></span><span class="annot"><a href="Torch.Functional.html#toDType"><span class="hs-identifier hs-type">toDType</span></a></span><span>
</span><span id="line-608"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span> </span><span class="hs-comment">-- ^ data type to cast to</span><span>
</span><span id="line-609"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-610"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-611"></span><span id="toDType"><span class="annot"><span class="annottext">toDType :: DType -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#toDType"><span class="hs-identifier hs-var hs-var">toDType</span></a></span></span><span> </span><span id="local-6989586621679880715"><span class="annot"><span class="annottext">dtype :: DType
</span><a href="#local-6989586621679880715"><span class="hs-identifier hs-var">dtype</span></a></span></span><span> </span><span id="local-6989586621679880714"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880714"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ScalarType -&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; DType -&gt; Bool -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ScalarType -&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_sbb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880714"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679880715"><span class="hs-identifier hs-var">dtype</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-612"></span><span>
</span><span id="line-613"></span><span class="hs-comment">-- | squeezeAll</span><span>
</span><span id="line-614"></span><span class="annot"><a href="Torch.Functional.html#squeezeAll"><span class="hs-identifier hs-type">squeezeAll</span></a></span><span>
</span><span id="line-615"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-616"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-617"></span><span id="squeezeAll"><span class="annot"><span class="annottext">squeezeAll :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#squeezeAll"><span class="hs-identifier hs-var hs-var">squeezeAll</span></a></span></span><span> </span><span id="local-6989586621679880710"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880710"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.squeeze_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880710"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-618"></span><span>
</span><span id="line-619"></span><span class="hs-comment">-- | squeezeDim</span><span>
</span><span id="line-620"></span><span class="annot"><a href="Torch.Functional.html#squeezeDim"><span class="hs-identifier hs-type">squeezeDim</span></a></span><span>
</span><span id="line-621"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-622"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-623"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-624"></span><span id="squeezeDim"><span class="annot"><span class="annottext">squeezeDim :: Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#squeezeDim"><span class="hs-identifier hs-var hs-var">squeezeDim</span></a></span></span><span> </span><span id="local-6989586621679880707"><span class="annot"><span class="annottext">dim :: Int
</span><a href="#local-6989586621679880707"><span class="hs-identifier hs-var">dim</span></a></span></span><span> </span><span id="local-6989586621679880706"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880706"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.squeeze_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880706"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880707"><span class="hs-identifier hs-var">dim</span></a></span><span>
</span><span id="line-625"></span><span>
</span><span id="line-626"></span><span class="hs-comment">--</span><span>
</span><span id="line-627"></span><span class="hs-comment">-- Loss Functions</span><span>
</span><span id="line-628"></span><span class="hs-comment">--</span><span>
</span><span id="line-629"></span><span>
</span><span id="line-630"></span><span class="hs-comment">-- | Function that measures the Binary Cross Entropy between the target and the output.</span><span>
</span><span id="line-631"></span><span class="annot"><a href="Torch.Functional.html#binaryCrossEntropyLoss"><span class="hs-identifier hs-type">binaryCrossEntropyLoss</span></a></span><span>
</span><span id="line-632"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ Specifies the reduction to apply to the output</span><span>
</span><span id="line-633"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-634"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weight</span><span>
</span><span id="line-635"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-636"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-637"></span><span id="binaryCrossEntropyLoss"><span class="annot"><span class="annottext">binaryCrossEntropyLoss :: Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#binaryCrossEntropyLoss"><span class="hs-identifier hs-var hs-var">binaryCrossEntropyLoss</span></a></span></span><span> </span><span id="local-6989586621679880703"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880703"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880702"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880702"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880701"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880701"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679880700"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880700"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.binary_cross_entropy_tttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880700"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880702"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880701"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880703"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-638"></span><span>
</span><span id="line-639"></span><span class="hs-comment">-- | Binary Cross Entropy with weights defaulted to 1.0 &amp; reduction defaulted to ReduceMean</span><span>
</span><span id="line-640"></span><span class="annot"><a href="Torch.Functional.html#binaryCrossEntropyLoss%27"><span class="hs-identifier hs-type">binaryCrossEntropyLoss'</span></a></span><span>
</span><span id="line-641"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-642"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-643"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-644"></span><span id="binaryCrossEntropyLoss%27"><span class="annot"><span class="annottext">binaryCrossEntropyLoss' :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#binaryCrossEntropyLoss%27"><span class="hs-identifier hs-var hs-var">binaryCrossEntropyLoss'</span></a></span></span><span> </span><span id="local-6989586621679880697"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880697"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880696"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880696"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.binary_cross_entropy_tttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880696"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880697"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.TensorFactories.html#onesLike"><span class="hs-identifier hs-var">onesLike</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880697"><span class="hs-identifier hs-var">target</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="Torch.Functional.html#ReduceMean"><span class="hs-identifier hs-var">ReduceMean</span></a></span><span>
</span><span id="line-645"></span><span>
</span><span id="line-646"></span><span class="hs-comment">-- | This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability.</span><span>
</span><span id="line-647"></span><span class="annot"><a href="Torch.Functional.html#binaryCrossEntropyWithLogits"><span class="hs-identifier hs-type">binaryCrossEntropyWithLogits</span></a></span><span>
</span><span id="line-648"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ Specifies the reduction to apply to the output</span><span>
</span><span id="line-649"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-650"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weight</span><span>
</span><span id="line-651"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ pos_weight</span><span>
</span><span id="line-652"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-653"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-654"></span><span id="binaryCrossEntropyWithLogits"><span class="annot"><span class="annottext">binaryCrossEntropyWithLogits :: Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#binaryCrossEntropyWithLogits"><span class="hs-identifier hs-var hs-var">binaryCrossEntropyWithLogits</span></a></span></span><span> </span><span id="local-6989586621679880694"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880694"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880693"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880693"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880692"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880692"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679880691"><span class="annot"><span class="annottext">pos_weight :: Tensor
</span><a href="#local-6989586621679880691"><span class="hs-identifier hs-var">pos_weight</span></a></span></span><span> </span><span id="local-6989586621679880690"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880690"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.binary_cross_entropy_with_logits_ttttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880690"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880693"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880692"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880691"><span class="hs-identifier hs-var">pos_weight</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880694"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-655"></span><span>
</span><span id="line-656"></span><span class="hs-comment">-- | Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the @input@ and @target@.</span><span>
</span><span id="line-657"></span><span class="annot"><a href="Torch.Functional.html#mseLoss"><span class="hs-identifier hs-type">mseLoss</span></a></span><span>
</span><span id="line-658"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target tensor</span><span>
</span><span id="line-659"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-660"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-661"></span><span id="mseLoss"><span class="annot"><span class="annottext">mseLoss :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mseLoss"><span class="hs-identifier hs-var hs-var">mseLoss</span></a></span></span><span> </span><span id="local-6989586621679880687"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880687"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880686"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880686"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Int64 -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mse_loss_ttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880686"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880687"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.kMean</span></a></span><span>
</span><span id="line-662"></span><span>
</span><span id="line-663"></span><span class="hs-comment">-- | The negative log likelihood loss.</span><span>
</span><span id="line-664"></span><span class="annot"><a href="Torch.Functional.html#nllLoss%27"><span class="hs-identifier hs-type">nllLoss'</span></a></span><span>
</span><span id="line-665"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target tensor</span><span>
</span><span id="line-666"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-667"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-668"></span><span id="nllLoss%27"><span class="annot"><span class="annottext">nllLoss' :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#nllLoss%27"><span class="hs-identifier hs-var hs-var">nllLoss'</span></a></span></span><span> </span><span id="local-6989586621679880682"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880682"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880681"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880681"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.nll_loss_tttll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880681"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880682"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880679"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="Torch.Functional.html#ReduceMean"><span class="hs-identifier hs-var">ReduceMean</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="annot"><span class="hs-number">100</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-669"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-670"></span><span>        </span><span id="local-6989586621679880678"><span class="annot"><span class="annottext">nClass :: Int
</span><a href="#local-6989586621679880678"><span class="hs-identifier hs-var hs-var">nClass</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor -&gt; [Int]
</span><a href="Torch.Tensor.html#shape"><span class="hs-identifier hs-var">shape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880681"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int -&gt; Int
forall a. [a] -&gt; Int -&gt; a
</span><span class="hs-operator hs-var">!!</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-comment">-- TODO nicer runtime error if input dimensions don't conform</span><span>
</span><span id="line-671"></span><span>        </span><span id="local-6989586621679880679"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880679"><span class="hs-identifier hs-var hs-var">weight</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Device -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Tensor.html#toDevice"><span class="hs-identifier hs-var">toDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor -&gt; Device
</span><a href="Torch.Tensor.html#device"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880682"><span class="hs-identifier hs-var">target</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor -&gt; Tensor) -&gt; Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Tensor
</span><a href="Torch.TensorFactories.html#ones%27"><span class="hs-identifier hs-var">ones'</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880678"><span class="hs-identifier hs-var">nClass</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-672"></span><span>
</span><span id="line-673"></span><span class="hs-comment">-- | Returns cosine similarity between x1 and x2, computed along dim.</span><span>
</span><span id="line-674"></span><span class="annot"><a href="Torch.Functional.html#cosineSimilarity"><span class="hs-identifier hs-type">cosineSimilarity</span></a></span><span>
</span><span id="line-675"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension of vectors (default=1)</span><span>
</span><span id="line-676"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ small value to avoid division by 0 (default=1e-8)</span><span>
</span><span id="line-677"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ x1</span><span>
</span><span id="line-678"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ x2</span><span>
</span><span id="line-679"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-680"></span><span id="cosineSimilarity"><span class="annot"><span class="annottext">cosineSimilarity :: Dim -&gt; Double -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#cosineSimilarity"><span class="hs-identifier hs-var hs-var">cosineSimilarity</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880672"><span class="annot"><span class="annottext">dim :: Int
</span><a href="#local-6989586621679880672"><span class="hs-identifier hs-var">dim</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880671"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679880671"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span id="local-6989586621679880670"><span class="annot"><span class="annottext">x1 :: Tensor
</span><a href="#local-6989586621679880670"><span class="hs-identifier hs-var">x1</span></a></span></span><span> </span><span id="local-6989586621679880669"><span class="annot"><span class="annottext">x2 :: Tensor
</span><a href="#local-6989586621679880669"><span class="hs-identifier hs-var">x2</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-681"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; CDouble -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Int -&gt; Double -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; CDouble -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cosine_similarity_ttld</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880670"><span class="hs-identifier hs-var">x1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880669"><span class="hs-identifier hs-var">x2</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880672"><span class="hs-identifier hs-var">dim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880671"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-682"></span><span>
</span><span id="line-683"></span><span class="hs-comment">-- | Returns cosine similarity with defaulted options.</span><span>
</span><span id="line-684"></span><span class="annot"><a href="Torch.Functional.html#cosineSimilarity%27"><span class="hs-identifier hs-type">cosineSimilarity'</span></a></span><span>
</span><span id="line-685"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ x1</span><span>
</span><span id="line-686"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ x2</span><span>
</span><span id="line-687"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-688"></span><span id="cosineSimilarity%27"><span class="annot"><span class="annottext">cosineSimilarity' :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#cosineSimilarity%27"><span class="hs-identifier hs-var hs-var">cosineSimilarity'</span></a></span></span><span> </span><span id="local-6989586621679880666"><span class="annot"><span class="annottext">x1 :: Tensor
</span><a href="#local-6989586621679880666"><span class="hs-identifier hs-var">x1</span></a></span></span><span> </span><span id="local-6989586621679880665"><span class="annot"><span class="annottext">x2 :: Tensor
</span><a href="#local-6989586621679880665"><span class="hs-identifier hs-var">x2</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-689"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-690"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; CDouble -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Int -&gt; Double -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; CDouble -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cosine_similarity_ttld</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880666"><span class="hs-identifier hs-var">x1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880665"><span class="hs-identifier hs-var">x2</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1e-8</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-691"></span><span>
</span><span id="line-692"></span><span class="hs-comment">-- | The Connectionist Temporal Classification loss.</span><span>
</span><span id="line-693"></span><span class="hs-comment">-- Calculates loss between a continuous (unsegmented) time series and a target sequence.</span><span>
</span><span id="line-694"></span><span class="hs-comment">-- CTCLoss sums over the probability of possible alignments of input to target,</span><span>
</span><span id="line-695"></span><span class="hs-comment">-- producing a loss value which is differentiable with respect to each input node.</span><span>
</span><span id="line-696"></span><span class="hs-comment">-- The alignment of input to target is assumed to be &#8220;many-to-one&#8221;, which limits</span><span>
</span><span id="line-697"></span><span class="hs-comment">-- the length of the target sequence such that it must be \leq&#8804; the input length.</span><span>
</span><span id="line-698"></span><span class="annot"><a href="Torch.Functional.html#ctcLoss"><span class="hs-identifier hs-type">ctcLoss</span></a></span><span>
</span><span id="line-699"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ zero_infinity - Whether to zero infinite losses and the associated gradients (False by default). Infinite losses mainly occur when the inputs are too short to be aligned to the targets.</span><span>
</span><span id="line-700"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ blank label</span><span>
</span><span id="line-701"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-702"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ input_lengths</span><span>
</span><span id="line-703"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ target_lengths</span><span>
</span><span id="line-704"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ log_probs</span><span>
</span><span id="line-705"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ targets</span><span>
</span><span id="line-706"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-707"></span><span id="ctcLoss"><span class="annot"><span class="annottext">ctcLoss :: Bool
-&gt; Int -&gt; Reduction -&gt; [Int] -&gt; [Int] -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#ctcLoss"><span class="hs-identifier hs-var hs-var">ctcLoss</span></a></span></span><span> </span><span id="local-6989586621679880663"><span class="annot"><span class="annottext">zeroInfinity :: Bool
</span><a href="#local-6989586621679880663"><span class="hs-identifier hs-var">zeroInfinity</span></a></span></span><span> </span><span id="local-6989586621679880662"><span class="annot"><span class="annottext">blank :: Int
</span><a href="#local-6989586621679880662"><span class="hs-identifier hs-var">blank</span></a></span></span><span> </span><span id="local-6989586621679880661"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880661"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880660"><span class="annot"><span class="annottext">inputLengths :: [Int]
</span><a href="#local-6989586621679880660"><span class="hs-identifier hs-var">inputLengths</span></a></span></span><span> </span><span id="local-6989586621679880659"><span class="annot"><span class="annottext">targetLengths :: [Int]
</span><a href="#local-6989586621679880659"><span class="hs-identifier hs-var">targetLengths</span></a></span></span><span> </span><span id="local-6989586621679880658"><span class="annot"><span class="annottext">logProbs :: Tensor
</span><a href="#local-6989586621679880658"><span class="hs-identifier hs-var">logProbs</span></a></span></span><span> </span><span id="local-6989586621679880657"><span class="annot"><span class="annottext">targets :: Tensor
</span><a href="#local-6989586621679880657"><span class="hs-identifier hs-var">targets</span></a></span></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; Int64
 -&gt; Int64
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; [Int]
-&gt; [Int]
-&gt; Int
-&gt; Reduction
-&gt; Bool
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast7</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; Int64
-&gt; Int64
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.ctc_loss_ttllllb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880658"><span class="hs-identifier hs-var">logProbs</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880657"><span class="hs-identifier hs-var">targets</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679880660"><span class="hs-identifier hs-var">inputLengths</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679880659"><span class="hs-identifier hs-var">targetLengths</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880662"><span class="hs-identifier hs-var">blank</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880661"><span class="hs-identifier hs-var">reduction</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880663"><span class="hs-identifier hs-var">zeroInfinity</span></a></span><span>
</span><span id="line-708"></span><span>
</span><span id="line-709"></span><span class="hs-comment">-- | Returns CTC loss with defaulted options.</span><span>
</span><span id="line-710"></span><span class="annot"><a href="Torch.Functional.html#ctcLoss%27"><span class="hs-identifier hs-type">ctcLoss'</span></a></span><span>
</span><span id="line-711"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-712"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ input lengths</span><span>
</span><span id="line-713"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ target lengths</span><span>
</span><span id="line-714"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ log probs</span><span>
</span><span id="line-715"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ targets</span><span>
</span><span id="line-716"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-717"></span><span id="ctcLoss%27"><span class="annot"><span class="annottext">ctcLoss' :: Reduction -&gt; [Int] -&gt; [Int] -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#ctcLoss%27"><span class="hs-identifier hs-var hs-var">ctcLoss'</span></a></span></span><span> </span><span id="local-6989586621679880653"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880653"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880652"><span class="annot"><span class="annottext">inputLengths :: [Int]
</span><a href="#local-6989586621679880652"><span class="hs-identifier hs-var">inputLengths</span></a></span></span><span> </span><span id="local-6989586621679880651"><span class="annot"><span class="annottext">targetLengths :: [Int]
</span><a href="#local-6989586621679880651"><span class="hs-identifier hs-var">targetLengths</span></a></span></span><span> </span><span id="local-6989586621679880650"><span class="annot"><span class="annottext">logProbs :: Tensor
</span><a href="#local-6989586621679880650"><span class="hs-identifier hs-var">logProbs</span></a></span></span><span> </span><span id="local-6989586621679880649"><span class="annot"><span class="annottext">targets :: Tensor
</span><a href="#local-6989586621679880649"><span class="hs-identifier hs-var">targets</span></a></span></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; Int64
 -&gt; Int64
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; [Int]
-&gt; [Int]
-&gt; Int
-&gt; Reduction
-&gt; Bool
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast7</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; Int64
-&gt; Int64
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.ctc_loss_ttllllb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880650"><span class="hs-identifier hs-var">logProbs</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880649"><span class="hs-identifier hs-var">targets</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679880652"><span class="hs-identifier hs-var">inputLengths</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679880651"><span class="hs-identifier hs-var">targetLengths</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880648"><span class="hs-identifier hs-var">blank</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880653"><span class="hs-identifier hs-var">reduction</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880647"><span class="hs-identifier hs-var">zeroInfinity</span></a></span><span>
</span><span id="line-718"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-719"></span><span>        </span><span id="local-6989586621679880648"><span class="annot"><span class="annottext">blank :: Int
</span><a href="#local-6989586621679880648"><span class="hs-identifier hs-var hs-var">blank</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-720"></span><span>        </span><span id="local-6989586621679880647"><span class="annot"><span class="annottext">zeroInfinity :: Bool
</span><a href="#local-6989586621679880647"><span class="hs-identifier hs-var hs-var">zeroInfinity</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-721"></span><span>
</span><span id="line-722"></span><span class="hs-comment">-- | Measures the loss given an input tensor xx and a labels tensor yy (containing 1 or -1).</span><span>
</span><span id="line-723"></span><span class="hs-comment">-- This is usually used for measuring whether two inputs are similar or dissimilar,</span><span>
</span><span id="line-724"></span><span class="hs-comment">-- e.g. using the L1 pairwise distance as xx,</span><span>
</span><span id="line-725"></span><span class="hs-comment">-- and is typically used for learning nonlinear embeddings or semi-supervised learning.</span><span>
</span><span id="line-726"></span><span class="annot"><a href="Torch.Functional.html#hingeEmbeddingLoss"><span class="hs-identifier hs-type">hingeEmbeddingLoss</span></a></span><span>
</span><span id="line-727"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ margin</span><span>
</span><span id="line-728"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-729"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-730"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-731"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-732"></span><span id="hingeEmbeddingLoss"><span class="annot"><span class="annottext">hingeEmbeddingLoss :: Double -&gt; Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#hingeEmbeddingLoss"><span class="hs-identifier hs-var hs-var">hingeEmbeddingLoss</span></a></span></span><span> </span><span id="local-6989586621679880645"><span class="annot"><span class="annottext">margin :: Double
</span><a href="#local-6989586621679880645"><span class="hs-identifier hs-var">margin</span></a></span></span><span> </span><span id="local-6989586621679880644"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880644"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880643"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880643"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880642"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880642"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; CDouble -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Double -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; CDouble -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.hinge_embedding_loss_ttdl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880642"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880643"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880645"><span class="hs-identifier hs-var">margin</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880644"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-733"></span><span>
</span><span id="line-734"></span><span class="annot"><a href="Torch.Functional.html#marginRankingLoss"><span class="hs-identifier hs-type">marginRankingLoss</span></a></span><span>
</span><span id="line-735"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input1</span><span>
</span><span id="line-736"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input2</span><span>
</span><span id="line-737"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-738"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ margin</span><span>
</span><span id="line-739"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-740"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-741"></span><span id="marginRankingLoss"><span class="annot"><span class="annottext">marginRankingLoss :: Tensor -&gt; Tensor -&gt; Tensor -&gt; Double -&gt; Reduction -&gt; Tensor
</span><a href="Torch.Functional.html#marginRankingLoss"><span class="hs-identifier hs-var hs-var">marginRankingLoss</span></a></span></span><span> </span><span id="local-6989586621679880639"><span class="annot"><span class="annottext">input1 :: Tensor
</span><a href="#local-6989586621679880639"><span class="hs-identifier hs-var">input1</span></a></span></span><span> </span><span id="local-6989586621679880638"><span class="annot"><span class="annottext">input2 :: Tensor
</span><a href="#local-6989586621679880638"><span class="hs-identifier hs-var">input2</span></a></span></span><span> </span><span id="local-6989586621679880637"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880637"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880636"><span class="annot"><span class="annottext">margin :: Double
</span><a href="#local-6989586621679880636"><span class="hs-identifier hs-var">margin</span></a></span></span><span> </span><span id="local-6989586621679880635"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880635"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; CDouble
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Double -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; CDouble
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.margin_ranking_loss_tttdl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880639"><span class="hs-identifier hs-var">input1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880638"><span class="hs-identifier hs-var">input2</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880637"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880636"><span class="hs-identifier hs-var">margin</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880635"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-742"></span><span>
</span><span id="line-743"></span><span class="hs-comment">-- | The 2D negative log likelihood loss</span><span>
</span><span id="line-744"></span><span class="annot"><a href="Torch.Functional.html#nllLoss2D"><span class="hs-identifier hs-type">nllLoss2D</span></a></span><span>
</span><span id="line-745"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- reduction</span><span>
</span><span id="line-746"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ignore_index</span><span>
</span><span id="line-747"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- input</span><span>
</span><span id="line-748"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- target</span><span>
</span><span id="line-749"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- weight</span><span>
</span><span id="line-750"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- output</span><span>
</span><span id="line-751"></span><span id="nllLoss2D"><span class="annot"><span class="annottext">nllLoss2D :: Reduction -&gt; Int -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#nllLoss2D"><span class="hs-identifier hs-var hs-var">nllLoss2D</span></a></span></span><span> </span><span id="local-6989586621679880632"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880632"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880631"><span class="annot"><span class="annottext">ignoreindex :: Int
</span><a href="#local-6989586621679880631"><span class="hs-identifier hs-var">ignoreindex</span></a></span></span><span> </span><span id="local-6989586621679880630"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880630"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679880629"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880629"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880628"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880628"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.nll_loss2d_tttll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880630"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880629"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880628"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880632"><span class="hs-identifier hs-var">reduction</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880631"><span class="hs-identifier hs-var">ignoreindex</span></a></span><span>
</span><span id="line-752"></span><span>
</span><span id="line-753"></span><span class="hs-comment">-- | Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input \(x\) (a 2D mini-batch Tensor) and output \(y\) (which is a 1D tensor of target class indices)</span><span>
</span><span id="line-754"></span><span class="annot"><a href="Torch.Functional.html#multiMarginLoss"><span class="hs-identifier hs-type">multiMarginLoss</span></a></span><span>
</span><span id="line-755"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-756"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ p</span><span>
</span><span id="line-757"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ margin</span><span>
</span><span id="line-758"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-759"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-760"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weight</span><span>
</span><span id="line-761"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-762"></span><span id="multiMarginLoss"><span class="annot"><span class="annottext">multiMarginLoss :: Reduction -&gt; Float -&gt; Float -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#multiMarginLoss"><span class="hs-identifier hs-var hs-var">multiMarginLoss</span></a></span></span><span> </span><span id="local-6989586621679880625"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880625"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880624"><span class="annot"><span class="annottext">p :: Float
</span><a href="#local-6989586621679880624"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679880623"><span class="annot"><span class="annottext">margin :: Float
</span><a href="#local-6989586621679880623"><span class="hs-identifier hs-var">margin</span></a></span></span><span> </span><span id="local-6989586621679880622"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880622"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679880621"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880621"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span id="local-6989586621679880620"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880620"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Tensor
-&gt; Reduction
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.multi_margin_loss_ttsstl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880622"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880621"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880624"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880623"><span class="hs-identifier hs-var">margin</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880620"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880625"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-763"></span><span>
</span><span id="line-764"></span><span class="hs-comment">-- | Creates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input \(x\) and target \(y\) of size \((N,C)\) .</span><span>
</span><span id="line-765"></span><span class="annot"><a href="Torch.Functional.html#multiLabelMarginLoss"><span class="hs-identifier hs-type">multiLabelMarginLoss</span></a></span><span>
</span><span id="line-766"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- reduction</span><span>
</span><span id="line-767"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- input</span><span>
</span><span id="line-768"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- target</span><span>
</span><span id="line-769"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- output</span><span>
</span><span id="line-770"></span><span id="multiLabelMarginLoss"><span class="annot"><span class="annottext">multiLabelMarginLoss :: Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#multiLabelMarginLoss"><span class="hs-identifier hs-var hs-var">multiLabelMarginLoss</span></a></span></span><span> </span><span id="local-6989586621679880616"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880616"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880615"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880615"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679880614"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880614"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.multilabel_margin_loss_ttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880615"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880614"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880616"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-771"></span><span>
</span><span id="line-772"></span><span class="hs-comment">-- | The Kullback-Leibler divergence Loss</span><span>
</span><span id="line-773"></span><span class="hs-comment">-- KL divergence is a useful distance measure for continuous distributions and is often useful when performing direct regression over the space of (discretely sampled) continuous output distributions.</span><span>
</span><span id="line-774"></span><span class="hs-comment">-- As with NLLLoss, the input given is expected to contain log-probabilities and is not restricted to a 2D Tensor. The targets are interpreted as probabilities by default, but could be considered as log-probabilities with log_target set to True.</span><span>
</span><span id="line-775"></span><span class="hs-comment">-- This criterion expects a target Tensor of the same size as the input Tensor.</span><span>
</span><span id="line-776"></span><span class="annot"><a href="Torch.Functional.html#klDiv"><span class="hs-identifier hs-type">klDiv</span></a></span><span>
</span><span id="line-777"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span>
</span><span id="line-778"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-779"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-780"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-781"></span><span id="klDiv"><span class="annot"><span class="annottext">klDiv :: Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#klDiv"><span class="hs-identifier hs-var hs-var">klDiv</span></a></span></span><span> </span><span id="local-6989586621679880611"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880611"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880610"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880610"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679880609"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880609"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.kl_div_ttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880610"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880609"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880611"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-782"></span><span>
</span><span id="line-783"></span><span class="hs-comment">-- | Creates a criterion that uses a squared term if the absolute element-wise</span><span>
</span><span id="line-784"></span><span class="hs-comment">--  error falls below 1 and an L1 term otherwise. It is less sensitive to</span><span>
</span><span id="line-785"></span><span class="hs-comment">-- outliers than the MSELoss and in some cases prevents exploding gradients</span><span>
</span><span id="line-786"></span><span class="hs-comment">-- (e.g. see Fast R-CNN paper by Ross Girshick). Also known as the Huber loss.</span><span>
</span><span id="line-787"></span><span class="annot"><a href="Torch.Functional.html#smoothL1Loss"><span class="hs-identifier hs-type">smoothL1Loss</span></a></span><span>
</span><span id="line-788"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-789"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-790"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-791"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-792"></span><span id="smoothL1Loss"><span class="annot"><span class="annottext">smoothL1Loss :: Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#smoothL1Loss"><span class="hs-identifier hs-var hs-var">smoothL1Loss</span></a></span></span><span> </span><span id="local-6989586621679880606"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880606"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880605"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880605"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679880604"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880604"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.smooth_l1_loss_ttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880605"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880604"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880606"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-793"></span><span>
</span><span id="line-794"></span><span class="hs-comment">-- | Creates a criterion that optimizes a two-class classification logistic loss</span><span>
</span><span id="line-795"></span><span class="hs-comment">--  between input tensor \(x\) and target tensor \(y\) (containing 1 or -1).</span><span>
</span><span id="line-796"></span><span class="annot"><a href="Torch.Functional.html#softMarginLoss"><span class="hs-identifier hs-type">softMarginLoss</span></a></span><span>
</span><span id="line-797"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-798"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-799"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-800"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-801"></span><span id="softMarginLoss"><span class="annot"><span class="annottext">softMarginLoss :: Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#softMarginLoss"><span class="hs-identifier hs-var hs-var">softMarginLoss</span></a></span></span><span> </span><span id="local-6989586621679880601"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880601"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880600"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880600"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679880599"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880599"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.soft_margin_loss_ttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880600"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880599"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880601"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-802"></span><span>
</span><span id="line-803"></span><span class="hs-comment">--</span><span>
</span><span id="line-804"></span><span class="hs-comment">-- Pooling</span><span>
</span><span id="line-805"></span><span class="hs-comment">--</span><span>
</span><span id="line-806"></span><span>
</span><span id="line-807"></span><span class="hs-comment">-- | Applies a 1D adaptive max pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-808"></span><span class="annot"><a href="Torch.Functional.html#adaptiveMaxPool1d"><span class="hs-identifier hs-type">adaptiveMaxPool1d</span></a></span><span>
</span><span id="line-809"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ output size</span><span>
</span><span id="line-810"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-811"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-812"></span><span id="adaptiveMaxPool1d"><span class="annot"><span class="annottext">adaptiveMaxPool1d :: Int -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#adaptiveMaxPool1d"><span class="hs-identifier hs-var hs-var">adaptiveMaxPool1d</span></a></span></span><span> </span><span id="local-6989586621679880596"><span class="annot"><span class="annottext">outputSize :: Int
</span><a href="#local-6989586621679880596"><span class="hs-identifier hs-var">outputSize</span></a></span></span><span> </span><span id="local-6989586621679880595"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880595"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-813"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Int -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.adaptive_max_pool1d_tl</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-814"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880595"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880596"><span class="hs-identifier hs-var">outputSize</span></a></span><span>
</span><span id="line-815"></span><span>
</span><span id="line-816"></span><span class="hs-comment">-- | Applies a 2D adaptive max pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-817"></span><span class="annot"><a href="Torch.Functional.html#adaptiveMaxPool2d"><span class="hs-identifier hs-type">adaptiveMaxPool2d</span></a></span><span>
</span><span id="line-818"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output size</span><span>
</span><span id="line-819"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-820"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-821"></span><span id="adaptiveMaxPool2d"><span class="annot"><span class="annottext">adaptiveMaxPool2d :: (Int, Int) -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#adaptiveMaxPool2d"><span class="hs-identifier hs-var hs-var">adaptiveMaxPool2d</span></a></span></span><span> </span><span id="local-6989586621679880592"><span class="annot"><span class="annottext">outputSize :: (Int, Int)
</span><a href="#local-6989586621679880592"><span class="hs-identifier hs-var">outputSize</span></a></span></span><span> </span><span id="local-6989586621679880591"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880591"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-822"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; (Int, Int) -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.adaptive_max_pool2d_tl</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-823"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880591"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880592"><span class="hs-identifier hs-var">outputSize</span></a></span><span>
</span><span id="line-824"></span><span>
</span><span id="line-825"></span><span class="hs-comment">-- | Applies a 3D adaptive max pooling over an input signal composed of several input planes</span><span>
</span><span id="line-826"></span><span class="annot"><a href="Torch.Functional.html#adaptiveMaxPool3d"><span class="hs-identifier hs-type">adaptiveMaxPool3d</span></a></span><span>
</span><span id="line-827"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output size</span><span>
</span><span id="line-828"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-829"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-830"></span><span id="adaptiveMaxPool3d"><span class="annot"><span class="annottext">adaptiveMaxPool3d :: (Int, Int) -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#adaptiveMaxPool3d"><span class="hs-identifier hs-var hs-var">adaptiveMaxPool3d</span></a></span></span><span> </span><span id="local-6989586621679880588"><span class="annot"><span class="annottext">outputSize :: (Int, Int)
</span><a href="#local-6989586621679880588"><span class="hs-identifier hs-var">outputSize</span></a></span></span><span> </span><span id="local-6989586621679880587"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880587"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; (Int, Int) -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.adaptive_max_pool3d_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880587"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880588"><span class="hs-identifier hs-var">outputSize</span></a></span><span>
</span><span id="line-831"></span><span>
</span><span id="line-832"></span><span>
</span><span id="line-833"></span><span class="hs-comment">-- | maxPool1dWithIndices</span><span>
</span><span id="line-834"></span><span class="annot"><a href="Torch.Functional.html#maxPool1dWithIndices"><span class="hs-identifier hs-type">maxPool1dWithIndices</span></a></span><span>
</span><span id="line-835"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ kernel size</span><span>
</span><span id="line-836"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-837"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-838"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ dilation</span><span>
</span><span id="line-839"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-type">CeilMode</span></a></span><span> </span><span class="hs-comment">-- ^ ceil mode</span><span>
</span><span id="line-840"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-841"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output, indices</span><span>
</span><span id="line-842"></span><span id="maxPool1dWithIndices"><span class="annot"><span class="annottext">maxPool1dWithIndices :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; CeilMode -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#maxPool1dWithIndices"><span class="hs-identifier hs-var hs-var">maxPool1dWithIndices</span></a></span></span><span> </span><span id="local-6989586621679880584"><span class="annot"><span class="annottext">kernelSize :: Int
</span><a href="#local-6989586621679880584"><span class="hs-identifier hs-var">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679880583"><span class="annot"><span class="annottext">stride :: Int
</span><a href="#local-6989586621679880583"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880582"><span class="annot"><span class="annottext">padding :: Int
</span><a href="#local-6989586621679880582"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880581"><span class="annot"><span class="annottext">dilation :: Int
</span><a href="#local-6989586621679880581"><span class="hs-identifier hs-var">dilation</span></a></span></span><span> </span><span id="local-6989586621679880580"><span class="annot"><span class="annottext">ceilMode :: CeilMode
</span><a href="#local-6989586621679880580"><span class="hs-identifier hs-var">ceilMode</span></a></span></span><span> </span><span id="local-6989586621679880579"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880579"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-843"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; CeilMode
-&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.max_pool1d_with_indices_tllllb</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-844"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880579"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880584"><span class="hs-identifier hs-var">kernelSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880583"><span class="hs-identifier hs-var">stride</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880582"><span class="hs-identifier hs-var">padding</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880581"><span class="hs-identifier hs-var">dilation</span></a></span><span> </span><span class="annot"><span class="annottext">CeilMode
</span><a href="#local-6989586621679880580"><span class="hs-identifier hs-var">ceilMode</span></a></span><span>
</span><span id="line-845"></span><span>
</span><span id="line-846"></span><span class="hs-comment">-- | Applies a 1D max pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-847"></span><span class="annot"><a href="Torch.Functional.html#maxPool1d"><span class="hs-identifier hs-type">maxPool1d</span></a></span><span>
</span><span id="line-848"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ kernel size</span><span>
</span><span id="line-849"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-850"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-851"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ dilation</span><span>
</span><span id="line-852"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-type">CeilMode</span></a></span><span> </span><span class="hs-comment">-- ^ ceil mode</span><span>
</span><span id="line-853"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-854"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-855"></span><span id="maxPool1d"><span class="annot"><span class="annottext">maxPool1d :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; CeilMode -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#maxPool1d"><span class="hs-identifier hs-var hs-var">maxPool1d</span></a></span></span><span> </span><span id="local-6989586621679880576"><span class="annot"><span class="annottext">kernelSize :: Int
</span><a href="#local-6989586621679880576"><span class="hs-identifier hs-var">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679880575"><span class="annot"><span class="annottext">stride :: Int
</span><a href="#local-6989586621679880575"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880574"><span class="annot"><span class="annottext">padding :: Int
</span><a href="#local-6989586621679880574"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880573"><span class="annot"><span class="annottext">dilation :: Int
</span><a href="#local-6989586621679880573"><span class="hs-identifier hs-var">dilation</span></a></span></span><span> </span><span id="local-6989586621679880572"><span class="annot"><span class="annottext">ceilMode :: CeilMode
</span><a href="#local-6989586621679880572"><span class="hs-identifier hs-var">ceilMode</span></a></span></span><span> </span><span id="local-6989586621679880571"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880571"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-856"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; CeilMode -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.max_pool1d_tllllb</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-857"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880571"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880576"><span class="hs-identifier hs-var">kernelSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880575"><span class="hs-identifier hs-var">stride</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880574"><span class="hs-identifier hs-var">padding</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880573"><span class="hs-identifier hs-var">dilation</span></a></span><span> </span><span class="annot"><span class="annottext">CeilMode
</span><a href="#local-6989586621679880572"><span class="hs-identifier hs-var">ceilMode</span></a></span><span>
</span><span id="line-858"></span><span>
</span><span id="line-859"></span><span class="hs-comment">-- | Applies a 2D max pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-860"></span><span class="annot"><a href="Torch.Functional.html#maxPool2d"><span class="hs-identifier hs-type">maxPool2d</span></a></span><span>
</span><span id="line-861"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ kernel size</span><span>
</span><span id="line-862"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-863"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-864"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ dilation</span><span>
</span><span id="line-865"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-type">CeilMode</span></a></span><span> </span><span class="hs-comment">-- ^ ceil mode</span><span>
</span><span id="line-866"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-867"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-868"></span><span id="maxPool2d"><span class="annot"><span class="annottext">maxPool2d :: (Int, Int)
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; CeilMode
-&gt; Tensor
-&gt; Tensor
</span><a href="Torch.Functional.html#maxPool2d"><span class="hs-identifier hs-var hs-var">maxPool2d</span></a></span></span><span> </span><span id="local-6989586621679880568"><span class="annot"><span class="annottext">kernelSize :: (Int, Int)
</span><a href="#local-6989586621679880568"><span class="hs-identifier hs-var">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679880567"><span class="annot"><span class="annottext">stride :: (Int, Int)
</span><a href="#local-6989586621679880567"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880566"><span class="annot"><span class="annottext">padding :: (Int, Int)
</span><a href="#local-6989586621679880566"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880565"><span class="annot"><span class="annottext">dilation :: (Int, Int)
</span><a href="#local-6989586621679880565"><span class="hs-identifier hs-var">dilation</span></a></span></span><span> </span><span id="local-6989586621679880564"><span class="annot"><span class="annottext">ceilMode :: CeilMode
</span><a href="#local-6989586621679880564"><span class="hs-identifier hs-var">ceilMode</span></a></span></span><span> </span><span id="local-6989586621679880563"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880563"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-869"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; CeilMode
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.max_pool2d_tllllb</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-870"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880563"><span class="hs-identifier hs-var">self</span></a></span><span>
</span><span id="line-871"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; [Int]
</span><a href="#local-6989586621679880561"><span class="hs-identifier hs-var">asList</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880568"><span class="hs-identifier hs-var">kernelSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-872"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; [Int]
</span><a href="#local-6989586621679880561"><span class="hs-identifier hs-var">asList</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880567"><span class="hs-identifier hs-var">stride</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-873"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; [Int]
</span><a href="#local-6989586621679880561"><span class="hs-identifier hs-var">asList</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880566"><span class="hs-identifier hs-var">padding</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-874"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; [Int]
</span><a href="#local-6989586621679880561"><span class="hs-identifier hs-var">asList</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880565"><span class="hs-identifier hs-var">dilation</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-875"></span><span>        </span><span class="annot"><span class="annottext">CeilMode
</span><a href="#local-6989586621679880564"><span class="hs-identifier hs-var">ceilMode</span></a></span><span>
</span><span id="line-876"></span><span>        </span><span class="hs-keyword">where</span><span>
</span><span id="line-877"></span><span>            </span><span class="annot"><a href="#local-6989586621679880561"><span class="hs-identifier hs-type">asList</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-878"></span><span>            </span><span id="local-6989586621679880561"><span class="annot"><span class="annottext">asList :: (Int, Int) -&gt; [Int]
</span><a href="#local-6989586621679880561"><span class="hs-identifier hs-var hs-var">asList</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880560"><span class="annot"><span class="annottext">a0 :: Int
</span><a href="#local-6989586621679880560"><span class="hs-identifier hs-var">a0</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880559"><span class="annot"><span class="annottext">a1 :: Int
</span><a href="#local-6989586621679880559"><span class="hs-identifier hs-var">a1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880560"><span class="hs-identifier hs-var">a0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880559"><span class="hs-identifier hs-var">a1</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-879"></span><span>
</span><span id="line-880"></span><span class="hs-comment">-- | Applies a 3D max pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-881"></span><span class="annot"><a href="Torch.Functional.html#maxPool3d"><span class="hs-identifier hs-type">maxPool3d</span></a></span><span>
</span><span id="line-882"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ kernel size</span><span>
</span><span id="line-883"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-884"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-885"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ dilation</span><span>
</span><span id="line-886"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-type">CeilMode</span></a></span><span> </span><span class="hs-comment">-- ^ ceil mode</span><span>
</span><span id="line-887"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-888"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-889"></span><span id="maxPool3d"><span class="annot"><span class="annottext">maxPool3d :: (Int, Int, Int)
-&gt; (Int, Int, Int)
-&gt; (Int, Int, Int)
-&gt; (Int, Int, Int)
-&gt; CeilMode
-&gt; Tensor
-&gt; Tensor
</span><a href="Torch.Functional.html#maxPool3d"><span class="hs-identifier hs-var hs-var">maxPool3d</span></a></span></span><span> </span><span id="local-6989586621679880557"><span class="annot"><span class="annottext">kernelSize :: (Int, Int, Int)
</span><a href="#local-6989586621679880557"><span class="hs-identifier hs-var">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679880556"><span class="annot"><span class="annottext">stride :: (Int, Int, Int)
</span><a href="#local-6989586621679880556"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880555"><span class="annot"><span class="annottext">padding :: (Int, Int, Int)
</span><a href="#local-6989586621679880555"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880554"><span class="annot"><span class="annottext">dilation :: (Int, Int, Int)
</span><a href="#local-6989586621679880554"><span class="hs-identifier hs-var">dilation</span></a></span></span><span> </span><span id="local-6989586621679880553"><span class="annot"><span class="annottext">ceilMode :: CeilMode
</span><a href="#local-6989586621679880553"><span class="hs-identifier hs-var">ceilMode</span></a></span></span><span> </span><span id="local-6989586621679880552"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880552"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-890"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; (Int, Int, Int)
-&gt; (Int, Int, Int)
-&gt; (Int, Int, Int)
-&gt; (Int, Int, Int)
-&gt; CeilMode
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.max_pool3d_tllllb</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-891"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880552"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int, Int)
</span><a href="#local-6989586621679880557"><span class="hs-identifier hs-var">kernelSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int, Int)
</span><a href="#local-6989586621679880556"><span class="hs-identifier hs-var">stride</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int, Int)
</span><a href="#local-6989586621679880555"><span class="hs-identifier hs-var">padding</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int, Int)
</span><a href="#local-6989586621679880554"><span class="hs-identifier hs-var">dilation</span></a></span><span> </span><span class="annot"><span class="annottext">CeilMode
</span><a href="#local-6989586621679880553"><span class="hs-identifier hs-var">ceilMode</span></a></span><span>
</span><span id="line-892"></span><span>
</span><span id="line-893"></span><span class="hs-comment">-- | Calculates resulting dimensions from a 2d maxpool operation</span><span>
</span><span id="line-894"></span><span class="hs-comment">-- see https://pytorch.org/docs/master/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d</span><span>
</span><span id="line-895"></span><span class="annot"><a href="Torch.Functional.html#maxPool2dDim"><span class="hs-identifier hs-type">maxPool2dDim</span></a></span><span>
</span><span id="line-896"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ kernel size</span><span>
</span><span id="line-897"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-898"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-899"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ dilation</span><span>
</span><span id="line-900"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-type">CeilMode</span></a></span><span>   </span><span class="hs-comment">-- ^ Ceiling or Floor</span><span>
</span><span id="line-901"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ image dimensions</span><span>
</span><span id="line-902"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ height, width after maxPool</span><span>
</span><span id="line-903"></span><span id="maxPool2dDim"><span class="annot"><span class="annottext">maxPool2dDim :: (Int, Int)
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; CeilMode
-&gt; (Int, Int)
-&gt; (Int, Int)
</span><a href="Torch.Functional.html#maxPool2dDim"><span class="hs-identifier hs-var hs-var">maxPool2dDim</span></a></span></span><span> </span><span id="local-6989586621679880549"><span class="annot"><span class="annottext">kernelSize :: (Int, Int)
</span><a href="#local-6989586621679880549"><span class="hs-identifier hs-var">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679880548"><span class="annot"><span class="annottext">stride :: (Int, Int)
</span><a href="#local-6989586621679880548"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880547"><span class="annot"><span class="annottext">padding :: (Int, Int)
</span><a href="#local-6989586621679880547"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880546"><span class="annot"><span class="annottext">dilation :: (Int, Int)
</span><a href="#local-6989586621679880546"><span class="hs-identifier hs-var">dilation</span></a></span></span><span> </span><span id="local-6989586621679880545"><span class="annot"><span class="annottext">ceilMode :: CeilMode
</span><a href="#local-6989586621679880545"><span class="hs-identifier hs-var">ceilMode</span></a></span></span><span> </span><span id="local-6989586621679880544"><span class="annot"><span class="annottext">imgDim :: (Int, Int)
</span><a href="#local-6989586621679880544"><span class="hs-identifier hs-var">imgDim</span></a></span></span><span>
</span><span id="line-904"></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">((Int, Int) -&gt; Int) -&gt; Int
forall b a. (Integral b, Integral a) =&gt; ((Int, Int) -&gt; a) -&gt; b
</span><a href="#local-6989586621679880543"><span class="hs-identifier hs-var">calc</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int) -&gt; Int
forall a b. (a, b) -&gt; a
</span><span class="hs-identifier hs-var">fst</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">((Int, Int) -&gt; Int) -&gt; Int
forall b a. (Integral b, Integral a) =&gt; ((Int, Int) -&gt; a) -&gt; b
</span><a href="#local-6989586621679880543"><span class="hs-identifier hs-var">calc</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int) -&gt; Int
forall a b. (a, b) -&gt; b
</span><span class="hs-identifier hs-var">snd</span></span><span class="hs-special">)</span><span>
</span><span id="line-905"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-906"></span><span>        </span><span id="local-6989586621679880542"><span class="annot"><span class="annottext">trunc :: CeilMode -&gt; a -&gt; b
</span><a href="#local-6989586621679880542"><span class="hs-identifier hs-var hs-var">trunc</span></a></span></span><span> </span><span class="annot"><a href="Torch.Functional.html#Ceil"><span class="hs-identifier hs-type">Ceil</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">a -&gt; b
forall a b. (RealFrac a, Integral b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">P.ceiling</span></span><span>
</span><span id="line-907"></span><span>        </span><span class="annot"><a href="#local-6989586621679880542"><span class="hs-identifier hs-var">trunc</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#Floor"><span class="hs-identifier hs-type">Floor</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">a -&gt; b
forall a b. (RealFrac a, Integral b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">P.floor</span></span><span>
</span><span id="line-908"></span><span>        </span><span id="local-6989586621679880543"><span class="annot"><span class="annottext">calc :: ((Int, Int) -&gt; a) -&gt; b
</span><a href="#local-6989586621679880543"><span class="hs-identifier hs-var hs-var">calc</span></a></span></span><span> </span><span id="local-6989586621679880540"><span class="annot"><span class="annottext">f' :: (Int, Int) -&gt; a
</span><a href="#local-6989586621679880540"><span class="hs-identifier hs-var">f'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-909"></span><span>            </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679880539"><span class="annot"><span class="annottext">f :: (Int, Int) -&gt; Float
</span><a href="#local-6989586621679880539"><span class="hs-identifier hs-var hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">a -&gt; Float
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(a -&gt; Float) -&gt; ((Int, Int) -&gt; a) -&gt; (Int, Int) -&gt; Float
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(Int, Int) -&gt; a
</span><a href="#local-6989586621679880540"><span class="hs-identifier hs-var">f'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">in</span><span>
</span><span id="line-910"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">CeilMode -&gt; Float -&gt; b
forall a b. (RealFrac a, Integral b) =&gt; CeilMode -&gt; a -&gt; b
</span><a href="#local-6989586621679880542"><span class="hs-identifier hs-var">trunc</span></a></span><span> </span><span class="annot"><span class="annottext">CeilMode
</span><a href="#local-6989586621679880545"><span class="hs-identifier hs-var">ceilMode</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Float -&gt; b) -&gt; Float -&gt; b
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; Float
</span><a href="#local-6989586621679880539"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880544"><span class="hs-identifier hs-var">imgDim</span></a></span><span>
</span><span id="line-911"></span><span>            </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">(Int, Int) -&gt; Float
</span><a href="#local-6989586621679880539"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880547"><span class="hs-identifier hs-var">padding</span></a></span><span>
</span><span id="line-912"></span><span>            </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; Float
</span><a href="#local-6989586621679880539"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880546"><span class="hs-identifier hs-var">dilation</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; Float
</span><a href="#local-6989586621679880539"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880549"><span class="hs-identifier hs-var">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-913"></span><span>            </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Int, Int) -&gt; Float
</span><a href="#local-6989586621679880539"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880548"><span class="hs-identifier hs-var">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-914"></span><span>
</span><span id="line-915"></span><span class="hs-comment">-- | Applies a 1D average pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-916"></span><span class="annot"><a href="Torch.Functional.html#avgPool1d"><span class="hs-identifier hs-type">avgPool1d</span></a></span><span>
</span><span id="line-917"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ kernel size</span><span>
</span><span id="line-918"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-919"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-920"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#CeilMode"><span class="hs-identifier hs-type">CeilMode</span></a></span><span> </span><span class="hs-comment">-- ^ ceil mode</span><span>
</span><span id="line-921"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ count include pad</span><span>
</span><span id="line-922"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-923"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-924"></span><span id="avgPool1d"><span class="annot"><span class="annottext">avgPool1d :: Int -&gt; Int -&gt; Int -&gt; CeilMode -&gt; Bool -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#avgPool1d"><span class="hs-identifier hs-var hs-var">avgPool1d</span></a></span></span><span> </span><span id="local-6989586621679880536"><span class="annot"><span class="annottext">kernelSize :: Int
</span><a href="#local-6989586621679880536"><span class="hs-identifier hs-var">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679880535"><span class="annot"><span class="annottext">stride :: Int
</span><a href="#local-6989586621679880535"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880534"><span class="annot"><span class="annottext">padding :: Int
</span><a href="#local-6989586621679880534"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880533"><span class="annot"><span class="annottext">ceilMode :: CeilMode
</span><a href="#local-6989586621679880533"><span class="hs-identifier hs-var">ceilMode</span></a></span></span><span> </span><span id="local-6989586621679880532"><span class="annot"><span class="annottext">countIncludePad :: Bool
</span><a href="#local-6989586621679880532"><span class="hs-identifier hs-var">countIncludePad</span></a></span></span><span> </span><span id="local-6989586621679880531"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880531"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-925"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; Int -&gt; CeilMode -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.avg_pool1d_tlllbb</span></a></span><span>
</span><span id="line-926"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880531"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-927"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880536"><span class="hs-identifier hs-var">kernelSize</span></a></span><span>
</span><span id="line-928"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880535"><span class="hs-identifier hs-var">stride</span></a></span><span>
</span><span id="line-929"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880534"><span class="hs-identifier hs-var">padding</span></a></span><span>
</span><span id="line-930"></span><span>        </span><span class="annot"><span class="annottext">CeilMode
</span><a href="#local-6989586621679880533"><span class="hs-identifier hs-var">ceilMode</span></a></span><span>
</span><span id="line-931"></span><span>        </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880532"><span class="hs-identifier hs-var">countIncludePad</span></a></span><span>
</span><span id="line-932"></span><span>
</span><span id="line-933"></span><span class="annot"><a href="Torch.Functional.html#avgPool1d%27"><span class="hs-identifier hs-type">avgPool1d'</span></a></span><span>
</span><span id="line-934"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ kernel size</span><span>
</span><span id="line-935"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-936"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-937"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-938"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-939"></span><span id="avgPool1d%27"><span class="annot"><span class="annottext">avgPool1d' :: Int -&gt; Int -&gt; Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#avgPool1d%27"><span class="hs-identifier hs-var hs-var">avgPool1d'</span></a></span></span><span> </span><span id="local-6989586621679880528"><span class="annot"><span class="annottext">kernelSize :: Int
</span><a href="#local-6989586621679880528"><span class="hs-identifier hs-var">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679880527"><span class="annot"><span class="annottext">stride :: Int
</span><a href="#local-6989586621679880527"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880526"><span class="annot"><span class="annottext">padding :: Int
</span><a href="#local-6989586621679880526"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880525"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880525"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-940"></span><span>    </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int -&gt; CeilMode -&gt; Bool -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#avgPool1d"><span class="hs-identifier hs-var">avgPool1d</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880528"><span class="hs-identifier hs-var">kernelSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880527"><span class="hs-identifier hs-var">stride</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880526"><span class="hs-identifier hs-var">padding</span></a></span><span> </span><span class="annot"><span class="annottext">CeilMode
</span><a href="Torch.Functional.html#Floor"><span class="hs-identifier hs-var">Floor</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880525"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-941"></span><span>
</span><span id="line-942"></span><span class="hs-comment">-- | Applies a 1D adaptive average pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-943"></span><span class="annot"><a href="Torch.Functional.html#adaptiveAvgPool1d"><span class="hs-identifier hs-type">adaptiveAvgPool1d</span></a></span><span>
</span><span id="line-944"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- outputSize</span><span>
</span><span id="line-945"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-946"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-947"></span><span id="adaptiveAvgPool1d"><span class="annot"><span class="annottext">adaptiveAvgPool1d :: Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#adaptiveAvgPool1d"><span class="hs-identifier hs-var hs-var">adaptiveAvgPool1d</span></a></span></span><span> </span><span id="local-6989586621679880523"><span class="annot"><span class="annottext">outputSize :: Int
</span><a href="#local-6989586621679880523"><span class="hs-identifier hs-var">outputSize</span></a></span></span><span> </span><span id="local-6989586621679880522"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880522"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span>
</span><span id="line-948"></span><span>  </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.adaptive_avg_pool1d_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880522"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880523"><span class="hs-identifier hs-var">outputSize</span></a></span><span>
</span><span id="line-949"></span><span>
</span><span id="line-950"></span><span class="hs-comment">-- | Applies a 2D adaptive average pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-951"></span><span class="annot"><a href="Torch.Functional.html#adaptiveAvgPool2d"><span class="hs-identifier hs-type">adaptiveAvgPool2d</span></a></span><span>
</span><span id="line-952"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output size (Height * Width)</span><span>
</span><span id="line-953"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-954"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-955"></span><span id="adaptiveAvgPool2d"><span class="annot"><span class="annottext">adaptiveAvgPool2d :: (Int, Int) -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#adaptiveAvgPool2d"><span class="hs-identifier hs-var hs-var">adaptiveAvgPool2d</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880519"><span class="annot"><span class="annottext">outputHeight :: Int
</span><a href="#local-6989586621679880519"><span class="hs-identifier hs-var">outputHeight</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880518"><span class="annot"><span class="annottext">outputWidth :: Int
</span><a href="#local-6989586621679880518"><span class="hs-identifier hs-var">outputWidth</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880517"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880517"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-956"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; [Int] -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.adaptive_avg_pool2d_tl</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-957"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880517"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-958"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880519"><span class="hs-identifier hs-var">outputHeight</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880518"><span class="hs-identifier hs-var">outputWidth</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-959"></span><span>
</span><span id="line-960"></span><span class="hs-comment">-- | Applies a 3D adaptive average pooling over an input signal composed of several input planes.</span><span>
</span><span id="line-961"></span><span class="annot"><a href="Torch.Functional.html#adaptiveAvgPool3d"><span class="hs-identifier hs-type">adaptiveAvgPool3d</span></a></span><span>
</span><span id="line-962"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output size (Depth * Height * Width)</span><span>
</span><span id="line-963"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-964"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-965"></span><span id="adaptiveAvgPool3d"><span class="annot"><span class="annottext">adaptiveAvgPool3d :: (Int, Int, Int) -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#adaptiveAvgPool3d"><span class="hs-identifier hs-var hs-var">adaptiveAvgPool3d</span></a></span></span><span> </span><span id="local-6989586621679880514"><span class="annot"><span class="annottext">_output_size :: (Int, Int, Int)
</span><a href="#local-6989586621679880514"><span class="hs-identifier hs-var">_output_size</span></a></span></span><span> </span><span id="local-6989586621679880513"><span class="annot"><span class="annottext">_self :: Tensor
</span><a href="#local-6989586621679880513"><span class="hs-identifier hs-var">_self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; (Int, Int, Int) -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.adaptive_avg_pool3d_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880513"><span class="hs-identifier hs-var">_self</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int, Int)
</span><a href="#local-6989586621679880514"><span class="hs-identifier hs-var">_output_size</span></a></span><span>
</span><span id="line-966"></span><span>
</span><span id="line-967"></span><span class="hs-comment">--</span><span>
</span><span id="line-968"></span><span class="hs-comment">-- matrix solvers</span><span>
</span><span id="line-969"></span><span class="hs-comment">--</span><span>
</span><span id="line-970"></span><span>
</span><span id="line-971"></span><span class="hs-comment">-- | Takes the inverse of the square matrix input. @input@ can be batches of 2D square tensors, in which case this function would return a tensor composed of individual inverses.</span><span>
</span><span id="line-972"></span><span class="annot"><a href="Torch.Functional.html#inverse"><span class="hs-identifier hs-type">inverse</span></a></span><span>
</span><span id="line-973"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-974"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-975"></span><span id="inverse"><span class="annot"><span class="annottext">inverse :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#inverse"><span class="hs-identifier hs-var hs-var">inverse</span></a></span></span><span> </span><span id="local-6989586621679880510"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880510"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.inverse_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880510"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-976"></span><span>
</span><span id="line-977"></span><span class="hs-comment">-- | This function returns eigenvalues and eigenvectors of a real symmetric matrix input or a batch of real symmetric matrices, represented by a namedtuple (eigenvalues, eigenvectors).</span><span>
</span><span id="line-978"></span><span class="annot"><a href="Torch.Functional.html#symeig"><span class="hs-identifier hs-type">symeig</span></a></span><span>
</span><span id="line-979"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ bool which controls whether eigenvectors have to be computed</span><span>
</span><span id="line-980"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-comment">-- ^ controls whether to consider upper-triangular or lower-triangular region</span><span>
</span><span id="line-981"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input tensor</span><span>
</span><span id="line-982"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output tensors</span><span>
</span><span id="line-983"></span><span id="symeig"><span class="annot"><span class="annottext">symeig :: Bool -&gt; Tri -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#symeig"><span class="hs-identifier hs-var hs-var">symeig</span></a></span></span><span> </span><span id="local-6989586621679880507"><span class="annot"><span class="annottext">eigenvectors :: Bool
</span><a href="#local-6989586621679880507"><span class="hs-identifier hs-var">eigenvectors</span></a></span></span><span> </span><span id="local-6989586621679880506"><span class="annot"><span class="annottext">upper :: Tri
</span><a href="#local-6989586621679880506"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679880505"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880505"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Bool -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.symeig_tbb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880505"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880507"><span class="hs-identifier hs-var">eigenvectors</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880503"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-984"></span><span>  </span><span class="hs-keyword">where</span><span> </span><span id="local-6989586621679880503"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679880503"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679880506"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-985"></span><span>
</span><span id="line-986"></span><span class="hs-comment">-- | Computes the eigenvalues and eigenvectors of a real square matrix</span><span>
</span><span id="line-987"></span><span class="annot"><a href="Torch.Functional.html#eig"><span class="hs-identifier hs-type">eig</span></a></span><span>
</span><span id="line-988"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ bool to compute both eigenvalues and eigenvectors; otherwise, only eigenvalues will be computed</span><span>
</span><span id="line-989"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input (square matrix) for which the eigen values and eigen vectors are to be computed</span><span>
</span><span id="line-990"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output tensors</span><span>
</span><span id="line-991"></span><span id="eig"><span class="annot"><span class="annottext">eig :: Bool -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#eig"><span class="hs-identifier hs-var hs-var">eig</span></a></span></span><span> </span><span id="local-6989586621679880501"><span class="annot"><span class="annottext">eigenvectors :: Bool
</span><a href="#local-6989586621679880501"><span class="hs-identifier hs-var">eigenvectors</span></a></span></span><span> </span><span id="local-6989586621679880500"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880500"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.eig_tb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880500"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880501"><span class="hs-identifier hs-var">eigenvectors</span></a></span><span>
</span><span id="line-992"></span><span>
</span><span id="line-993"></span><span class="hs-comment">-- | This function returns a namedtuple (U, S, V) which is the singular value decomposition of a input real matrix or batches of real matrices input such that input = U * diag(S) * V^T</span><span>
</span><span id="line-994"></span><span class="annot"><a href="Torch.Functional.html#svd"><span class="hs-identifier hs-type">svd</span></a></span><span>
</span><span id="line-995"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ controls the shape of returned U and V</span><span>
</span><span id="line-996"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ option whether to compute U and V or not</span><span>
</span><span id="line-997"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-998"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output tuple of tensors</span><span>
</span><span id="line-999"></span><span id="svd"><span class="annot"><span class="annottext">svd :: Bool -&gt; Bool -&gt; Tensor -&gt; (Tensor, Tensor, Tensor)
</span><a href="Torch.Functional.html#svd"><span class="hs-identifier hs-var hs-var">svd</span></a></span></span><span> </span><span id="local-6989586621679880497"><span class="annot"><span class="annottext">some :: Bool
</span><a href="#local-6989586621679880497"><span class="hs-identifier hs-var">some</span></a></span></span><span> </span><span id="local-6989586621679880496"><span class="annot"><span class="annottext">compute_uv :: Bool
</span><a href="#local-6989586621679880496"><span class="hs-identifier hs-var">compute_uv</span></a></span></span><span> </span><span id="local-6989586621679880495"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880495"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor, Tensor) -&gt; (Tensor, Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor, Tensor) -&gt; (Tensor, Tensor, Tensor))
-&gt; IO (Tensor, Tensor, Tensor) -&gt; (Tensor, Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor, Tensor))))
-&gt; Tensor -&gt; Bool -&gt; Bool -&gt; IO (Tensor, Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.svd_tbb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880495"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880497"><span class="hs-identifier hs-var">some</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880496"><span class="hs-identifier hs-var">compute_uv</span></a></span><span>
</span><span id="line-1000"></span><span>
</span><span id="line-1001"></span><span class="hs-comment">-- | Computes the Cholesky decomposition of a symmetric positive-definite matrix AA or for batches of symmetric positive-definite matrices.</span><span>
</span><span id="line-1002"></span><span class="annot"><a href="Torch.Functional.html#cholesky"><span class="hs-identifier hs-type">cholesky</span></a></span><span>
</span><span id="line-1003"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-comment">-- ^ flag that indicates whether to return a upper or lower triangular matrix.</span><span>
</span><span id="line-1004"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1005"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1006"></span><span id="cholesky"><span class="annot"><span class="annottext">cholesky :: Tri -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#cholesky"><span class="hs-identifier hs-var hs-var">cholesky</span></a></span></span><span> </span><span id="local-6989586621679880492"><span class="annot"><span class="annottext">upper :: Tri
</span><a href="#local-6989586621679880492"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679880491"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880491"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cholesky_tb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880491"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880489"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-1007"></span><span>  </span><span class="hs-keyword">where</span><span> </span><span id="local-6989586621679880489"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679880489"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679880492"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-1008"></span><span>
</span><span id="line-1009"></span><span>
</span><span id="line-1010"></span><span class="hs-comment">-- | Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uu .</span><span>
</span><span id="line-1011"></span><span class="annot"><a href="Torch.Functional.html#choleskySolve"><span class="hs-identifier hs-type">choleskySolve</span></a></span><span>
</span><span id="line-1012"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-comment">-- ^ bool whether to consider the Cholesky factor as a lower or upper triangular matrix</span><span>
</span><span id="line-1013"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input matrix b</span><span>
</span><span id="line-1014"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input matrix u</span><span>
</span><span id="line-1015"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1016"></span><span id="choleskySolve"><span class="annot"><span class="annottext">choleskySolve :: Tri -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#choleskySolve"><span class="hs-identifier hs-var hs-var">choleskySolve</span></a></span></span><span> </span><span id="local-6989586621679880487"><span class="annot"><span class="annottext">upper :: Tri
</span><a href="#local-6989586621679880487"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679880486"><span class="annot"><span class="annottext">t1 :: Tensor
</span><a href="#local-6989586621679880486"><span class="hs-identifier hs-var">t1</span></a></span></span><span> </span><span id="local-6989586621679880485"><span class="annot"><span class="annottext">t2 :: Tensor
</span><a href="#local-6989586621679880485"><span class="hs-identifier hs-var">t2</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cholesky_solve_ttb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880486"><span class="hs-identifier hs-var">t1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880485"><span class="hs-identifier hs-var">t2</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880483"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-1017"></span><span>  </span><span class="hs-keyword">where</span><span> </span><span id="local-6989586621679880483"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679880483"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679880487"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-1018"></span><span>
</span><span id="line-1019"></span><span class="hs-comment">-- | This function returns the solution to the system of linear equations represented by AX = BAX=B and the LU factorization of A, in order as a namedtuple solution, LU.</span><span>
</span><span id="line-1020"></span><span class="hs-comment">-- LU contains L and U factors for LU factorization of A</span><span>
</span><span id="line-1021"></span><span class="annot"><a href="Torch.Functional.html#solve"><span class="hs-identifier hs-type">solve</span></a></span><span>
</span><span id="line-1022"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input matrix</span><span>
</span><span id="line-1023"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input square matrix</span><span>
</span><span id="line-1024"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output tuple with solution and LU</span><span>
</span><span id="line-1025"></span><span id="solve"><span class="annot"><span class="annottext">solve :: Tensor -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#solve"><span class="hs-identifier hs-var hs-var">solve</span></a></span></span><span> </span><span id="local-6989586621679880481"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880481"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span id="local-6989586621679880480"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880480"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Tensor -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.solve_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880481"><span class="hs-identifier hs-var">b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880480"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-1026"></span><span>
</span><span id="line-1027"></span><span class="hs-comment">-- | Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uu .</span><span>
</span><span id="line-1028"></span><span class="annot"><a href="Torch.Functional.html#choleskyInverse"><span class="hs-identifier hs-type">choleskyInverse</span></a></span><span>
</span><span id="line-1029"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-comment">-- ^ upper or lower triangle</span><span>
</span><span id="line-1030"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1031"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ solution</span><span>
</span><span id="line-1032"></span><span id="choleskyInverse"><span class="annot"><span class="annottext">choleskyInverse :: Tri -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#choleskyInverse"><span class="hs-identifier hs-var hs-var">choleskyInverse</span></a></span></span><span> </span><span id="local-6989586621679880477"><span class="annot"><span class="annottext">upper :: Tri
</span><a href="#local-6989586621679880477"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679880476"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880476"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cholesky_inverse_tb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880476"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880474"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-1033"></span><span>  </span><span class="hs-keyword">where</span><span> </span><span id="local-6989586621679880474"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679880474"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679880477"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-1034"></span><span>
</span><span id="line-1035"></span><span class="hs-comment">-- pstrf :: Bool -&gt; Double -&gt; Tensor -&gt; (Tensor, Tensor)</span><span>
</span><span id="line-1036"></span><span class="hs-comment">-- pstrf upper tol t = unsafePerformIO $ (cast3 ATen.pstrf_tbs) t upper tol</span><span>
</span><span id="line-1037"></span><span>
</span><span id="line-1038"></span><span class="hs-comment">-- qr :: Tensor -&gt; (Tensor, Tensor)</span><span>
</span><span id="line-1039"></span><span class="hs-comment">-- qr t = unsafePerformIO $ (cast1 ATen.qr_t) t</span><span>
</span><span id="line-1040"></span><span>
</span><span id="line-1041"></span><span class="hs-comment">-- | This is a low-level function for calling LAPACK directly. This function returns a namedtuple (a, tau) as defined in LAPACK documentation for geqrf.</span><span>
</span><span id="line-1042"></span><span class="annot"><a href="Torch.Functional.html#geqrf"><span class="hs-identifier hs-type">geqrf</span></a></span><span>
</span><span id="line-1043"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1044"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ a, tau output matrices (see https://software.intel.com/en-us/node/521004)</span><span>
</span><span id="line-1045"></span><span id="geqrf"><span class="annot"><span class="annottext">geqrf :: Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#geqrf"><span class="hs-identifier hs-var hs-var">geqrf</span></a></span></span><span> </span><span id="local-6989586621679880472"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880472"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; IO (Tensor, Tensor)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.geqrf_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880472"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1046"></span><span>
</span><span id="line-1047"></span><span>
</span><span id="line-1048"></span><span class="hs-comment">-- | Computes the orthogonal matrix Q of a QR factorization, from the @(input, input2)@ tuple returned by 'geqrf' function.</span><span>
</span><span id="line-1049"></span><span class="hs-comment">-- This directly calls the underlying LAPACK function @?orgqr@. See LAPACK documentation for @orgqr@ for further details.</span><span>
</span><span id="line-1050"></span><span class="annot"><a href="Torch.Functional.html#orgqr"><span class="hs-identifier hs-type">orgqr</span></a></span><span>
</span><span id="line-1051"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ the @a@ from @geqrf@ function</span><span>
</span><span id="line-1052"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ the @tau@ from @geqrf@ function</span><span>
</span><span id="line-1053"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1054"></span><span id="orgqr"><span class="annot"><span class="annottext">orgqr :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#orgqr"><span class="hs-identifier hs-var hs-var">orgqr</span></a></span></span><span> </span><span id="local-6989586621679880469"><span class="annot"><span class="annottext">b :: Tensor
</span><a href="#local-6989586621679880469"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span id="local-6989586621679880468"><span class="annot"><span class="annottext">a :: Tensor
</span><a href="#local-6989586621679880468"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.orgqr_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880469"><span class="hs-identifier hs-var">b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880468"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-1055"></span><span>
</span><span id="line-1056"></span><span class="hs-comment">--</span><span>
</span><span id="line-1057"></span><span class="hs-comment">-- dropout</span><span>
</span><span id="line-1058"></span><span class="hs-comment">--</span><span>
</span><span id="line-1059"></span><span>
</span><span id="line-1060"></span><span class="hs-comment">-- | During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.</span><span>
</span><span id="line-1061"></span><span class="annot"><a href="Torch.Functional.html#dropout"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-1062"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ dropout probability</span><span>
</span><span id="line-1063"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ whether or not to activate dropout</span><span>
</span><span id="line-1064"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1065"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1066"></span><span id="dropout"><span class="annot"><span class="annottext">dropout :: Double -&gt; Bool -&gt; Tensor -&gt; IO Tensor
</span><a href="Torch.Functional.html#dropout"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span id="local-6989586621679880465"><span class="annot"><span class="annottext">p :: Double
</span><a href="#local-6989586621679880465"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679880464"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679880464"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679880463"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880463"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Double -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880463"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880465"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880464"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1067"></span><span>
</span><span id="line-1068"></span><span class="annot"><a href="Torch.Functional.html#featureDropout"><span class="hs-identifier hs-type">featureDropout</span></a></span><span>
</span><span id="line-1069"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ dropout probability</span><span>
</span><span id="line-1070"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ whether or not to activate dropout</span><span>
</span><span id="line-1071"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1072"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1073"></span><span id="featureDropout"><span class="annot"><span class="annottext">featureDropout :: Double -&gt; Bool -&gt; Tensor -&gt; IO Tensor
</span><a href="Torch.Functional.html#featureDropout"><span class="hs-identifier hs-var hs-var">featureDropout</span></a></span></span><span> </span><span id="local-6989586621679880460"><span class="annot"><span class="annottext">p :: Double
</span><a href="#local-6989586621679880460"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679880459"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679880459"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679880458"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880458"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1074"></span><span>  </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Double -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.feature_dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880458"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880460"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880459"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1075"></span><span>
</span><span id="line-1076"></span><span class="hs-comment">-- | Applies alpha dropout to the input.</span><span>
</span><span id="line-1077"></span><span class="annot"><a href="Torch.Functional.html#alphaDropout"><span class="hs-identifier hs-type">alphaDropout</span></a></span><span>
</span><span id="line-1078"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ dropout probability</span><span>
</span><span id="line-1079"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ whether or not to activate dropout</span><span>
</span><span id="line-1080"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1081"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1082"></span><span id="alphaDropout"><span class="annot"><span class="annottext">alphaDropout :: Double -&gt; Bool -&gt; Tensor -&gt; IO Tensor
</span><a href="Torch.Functional.html#alphaDropout"><span class="hs-identifier hs-var hs-var">alphaDropout</span></a></span></span><span> </span><span id="local-6989586621679880455"><span class="annot"><span class="annottext">p :: Double
</span><a href="#local-6989586621679880455"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679880454"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679880454"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679880453"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880453"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1083"></span><span>  </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Double -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.alpha_dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880453"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880455"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880454"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1084"></span><span>
</span><span id="line-1085"></span><span class="annot"><a href="Torch.Functional.html#featureAlphaDropout"><span class="hs-identifier hs-type">featureAlphaDropout</span></a></span><span>
</span><span id="line-1086"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-comment">-- ^ dropout probability</span><span>
</span><span id="line-1087"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ whether or not to activate dropout</span><span>
</span><span id="line-1088"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1089"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1090"></span><span id="featureAlphaDropout"><span class="annot"><span class="annottext">featureAlphaDropout :: Double -&gt; Bool -&gt; Tensor -&gt; IO Tensor
</span><a href="Torch.Functional.html#featureAlphaDropout"><span class="hs-identifier hs-var hs-var">featureAlphaDropout</span></a></span></span><span> </span><span id="local-6989586621679880450"><span class="annot"><span class="annottext">p :: Double
</span><a href="#local-6989586621679880450"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679880449"><span class="annot"><span class="annottext">train :: Bool
</span><a href="#local-6989586621679880449"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679880448"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880448"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1091"></span><span>  </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Double -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.feature_alpha_dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880448"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679880450"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880449"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1092"></span><span>
</span><span id="line-1093"></span><span class="hs-comment">--</span><span>
</span><span id="line-1094"></span><span class="hs-comment">-- Element-wise logical operators</span><span>
</span><span id="line-1095"></span><span class="hs-comment">--</span><span>
</span><span id="line-1096"></span><span>
</span><span id="line-1097"></span><span class="hs-comment">-- | Computes the bitwise NOT of the given input tensor. The input tensor must be of integral or Boolean types. For bool tensors, it computes the logical NOT.</span><span>
</span><span id="line-1098"></span><span class="annot"><a href="Torch.Functional.html#bitwiseNot"><span class="hs-identifier hs-type">bitwiseNot</span></a></span><span>
</span><span id="line-1099"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1100"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1101"></span><span id="bitwiseNot"><span class="annot"><span class="annottext">bitwiseNot :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#bitwiseNot"><span class="hs-identifier hs-var hs-var">bitwiseNot</span></a></span></span><span> </span><span id="local-6989586621679880445"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880445"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_not_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880445"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1102"></span><span>
</span><span id="line-1103"></span><span class="hs-comment">-- | Computes the element-wise logical NOT of the given input tensor. If not specified, the output tensor will have the bool dtype. If the input tensor is not a bool tensor, zeros are treated as False and non-zeros are treated as True.</span><span>
</span><span id="line-1104"></span><span class="annot"><a href="Torch.Functional.html#logicalNot"><span class="hs-identifier hs-type">logicalNot</span></a></span><span>
</span><span id="line-1105"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1106"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1107"></span><span id="logicalNot"><span class="annot"><span class="annottext">logicalNot :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#logicalNot"><span class="hs-identifier hs-var hs-var">logicalNot</span></a></span></span><span> </span><span id="local-6989586621679880442"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880442"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_not_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880442"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1108"></span><span>
</span><span id="line-1109"></span><span class="annot"><a href="Torch.Functional.html#logicalXor"><span class="hs-identifier hs-type">logicalXor</span></a></span><span>
</span><span id="line-1110"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1111"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-1112"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1113"></span><span id="logicalXor"><span class="annot"><span class="annottext">logicalXor :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#logicalXor"><span class="hs-identifier hs-var hs-var">logicalXor</span></a></span></span><span> </span><span id="local-6989586621679880439"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880439"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679880438"><span class="annot"><span class="annottext">other :: Tensor
</span><a href="#local-6989586621679880438"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_xor_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880439"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880438"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1114"></span><span>
</span><span id="line-1115"></span><span class="annot"><a href="Torch.Functional.html#logicalAnd"><span class="hs-identifier hs-type">logicalAnd</span></a></span><span>
</span><span id="line-1116"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1117"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-1118"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1119"></span><span id="logicalAnd"><span class="annot"><span class="annottext">logicalAnd :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#logicalAnd"><span class="hs-identifier hs-var hs-var">logicalAnd</span></a></span></span><span> </span><span id="local-6989586621679880435"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880435"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679880434"><span class="annot"><span class="annottext">other :: Tensor
</span><a href="#local-6989586621679880434"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_and_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880435"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880434"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1120"></span><span>
</span><span id="line-1121"></span><span class="annot"><a href="Torch.Functional.html#logicalOr"><span class="hs-identifier hs-type">logicalOr</span></a></span><span>
</span><span id="line-1122"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1123"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ other</span><span>
</span><span id="line-1124"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1125"></span><span id="logicalOr"><span class="annot"><span class="annottext">logicalOr :: Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#logicalOr"><span class="hs-identifier hs-var hs-var">logicalOr</span></a></span></span><span> </span><span id="local-6989586621679880431"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880431"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679880430"><span class="annot"><span class="annottext">other :: Tensor
</span><a href="#local-6989586621679880430"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_or_tt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880431"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880430"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1126"></span><span>
</span><span id="line-1127"></span><span class="hs-comment">-- | Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.</span><span>
</span><span id="line-1128"></span><span class="annot"><a href="Torch.Functional.html#cat"><span class="hs-identifier hs-type">cat</span></a></span><span>
</span><span id="line-1129"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1130"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ list of tensors to concatenate</span><span>
</span><span id="line-1131"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output tensor</span><span>
</span><span id="line-1132"></span><span id="cat"><span class="annot"><span class="annottext">cat :: Dim -&gt; [Tensor] -&gt; Tensor
</span><a href="Torch.Functional.html#cat"><span class="hs-identifier hs-var hs-var">cat</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880427"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880427"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880426"><span class="annot"><span class="annottext">tensors :: [Tensor]
</span><a href="#local-6989586621679880426"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; [Tensor] -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cat_ll</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679880426"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880427"><span class="hs-identifier hs-var">d</span></a></span><span>
</span><span id="line-1133"></span><span>
</span><span id="line-1134"></span><span class="annot"><a href="Torch.Functional.html#index"><span class="hs-identifier hs-type">index</span></a></span><span>
</span><span id="line-1135"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ indices</span><span>
</span><span id="line-1136"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1137"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1138"></span><span id="index"><span class="annot"><span class="annottext">index :: [Tensor] -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#index"><span class="hs-identifier hs-var hs-var">index</span></a></span></span><span> </span><span id="local-6989586621679880423"><span class="annot"><span class="annottext">_indices :: [Tensor]
</span><a href="#local-6989586621679880423"><span class="hs-identifier hs-var">_indices</span></a></span></span><span> </span><span id="local-6989586621679880422"><span class="annot"><span class="annottext">_self :: Tensor
</span><a href="#local-6989586621679880422"><span class="hs-identifier hs-var">_self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorList -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; [Tensor] -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorList -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.index_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880422"><span class="hs-identifier hs-var">_self</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679880423"><span class="hs-identifier hs-var">_indices</span></a></span><span>
</span><span id="line-1139"></span><span>
</span><span id="line-1140"></span><span class="hs-comment">-- Copies the elements of tensor into the self tensor (out-of-place) by selecting the indices in the order given in index.</span><span>
</span><span id="line-1141"></span><span class="hs-comment">-- For example, if dim == 0 and index[i] == j, then the ith row of tensor is copied to the jth row of self.</span><span>
</span><span id="line-1142"></span><span class="hs-comment">-- The dimth dimension of tensor must have the same size as the length of index (which must be a vector), and all other dimensions must match self, or an error will be raised.</span><span>
</span><span id="line-1143"></span><span class="annot"><a href="Torch.Functional.html#indexCopy"><span class="hs-identifier hs-type">indexCopy</span></a></span><span>
</span><span id="line-1144"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-1145"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ index</span><span>
</span><span id="line-1146"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ source</span><span>
</span><span id="line-1147"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1148"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1149"></span><span id="indexCopy"><span class="annot"><span class="annottext">indexCopy :: Int -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#indexCopy"><span class="hs-identifier hs-var hs-var">indexCopy</span></a></span></span><span> </span><span id="local-6989586621679880419"><span class="annot"><span class="annottext">dim :: Int
</span><a href="#local-6989586621679880419"><span class="hs-identifier hs-var">dim</span></a></span></span><span> </span><span id="local-6989586621679880418"><span class="annot"><span class="annottext">index :: Tensor
</span><a href="#local-6989586621679880418"><span class="hs-identifier hs-var">index</span></a></span></span><span> </span><span id="local-6989586621679880417"><span class="annot"><span class="annottext">source :: Tensor
</span><a href="#local-6989586621679880417"><span class="hs-identifier hs-var">source</span></a></span></span><span> </span><span id="local-6989586621679880416"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880416"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.index_copy_tltt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880416"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880419"><span class="hs-identifier hs-var">dim</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880418"><span class="hs-identifier hs-var">index</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880417"><span class="hs-identifier hs-var">source</span></a></span><span>
</span><span id="line-1150"></span><span>
</span><span id="line-1151"></span><span class="annot"><a href="Torch.Functional.html#indexCopyWithDimname"><span class="hs-identifier hs-type">indexCopyWithDimname</span></a></span><span>
</span><span id="line-1152"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Dimname.html#Dimname"><span class="hs-identifier hs-type">Dimname</span></a></span><span> </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-1153"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ index</span><span>
</span><span id="line-1154"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ source</span><span>
</span><span id="line-1155"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1156"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1157"></span><span id="indexCopyWithDimname"><span class="annot"><span class="annottext">indexCopyWithDimname :: Dimname -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#indexCopyWithDimname"><span class="hs-identifier hs-var hs-var">indexCopyWithDimname</span></a></span></span><span> </span><span id="local-6989586621679880413"><span class="annot"><span class="annottext">dim :: Dimname
</span><a href="#local-6989586621679880413"><span class="hs-identifier hs-var">dim</span></a></span></span><span> </span><span id="local-6989586621679880412"><span class="annot"><span class="annottext">index :: Tensor
</span><a href="#local-6989586621679880412"><span class="hs-identifier hs-var">index</span></a></span></span><span> </span><span id="local-6989586621679880411"><span class="annot"><span class="annottext">source :: Tensor
</span><a href="#local-6989586621679880411"><span class="hs-identifier hs-var">source</span></a></span></span><span> </span><span id="local-6989586621679880410"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880410"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Dimname
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Dimname -&gt; Tensor -&gt; Tensor -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Dimname
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.index_copy_tntt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880410"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Dimname
</span><a href="#local-6989586621679880413"><span class="hs-identifier hs-var">dim</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880412"><span class="hs-identifier hs-var">index</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880411"><span class="hs-identifier hs-var">source</span></a></span><span>
</span><span id="line-1158"></span><span>
</span><span id="line-1159"></span><span class="hs-comment">-- | Puts values from the tensor value into the input tensor (out-of-place)</span><span>
</span><span id="line-1160"></span><span class="hs-comment">-- using the indices specified in indices (which is a tuple of Tensors).</span><span>
</span><span id="line-1161"></span><span class="hs-comment">-- The expression tensor.index_put_(indices, value) is equivalent to tensor[indices] = value.</span><span>
</span><span id="line-1162"></span><span class="hs-comment">-- If accumulate is True, the elements in value are added to self. If accumulate is False, the behavior is undefined if indices contain duplicate elements.</span><span>
</span><span id="line-1163"></span><span class="annot"><a href="Torch.Functional.html#indexPut"><span class="hs-identifier hs-type">indexPut</span></a></span><span>
</span><span id="line-1164"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ accumulate</span><span>
</span><span id="line-1165"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ indices</span><span>
</span><span id="line-1166"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ values</span><span>
</span><span id="line-1167"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1168"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1169"></span><span id="indexPut"><span class="annot"><span class="annottext">indexPut :: Bool -&gt; [Tensor] -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#indexPut"><span class="hs-identifier hs-var hs-var">indexPut</span></a></span></span><span> </span><span id="local-6989586621679880407"><span class="annot"><span class="annottext">accumulate :: Bool
</span><a href="#local-6989586621679880407"><span class="hs-identifier hs-var">accumulate</span></a></span></span><span> </span><span id="local-6989586621679880406"><span class="annot"><span class="annottext">indices :: [Tensor]
</span><a href="#local-6989586621679880406"><span class="hs-identifier hs-var">indices</span></a></span></span><span> </span><span id="local-6989586621679880405"><span class="annot"><span class="annottext">values :: Tensor
</span><a href="#local-6989586621679880405"><span class="hs-identifier hs-var">values</span></a></span></span><span> </span><span id="local-6989586621679880404"><span class="annot"><span class="annottext">self :: Tensor
</span><a href="#local-6989586621679880404"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorList
 -&gt; ForeignPtr Tensor
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; [Tensor] -&gt; Tensor -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorList
-&gt; ForeignPtr Tensor
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.index_put_tltb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880404"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679880406"><span class="hs-identifier hs-var">indices</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880405"><span class="hs-identifier hs-var">values</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880407"><span class="hs-identifier hs-var">accumulate</span></a></span><span>
</span><span id="line-1170"></span><span>
</span><span id="line-1171"></span><span class="hs-comment">-- | Splits a tensor into a specific number of chunks.</span><span>
</span><span id="line-1172"></span><span class="hs-comment">-- Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by chunks.</span><span>
</span><span id="line-1173"></span><span class="annot"><a href="Torch.Functional.html#chunk"><span class="hs-identifier hs-type">chunk</span></a></span><span>
</span><span id="line-1174"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ chunks</span><span>
</span><span id="line-1175"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-1176"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input tensor</span><span>
</span><span id="line-1177"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ output list of tensors</span><span>
</span><span id="line-1178"></span><span id="chunk"><span class="annot"><span class="annottext">chunk :: Int -&gt; Dim -&gt; Tensor -&gt; [Tensor]
</span><a href="Torch.Functional.html#chunk"><span class="hs-identifier hs-var hs-var">chunk</span></a></span></span><span> </span><span id="local-6989586621679880401"><span class="annot"><span class="annottext">chunks :: Int
</span><a href="#local-6989586621679880401"><span class="hs-identifier hs-var">chunks</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880400"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880400"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880399"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880399"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO [Tensor] -&gt; [Tensor]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span>
</span><span id="line-1179"></span><span>  </span><span class="annot"><span class="annottext">(IO [Tensor] -&gt; [Tensor]) -&gt; IO [Tensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr TensorList))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; IO [Tensor]
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr TensorList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.chunk_tll</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880399"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880401"><span class="hs-identifier hs-var">chunks</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880400"><span class="hs-identifier hs-var">d</span></a></span><span>
</span><span id="line-1180"></span><span>
</span><span id="line-1181"></span><span class="hs-comment">-- | Clamp all elements in input into the range [ min, max ] and return a resulting tensor.</span><span>
</span><span id="line-1182"></span><span class="annot"><a href="Torch.Functional.html#clamp"><span class="hs-identifier hs-type">clamp</span></a></span><span>
</span><span id="line-1183"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ minimum value</span><span>
</span><span id="line-1184"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ maximum value</span><span>
</span><span id="line-1185"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1186"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1187"></span><span id="clamp"><span class="annot"><span class="annottext">clamp :: Float -&gt; Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#clamp"><span class="hs-identifier hs-var hs-var">clamp</span></a></span></span><span> </span><span id="local-6989586621679880396"><span class="annot"><span class="annottext">min :: Float
</span><a href="#local-6989586621679880396"><span class="hs-identifier hs-var">min</span></a></span></span><span> </span><span id="local-6989586621679880395"><span class="annot"><span class="annottext">max :: Float
</span><a href="#local-6989586621679880395"><span class="hs-identifier hs-var">max</span></a></span></span><span> </span><span id="local-6989586621679880394"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880394"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Float -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.clamp_tss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880394"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880396"><span class="hs-identifier hs-var">min</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880395"><span class="hs-identifier hs-var">max</span></a></span><span>
</span><span id="line-1188"></span><span>
</span><span id="line-1189"></span><span class="hs-comment">-- | Clamps all elements in input to be smaller or equal max.</span><span>
</span><span id="line-1190"></span><span class="annot"><a href="Torch.Functional.html#clampMax"><span class="hs-identifier hs-type">clampMax</span></a></span><span>
</span><span id="line-1191"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ maximum value</span><span>
</span><span id="line-1192"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1193"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1194"></span><span id="clampMax"><span class="annot"><span class="annottext">clampMax :: Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#clampMax"><span class="hs-identifier hs-var hs-var">clampMax</span></a></span></span><span> </span><span id="local-6989586621679880391"><span class="annot"><span class="annottext">max :: Float
</span><a href="#local-6989586621679880391"><span class="hs-identifier hs-var">max</span></a></span></span><span> </span><span id="local-6989586621679880390"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880390"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.clamp_max_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880390"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880391"><span class="hs-identifier hs-var">max</span></a></span><span>
</span><span id="line-1195"></span><span>
</span><span id="line-1196"></span><span class="hs-comment">-- | Clamps all elements in input to be larger or equal min.</span><span>
</span><span id="line-1197"></span><span class="annot"><a href="Torch.Functional.html#clampMin"><span class="hs-identifier hs-type">clampMin</span></a></span><span>
</span><span id="line-1198"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ minimum value</span><span>
</span><span id="line-1199"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1200"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1201"></span><span id="clampMin"><span class="annot"><span class="annottext">clampMin :: Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#clampMin"><span class="hs-identifier hs-var hs-var">clampMin</span></a></span></span><span> </span><span id="local-6989586621679880387"><span class="annot"><span class="annottext">min :: Float
</span><a href="#local-6989586621679880387"><span class="hs-identifier hs-var">min</span></a></span></span><span> </span><span id="local-6989586621679880386"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880386"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.clamp_min_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880386"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880387"><span class="hs-identifier hs-var">min</span></a></span><span>
</span><span id="line-1202"></span><span>
</span><span id="line-1203"></span><span class="annot"><a href="Torch.Functional.html#cudnnIsAcceptable"><span class="hs-identifier hs-type">cudnnIsAcceptable</span></a></span><span>
</span><span id="line-1204"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1205"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1206"></span><span id="cudnnIsAcceptable"><span class="annot"><span class="annottext">cudnnIsAcceptable :: Tensor -&gt; Bool
</span><a href="Torch.Functional.html#cudnnIsAcceptable"><span class="hs-identifier hs-var hs-var">cudnnIsAcceptable</span></a></span></span><span> </span><span id="local-6989586621679880383"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880383"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1207"></span><span>  </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool) -&gt; Tensor -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cudnn_is_acceptable_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880383"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1208"></span><span>
</span><span id="line-1209"></span><span class="hs-comment">-- | Pads the input tensor boundaries with a constant value.</span><span>
</span><span id="line-1210"></span><span class="annot"><a href="Torch.Functional.html#constantPadNd1d"><span class="hs-identifier hs-type">constantPadNd1d</span></a></span><span>
</span><span id="line-1211"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ list of padding per dimension</span><span>
</span><span id="line-1212"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ value</span><span>
</span><span id="line-1213"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1214"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ ouptut</span><span>
</span><span id="line-1215"></span><span id="constantPadNd1d"><span class="annot"><span class="annottext">constantPadNd1d :: [Int] -&gt; Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#constantPadNd1d"><span class="hs-identifier hs-var hs-var">constantPadNd1d</span></a></span></span><span> </span><span id="local-6989586621679880380"><span class="annot"><span class="annottext">padding :: [Int]
</span><a href="#local-6989586621679880380"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880379"><span class="annot"><span class="annottext">value :: Float
</span><a href="#local-6989586621679880379"><span class="hs-identifier hs-var">value</span></a></span></span><span> </span><span id="local-6989586621679880378"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880378"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; [Int] -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span>
</span><span id="line-1216"></span><span>  </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.constant_pad_nd_tls</span></a></span><span>
</span><span id="line-1217"></span><span>  </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880378"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1218"></span><span>  </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679880380"><span class="hs-identifier hs-var">padding</span></a></span><span>
</span><span id="line-1219"></span><span>  </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880379"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-1220"></span><span>
</span><span id="line-1221"></span><span class="hs-comment">--</span><span>
</span><span id="line-1222"></span><span class="hs-comment">-- convolutions</span><span>
</span><span id="line-1223"></span><span class="hs-comment">--</span><span>
</span><span id="line-1224"></span><span>
</span><span id="line-1225"></span><span class="hs-comment">-- | Applies a 1D convolution over an input signal composed of several input planes.</span><span>
</span><span id="line-1226"></span><span class="annot"><a href="Torch.Functional.html#conv1d"><span class="hs-identifier hs-type">conv1d</span></a></span><span>
</span><span id="line-1227"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weight</span><span>
</span><span id="line-1228"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ bias</span><span>
</span><span id="line-1229"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ stride</span><span>
</span><span id="line-1230"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-1231"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ dilation</span><span>
</span><span id="line-1232"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ groups</span><span>
</span><span id="line-1233"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1234"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1235"></span><span id="conv1d"><span class="annot"><span class="annottext">conv1d :: Tensor -&gt; Tensor -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#conv1d"><span class="hs-identifier hs-var hs-var">conv1d</span></a></span></span><span> </span><span id="local-6989586621679880375"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880375"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679880374"><span class="annot"><span class="annottext">bias :: Tensor
</span><a href="#local-6989586621679880374"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679880373"><span class="annot"><span class="annottext">stride :: Int
</span><a href="#local-6989586621679880373"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880372"><span class="annot"><span class="annottext">padding :: Int
</span><a href="#local-6989586621679880372"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880371"><span class="annot"><span class="annottext">dilation :: Int
</span><a href="#local-6989586621679880371"><span class="hs-identifier hs-var">dilation</span></a></span></span><span> </span><span id="local-6989586621679880370"><span class="annot"><span class="annottext">groups :: Int
</span><a href="#local-6989586621679880370"><span class="hs-identifier hs-var">groups</span></a></span></span><span> </span><span id="local-6989586621679880369"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880369"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1236"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast7</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.conv1d_tttllll</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1237"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880369"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1238"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880375"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-1239"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880374"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-1240"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880373"><span class="hs-identifier hs-var">stride</span></a></span><span>
</span><span id="line-1241"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880372"><span class="hs-identifier hs-var">padding</span></a></span><span>
</span><span id="line-1242"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880371"><span class="hs-identifier hs-var">dilation</span></a></span><span>
</span><span id="line-1243"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880370"><span class="hs-identifier hs-var">groups</span></a></span><span>
</span><span id="line-1244"></span><span>
</span><span id="line-1245"></span><span id="conv1d%27"><span class="annot"><span class="annottext">conv1d' :: Tensor -&gt; Tensor -&gt; Int -&gt; Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#conv1d%27"><span class="hs-identifier hs-var hs-var">conv1d'</span></a></span></span><span> </span><span id="local-6989586621679880366"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880366"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679880365"><span class="annot"><span class="annottext">bias :: Tensor
</span><a href="#local-6989586621679880365"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679880364"><span class="annot"><span class="annottext">stride :: Int
</span><a href="#local-6989586621679880364"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880363"><span class="annot"><span class="annottext">padding :: Int
</span><a href="#local-6989586621679880363"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880362"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880362"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#conv1d"><span class="hs-identifier hs-var">conv1d</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880366"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880365"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880364"><span class="hs-identifier hs-var">stride</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880363"><span class="hs-identifier hs-var">padding</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880362"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1246"></span><span>
</span><span id="line-1247"></span><span class="hs-comment">-- | Applies a 2D convolution over an input signal composed of several input planes.</span><span>
</span><span id="line-1248"></span><span class="annot"><a href="Torch.Functional.html#conv2d"><span class="hs-identifier hs-type">conv2d</span></a></span><span>
</span><span id="line-1249"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weight</span><span>
</span><span id="line-1250"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ bias</span><span>
</span><span id="line-1251"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ strides</span><span>
</span><span id="line-1252"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-1253"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ dilation</span><span>
</span><span id="line-1254"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ groups</span><span>
</span><span id="line-1255"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1256"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1257"></span><span id="conv2d"><span class="annot"><span class="annottext">conv2d :: Tensor
-&gt; Tensor
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; Int
-&gt; Tensor
-&gt; Tensor
</span><a href="Torch.Functional.html#conv2d"><span class="hs-identifier hs-var hs-var">conv2d</span></a></span></span><span> </span><span id="local-6989586621679880360"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880360"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679880359"><span class="annot"><span class="annottext">bias :: Tensor
</span><a href="#local-6989586621679880359"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880358"><span class="annot"><span class="annottext">stride0 :: Int
</span><a href="#local-6989586621679880358"><span class="hs-identifier hs-var">stride0</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880357"><span class="annot"><span class="annottext">stride1 :: Int
</span><a href="#local-6989586621679880357"><span class="hs-identifier hs-var">stride1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880356"><span class="annot"><span class="annottext">padding0 :: Int
</span><a href="#local-6989586621679880356"><span class="hs-identifier hs-var">padding0</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880355"><span class="annot"><span class="annottext">padding1 :: Int
</span><a href="#local-6989586621679880355"><span class="hs-identifier hs-var">padding1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880354"><span class="annot"><span class="annottext">dilation0 :: Int
</span><a href="#local-6989586621679880354"><span class="hs-identifier hs-var">dilation0</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880353"><span class="annot"><span class="annottext">dilation1 :: Int
</span><a href="#local-6989586621679880353"><span class="hs-identifier hs-var">dilation1</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880352"><span class="annot"><span class="annottext">groups :: Int
</span><a href="#local-6989586621679880352"><span class="hs-identifier hs-var">groups</span></a></span></span><span> </span><span id="local-6989586621679880351"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880351"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1258"></span><span>    </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Int
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast7</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.conv2d_tttllll</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1259"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880351"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1260"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880360"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-1261"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880359"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-1262"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880358"><span class="hs-identifier hs-var">stride0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880357"><span class="hs-identifier hs-var">stride1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1263"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880356"><span class="hs-identifier hs-var">padding0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880355"><span class="hs-identifier hs-var">padding1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1264"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880354"><span class="hs-identifier hs-var">dilation0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880353"><span class="hs-identifier hs-var">dilation1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1265"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880352"><span class="hs-identifier hs-var">groups</span></a></span><span>
</span><span id="line-1266"></span><span>
</span><span id="line-1267"></span><span class="annot"><a href="Torch.Functional.html#conv2d%27"><span class="hs-identifier hs-type">conv2d'</span></a></span><span>
</span><span id="line-1268"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ weight</span><span>
</span><span id="line-1269"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ bias</span><span>
</span><span id="line-1270"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ strides</span><span>
</span><span id="line-1271"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ padding</span><span>
</span><span id="line-1272"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1273"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1274"></span><span id="conv2d%27"><span class="annot"><span class="annottext">conv2d' :: Tensor -&gt; Tensor -&gt; (Int, Int) -&gt; (Int, Int) -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#conv2d%27"><span class="hs-identifier hs-var hs-var">conv2d'</span></a></span></span><span> </span><span id="local-6989586621679880348"><span class="annot"><span class="annottext">weight :: Tensor
</span><a href="#local-6989586621679880348"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679880347"><span class="annot"><span class="annottext">bias :: Tensor
</span><a href="#local-6989586621679880347"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679880346"><span class="annot"><span class="annottext">stride :: (Int, Int)
</span><a href="#local-6989586621679880346"><span class="hs-identifier hs-var">stride</span></a></span></span><span> </span><span id="local-6989586621679880345"><span class="annot"><span class="annottext">padding :: (Int, Int)
</span><a href="#local-6989586621679880345"><span class="hs-identifier hs-var">padding</span></a></span></span><span> </span><span id="local-6989586621679880344"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880344"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1275"></span><span>    </span><span class="annot"><span class="annottext">Tensor
-&gt; Tensor
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; (Int, Int)
-&gt; Int
-&gt; Tensor
-&gt; Tensor
</span><a href="Torch.Functional.html#conv2d"><span class="hs-identifier hs-var">conv2d</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880348"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880347"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880346"><span class="hs-identifier hs-var">stride</span></a></span><span> </span><span class="annot"><span class="annottext">(Int, Int)
</span><a href="#local-6989586621679880345"><span class="hs-identifier hs-var">padding</span></a></span><span>
</span><span id="line-1276"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- dilation</span><span>
</span><span id="line-1277"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- groups</span><span>
</span><span id="line-1278"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880344"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1279"></span><span>
</span><span id="line-1280"></span><span class="hs-comment">-- | Returns a new tensor with the signs of the elements of @input@</span><span>
</span><span id="line-1281"></span><span class="annot"><a href="Torch.Functional.html#sign"><span class="hs-identifier hs-type">sign</span></a></span><span>
</span><span id="line-1282"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1283"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1284"></span><span id="sign"><span class="annot"><span class="annottext">sign :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sign"><span class="hs-identifier hs-var hs-var">sign</span></a></span></span><span> </span><span id="local-6989586621679880342"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880342"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sign_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880342"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1285"></span><span>
</span><span id="line-1286"></span><span class="hs-comment">-- | Returns a tensor that is a transposed version of @input@. The given dimensions @dim0@ and @dim1@ are swapped.</span><span>
</span><span id="line-1287"></span><span class="annot"><a href="Torch.Functional.html#transpose"><span class="hs-identifier hs-type">transpose</span></a></span><span>
</span><span id="line-1288"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim1</span><span>
</span><span id="line-1289"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim2</span><span>
</span><span id="line-1290"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1291"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1292"></span><span id="transpose"><span class="annot"><span class="annottext">transpose :: Dim -&gt; Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#transpose"><span class="hs-identifier hs-var hs-var">transpose</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880340"><span class="annot"><span class="annottext">d1 :: Int
</span><a href="#local-6989586621679880340"><span class="hs-identifier hs-var">d1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880339"><span class="annot"><span class="annottext">d2 :: Int
</span><a href="#local-6989586621679880339"><span class="hs-identifier hs-var">d2</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880338"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880338"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.transpose_tll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880338"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880340"><span class="hs-identifier hs-var">d1</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880339"><span class="hs-identifier hs-var">d2</span></a></span><span>
</span><span id="line-1293"></span><span>
</span><span id="line-1294"></span><span class="hs-comment">-- | transpose special case for a 2D tensor</span><span>
</span><span id="line-1295"></span><span class="annot"><a href="Torch.Functional.html#transpose2D"><span class="hs-identifier hs-type">transpose2D</span></a></span><span>
</span><span id="line-1296"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1297"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1298"></span><span id="transpose2D"><span class="annot"><span class="annottext">transpose2D :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#transpose2D"><span class="hs-identifier hs-var hs-var">transpose2D</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Dim -&gt; Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Dim
</span><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Dim
</span><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-1299"></span><span>
</span><span id="line-1300"></span><span class="hs-comment">-- | Returns a tensor with the elements of input as the diagonal.</span><span>
</span><span id="line-1301"></span><span class="hs-comment">-- The second argument controls which diagonal to consider:</span><span>
</span><span id="line-1302"></span><span class="hs-comment">--        If Int = 0, it is the main diagonal.</span><span>
</span><span id="line-1303"></span><span class="hs-comment">--        If Int &gt; 0, it is above the main diagonal.</span><span>
</span><span id="line-1304"></span><span class="hs-comment">--        If Int &lt; 0, it is below the main diagonal.</span><span>
</span><span id="line-1305"></span><span class="annot"><a href="Torch.Functional.html#diag"><span class="hs-identifier hs-type">diag</span></a></span><span>
</span><span id="line-1306"></span><span>    </span><span class="hs-glyph">::</span><span>  </span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span class="hs-comment">-- ^ diagonal</span><span>
</span><span id="line-1307"></span><span>    </span><span class="hs-glyph">-&gt;</span><span>  </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1308"></span><span>    </span><span class="hs-glyph">-&gt;</span><span>  </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1309"></span><span id="diag"><span class="annot"><span class="annottext">diag :: Diag -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#diag"><span class="hs-identifier hs-var hs-var">diag</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span id="local-6989586621679880334"><span class="annot"><span class="annottext">index :: Int
</span><a href="#local-6989586621679880334"><span class="hs-identifier hs-var">index</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880333"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880333"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_diag_l</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880333"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880334"><span class="hs-identifier hs-var">index</span></a></span><span>
</span><span id="line-1310"></span><span>
</span><span id="line-1311"></span><span class="hs-comment">--</span><span>
</span><span id="line-1312"></span><span class="annot"><a href="Torch.Functional.html#diagEmbed"><span class="hs-identifier hs-type">diagEmbed</span></a></span><span>
</span><span id="line-1313"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span class="hs-comment">-- ^ offset</span><span>
</span><span id="line-1314"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim1</span><span>
</span><span id="line-1315"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim2</span><span>
</span><span id="line-1316"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1317"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1318"></span><span id="diagEmbed"><span class="annot"><span class="annottext">diagEmbed :: Diag -&gt; Dim -&gt; Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#diagEmbed"><span class="hs-identifier hs-var hs-var">diagEmbed</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span id="local-6989586621679880330"><span class="annot"><span class="annottext">offset :: Int
</span><a href="#local-6989586621679880330"><span class="hs-identifier hs-var">offset</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880329"><span class="annot"><span class="annottext">dim1 :: Int
</span><a href="#local-6989586621679880329"><span class="hs-identifier hs-var">dim1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880328"><span class="annot"><span class="annottext">dim2 :: Int
</span><a href="#local-6989586621679880328"><span class="hs-identifier hs-var">dim2</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880327"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880327"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.diag_embed_tlll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880327"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880330"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880329"><span class="hs-identifier hs-var">dim1</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880328"><span class="hs-identifier hs-var">dim2</span></a></span><span>
</span><span id="line-1319"></span><span>
</span><span id="line-1320"></span><span class="hs-comment">-- | If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal.</span><span>
</span><span id="line-1321"></span><span class="hs-comment">-- If input is a tensor with more than one dimension, then returns a 2-D tensor with diagonal elements equal to a flattened input.</span><span>
</span><span id="line-1322"></span><span class="hs-comment">-- The argument offset controls which diagonal to consider:</span><span>
</span><span id="line-1323"></span><span class="hs-comment">--  If offset = 0, it is the main diagonal.</span><span>
</span><span id="line-1324"></span><span class="hs-comment">--  If offset &gt; 0, it is above the main diagonal.</span><span>
</span><span id="line-1325"></span><span class="hs-comment">--  If offset &lt; 0, it is below the main diagonal.</span><span>
</span><span id="line-1326"></span><span class="annot"><a href="Torch.Functional.html#diagflat"><span class="hs-identifier hs-type">diagflat</span></a></span><span>
</span><span id="line-1327"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span class="hs-comment">-- ^ offset</span><span>
</span><span id="line-1328"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1329"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1330"></span><span id="diagflat"><span class="annot"><span class="annottext">diagflat :: Diag -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#diagflat"><span class="hs-identifier hs-var hs-var">diagflat</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span id="local-6989586621679880324"><span class="annot"><span class="annottext">offset :: Int
</span><a href="#local-6989586621679880324"><span class="hs-identifier hs-var">offset</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880323"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880323"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.diagflat_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880323"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880324"><span class="hs-identifier hs-var">offset</span></a></span><span>
</span><span id="line-1331"></span><span>
</span><span id="line-1332"></span><span class="hs-comment">-- | Returns a partial view of input with the its diagonal elements with respect to dim1 and dim2 appended as a dimension at the end of the shape.</span><span>
</span><span id="line-1333"></span><span class="hs-comment">-- Applying diagEmbed to the output of this function with the same arguments yields a diagonal matrix with the diagonal entries of the input. However, diagEmbed has different default dimensions, so those need to be explicitly specified.</span><span>
</span><span id="line-1334"></span><span class="annot"><a href="Torch.Functional.html#diagonal"><span class="hs-identifier hs-type">diagonal</span></a></span><span>
</span><span id="line-1335"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span class="hs-comment">-- ^ offset</span><span>
</span><span id="line-1336"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim1</span><span>
</span><span id="line-1337"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim2</span><span>
</span><span id="line-1338"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1339"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1340"></span><span id="diagonal"><span class="annot"><span class="annottext">diagonal :: Diag -&gt; Dim -&gt; Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#diagonal"><span class="hs-identifier hs-var hs-var">diagonal</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span id="local-6989586621679880320"><span class="annot"><span class="annottext">offset :: Int
</span><a href="#local-6989586621679880320"><span class="hs-identifier hs-var">offset</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880319"><span class="annot"><span class="annottext">dim1 :: Int
</span><a href="#local-6989586621679880319"><span class="hs-identifier hs-var">dim1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880318"><span class="annot"><span class="annottext">dim2 :: Int
</span><a href="#local-6989586621679880318"><span class="hs-identifier hs-var">dim2</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880317"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880317"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.diagonal_tlll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880317"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880320"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880319"><span class="hs-identifier hs-var">dim1</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880318"><span class="hs-identifier hs-var">dim2</span></a></span><span>
</span><span id="line-1341"></span><span>
</span><span id="line-1342"></span><span>
</span><span id="line-1343"></span><span class="hs-comment">-- | Returns True if all elements in the tensor are True, False otherwise.</span><span>
</span><span id="line-1344"></span><span class="annot"><a href="Torch.Functional.html#all"><span class="hs-identifier hs-type">all</span></a></span><span>
</span><span id="line-1345"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1346"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1347"></span><span id="all"><span class="annot"><span class="annottext">all :: Tensor -&gt; Bool
</span><a href="Torch.Functional.html#all"><span class="hs-identifier hs-var hs-var">all</span></a></span></span><span> </span><span id="local-6989586621679880315"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880315"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Int
</span><a href="Torch.Tensor.html#toInt"><span class="hs-identifier hs-var">toInt</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.all_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880315"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-1348"></span><span>
</span><span id="line-1349"></span><span class="hs-comment">-- | Returns True if any elements in the tensor are True, False otherwise.</span><span>
</span><span id="line-1350"></span><span class="annot"><a href="Torch.Functional.html#any"><span class="hs-identifier hs-type">any</span></a></span><span>
</span><span id="line-1351"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1352"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1353"></span><span id="any"><span class="annot"><span class="annottext">any :: Tensor -&gt; Bool
</span><a href="Torch.Functional.html#any"><span class="hs-identifier hs-var hs-var">any</span></a></span></span><span> </span><span id="local-6989586621679880311"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880311"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Int
</span><a href="Torch.Tensor.html#toInt"><span class="hs-identifier hs-var">toInt</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.any_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880311"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-1354"></span><span>
</span><span id="line-1355"></span><span>
</span><span id="line-1356"></span><span class="hs-comment">-- | Returns True if all elements in each row of the tensor in the given dimension dim are True, False otherwise.</span><span>
</span><span id="line-1357"></span><span class="hs-comment">-- If keepdim is True, the output tensor is of the same size as input except in the dimension dim where it is of size 1. Otherwise, dim is squeezed, resulting in the output tensor having 1 fewer dimension than input.</span><span>
</span><span id="line-1358"></span><span class="annot"><a href="Torch.Functional.html#allDim"><span class="hs-identifier hs-type">allDim</span></a></span><span>
</span><span id="line-1359"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1360"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ boolean corresponding to keepdim</span><span>
</span><span id="line-1361"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1362"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1363"></span><span id="allDim"><span class="annot"><span class="annottext">allDim :: Dim -&gt; Bool -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#allDim"><span class="hs-identifier hs-var hs-var">allDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880308"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880308"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880307"><span class="annot"><span class="annottext">keepdim :: Bool
</span><a href="#local-6989586621679880307"><span class="hs-identifier hs-var">keepdim</span></a></span></span><span> </span><span id="local-6989586621679880306"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880306"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.all_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880306"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880308"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880307"><span class="hs-identifier hs-var">keepdim</span></a></span><span>
</span><span id="line-1364"></span><span>
</span><span id="line-1365"></span><span class="hs-comment">-- | Returns True if any elements in each row of the tensor in the given dimension dim are True, False otherwise.</span><span>
</span><span id="line-1366"></span><span class="hs-comment">-- If keepdim is True, the output tensor is of the same size as input except in the dimension dim where it is of size 1. Otherwise, dim is squeezed, resulting in the output tensor having 1 fewer dimension than input.</span><span>
</span><span id="line-1367"></span><span class="annot"><a href="Torch.Functional.html#anyDim"><span class="hs-identifier hs-type">anyDim</span></a></span><span>
</span><span id="line-1368"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1369"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ boolean corresponding to keepdim</span><span>
</span><span id="line-1370"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1371"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- output</span><span>
</span><span id="line-1372"></span><span id="anyDim"><span class="annot"><span class="annottext">anyDim :: Dim -&gt; Bool -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#anyDim"><span class="hs-identifier hs-var hs-var">anyDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880303"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880303"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880302"><span class="annot"><span class="annottext">keepdim :: Bool
</span><a href="#local-6989586621679880302"><span class="hs-identifier hs-var">keepdim</span></a></span></span><span> </span><span id="local-6989586621679880301"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880301"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.any_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880301"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880303"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880302"><span class="hs-identifier hs-var">keepdim</span></a></span><span>
</span><span id="line-1373"></span><span>
</span><span id="line-1374"></span><span class="hs-comment">-- | Permute the dimensions of this tensor.</span><span>
</span><span id="line-1375"></span><span class="annot"><a href="Torch.Functional.html#permute"><span class="hs-identifier hs-type">permute</span></a></span><span>
</span><span id="line-1376"></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ list corresponding to ordering of dimensions to permute with</span><span>
</span><span id="line-1377"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1378"></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- output</span><span>
</span><span id="line-1379"></span><span id="permute"><span class="annot"><span class="annottext">permute :: [Int] -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#permute"><span class="hs-identifier hs-var hs-var">permute</span></a></span></span><span> </span><span id="local-6989586621679880298"><span class="annot"><span class="annottext">dims :: [Int]
</span><a href="#local-6989586621679880298"><span class="hs-identifier hs-var">dims</span></a></span></span><span> </span><span id="local-6989586621679880297"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880297"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; [Int] -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_permute_l</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880297"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679880298"><span class="hs-identifier hs-var">dims</span></a></span><span>
</span><span id="line-1380"></span><span>
</span><span id="line-1381"></span><span class="hs-comment">-- | expand</span><span>
</span><span id="line-1382"></span><span class="hs-comment">-- TODO: figure out what the `implicit` boolean value does</span><span>
</span><span id="line-1383"></span><span class="annot"><a href="Torch.Functional.html#expand"><span class="hs-identifier hs-type">expand</span></a></span><span>
</span><span id="line-1384"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1385"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ some boolean value with unknown function</span><span>
</span><span id="line-1386"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ the desired expanded size</span><span>
</span><span id="line-1387"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1388"></span><span id="expand"><span class="annot"><span class="annottext">expand :: Tensor -&gt; Bool -&gt; [Int] -&gt; Tensor
</span><a href="Torch.Functional.html#expand"><span class="hs-identifier hs-var hs-var">expand</span></a></span></span><span> </span><span id="local-6989586621679880294"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880294"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span id="local-6989586621679880293"><span class="annot"><span class="annottext">someBool :: Bool
</span><a href="#local-6989586621679880293"><span class="hs-identifier hs-var">someBool</span></a></span></span><span> </span><span id="local-6989586621679880292"><span class="annot"><span class="annottext">dims :: [Int]
</span><a href="#local-6989586621679880292"><span class="hs-identifier hs-var">dims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; [Int] -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_expand_lb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880294"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679880292"><span class="hs-identifier hs-var">dims</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880293"><span class="hs-identifier hs-var">someBool</span></a></span><span>
</span><span id="line-1389"></span><span>
</span><span id="line-1390"></span><span class="hs-comment">-- | flatten</span><span>
</span><span id="line-1391"></span><span class="annot"><a href="Torch.Functional.html#flatten"><span class="hs-identifier hs-type">flatten</span></a></span><span>
</span><span id="line-1392"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ startDim</span><span>
</span><span id="line-1393"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ endDim</span><span>
</span><span id="line-1394"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1395"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1396"></span><span id="flatten"><span class="annot"><span class="annottext">flatten :: Dim -&gt; Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#flatten"><span class="hs-identifier hs-var hs-var">flatten</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880289"><span class="annot"><span class="annottext">startDim :: Int
</span><a href="#local-6989586621679880289"><span class="hs-identifier hs-var">startDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880288"><span class="annot"><span class="annottext">endDim :: Int
</span><a href="#local-6989586621679880288"><span class="hs-identifier hs-var">endDim</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880287"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880287"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.flatten_tll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880287"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880289"><span class="hs-identifier hs-var">startDim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880288"><span class="hs-identifier hs-var">endDim</span></a></span><span>
</span><span id="line-1397"></span><span>
</span><span id="line-1398"></span><span class="hs-comment">-- | flattenAll</span><span>
</span><span id="line-1399"></span><span class="annot"><a href="Torch.Functional.html#flattenAll"><span class="hs-identifier hs-type">flattenAll</span></a></span><span>
</span><span id="line-1400"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1401"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1402"></span><span id="flattenAll"><span class="annot"><span class="annottext">flattenAll :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#flattenAll"><span class="hs-identifier hs-var hs-var">flattenAll</span></a></span></span><span> </span><span id="local-6989586621679880284"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880284"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1403"></span><span>  </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.flatten_tll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880284"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-1404"></span><span>
</span><span id="line-1405"></span><span class="hs-comment">-- Not used yet</span><span>
</span><span id="line-1406"></span><span class="hs-keyword">data</span><span> </span><span id="RNNParams"><span class="annot"><a href="Torch.Functional.html#RNNParams"><span class="hs-identifier hs-var">RNNParams</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="RNNParams"><span class="annot"><a href="Torch.Functional.html#RNNParams"><span class="hs-identifier hs-var">RNNParams</span></a></span></span><span> </span><span class="hs-special">{</span><span>
</span><span id="line-1407"></span><span>    </span><span id="weightIH"><span class="annot"><span class="annottext">RNNParams -&gt; Tensor
</span><a href="Torch.Functional.html#weightIH"><span class="hs-identifier hs-var hs-var">weightIH</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1408"></span><span>    </span><span id="weightHH"><span class="annot"><span class="annottext">RNNParams -&gt; Tensor
</span><a href="Torch.Functional.html#weightHH"><span class="hs-identifier hs-var hs-var">weightHH</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1409"></span><span>    </span><span id="biasIH"><span class="annot"><span class="annottext">RNNParams -&gt; Tensor
</span><a href="Torch.Functional.html#biasIH"><span class="hs-identifier hs-var hs-var">biasIH</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1410"></span><span>    </span><span id="biasHH"><span class="annot"><span class="annottext">RNNParams -&gt; Tensor
</span><a href="Torch.Functional.html#biasHH"><span class="hs-identifier hs-var hs-var">biasHH</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1411"></span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880273"><span id="local-6989586621679880275"><span id="local-6989586621679880277"><span class="annot"><span class="annottext">Int -&gt; RNNParams -&gt; ShowS
[RNNParams] -&gt; ShowS
RNNParams -&gt; String
(Int -&gt; RNNParams -&gt; ShowS)
-&gt; (RNNParams -&gt; String)
-&gt; ([RNNParams] -&gt; ShowS)
-&gt; Show RNNParams
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [RNNParams] -&gt; ShowS
$cshowList :: [RNNParams] -&gt; ShowS
show :: RNNParams -&gt; String
$cshow :: RNNParams -&gt; String
showsPrec :: Int -&gt; RNNParams -&gt; ShowS
$cshowsPrec :: Int -&gt; RNNParams -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-1412"></span><span>
</span><span id="line-1413"></span><span class="hs-comment">-- | A long short-term memory (LSTM) cell.</span><span>
</span><span id="line-1414"></span><span class="annot"><a href="Torch.Functional.html#lstmCell"><span class="hs-identifier hs-type">lstmCell</span></a></span><span>
</span><span id="line-1415"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights (4*hidden_size, input_size)</span><span>
</span><span id="line-1416"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights (4*hidden_size, hidden_size)</span><span>
</span><span id="line-1417"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias (4*hidden_size)</span><span>
</span><span id="line-1418"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias, of shape (4*hidden_size)</span><span>
</span><span id="line-1419"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1420"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1421"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- next hidden state, next cell state</span><span>
</span><span id="line-1422"></span><span id="lstmCell"><span class="annot"><span class="annottext">lstmCell :: Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; (Tensor, Tensor)
-&gt; Tensor
-&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#lstmCell"><span class="hs-identifier hs-var hs-var">lstmCell</span></a></span></span><span> </span><span id="local-6989586621679880271"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880271"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880270"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880270"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880269"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880269"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880268"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880268"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880267"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880267"><span class="hs-identifier hs-var">_hx</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880266"><span class="annot"><span class="annottext">_cx :: Tensor
</span><a href="#local-6989586621679880266"><span class="hs-identifier hs-var">_cx</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880265"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880265"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1423"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1424"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorList
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor
-&gt; [Tensor]
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorList
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lstm_cell_tltttt</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1425"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880265"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880267"><span class="hs-identifier hs-var">_hx</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880266"><span class="hs-identifier hs-var">_cx</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880271"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880270"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880269"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880268"><span class="hs-identifier hs-var">_b_hh</span></a></span><span> </span><span class="hs-comment">-- TODO: make cast work with 2-tuples</span><span>
</span><span id="line-1426"></span><span>
</span><span id="line-1427"></span><span class="hs-comment">-- | A gated recurrent unit (GRU) cell</span><span>
</span><span id="line-1428"></span><span class="annot"><a href="Torch.Functional.html#gruCell"><span class="hs-identifier hs-type">gruCell</span></a></span><span>
</span><span id="line-1429"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights</span><span>
</span><span id="line-1430"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights</span><span>
</span><span id="line-1431"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias</span><span>
</span><span id="line-1432"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias</span><span>
</span><span id="line-1433"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1434"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1435"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1436"></span><span id="gruCell"><span class="annot"><span class="annottext">gruCell :: Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#gruCell"><span class="hs-identifier hs-var hs-var">gruCell</span></a></span></span><span> </span><span id="local-6989586621679880262"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880262"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880261"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880261"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880260"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880260"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880259"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880259"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span id="local-6989586621679880258"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880258"><span class="hs-identifier hs-var">_hx</span></a></span></span><span> </span><span id="local-6989586621679880257"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880257"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1437"></span><span>  </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1438"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.gru_cell_tttttt</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1439"></span><span>    </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880257"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880258"><span class="hs-identifier hs-var">_hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880262"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880261"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880260"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880259"><span class="hs-identifier hs-var">_b_hh</span></a></span><span>
</span><span id="line-1440"></span><span>
</span><span id="line-1441"></span><span class="hs-comment">-- | An Elman RNN cell with tanh non-linearity</span><span>
</span><span id="line-1442"></span><span class="annot"><a href="Torch.Functional.html#rnnTanhCell"><span class="hs-identifier hs-type">rnnTanhCell</span></a></span><span>
</span><span id="line-1443"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights</span><span>
</span><span id="line-1444"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights</span><span>
</span><span id="line-1445"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias</span><span>
</span><span id="line-1446"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias</span><span>
</span><span id="line-1447"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1448"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1449"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1450"></span><span id="rnnTanhCell"><span class="annot"><span class="annottext">rnnTanhCell :: Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#rnnTanhCell"><span class="hs-identifier hs-var hs-var">rnnTanhCell</span></a></span></span><span> </span><span id="local-6989586621679880254"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880254"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880253"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880253"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880252"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880252"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880251"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880251"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span id="local-6989586621679880250"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880250"><span class="hs-identifier hs-var">_hx</span></a></span></span><span> </span><span id="local-6989586621679880249"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880249"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1451"></span><span>  </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.rnn_tanh_cell_tttttt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880249"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880250"><span class="hs-identifier hs-var">_hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880254"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880253"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880252"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880251"><span class="hs-identifier hs-var">_b_hh</span></a></span><span>
</span><span id="line-1452"></span><span>
</span><span id="line-1453"></span><span class="hs-comment">-- | An Elman RNN cell with ReLU non-linearity</span><span>
</span><span id="line-1454"></span><span class="annot"><a href="Torch.Functional.html#rnnReluCell"><span class="hs-identifier hs-type">rnnReluCell</span></a></span><span>
</span><span id="line-1455"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights</span><span>
</span><span id="line-1456"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights</span><span>
</span><span id="line-1457"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias</span><span>
</span><span id="line-1458"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias</span><span>
</span><span id="line-1459"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1460"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1461"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1462"></span><span id="rnnReluCell"><span class="annot"><span class="annottext">rnnReluCell :: Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#rnnReluCell"><span class="hs-identifier hs-var hs-var">rnnReluCell</span></a></span></span><span> </span><span id="local-6989586621679880246"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880246"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880245"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880245"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880244"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880244"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880243"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880243"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span id="local-6989586621679880242"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880242"><span class="hs-identifier hs-var">_hx</span></a></span></span><span> </span><span id="local-6989586621679880241"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880241"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1463"></span><span>  </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.rnn_relu_cell_tttttt</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880241"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880242"><span class="hs-identifier hs-var">_hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880246"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880245"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880244"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880243"><span class="hs-identifier hs-var">_b_hh</span></a></span><span>
</span><span id="line-1464"></span><span>
</span><span id="line-1465"></span><span class="hs-comment">-- | A quantized long short-term memory (LSTM) cell.</span><span>
</span><span id="line-1466"></span><span class="annot"><a href="Torch.Functional.html#quantizedLstmCell"><span class="hs-identifier hs-type">quantizedLstmCell</span></a></span><span>
</span><span id="line-1467"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights</span><span>
</span><span id="line-1468"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights</span><span>
</span><span id="line-1469"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias</span><span>
</span><span id="line-1470"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias</span><span>
</span><span id="line-1471"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden packed</span><span>
</span><span id="line-1472"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden packed</span><span>
</span><span id="line-1473"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden column offsets</span><span>
</span><span id="line-1474"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden column offsets</span><span>
</span><span id="line-1475"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden scale</span><span>
</span><span id="line-1476"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden scale</span><span>
</span><span id="line-1477"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden zero point</span><span>
</span><span id="line-1478"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden zero point</span><span>
</span><span id="line-1479"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1480"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1481"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1482"></span><span id="quantizedLstmCell"><span class="annot"><span class="annottext">quantizedLstmCell :: Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; (Tensor, Tensor)
-&gt; Tensor
-&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#quantizedLstmCell"><span class="hs-identifier hs-var hs-var">quantizedLstmCell</span></a></span></span><span> </span><span id="local-6989586621679880238"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880238"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880237"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880237"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880236"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880236"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880235"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880235"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span id="local-6989586621679880234"><span class="annot"><span class="annottext">_packed_ih :: Tensor
</span><a href="#local-6989586621679880234"><span class="hs-identifier hs-var">_packed_ih</span></a></span></span><span> </span><span id="local-6989586621679880233"><span class="annot"><span class="annottext">_packed_hh :: Tensor
</span><a href="#local-6989586621679880233"><span class="hs-identifier hs-var">_packed_hh</span></a></span></span><span> </span><span id="local-6989586621679880232"><span class="annot"><span class="annottext">_col_offsets_ih :: Tensor
</span><a href="#local-6989586621679880232"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span></span><span> </span><span id="local-6989586621679880231"><span class="annot"><span class="annottext">_col_offsets_hh :: Tensor
</span><a href="#local-6989586621679880231"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span></span><span> </span><span id="local-6989586621679880230"><span class="annot"><span class="annottext">_scale_ih :: Float
</span><a href="#local-6989586621679880230"><span class="hs-identifier hs-var">_scale_ih</span></a></span></span><span> </span><span id="local-6989586621679880229"><span class="annot"><span class="annottext">_scale_hh :: Float
</span><a href="#local-6989586621679880229"><span class="hs-identifier hs-var">_scale_hh</span></a></span></span><span> </span><span id="local-6989586621679880228"><span class="annot"><span class="annottext">_zero_point_ih :: Float
</span><a href="#local-6989586621679880228"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span></span><span> </span><span id="local-6989586621679880227"><span class="annot"><span class="annottext">_zero_point_hh :: Float
</span><a href="#local-6989586621679880227"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880226"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880226"><span class="hs-identifier hs-var">_hx</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880225"><span class="annot"><span class="annottext">_cx :: Tensor
</span><a href="#local-6989586621679880225"><span class="hs-identifier hs-var">_cx</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880224"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880224"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1483"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1484"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorList
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor
-&gt; [Tensor]
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 x7 cx7 x8 cx8
       x9 cx9 x10 cx10 x11 cx11 x12 cx12 x13 cx13 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6, Castable x7 cx7,
 Castable x8 cx8, Castable x9 cx9, Castable x10 cx10,
 Castable x11 cx11, Castable x12 cx12, Castable x13 cx13,
 Castable y cy) =&gt;
(ca
 -&gt; cx1
 -&gt; cx2
 -&gt; cx3
 -&gt; cx4
 -&gt; cx5
 -&gt; cx6
 -&gt; cx7
 -&gt; cx8
 -&gt; cx9
 -&gt; cx10
 -&gt; cx11
 -&gt; cx12
 -&gt; cx13
 -&gt; IO cy)
-&gt; a
-&gt; x1
-&gt; x2
-&gt; x3
-&gt; x4
-&gt; x5
-&gt; x6
-&gt; x7
-&gt; x8
-&gt; x9
-&gt; x10
-&gt; x11
-&gt; x12
-&gt; x13
-&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast14</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorList
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.quantized_lstm_cell_tlttttttttssss</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1485"></span><span>        </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880224"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880226"><span class="hs-identifier hs-var">_hx</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880225"><span class="hs-identifier hs-var">_cx</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880238"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880237"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880236"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880235"><span class="hs-identifier hs-var">_b_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880234"><span class="hs-identifier hs-var">_packed_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880233"><span class="hs-identifier hs-var">_packed_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880232"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880231"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880230"><span class="hs-identifier hs-var">_scale_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880229"><span class="hs-identifier hs-var">_scale_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880228"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880227"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span><span>
</span><span id="line-1486"></span><span>
</span><span id="line-1487"></span><span class="hs-comment">-- | A quantized long gated recurrent unit (GRU) cell.</span><span>
</span><span id="line-1488"></span><span class="annot"><a href="Torch.Functional.html#quantizedGruCell"><span class="hs-identifier hs-type">quantizedGruCell</span></a></span><span>
</span><span id="line-1489"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights</span><span>
</span><span id="line-1490"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights</span><span>
</span><span id="line-1491"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias</span><span>
</span><span id="line-1492"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias</span><span>
</span><span id="line-1493"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden packed</span><span>
</span><span id="line-1494"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden packed</span><span>
</span><span id="line-1495"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden column offsets</span><span>
</span><span id="line-1496"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden column offsets</span><span>
</span><span id="line-1497"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden scale</span><span>
</span><span id="line-1498"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden scale</span><span>
</span><span id="line-1499"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden zero point</span><span>
</span><span id="line-1500"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden zero point</span><span>
</span><span id="line-1501"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1502"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1503"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1504"></span><span id="quantizedGruCell"><span class="annot"><span class="annottext">quantizedGruCell :: Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
</span><a href="Torch.Functional.html#quantizedGruCell"><span class="hs-identifier hs-var hs-var">quantizedGruCell</span></a></span></span><span> </span><span id="local-6989586621679880220"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880220"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880219"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880219"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880218"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880218"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880217"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880217"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span id="local-6989586621679880216"><span class="annot"><span class="annottext">_packed_ih :: Tensor
</span><a href="#local-6989586621679880216"><span class="hs-identifier hs-var">_packed_ih</span></a></span></span><span> </span><span id="local-6989586621679880215"><span class="annot"><span class="annottext">_packed_hh :: Tensor
</span><a href="#local-6989586621679880215"><span class="hs-identifier hs-var">_packed_hh</span></a></span></span><span> </span><span id="local-6989586621679880214"><span class="annot"><span class="annottext">_col_offsets_ih :: Tensor
</span><a href="#local-6989586621679880214"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span></span><span> </span><span id="local-6989586621679880213"><span class="annot"><span class="annottext">_col_offsets_hh :: Tensor
</span><a href="#local-6989586621679880213"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span></span><span> </span><span id="local-6989586621679880212"><span class="annot"><span class="annottext">_scale_ih :: Float
</span><a href="#local-6989586621679880212"><span class="hs-identifier hs-var">_scale_ih</span></a></span></span><span> </span><span id="local-6989586621679880211"><span class="annot"><span class="annottext">_scale_hh :: Float
</span><a href="#local-6989586621679880211"><span class="hs-identifier hs-var">_scale_hh</span></a></span></span><span> </span><span id="local-6989586621679880210"><span class="annot"><span class="annottext">_zero_point_ih :: Float
</span><a href="#local-6989586621679880210"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span></span><span> </span><span id="local-6989586621679880209"><span class="annot"><span class="annottext">_zero_point_hh :: Float
</span><a href="#local-6989586621679880209"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span></span><span> </span><span id="local-6989586621679880208"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880208"><span class="hs-identifier hs-var">_hx</span></a></span></span><span> </span><span id="local-6989586621679880207"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880207"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1505"></span><span>  </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 x7 cx7 x8 cx8
       x9 cx9 x10 cx10 x11 cx11 x12 cx12 x13 cx13 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6, Castable x7 cx7,
 Castable x8 cx8, Castable x9 cx9, Castable x10 cx10,
 Castable x11 cx11, Castable x12 cx12, Castable x13 cx13,
 Castable y cy) =&gt;
(ca
 -&gt; cx1
 -&gt; cx2
 -&gt; cx3
 -&gt; cx4
 -&gt; cx5
 -&gt; cx6
 -&gt; cx7
 -&gt; cx8
 -&gt; cx9
 -&gt; cx10
 -&gt; cx11
 -&gt; cx12
 -&gt; cx13
 -&gt; IO cy)
-&gt; a
-&gt; x1
-&gt; x2
-&gt; x3
-&gt; x4
-&gt; x5
-&gt; x6
-&gt; x7
-&gt; x8
-&gt; x9
-&gt; x10
-&gt; x11
-&gt; x12
-&gt; x13
-&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast14</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.quantized_gru_cell_ttttttttttssss</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880207"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880208"><span class="hs-identifier hs-var">_hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880220"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880219"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880218"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880217"><span class="hs-identifier hs-var">_b_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880216"><span class="hs-identifier hs-var">_packed_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880215"><span class="hs-identifier hs-var">_packed_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880214"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880213"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880212"><span class="hs-identifier hs-var">_scale_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880211"><span class="hs-identifier hs-var">_scale_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880210"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880209"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span><span>
</span><span id="line-1506"></span><span>
</span><span id="line-1507"></span><span class="hs-comment">-- | A quantized Elman RNN cell with relu non-linearity</span><span>
</span><span id="line-1508"></span><span class="annot"><a href="Torch.Functional.html#quantizedRnnReluCell"><span class="hs-identifier hs-type">quantizedRnnReluCell</span></a></span><span>
</span><span id="line-1509"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights</span><span>
</span><span id="line-1510"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights</span><span>
</span><span id="line-1511"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias</span><span>
</span><span id="line-1512"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias</span><span>
</span><span id="line-1513"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden packed</span><span>
</span><span id="line-1514"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden packed</span><span>
</span><span id="line-1515"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden column offsets</span><span>
</span><span id="line-1516"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden column offsets</span><span>
</span><span id="line-1517"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden scale</span><span>
</span><span id="line-1518"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden scale</span><span>
</span><span id="line-1519"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden zero point</span><span>
</span><span id="line-1520"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden zero point</span><span>
</span><span id="line-1521"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1522"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1523"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1524"></span><span id="quantizedRnnReluCell"><span class="annot"><span class="annottext">quantizedRnnReluCell :: Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
</span><a href="Torch.Functional.html#quantizedRnnReluCell"><span class="hs-identifier hs-var hs-var">quantizedRnnReluCell</span></a></span></span><span> </span><span id="local-6989586621679880204"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880204"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880203"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880203"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880202"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880202"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880201"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880201"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span id="local-6989586621679880200"><span class="annot"><span class="annottext">_packed_ih :: Tensor
</span><a href="#local-6989586621679880200"><span class="hs-identifier hs-var">_packed_ih</span></a></span></span><span> </span><span id="local-6989586621679880199"><span class="annot"><span class="annottext">_packed_hh :: Tensor
</span><a href="#local-6989586621679880199"><span class="hs-identifier hs-var">_packed_hh</span></a></span></span><span> </span><span id="local-6989586621679880198"><span class="annot"><span class="annottext">_col_offsets_ih :: Tensor
</span><a href="#local-6989586621679880198"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span></span><span> </span><span id="local-6989586621679880197"><span class="annot"><span class="annottext">_col_offsets_hh :: Tensor
</span><a href="#local-6989586621679880197"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span></span><span> </span><span id="local-6989586621679880196"><span class="annot"><span class="annottext">_scale_ih :: Float
</span><a href="#local-6989586621679880196"><span class="hs-identifier hs-var">_scale_ih</span></a></span></span><span> </span><span id="local-6989586621679880195"><span class="annot"><span class="annottext">_scale_hh :: Float
</span><a href="#local-6989586621679880195"><span class="hs-identifier hs-var">_scale_hh</span></a></span></span><span> </span><span id="local-6989586621679880194"><span class="annot"><span class="annottext">_zero_point_ih :: Float
</span><a href="#local-6989586621679880194"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span></span><span> </span><span id="local-6989586621679880193"><span class="annot"><span class="annottext">_zero_point_hh :: Float
</span><a href="#local-6989586621679880193"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span></span><span> </span><span id="local-6989586621679880192"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880192"><span class="hs-identifier hs-var">_hx</span></a></span></span><span> </span><span id="local-6989586621679880191"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880191"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1525"></span><span>  </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 x7 cx7 x8 cx8
       x9 cx9 x10 cx10 x11 cx11 x12 cx12 x13 cx13 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6, Castable x7 cx7,
 Castable x8 cx8, Castable x9 cx9, Castable x10 cx10,
 Castable x11 cx11, Castable x12 cx12, Castable x13 cx13,
 Castable y cy) =&gt;
(ca
 -&gt; cx1
 -&gt; cx2
 -&gt; cx3
 -&gt; cx4
 -&gt; cx5
 -&gt; cx6
 -&gt; cx7
 -&gt; cx8
 -&gt; cx9
 -&gt; cx10
 -&gt; cx11
 -&gt; cx12
 -&gt; cx13
 -&gt; IO cy)
-&gt; a
-&gt; x1
-&gt; x2
-&gt; x3
-&gt; x4
-&gt; x5
-&gt; x6
-&gt; x7
-&gt; x8
-&gt; x9
-&gt; x10
-&gt; x11
-&gt; x12
-&gt; x13
-&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast14</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.quantized_rnn_relu_cell_ttttttttttssss</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880191"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880192"><span class="hs-identifier hs-var">_hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880204"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880203"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880202"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880201"><span class="hs-identifier hs-var">_b_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880200"><span class="hs-identifier hs-var">_packed_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880199"><span class="hs-identifier hs-var">_packed_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880198"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880197"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880196"><span class="hs-identifier hs-var">_scale_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880195"><span class="hs-identifier hs-var">_scale_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880194"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880193"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span><span>
</span><span id="line-1526"></span><span>
</span><span id="line-1527"></span><span class="hs-comment">-- | A quantized Elman RNN cell with tanh non-linearity</span><span>
</span><span id="line-1528"></span><span class="annot"><a href="Torch.Functional.html#quantizedRnnTanhCell"><span class="hs-identifier hs-type">quantizedRnnTanhCell</span></a></span><span>
</span><span id="line-1529"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden weights</span><span>
</span><span id="line-1530"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden weights</span><span>
</span><span id="line-1531"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden bias</span><span>
</span><span id="line-1532"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden bias</span><span>
</span><span id="line-1533"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden packed</span><span>
</span><span id="line-1534"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden packed</span><span>
</span><span id="line-1535"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input-hidden column offsets</span><span>
</span><span id="line-1536"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden-hidden column offsets</span><span>
</span><span id="line-1537"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden scale</span><span>
</span><span id="line-1538"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden scale</span><span>
</span><span id="line-1539"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ input-hidden zero point</span><span>
</span><span id="line-1540"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ hidden-hidden zero point</span><span>
</span><span id="line-1541"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ hidden state</span><span>
</span><span id="line-1542"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1543"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1544"></span><span id="quantizedRnnTanhCell"><span class="annot"><span class="annottext">quantizedRnnTanhCell :: Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
</span><a href="Torch.Functional.html#quantizedRnnTanhCell"><span class="hs-identifier hs-var hs-var">quantizedRnnTanhCell</span></a></span></span><span> </span><span id="local-6989586621679880188"><span class="annot"><span class="annottext">_w_ih :: Tensor
</span><a href="#local-6989586621679880188"><span class="hs-identifier hs-var">_w_ih</span></a></span></span><span> </span><span id="local-6989586621679880187"><span class="annot"><span class="annottext">_w_hh :: Tensor
</span><a href="#local-6989586621679880187"><span class="hs-identifier hs-var">_w_hh</span></a></span></span><span> </span><span id="local-6989586621679880186"><span class="annot"><span class="annottext">_b_ih :: Tensor
</span><a href="#local-6989586621679880186"><span class="hs-identifier hs-var">_b_ih</span></a></span></span><span> </span><span id="local-6989586621679880185"><span class="annot"><span class="annottext">_b_hh :: Tensor
</span><a href="#local-6989586621679880185"><span class="hs-identifier hs-var">_b_hh</span></a></span></span><span> </span><span id="local-6989586621679880184"><span class="annot"><span class="annottext">_packed_ih :: Tensor
</span><a href="#local-6989586621679880184"><span class="hs-identifier hs-var">_packed_ih</span></a></span></span><span> </span><span id="local-6989586621679880183"><span class="annot"><span class="annottext">_packed_hh :: Tensor
</span><a href="#local-6989586621679880183"><span class="hs-identifier hs-var">_packed_hh</span></a></span></span><span> </span><span id="local-6989586621679880182"><span class="annot"><span class="annottext">_col_offsets_ih :: Tensor
</span><a href="#local-6989586621679880182"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span></span><span> </span><span id="local-6989586621679880181"><span class="annot"><span class="annottext">_col_offsets_hh :: Tensor
</span><a href="#local-6989586621679880181"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span></span><span> </span><span id="local-6989586621679880180"><span class="annot"><span class="annottext">_scale_ih :: Float
</span><a href="#local-6989586621679880180"><span class="hs-identifier hs-var">_scale_ih</span></a></span></span><span> </span><span id="local-6989586621679880179"><span class="annot"><span class="annottext">_scale_hh :: Float
</span><a href="#local-6989586621679880179"><span class="hs-identifier hs-var">_scale_hh</span></a></span></span><span> </span><span id="local-6989586621679880178"><span class="annot"><span class="annottext">_zero_point_ih :: Float
</span><a href="#local-6989586621679880178"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span></span><span> </span><span id="local-6989586621679880177"><span class="annot"><span class="annottext">_zero_point_hh :: Float
</span><a href="#local-6989586621679880177"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span></span><span> </span><span id="local-6989586621679880176"><span class="annot"><span class="annottext">_hx :: Tensor
</span><a href="#local-6989586621679880176"><span class="hs-identifier hs-var">_hx</span></a></span></span><span> </span><span id="local-6989586621679880175"><span class="annot"><span class="annottext">_input :: Tensor
</span><a href="#local-6989586621679880175"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1545"></span><span>  </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; Float
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 x7 cx7 x8 cx8
       x9 cx9 x10 cx10 x11 cx11 x12 cx12 x13 cx13 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6, Castable x7 cx7,
 Castable x8 cx8, Castable x9 cx9, Castable x10 cx10,
 Castable x11 cx11, Castable x12 cx12, Castable x13 cx13,
 Castable y cy) =&gt;
(ca
 -&gt; cx1
 -&gt; cx2
 -&gt; cx3
 -&gt; cx4
 -&gt; cx5
 -&gt; cx6
 -&gt; cx7
 -&gt; cx8
 -&gt; cx9
 -&gt; cx10
 -&gt; cx11
 -&gt; cx12
 -&gt; cx13
 -&gt; IO cy)
-&gt; a
-&gt; x1
-&gt; x2
-&gt; x3
-&gt; x4
-&gt; x5
-&gt; x6
-&gt; x7
-&gt; x8
-&gt; x9
-&gt; x10
-&gt; x11
-&gt; x12
-&gt; x13
-&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast14</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.quantized_rnn_tanh_cell_ttttttttttssss</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880175"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880176"><span class="hs-identifier hs-var">_hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880188"><span class="hs-identifier hs-var">_w_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880187"><span class="hs-identifier hs-var">_w_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880186"><span class="hs-identifier hs-var">_b_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880185"><span class="hs-identifier hs-var">_b_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880184"><span class="hs-identifier hs-var">_packed_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880183"><span class="hs-identifier hs-var">_packed_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880182"><span class="hs-identifier hs-var">_col_offsets_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880181"><span class="hs-identifier hs-var">_col_offsets_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880180"><span class="hs-identifier hs-var">_scale_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880179"><span class="hs-identifier hs-var">_scale_hh</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880178"><span class="hs-identifier hs-var">_zero_point_ih</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880177"><span class="hs-identifier hs-var">_zero_point_hh</span></a></span><span>
</span><span id="line-1546"></span><span>
</span><span id="line-1547"></span><span class="hs-comment">-- | Applies the soft shrinkage function elementwise</span><span>
</span><span id="line-1548"></span><span class="annot"><a href="Torch.Functional.html#softShrink"><span class="hs-identifier hs-type">softShrink</span></a></span><span>
</span><span id="line-1549"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ lambda</span><span>
</span><span id="line-1550"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1551"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1552"></span><span id="softShrink"><span class="annot"><span class="annottext">softShrink :: Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#softShrink"><span class="hs-identifier hs-var hs-var">softShrink</span></a></span></span><span> </span><span id="local-6989586621679880172"><span class="annot"><span class="annottext">lambda :: Float
</span><a href="#local-6989586621679880172"><span class="hs-identifier hs-var">lambda</span></a></span></span><span> </span><span id="local-6989586621679880171"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880171"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.softshrink_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880171"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880172"><span class="hs-identifier hs-var">lambda</span></a></span><span>
</span><span id="line-1553"></span><span>
</span><span id="line-1554"></span><span class="hs-comment">-- | Concatenates sequence of tensors along a new dimension.</span><span>
</span><span id="line-1555"></span><span class="hs-comment">-- All tensors need to be of the same size.</span><span>
</span><span id="line-1556"></span><span class="annot"><a href="Torch.Functional.html#stack"><span class="hs-identifier hs-type">stack</span></a></span><span>
</span><span id="line-1557"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-1558"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1559"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1560"></span><span id="stack"><span class="annot"><span class="annottext">stack :: Dim -&gt; [Tensor] -&gt; Tensor
</span><a href="Torch.Functional.html#stack"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880168"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880168"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880167"><span class="annot"><span class="annottext">tensors :: [Tensor]
</span><a href="#local-6989586621679880167"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; [Tensor] -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.stack_ll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679880167"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880168"><span class="hs-identifier hs-var">d</span></a></span><span>
</span><span id="line-1561"></span><span>
</span><span id="line-1562"></span><span class="hs-comment">-- | Returns the sum of each row of the input tensor in the given dimension dim.</span><span>
</span><span id="line-1563"></span><span class="hs-comment">-- If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1.</span><span>
</span><span id="line-1564"></span><span class="hs-comment">-- Otherwise, dim is squeezed, resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).</span><span>
</span><span id="line-1565"></span><span class="annot"><a href="Torch.Functional.html#sumDim"><span class="hs-identifier hs-type">sumDim</span></a></span><span>
</span><span id="line-1566"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim to sum along</span><span>
</span><span id="line-1567"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-comment">-- ^ whether the output tensor has dim retained or not</span><span>
</span><span id="line-1568"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span> </span><span class="hs-comment">-- ^ datatype</span><span>
</span><span id="line-1569"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1570"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1571"></span><span id="sumDim"><span class="annot"><span class="annottext">sumDim :: Dim -&gt; KeepDim -&gt; DType -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sumDim"><span class="hs-identifier hs-var hs-var">sumDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880164"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880164"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880163"><span class="annot"><span class="annottext">k :: KeepDim
</span><a href="#local-6989586621679880163"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span id="local-6989586621679880162"><span class="annot"><span class="annottext">dtype :: DType
</span><a href="#local-6989586621679880162"><span class="hs-identifier hs-var">dtype</span></a></span></span><span> </span><span id="local-6989586621679880161"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880161"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; ScalarType
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; DType -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; ScalarType
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sum_tlbs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880161"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880164"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><span class="annottext">KeepDim
</span><a href="#local-6989586621679880163"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679880162"><span class="hs-identifier hs-var">dtype</span></a></span><span>
</span><span id="line-1572"></span><span>
</span><span id="line-1573"></span><span class="hs-comment">-- | Returns the k largest elements of the given input tensor along a given dimension.</span><span>
</span><span id="line-1574"></span><span class="hs-comment">-- If largest is False then the k smallest elements are returned.</span><span>
</span><span id="line-1575"></span><span class="hs-comment">-- The boolean option sorted if True, will make sure that the returned k elements are themselves sorted</span><span>
</span><span id="line-1576"></span><span class="hs-comment">-- A tuple of (values, indices) is returned, where the indices are the indices of the elements in the original input tensor.</span><span>
</span><span id="line-1577"></span><span class="annot"><a href="Torch.Functional.html#topK"><span class="hs-identifier hs-type">topK</span></a></span><span>
</span><span id="line-1578"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ k</span><span>
</span><span id="line-1579"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim to find topK along</span><span>
</span><span id="line-1580"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ largest</span><span>
</span><span id="line-1581"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ sorted</span><span>
</span><span id="line-1582"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1583"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1584"></span><span id="topK"><span class="annot"><span class="annottext">topK :: Int -&gt; Dim -&gt; Bool -&gt; Bool -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#topK"><span class="hs-identifier hs-var hs-var">topK</span></a></span></span><span> </span><span id="local-6989586621679880158"><span class="annot"><span class="annottext">k :: Int
</span><a href="#local-6989586621679880158"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880157"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880157"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880156"><span class="annot"><span class="annottext">largest :: Bool
</span><a href="#local-6989586621679880156"><span class="hs-identifier hs-var">largest</span></a></span></span><span> </span><span id="local-6989586621679880155"><span class="annot"><span class="annottext">sorted :: Bool
</span><a href="#local-6989586621679880155"><span class="hs-identifier hs-var">sorted</span></a></span></span><span> </span><span id="local-6989586621679880154"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880154"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64
 -&gt; Int64
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; Bool -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64
-&gt; Int64
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.topk_tllbb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880154"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880158"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880157"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880156"><span class="hs-identifier hs-var">largest</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880155"><span class="hs-identifier hs-var">sorted</span></a></span><span>
</span><span id="line-1585"></span><span>
</span><span id="line-1586"></span><span class="hs-comment">-- | Returns the log of summed exponentials of each row of the input tensor in the given dimension dim. The computation is numerically stabilized.</span><span>
</span><span id="line-1587"></span><span class="annot"><a href="Torch.Functional.html#logsumexp"><span class="hs-identifier hs-type">logsumexp</span></a></span><span>
</span><span id="line-1588"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ keepdim</span><span>
</span><span id="line-1589"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-1590"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1591"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1592"></span><span id="logsumexp"><span class="annot"><span class="annottext">logsumexp :: Bool -&gt; Int -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#logsumexp"><span class="hs-identifier hs-var hs-var">logsumexp</span></a></span></span><span> </span><span id="local-6989586621679880151"><span class="annot"><span class="annottext">keepdim :: Bool
</span><a href="#local-6989586621679880151"><span class="hs-identifier hs-var">keepdim</span></a></span></span><span> </span><span id="local-6989586621679880150"><span class="annot"><span class="annottext">dim :: Int
</span><a href="#local-6989586621679880150"><span class="hs-identifier hs-var">dim</span></a></span></span><span> </span><span id="local-6989586621679880149"><span class="annot"><span class="annottext">t :: Tensor
</span><a href="#local-6989586621679880149"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logsumexp_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880149"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880150"><span class="hs-identifier hs-var">dim</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880151"><span class="hs-identifier hs-var">keepdim</span></a></span><span>
</span><span id="line-1593"></span><span>
</span><span id="line-1594"></span><span class="hs-comment">-- | Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0.</span><span>
</span><span id="line-1595"></span><span class="hs-comment">-- The upper triangular part of the matrix is defined as the elements on and above the diagonal.</span><span>
</span><span id="line-1596"></span><span class="hs-comment">-- The argument diagonal controls which diagonal to consider. If diagonal = 0, all elements on and above the main diagonal are retained.</span><span>
</span><span id="line-1597"></span><span class="hs-comment">-- A positive value excludes just as many diagonals above the main diagonal, and similarly a negative value includes just as many diagonals below the main diagonal.</span><span>
</span><span id="line-1598"></span><span class="hs-comment">-- The main diagonal are the set of indices \((i,i)\) for \(i\) \(\in [0,\min(d_1,d_2)-1]\) where \(d_1\) and \(d_2 \) are the dimensions of the matrix.</span><span>
</span><span id="line-1599"></span><span class="annot"><a href="Torch.Functional.html#triu"><span class="hs-identifier hs-type">triu</span></a></span><span>
</span><span id="line-1600"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span class="hs-comment">-- ^ diagonal</span><span>
</span><span id="line-1601"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1602"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1603"></span><span id="triu"><span class="annot"><span class="annottext">triu :: Diag -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#triu"><span class="hs-identifier hs-var hs-var">triu</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span id="local-6989586621679880146"><span class="annot"><span class="annottext">diagonal :: Int
</span><a href="#local-6989586621679880146"><span class="hs-identifier hs-var">diagonal</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880145"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880145"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.triu_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880145"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880146"><span class="hs-identifier hs-var">diagonal</span></a></span><span>
</span><span id="line-1604"></span><span>
</span><span id="line-1605"></span><span class="hs-comment">-- | Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0.</span><span>
</span><span id="line-1606"></span><span class="hs-comment">-- The lower triangular part of the matrix is defined as the elements on and below the diagonal.</span><span>
</span><span id="line-1607"></span><span class="hs-comment">-- The argument diagonal controls which diagonal to consider. If diagonal = 0, all elements on and below the main diagonal are retained.</span><span>
</span><span id="line-1608"></span><span class="hs-comment">-- A positive value includes just as many diagonals above the main diagonal, and similarly a negative value excludes just as many diagonals below the main diagonal.</span><span>
</span><span id="line-1609"></span><span class="hs-comment">-- The main diagonals are the set of indices \((i,i)\) for \(i\) \(\in [0,\min(d_1,d_2)-1]\) where \(d_1\) and \(d_2 \) are the dimensions of the matrix.</span><span>
</span><span id="line-1610"></span><span class="annot"><a href="Torch.Functional.html#tril"><span class="hs-identifier hs-type">tril</span></a></span><span>
</span><span id="line-1611"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span class="hs-comment">-- ^ diagonal</span><span>
</span><span id="line-1612"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1613"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1614"></span><span id="tril"><span class="annot"><span class="annottext">tril :: Diag -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#tril"><span class="hs-identifier hs-var hs-var">tril</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Diag"><span class="hs-identifier hs-type">Diag</span></a></span><span> </span><span id="local-6989586621679880142"><span class="annot"><span class="annottext">diagonal :: Int
</span><a href="#local-6989586621679880142"><span class="hs-identifier hs-var">diagonal</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880141"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880141"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tril_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880141"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880142"><span class="hs-identifier hs-var">diagonal</span></a></span><span>
</span><span id="line-1615"></span><span>
</span><span id="line-1616"></span><span class="hs-comment">-- | Returns a new tensor with a dimension of size one inserted at the specified position.</span><span>
</span><span id="line-1617"></span><span class="hs-comment">-- The returned tensor shares the same underlying data with this tensor.</span><span>
</span><span id="line-1618"></span><span class="hs-comment">-- A dim value within the range [(dim input) - 1, (dim input) + 1)] can be used. Negative dim will correspond to unsqueeze applied at dim = dim + (dim input) + 1</span><span>
</span><span id="line-1619"></span><span class="annot"><a href="Torch.Functional.html#unsqueeze"><span class="hs-identifier hs-type">unsqueeze</span></a></span><span>
</span><span id="line-1620"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span>  </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-1621"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1622"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1623"></span><span id="unsqueeze"><span class="annot"><span class="annottext">unsqueeze :: Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#unsqueeze"><span class="hs-identifier hs-var hs-var">unsqueeze</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880138"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880138"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880137"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880137"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.unsqueeze_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880137"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880138"><span class="hs-identifier hs-var">d</span></a></span><span>
</span><span id="line-1624"></span><span>
</span><span id="line-1625"></span><span class="hs-comment">-- | Upsamples the input, using bilinear upsampling. Expected inputs are spatial (4 dimensional).</span><span>
</span><span id="line-1626"></span><span class="annot"><a href="Torch.Functional.html#upsampleBilinear2d"><span class="hs-identifier hs-type">upsampleBilinear2d</span></a></span><span>
</span><span id="line-1627"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output-size</span><span>
</span><span id="line-1628"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ align corners</span><span>
</span><span id="line-1629"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1630"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1631"></span><span id="upsampleBilinear2d"><span class="annot"><span class="annottext">upsampleBilinear2d :: (Int, Int) -&gt; Bool -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#upsampleBilinear2d"><span class="hs-identifier hs-var hs-var">upsampleBilinear2d</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679880134"><span class="annot"><span class="annottext">outputHeight :: Int
</span><a href="#local-6989586621679880134"><span class="hs-identifier hs-var">outputHeight</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679880133"><span class="annot"><span class="annottext">outputWidth :: Int
</span><a href="#local-6989586621679880133"><span class="hs-identifier hs-var">outputWidth</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880132"><span class="annot"><span class="annottext">alignCorners :: Bool
</span><a href="#local-6989586621679880132"><span class="hs-identifier hs-var">alignCorners</span></a></span></span><span> </span><span id="local-6989586621679880131"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880131"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; [Int] -&gt; Bool -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.upsample_bilinear2d_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880131"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880134"><span class="hs-identifier hs-var">outputHeight</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880133"><span class="hs-identifier hs-var">outputWidth</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880132"><span class="hs-identifier hs-var">alignCorners</span></a></span><span>
</span><span id="line-1632"></span><span>
</span><span id="line-1633"></span><span class="hs-comment">-- | Splits the tensor into chunks of given size if possible.</span><span>
</span><span id="line-1634"></span><span class="annot"><a href="Torch.Functional.html#split"><span class="hs-identifier hs-type">split</span></a></span><span>
</span><span id="line-1635"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-comment">-- ^ split-size</span><span>
</span><span id="line-1636"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dim</span><span>
</span><span id="line-1637"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ self</span><span>
</span><span id="line-1638"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1639"></span><span id="split"><span class="annot"><span class="annottext">split :: Int -&gt; Dim -&gt; Tensor -&gt; [Tensor]
</span><a href="Torch.Functional.html#split"><span class="hs-identifier hs-var hs-var">split</span></a></span></span><span> </span><span id="local-6989586621679880128"><span class="annot"><span class="annottext">splitSize :: Int
</span><a href="#local-6989586621679880128"><span class="hs-identifier hs-var">splitSize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880127"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880127"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880126"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880126"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO [Tensor] -&gt; [Tensor]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO [Tensor] -&gt; [Tensor]) -&gt; IO [Tensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr TensorList))
-&gt; Tensor -&gt; Int -&gt; Int -&gt; IO [Tensor]
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr TensorList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.split_tll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880126"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880128"><span class="hs-identifier hs-var">splitSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880127"><span class="hs-identifier hs-var">d</span></a></span><span>
</span><span id="line-1640"></span><span>
</span><span id="line-1641"></span><span class="hs-comment">-- | Creates a criterion that measures the mean absolute error (MAE) between each element in the input \(x\) and target \(y\) .</span><span>
</span><span id="line-1642"></span><span class="annot"><a href="Torch.Functional.html#l1Loss"><span class="hs-identifier hs-type">l1Loss</span></a></span><span>
</span><span id="line-1643"></span><span>  </span><span class="hs-glyph">::</span><span>  </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span> </span><span class="hs-comment">-- ^ reduction</span><span>
</span><span id="line-1644"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1645"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ target</span><span>
</span><span id="line-1646"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1647"></span><span id="l1Loss"><span class="annot"><span class="annottext">l1Loss :: Reduction -&gt; Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#l1Loss"><span class="hs-identifier hs-var hs-var">l1Loss</span></a></span></span><span> </span><span id="local-6989586621679880123"><span class="annot"><span class="annottext">reduction :: Reduction
</span><a href="#local-6989586621679880123"><span class="hs-identifier hs-var">reduction</span></a></span></span><span> </span><span id="local-6989586621679880122"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880122"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679880121"><span class="annot"><span class="annottext">target :: Tensor
</span><a href="#local-6989586621679880121"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Tensor -&gt; Reduction -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.l1_loss_ttl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880122"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880121"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="annot"><span class="annottext">Reduction
</span><a href="#local-6989586621679880123"><span class="hs-identifier hs-var">reduction</span></a></span><span>
</span><span id="line-1648"></span><span>
</span><span id="line-1649"></span><span class="hs-comment">-- | Applies the element-wise function:</span><span>
</span><span id="line-1650"></span><span class="hs-comment">-- \(\text{LeakyReLU}(x) = \max(0,x) + \text{negative_slope} &#8727; \min(0,x)\)</span><span>
</span><span id="line-1651"></span><span class="annot"><a href="Torch.Functional.html#leakyRelu"><span class="hs-identifier hs-type">leakyRelu</span></a></span><span>
</span><span id="line-1652"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-comment">-- ^ negative slope</span><span>
</span><span id="line-1653"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1654"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1655"></span><span id="leakyRelu"><span class="annot"><span class="annottext">leakyRelu :: Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#leakyRelu"><span class="hs-identifier hs-var hs-var">leakyRelu</span></a></span></span><span> </span><span id="local-6989586621679880118"><span class="annot"><span class="annottext">negSlope :: Float
</span><a href="#local-6989586621679880118"><span class="hs-identifier hs-var">negSlope</span></a></span></span><span> </span><span id="local-6989586621679880117"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880117"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Float -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.leaky_relu_ts</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880117"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679880118"><span class="hs-identifier hs-var">negSlope</span></a></span><span>
</span><span id="line-1656"></span><span>
</span><span id="line-1657"></span><span class="hs-comment">-- | Applies the element-wise function:</span><span>
</span><span id="line-1658"></span><span class="hs-comment">-- \(\text{LogSigmoid}(x) = \log(\frac{ 1 }{ 1 + \exp(-x)})\)</span><span>
</span><span id="line-1659"></span><span class="annot"><a href="Torch.Functional.html#logSigmoid"><span class="hs-identifier hs-type">logSigmoid</span></a></span><span>
</span><span id="line-1660"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1661"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1662"></span><span id="logSigmoid"><span class="annot"><span class="annottext">logSigmoid :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#logSigmoid"><span class="hs-identifier hs-var hs-var">logSigmoid</span></a></span></span><span> </span><span id="local-6989586621679880114"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880114"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log_sigmoid_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880114"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1663"></span><span>
</span><span id="line-1664"></span><span class="hs-comment">-- | Returns a namedtuple (values, indices) where values is the maximum value of each row of the input tensor in the given dimension dim.</span><span>
</span><span id="line-1665"></span><span class="hs-comment">-- And indices is the index location of each maximum value found (argmax).</span><span>
</span><span id="line-1666"></span><span class="hs-comment">-- If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1.</span><span>
</span><span id="line-1667"></span><span class="hs-comment">-- Otherwise, dim is squeezed , resulting in the output tensors having 1 fewer dimension than input.</span><span>
</span><span id="line-1668"></span><span class="annot"><a href="Torch.Functional.html#maxDim"><span class="hs-identifier hs-type">maxDim</span></a></span><span>
</span><span id="line-1669"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1670"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-comment">-- ^ keepdim</span><span>
</span><span id="line-1671"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1672"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1673"></span><span id="maxDim"><span class="annot"><span class="annottext">maxDim :: Dim -&gt; KeepDim -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#maxDim"><span class="hs-identifier hs-var hs-var">maxDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880111"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880111"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880110"><span class="annot"><span class="annottext">k :: KeepDim
</span><a href="#local-6989586621679880110"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span id="local-6989586621679880109"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880109"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.max_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880109"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880111"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><span class="annottext">KeepDim
</span><a href="#local-6989586621679880110"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1674"></span><span>
</span><span id="line-1675"></span><span class="hs-comment">-- | Returns a namedtuple (values, indices) where values is the minimum value of each row of the input tensor in the given dimension dim.</span><span>
</span><span id="line-1676"></span><span class="hs-comment">-- And indices is the index location of each minimum value found (argmin).</span><span>
</span><span id="line-1677"></span><span class="hs-comment">-- If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1.</span><span>
</span><span id="line-1678"></span><span class="hs-comment">-- Otherwise, dim is squeezed, resulting in the output tensors having 1 fewer dimension than input.</span><span>
</span><span id="line-1679"></span><span class="annot"><a href="Torch.Functional.html#minDim"><span class="hs-identifier hs-type">minDim</span></a></span><span>
</span><span id="line-1680"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1681"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-comment">-- ^ keepdim</span><span>
</span><span id="line-1682"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1683"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1684"></span><span id="minDim"><span class="annot"><span class="annottext">minDim :: Dim -&gt; KeepDim -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#minDim"><span class="hs-identifier hs-var hs-var">minDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880106"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880106"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880105"><span class="annot"><span class="annottext">k :: KeepDim
</span><a href="#local-6989586621679880105"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span id="local-6989586621679880104"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880104"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.min_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880104"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880106"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><span class="annottext">KeepDim
</span><a href="#local-6989586621679880105"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1685"></span><span>
</span><span id="line-1686"></span><span class="hs-comment">-- | Returns the mean value of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them.</span><span>
</span><span id="line-1687"></span><span class="hs-comment">-- If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1.</span><span>
</span><span id="line-1688"></span><span class="hs-comment">-- Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).</span><span>
</span><span id="line-1689"></span><span class="annot"><a href="Torch.Functional.html#meanDim"><span class="hs-identifier hs-type">meanDim</span></a></span><span>
</span><span id="line-1690"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1691"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-comment">-- ^ keepdim</span><span>
</span><span id="line-1692"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span> </span><span class="hs-comment">-- ^ dtype</span><span>
</span><span id="line-1693"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1694"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1695"></span><span id="meanDim"><span class="annot"><span class="annottext">meanDim :: Dim -&gt; KeepDim -&gt; DType -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#meanDim"><span class="hs-identifier hs-var hs-var">meanDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880101"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880101"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880100"><span class="annot"><span class="annottext">k :: KeepDim
</span><a href="#local-6989586621679880100"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span id="local-6989586621679880099"><span class="annot"><span class="annottext">dtype :: DType
</span><a href="#local-6989586621679880099"><span class="hs-identifier hs-var">dtype</span></a></span></span><span> </span><span id="local-6989586621679880098"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880098"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; ScalarType
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; DType -&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; ScalarType
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mean_tlbs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880098"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880101"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><span class="annottext">KeepDim
</span><a href="#local-6989586621679880100"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679880099"><span class="hs-identifier hs-var">dtype</span></a></span><span>
</span><span id="line-1696"></span><span>
</span><span id="line-1697"></span><span class="hs-comment">-- | Returns a namedtuple (values, indices) where values is the median value of each row of the input tensor in the given dimension dim.</span><span>
</span><span id="line-1698"></span><span class="hs-comment">-- And indices is the index location of each median value found.</span><span>
</span><span id="line-1699"></span><span class="hs-comment">-- By default, dim is the last dimension of the input tensor.</span><span>
</span><span id="line-1700"></span><span class="hs-comment">-- If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1.</span><span>
</span><span id="line-1701"></span><span class="hs-comment">-- Otherwise, dim is squeezed (see torch.squeeze()), resulting in the outputs tensor having 1 fewer dimension than input.</span><span>
</span><span id="line-1702"></span><span class="annot"><a href="Torch.Functional.html#medianDim"><span class="hs-identifier hs-type">medianDim</span></a></span><span>
</span><span id="line-1703"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1704"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-comment">-- ^ keepdim</span><span>
</span><span id="line-1705"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1706"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1707"></span><span id="medianDim"><span class="annot"><span class="annottext">medianDim :: Dim -&gt; KeepDim -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#medianDim"><span class="hs-identifier hs-var hs-var">medianDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880095"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880095"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880094"><span class="annot"><span class="annottext">k :: KeepDim
</span><a href="#local-6989586621679880094"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span id="local-6989586621679880093"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880093"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.median_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880093"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880095"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><span class="annottext">KeepDim
</span><a href="#local-6989586621679880094"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1708"></span><span>
</span><span id="line-1709"></span><span class="hs-comment">-- | Returns the matrix product of the NN 2-D tensors.</span><span>
</span><span id="line-1710"></span><span class="hs-comment">-- This product is efficiently computed using the matrix chain order algorithm which selects the order in which incurs the lowest cost in terms of arithmetic operations.</span><span>
</span><span id="line-1711"></span><span class="hs-comment">-- Note that since this is a function to compute the product, NN needs to be greater than or equal to 2; if equal to 2 then a trivial matrix-matrix product is returned.</span><span>
</span><span id="line-1712"></span><span class="hs-comment">-- If NN is 1, then this is a no-op - the original matrix is returned as is.</span><span>
</span><span id="line-1713"></span><span class="annot"><a href="Torch.Functional.html#chainMatmul"><span class="hs-identifier hs-type">chainMatmul</span></a></span><span>
</span><span id="line-1714"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ list of tensors</span><span>
</span><span id="line-1715"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1716"></span><span id="chainMatmul"><span class="annot"><span class="annottext">chainMatmul :: [Tensor] -&gt; Tensor
</span><a href="Torch.Functional.html#chainMatmul"><span class="hs-identifier hs-var hs-var">chainMatmul</span></a></span></span><span> </span><span id="local-6989586621679880090"><span class="annot"><span class="annottext">tensors :: [Tensor]
</span><a href="#local-6989586621679880090"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr TensorList -&gt; IO (ForeignPtr Tensor))
-&gt; [Tensor] -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.chain_matmul_l</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679880090"><span class="hs-identifier hs-var">tensors</span></a></span><span>
</span><span id="line-1717"></span><span>
</span><span id="line-1718"></span><span class="hs-comment">-- | Applies element-wise the function \(\text{GELU}(x) = x * \Phi(x)\)</span><span>
</span><span id="line-1719"></span><span class="hs-comment">-- where \(\Phi(x)\) is the Cumulative Distribution Function for Gaussian Distribution.</span><span>
</span><span id="line-1720"></span><span class="annot"><a href="Torch.Functional.html#gelu"><span class="hs-identifier hs-type">gelu</span></a></span><span>
</span><span id="line-1721"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1722"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1723"></span><span id="gelu"><span class="annot"><span class="annottext">gelu :: Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#gelu"><span class="hs-identifier hs-var hs-var">gelu</span></a></span></span><span> </span><span id="local-6989586621679880087"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880087"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; IO Tensor
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.gelu_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880087"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1724"></span><span>
</span><span id="line-1725"></span><span class="hs-comment">-- | The gated linear unit. Computes:</span><span>
</span><span id="line-1726"></span><span class="hs-comment">-- \(\text{GLU}(a, b) = a \otimes \sigma(b)\)</span><span>
</span><span id="line-1727"></span><span class="hs-comment">-- where input is split in half along dim to form a and b, \(\sigma\) is the sigmoid function and \(\otimes\) is the element-wise product between matrices.</span><span>
</span><span id="line-1728"></span><span class="annot"><a href="Torch.Functional.html#glu"><span class="hs-identifier hs-type">glu</span></a></span><span>
</span><span id="line-1729"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1730"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1731"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1732"></span><span id="glu"><span class="annot"><span class="annottext">glu :: Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#glu"><span class="hs-identifier hs-var hs-var">glu</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880084"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880084"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880083"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880083"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor -&gt; Int -&gt; IO Tensor
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.glu_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880083"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880084"><span class="hs-identifier hs-var">d</span></a></span><span>
</span><span id="line-1733"></span><span>
</span><span id="line-1734"></span><span class="hs-comment">-- | Returns the standard-deviation and mean of all elements in the input tensor.</span><span>
</span><span id="line-1735"></span><span class="hs-comment">-- If unbiased is False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel&#8217;s correction will be used.</span><span>
</span><span id="line-1736"></span><span class="annot"><a href="Torch.Functional.html#stdMean"><span class="hs-identifier hs-type">stdMean</span></a></span><span>
</span><span id="line-1737"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ unbiased</span><span>
</span><span id="line-1738"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1739"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1740"></span><span id="stdMean"><span class="annot"><span class="annottext">stdMean :: Bool -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#stdMean"><span class="hs-identifier hs-var hs-var">stdMean</span></a></span></span><span> </span><span id="local-6989586621679880080"><span class="annot"><span class="annottext">unbiased :: Bool
</span><a href="#local-6989586621679880080"><span class="hs-identifier hs-var">unbiased</span></a></span></span><span> </span><span id="local-6989586621679880079"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880079"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.std_mean_tb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880079"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880080"><span class="hs-identifier hs-var">unbiased</span></a></span><span>
</span><span id="line-1741"></span><span>
</span><span id="line-1742"></span><span class="hs-comment">-- | Returns the standard-deviation and mean of each row of the input tensor in the dimension dim. If dim is a list of dimensions, reduce over all of them.</span><span>
</span><span id="line-1743"></span><span class="hs-comment">-- If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1.</span><span>
</span><span id="line-1744"></span><span class="hs-comment">-- Otherwise, dim is squeezed, resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).</span><span>
</span><span id="line-1745"></span><span class="hs-comment">-- If unbiased is False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel&#8217;s correction will be used.</span><span>
</span><span id="line-1746"></span><span class="annot"><a href="Torch.Functional.html#stdMeanDim"><span class="hs-identifier hs-type">stdMeanDim</span></a></span><span>
</span><span id="line-1747"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-comment">-- ^ dimension</span><span>
</span><span id="line-1748"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-comment">-- ^ unbiased</span><span>
</span><span id="line-1749"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-comment">-- ^ whether the output tensor has dim retained or not</span><span>
</span><span id="line-1750"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-comment">-- ^ input</span><span>
</span><span id="line-1751"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">,</span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- ^ output</span><span>
</span><span id="line-1752"></span><span id="stdMeanDim"><span class="annot"><span class="annottext">stdMeanDim :: Dim -&gt; Bool -&gt; KeepDim -&gt; Tensor -&gt; (Tensor, Tensor)
</span><a href="Torch.Functional.html#stdMeanDim"><span class="hs-identifier hs-var hs-var">stdMeanDim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679880076"><span class="annot"><span class="annottext">d :: Int
</span><a href="#local-6989586621679880076"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679880075"><span class="annot"><span class="annottext">unbiased :: Bool
</span><a href="#local-6989586621679880075"><span class="hs-identifier hs-var">unbiased</span></a></span></span><span> </span><span id="local-6989586621679880074"><span class="annot"><span class="annottext">k :: KeepDim
</span><a href="#local-6989586621679880074"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span id="local-6989586621679880073"><span class="annot"><span class="annottext">input :: Tensor
</span><a href="#local-6989586621679880073"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor, Tensor) -&gt; (Tensor, Tensor))
-&gt; IO (Tensor, Tensor) -&gt; (Tensor, Tensor)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor -&gt; Int -&gt; Bool -&gt; Bool -&gt; IO (Tensor, Tensor)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.std_mean_tlbb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679880073"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679880076"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679880075"><span class="hs-identifier hs-var">unbiased</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KeepDim -&gt; Bool
</span><a href="Torch.Functional.html#keepdim"><span class="hs-identifier hs-var">keepdim</span></a></span><span> </span><span class="annot"><span class="annottext">KeepDim
</span><a href="#local-6989586621679880074"><span class="hs-identifier hs-var">k</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1753"></span></pre></body></html>