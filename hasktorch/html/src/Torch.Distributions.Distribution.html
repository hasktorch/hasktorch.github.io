<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Distributions.Distribution</span><span>
</span><span id="line-2"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Distributions.Distribution.html#Scale"><span class="hs-identifier">Scale</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3"></span><span>    </span><span class="annot"><a href="Torch.Distributions.Distribution.html#Distribution"><span class="hs-identifier">Distribution</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4"></span><span>    </span><span class="annot"><a href="Torch.Distributions.Distribution.html#stddev"><span class="hs-identifier">stddev</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5"></span><span>    </span><span class="annot"><a href="Torch.Distributions.Distribution.html#perplexity"><span class="hs-identifier">perplexity</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-6"></span><span>    </span><span class="annot"><a href="Torch.Distributions.Distribution.html#logitsToProbs"><span class="hs-identifier">logitsToProbs</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-7"></span><span>    </span><span class="annot"><a href="Torch.Distributions.Distribution.html#clampProbs"><span class="hs-identifier">clampProbs</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-8"></span><span>    </span><span class="annot"><a href="Torch.Distributions.Distribution.html#probsToLogits"><span class="hs-identifier">probsToLogits</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-9"></span><span>    </span><span class="annot"><a href="Torch.Distributions.Distribution.html#extendedShape"><span class="hs-identifier">extendedShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-10"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-11"></span><span class="hs-keyword">where</span><span>
</span><span id="line-12"></span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Distributions.Constraints.html"><span class="hs-identifier">Torch.Distributions.Constraints</span></a></span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Functional.html"><span class="hs-identifier">Torch.Functional</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">F</span></span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.TensorFactories.html"><span class="hs-identifier">Torch.TensorFactories</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.TensorFactories.html#ones"><span class="hs-identifier">ones</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.TensorFactories.html#onesLike"><span class="hs-identifier">onesLike</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span>
</span><span id="line-18"></span><span class="hs-keyword">data</span><span> </span><span id="Scale"><span class="annot"><a href="Torch.Distributions.Distribution.html#Scale"><span class="hs-identifier hs-var">Scale</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="Probs"><span class="annot"><a href="Torch.Distributions.Distribution.html#Probs"><span class="hs-identifier hs-var">Probs</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="Logits"><span class="annot"><a href="Torch.Distributions.Distribution.html#Logits"><span class="hs-identifier hs-var">Logits</span></a></span></span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">class</span><span> </span><span id="Distribution"><span class="annot"><a href="Torch.Distributions.Distribution.html#Distribution"><span class="hs-identifier hs-var">Distribution</span></a></span></span><span> </span><span id="local-6989586621679728343"><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-21"></span><span>  </span><span id="batchShape"><span class="annot"><a href="Torch.Distributions.Distribution.html#batchShape"><span class="hs-identifier hs-type">batchShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-22"></span><span>  </span><span id="eventShape"><span class="annot"><a href="Torch.Distributions.Distribution.html#eventShape"><span class="hs-identifier hs-type">eventShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-23"></span><span>  </span><span id="expand"><span class="annot"><a href="Torch.Distributions.Distribution.html#expand"><span class="hs-identifier hs-type">expand</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-24"></span><span>  </span><span id="support"><span class="annot"><a href="Torch.Distributions.Distribution.html#support"><span class="hs-identifier hs-type">support</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Distributions.Constraints.html#Constraint"><span class="hs-identifier hs-type">Constraint</span></a></span><span>
</span><span id="line-25"></span><span>  </span><span id="mean"><span class="annot"><a href="Torch.Distributions.Distribution.html#mean"><span class="hs-identifier hs-type">mean</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span>
</span><span id="line-26"></span><span>  </span><span id="variance"><span class="annot"><a href="Torch.Distributions.Distribution.html#variance"><span class="hs-identifier hs-type">variance</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span>
</span><span id="line-27"></span><span>  </span><span id="sample"><span class="annot"><a href="Torch.Distributions.Distribution.html#sample"><span class="hs-identifier hs-type">sample</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span>
</span><span id="line-28"></span><span>  </span><span id="logProb"><span class="annot"><a href="Torch.Distributions.Distribution.html#logProb"><span class="hs-identifier hs-type">logProb</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span>
</span><span id="line-29"></span><span>  </span><span id="entropy"><span class="annot"><a href="Torch.Distributions.Distribution.html#entropy"><span class="hs-identifier hs-type">entropy</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span>
</span><span id="line-30"></span><span>  </span><span id="enumerateSupport"><span class="annot"><a href="Torch.Distributions.Distribution.html#enumerateSupport"><span class="hs-identifier hs-type">enumerateSupport</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728343"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-comment">-- (expand=True)</span><span>
</span><span id="line-31"></span><span>
</span><span id="line-32"></span><span id="local-6989586621679728309"><span class="annot"><a href="Torch.Distributions.Distribution.html#stddev"><span class="hs-identifier hs-type">stddev</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Distributions.Distribution.html#Distribution"><span class="hs-identifier hs-type">Distribution</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728309"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679728309"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span></span><span> </span><span class="hs-comment">-- 'D.Float</span><span>
</span><span id="line-33"></span><span id="stddev"><span class="annot"><span class="annottext">stddev :: a -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#stddev"><span class="hs-identifier hs-var hs-var">stddev</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sqrt"><span class="hs-identifier hs-var">F.sqrt</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor -&gt; Tensor) -&gt; (a -&gt; Tensor) -&gt; a -&gt; Tensor
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Tensor
forall a. Distribution a =&gt; a -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#variance"><span class="hs-identifier hs-var">variance</span></a></span><span>
</span><span id="line-34"></span><span>
</span><span id="line-35"></span><span class="hs-comment">-- Tensor device 'D.Float '[batchShape]</span><span>
</span><span id="line-36"></span><span id="local-6989586621679728306"><span class="annot"><a href="Torch.Distributions.Distribution.html#perplexity"><span class="hs-identifier hs-type">perplexity</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Distributions.Distribution.html#Distribution"><span class="hs-identifier hs-type">Distribution</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728306"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679728306"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span></span><span>
</span><span id="line-37"></span><span id="perplexity"><span class="annot"><span class="annottext">perplexity :: a -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#perplexity"><span class="hs-identifier hs-var hs-var">perplexity</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#exp"><span class="hs-identifier hs-var">F.exp</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor -&gt; Tensor) -&gt; (a -&gt; Tensor) -&gt; a -&gt; Tensor
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Tensor
forall a. Distribution a =&gt; a -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#entropy"><span class="hs-identifier hs-var">entropy</span></a></span><span>
</span><span id="line-38"></span><span>
</span><span id="line-39"></span><span class="hs-comment">-- | Converts a tensor of logits into probabilities. Note that for the</span><span>
</span><span id="line-40"></span><span class="hs-comment">-- | binary case, each value denotes log odds, whereas for the</span><span>
</span><span id="line-41"></span><span class="hs-comment">-- | multi-dimensional case, the values along the last dimension denote</span><span>
</span><span id="line-42"></span><span class="hs-comment">-- | the log probabilities (possibly unnormalized) of the events.</span><span>
</span><span id="line-43"></span><span class="annot"><a href="Torch.Distributions.Distribution.html#logitsToProbs"><span class="hs-identifier hs-type">logitsToProbs</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-comment">-- isBinary=False</span><span>
</span><span id="line-44"></span><span id="logitsToProbs"><span class="annot"><span class="annottext">logitsToProbs :: Bool -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#logitsToProbs"><span class="hs-identifier hs-var hs-var">logitsToProbs</span></a></span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sigmoid"><span class="hs-identifier hs-var">F.sigmoid</span></a></span><span>
</span><span id="line-45"></span><span class="annot"><a href="Torch.Distributions.Distribution.html#logitsToProbs"><span class="hs-identifier hs-var">logitsToProbs</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Dim -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#softmax"><span class="hs-identifier hs-var">F.softmax</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Dim
</span><a href="Torch.Functional.html#Dim"><span class="hs-identifier hs-var">F.Dim</span></a></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Dim) -&gt; Int -&gt; Dim
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">-</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span>
</span><span id="line-47"></span><span class="annot"><a href="Torch.Distributions.Distribution.html#clampProbs"><span class="hs-identifier hs-type">clampProbs</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span>
</span><span id="line-48"></span><span id="clampProbs"><span class="annot"><span class="annottext">clampProbs :: Tensor -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#clampProbs"><span class="hs-identifier hs-var hs-var">clampProbs</span></a></span></span><span> </span><span id="local-6989586621679728301"><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728301"><span class="hs-identifier hs-var">probs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-49"></span><span>  </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#clamp"><span class="hs-identifier hs-var">F.clamp</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679728299"><span class="hs-identifier hs-var">eps</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1.0</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679728299"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728301"><span class="hs-identifier hs-var">probs</span></a></span><span>
</span><span id="line-50"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-51"></span><span>    </span><span id="local-6989586621679728299"><span class="annot"><span class="annottext">eps :: Float
</span><a href="#local-6989586621679728299"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">0.000001</span></span><span> </span><span class="hs-comment">-- torch.finfo(probs.dtype).eps</span><span>
</span><span id="line-52"></span><span>
</span><span id="line-53"></span><span class="hs-comment">-- | Converts a tensor of probabilities into logits. For the binary case,</span><span>
</span><span id="line-54"></span><span class="hs-comment">-- | this denotes the probability of occurrence of the event indexed by `1`.</span><span>
</span><span id="line-55"></span><span class="hs-comment">-- | For the multi-dimensional case, the values along the last dimension</span><span>
</span><span id="line-56"></span><span class="hs-comment">-- | denote the probabilities of occurrence of each of the events.</span><span>
</span><span id="line-57"></span><span class="annot"><a href="Torch.Distributions.Distribution.html#probsToLogits"><span class="hs-identifier hs-type">probsToLogits</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-comment">-- isBinary=False</span><span>
</span><span id="line-58"></span><span id="probsToLogits"><span class="annot"><span class="annottext">probsToLogits :: Bool -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#probsToLogits"><span class="hs-identifier hs-var hs-var">probsToLogits</span></a></span></span><span> </span><span id="local-6989586621679728298"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679728298"><span class="hs-identifier hs-var">isBinary</span></a></span></span><span> </span><span id="local-6989586621679728297"><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728297"><span class="hs-identifier hs-var">probs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-59"></span><span>  </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679728298"><span class="hs-identifier hs-var">isBinary</span></a></span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#log10"><span class="hs-identifier hs-var">F.log10</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728295"><span class="hs-identifier hs-var">psClamped</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#sub"><span class="hs-operator hs-var">`F.sub`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#log1p"><span class="hs-identifier hs-var">F.log1p</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; Tensor -&gt; Tensor
forall a. Scalar a =&gt; a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mulScalar"><span class="hs-identifier hs-var">F.mulScalar</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1.0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728295"><span class="hs-identifier hs-var">psClamped</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#log10"><span class="hs-identifier hs-var">F.log10</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728295"><span class="hs-identifier hs-var">psClamped</span></a></span><span>
</span><span id="line-62"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-63"></span><span>    </span><span id="local-6989586621679728295"><span class="annot"><span class="annottext">psClamped :: Tensor
</span><a href="#local-6989586621679728295"><span class="hs-identifier hs-var hs-var">psClamped</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor
</span><a href="Torch.Distributions.Distribution.html#clampProbs"><span class="hs-identifier hs-var">clampProbs</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728297"><span class="hs-identifier hs-var">probs</span></a></span><span>
</span><span id="line-64"></span><span>
</span><span id="line-65"></span><span class="hs-comment">-- | Returns the size of the sample returned by the distribution, given</span><span>
</span><span id="line-66"></span><span class="hs-comment">-- | a `sampleShape`. Note, that the batch and event shapes of a distribution</span><span>
</span><span id="line-67"></span><span class="hs-comment">-- | instance are fixed at the time of construction. If this is empty, the</span><span>
</span><span id="line-68"></span><span class="hs-comment">-- | returned shape is upcast to (1,).</span><span>
</span><span id="line-69"></span><span class="hs-comment">-- | Args:</span><span>
</span><span id="line-70"></span><span class="hs-comment">-- |     sampleShape (torch.Size): the size of the sample to be drawn.</span><span>
</span><span id="line-71"></span><span id="local-6989586621679728291"><span class="annot"><a href="Torch.Distributions.Distribution.html#extendedShape"><span class="hs-identifier hs-type">extendedShape</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Distributions.Distribution.html#Distribution"><span class="hs-identifier hs-type">Distribution</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728291"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679728291"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span></span><span>
</span><span id="line-72"></span><span id="extendedShape"><span class="annot"><span class="annottext">extendedShape :: a -&gt; [Int] -&gt; [Int]
</span><a href="Torch.Distributions.Distribution.html#extendedShape"><span class="hs-identifier hs-var hs-var">extendedShape</span></a></span></span><span> </span><span id="local-6989586621679728290"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679728290"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span id="local-6989586621679728289"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679728289"><span class="hs-identifier hs-var">sampleShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-73"></span><span>  </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679728289"><span class="hs-identifier hs-var">sampleShape</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; [Int]
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; [Int]
forall a. Distribution a =&gt; a -&gt; [Int]
</span><a href="Torch.Distributions.Distribution.html#batchShape"><span class="hs-identifier hs-var">batchShape</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679728290"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; [Int]
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; [Int]
forall a. Distribution a =&gt; a -&gt; [Int]
</span><a href="Torch.Distributions.Distribution.html#eventShape"><span class="hs-identifier hs-var">eventShape</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679728290"><span class="hs-identifier hs-var">d</span></a></span><span>
</span><span id="line-74"></span></pre></body></html>