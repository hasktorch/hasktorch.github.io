<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE NoStarIsType #-}</span><span>
</span><span id="line-15"></span><span>
</span><span id="line-16"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Typed.Optim</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-17"></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.State</span></span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.DType.html"><span class="hs-identifier">Torch.DType</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Device.html"><span class="hs-identifier">Torch.Device</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.HList.html"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Autograd.html"><span class="hs-identifier">Torch.Typed.Autograd</span></a></span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html"><span class="hs-identifier">Torch.Typed.Aux</span></a></span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html"><span class="hs-identifier">Torch.Typed.Factories</span></a></span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html"><span class="hs-identifier">Torch.Typed.Functional</span></a></span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html"><span class="hs-identifier">Torch.Typed.Parameter</span></a></span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html"><span class="hs-identifier">Torch.Typed.Tensor</span></a></span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">div</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">sqrt</span></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.Mem</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">performGC</span></span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span>
</span><span id="line-35"></span><span class="hs-keyword">type</span><span> </span><span id="LearningRate"><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-var">LearningRate</span></a></span></span><span> </span><span id="local-6989586621679700554"><span class="annot"><a href="#local-6989586621679700554"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679700553"><span class="annot"><a href="#local-6989586621679700553"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700554"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700553"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-36"></span><span>
</span><span id="line-37"></span><span class="hs-keyword">type</span><span> </span><span id="Loss"><span class="annot"><a href="Torch.Typed.Optim.html#Loss"><span class="hs-identifier hs-var">Loss</span></a></span></span><span> </span><span id="local-6989586621679700552"><span class="annot"><a href="#local-6989586621679700552"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679700551"><span class="annot"><a href="#local-6989586621679700551"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700552"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700551"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-38"></span><span>
</span><span id="line-39"></span><span class="hs-keyword">data</span><span> </span><span id="ZerosLike"><span class="annot"><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-var">ZerosLike</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ZerosLike"><span class="annot"><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-var">ZerosLike</span></a></span></span><span>
</span><span id="line-40"></span><span>
</span><span id="line-41"></span><span id="local-6989586621679700545"><span id="local-6989586621679700546"><span id="local-6989586621679700547"><span id="local-6989586621679700548"><span id="local-6989586621679700549"><span class="hs-keyword">instance</span><span>
</span><span id="line-42"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679700549"><span class="hs-identifier hs-type">parameter</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700548"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700547"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700546"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-43"></span><span>    </span><span class="annot"><a href="#local-6989586621679700545"><span class="hs-identifier hs-type">momentum</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700548"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700547"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700546"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-44"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#TensorOptions"><span class="hs-identifier hs-type">TensorOptions</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700546"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700547"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700548"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-45"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-46"></span><span>  </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-type">ZerosLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700549"><span class="hs-identifier hs-type">parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700545"><span class="hs-identifier hs-type">momentum</span></a></span><span>
</span><span id="line-47"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-48"></span><span>  </span><span id="local-6989586621679700542"><span class="annot"><span class="annottext">apply' :: ZerosLike -&gt; parameter -&gt; momentum
</span><a href="Torch.HList.html#apply%27"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="annot"><span class="annottext">ZerosLike
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">parameter
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">momentum
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span></span></span></span></span></span><span>
</span><span id="line-49"></span><span>
</span><span id="line-50"></span><span class="hs-keyword">class</span><span> </span><span id="Optimizer"><span class="annot"><a href="Torch.Typed.Optim.html#Optimizer"><span class="hs-identifier hs-var">Optimizer</span></a></span></span><span> </span><span id="local-6989586621679700765"><span class="annot"><a href="#local-6989586621679700765"><span class="hs-identifier hs-type">optim</span></a></span></span><span> </span><span id="local-6989586621679700764"><span class="annot"><a href="#local-6989586621679700764"><span class="hs-identifier hs-type">gradients</span></a></span></span><span> </span><span id="local-6989586621679700763"><span class="annot"><a href="#local-6989586621679700763"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span id="local-6989586621679700762"><span class="annot"><a href="#local-6989586621679700762"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679700761"><span class="annot"><a href="#local-6989586621679700761"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-51"></span><span>  </span><span id="step"><span class="annot"><a href="Torch.Typed.Optim.html#step"><span class="hs-identifier hs-type">step</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-52"></span><span>    </span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700761"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700762"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-53"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700764"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-54"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700763"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-55"></span><span>    </span><span class="annot"><a href="#local-6989586621679700765"><span class="hs-identifier hs-type">optim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-56"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700763"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700765"><span class="hs-identifier hs-type">optim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span>
</span><span id="line-58"></span><span class="annot"><a href="Torch.Typed.Optim.html#runStep"><span class="hs-identifier hs-type">runStep</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-59"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679700537"><span class="annot"><a href="#local-6989586621679700537"><span class="hs-identifier hs-type">model</span></a></span></span><span> </span><span id="local-6989586621679700536"><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-type">optim</span></a></span></span><span> </span><span id="local-6989586621679700535"><span class="annot"><a href="#local-6989586621679700535"><span class="hs-identifier hs-type">parameters</span></a></span></span><span> </span><span id="local-6989586621679700534"><span class="annot"><a href="#local-6989586621679700534"><span class="hs-identifier hs-type">gradients</span></a></span></span><span> </span><span id="local-6989586621679700533"><span class="annot"><a href="#local-6989586621679700533"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span id="local-6989586621679700532"><span class="annot"><a href="#local-6989586621679700532"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679700531"><span class="annot"><a href="#local-6989586621679700531"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-60"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700537"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-61"></span><span>    </span><span class="annot"><a href="#local-6989586621679700535"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameters"><span class="hs-identifier hs-type">Parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700537"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-62"></span><span>    </span><span class="annot"><a href="Torch.Typed.Autograd.html#HasGrad"><span class="hs-identifier hs-type">HasGrad</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700535"><span class="hs-identifier hs-type">parameters</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700534"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-63"></span><span>    </span><span class="annot"><a href="#local-6989586621679700533"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679700534"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-64"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-type">ToDependent</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700535"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700533"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-65"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700534"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-66"></span><span>    </span><span class="annot"><a href="Torch.Typed.Optim.html#Optimizer"><span class="hs-identifier hs-type">Optimizer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-type">optim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700534"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700533"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700532"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700531"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-67"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMapM%27"><span class="hs-identifier hs-type">HMapM'</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#MakeIndependent"><span class="hs-identifier hs-type">MakeIndependent</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700533"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700535"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-68"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-69"></span><span>  </span><span class="annot"><a href="#local-6989586621679700537"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-70"></span><span>  </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-type">optim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-71"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#Loss"><span class="hs-identifier hs-type">Loss</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700531"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700532"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-72"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700531"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700532"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-73"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700537"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-type">optim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span id="runStep"><span class="annot"><span class="annottext">runStep :: model
-&gt; optim
-&gt; Loss device dtype
-&gt; Loss device dtype
-&gt; IO (model, optim)
</span><a href="Torch.Typed.Optim.html#runStep"><span class="hs-identifier hs-var hs-var">runStep</span></a></span></span><span> </span><span id="local-6989586621679700528"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700528"><span class="hs-identifier hs-var">model</span></a></span></span><span> </span><span id="local-6989586621679700527"><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700527"><span class="hs-identifier hs-var">optim</span></a></span></span><span> </span><span id="local-6989586621679700526"><span class="annot"><span class="annottext">Loss device dtype
</span><a href="#local-6989586621679700526"><span class="hs-identifier hs-var">loss</span></a></span></span><span> </span><span id="local-6989586621679700525"><span class="annot"><span class="annottext">Loss device dtype
</span><a href="#local-6989586621679700525"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-75"></span><span>  </span><span class="annot"><span class="annottext">IO ()
</span><span class="hs-identifier hs-var">performGC</span></span><span>
</span><span id="line-76"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700524"><span class="annot"><span class="annottext">parameters :: HList (Parameters model)
</span><a href="#local-6989586621679700524"><span class="hs-identifier hs-var hs-var">parameters</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; HList (Parameters model)
forall f. Parameterized f =&gt; f -&gt; HList (Parameters f)
</span><a href="Torch.Typed.Parameter.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700528"><span class="hs-identifier hs-var">model</span></a></span><span>
</span><span id="line-77"></span><span>      </span><span id="local-6989586621679700522"><span class="annot"><span class="annottext">gradients :: HList gradients
</span><a href="#local-6989586621679700522"><span class="hs-identifier hs-var hs-var">gradients</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Loss device dtype -&gt; HList parameters -&gt; HList gradients
forall a b (dtype :: DType) (device :: (DeviceType, Nat)).
HasGrad a b =&gt;
Tensor device dtype '[] -&gt; a -&gt; b
</span><a href="Torch.Typed.Autograd.html#grad"><span class="hs-identifier hs-var">grad</span></a></span><span> </span><span class="annot"><span class="annottext">Loss device dtype
</span><a href="#local-6989586621679700526"><span class="hs-identifier hs-var">loss</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
HList (Parameters model)
</span><a href="#local-6989586621679700524"><span class="hs-identifier hs-var">parameters</span></a></span><span>
</span><span id="line-78"></span><span>      </span><span id="local-6989586621679700520"><span class="annot"><span class="annottext">tensors :: HList gradients
</span><a href="#local-6989586621679700520"><span class="hs-identifier hs-var hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ToDependent -&gt; HList parameters -&gt; HList gradients
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ToDependent
</span><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-var">ToDependent</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
HList (Parameters model)
</span><a href="#local-6989586621679700524"><span class="hs-identifier hs-var">parameters</span></a></span><span>
</span><span id="line-79"></span><span>      </span><span class="hs-special">(</span><span id="local-6989586621679700517"><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700517"><span class="hs-identifier hs-var">tensors'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700516"><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700516"><span class="hs-identifier hs-var">optim'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Loss device dtype
-&gt; HList gradients
-&gt; HList gradients
-&gt; optim
-&gt; (HList gradients, optim)
forall k k optim (gradients :: [k]) (tensors :: [k])
       (dtype :: DType) (device :: (DeviceType, Nat)).
Optimizer optim gradients tensors dtype device =&gt;
LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; optim
-&gt; (HList tensors, optim)
</span><a href="Torch.Typed.Optim.html#step"><span class="hs-identifier hs-var">step</span></a></span><span> </span><span class="annot"><span class="annottext">Loss device dtype
</span><a href="#local-6989586621679700525"><span class="hs-identifier hs-var">learningRate</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700522"><span class="hs-identifier hs-var">gradients</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700520"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700527"><span class="hs-identifier hs-var">optim</span></a></span><span>
</span><span id="line-80"></span><span>  </span><span id="local-6989586621679700515"><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679700515"><span class="hs-identifier hs-var">parameters'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">MakeIndependent -&gt; HList gradients -&gt; IO (HList parameters)
forall k (m :: Type -&gt; Type) f (xs :: [k]) (ys :: [k]).
HMapM' m f xs ys =&gt;
f -&gt; HList xs -&gt; m (HList ys)
</span><a href="Torch.HList.html#hmapM%27"><span class="hs-identifier hs-var">hmapM'</span></a></span><span> </span><span class="annot"><span class="annottext">MakeIndependent
</span><a href="Torch.Typed.Parameter.html#MakeIndependent"><span class="hs-identifier hs-var">MakeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700517"><span class="hs-identifier hs-var">tensors'</span></a></span><span>
</span><span id="line-81"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700512"><span class="annot"><span class="annottext">model' :: model
</span><a href="#local-6989586621679700512"><span class="hs-identifier hs-var hs-var">model'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; HList (Parameters model) -&gt; model
forall f. Parameterized f =&gt; f -&gt; HList (Parameters f) -&gt; f
</span><a href="Torch.Typed.Parameter.html#replaceParameters"><span class="hs-identifier hs-var">replaceParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700528"><span class="hs-identifier hs-var">model</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
HList (Parameters model)
</span><a href="#local-6989586621679700515"><span class="hs-identifier hs-var">parameters'</span></a></span><span>
</span><span id="line-82"></span><span>  </span><span class="annot"><span class="annottext">(model, optim) -&gt; IO (model, optim)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700512"><span class="hs-identifier hs-var">model'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700516"><span class="hs-identifier hs-var">optim'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>
</span><span id="line-84"></span><span class="annot"><a href="Torch.Typed.Optim.html#runStep%27"><span class="hs-identifier hs-type">runStep'</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-85"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679700509"><span class="annot"><a href="#local-6989586621679700509"><span class="hs-identifier hs-type">model</span></a></span></span><span> </span><span id="local-6989586621679700508"><span class="annot"><a href="#local-6989586621679700508"><span class="hs-identifier hs-type">optim</span></a></span></span><span> </span><span id="local-6989586621679700507"><span class="annot"><a href="#local-6989586621679700507"><span class="hs-identifier hs-type">parameters</span></a></span></span><span> </span><span id="local-6989586621679700506"><span class="annot"><a href="#local-6989586621679700506"><span class="hs-identifier hs-type">gradients</span></a></span></span><span> </span><span id="local-6989586621679700505"><span class="annot"><a href="#local-6989586621679700505"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span id="local-6989586621679700504"><span class="annot"><a href="#local-6989586621679700504"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679700503"><span class="annot"><a href="#local-6989586621679700503"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-86"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700509"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-87"></span><span>    </span><span class="annot"><a href="#local-6989586621679700507"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameters"><span class="hs-identifier hs-type">Parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700509"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-88"></span><span>    </span><span class="annot"><a href="#local-6989586621679700505"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679700506"><span class="hs-identifier hs-type">gradients</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-89"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-type">ToDependent</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700507"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700505"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-90"></span><span>    </span><span class="annot"><a href="Torch.Typed.Optim.html#Optimizer"><span class="hs-identifier hs-type">Optimizer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700508"><span class="hs-identifier hs-type">optim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700506"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700505"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700504"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700503"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-91"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMapM%27"><span class="hs-identifier hs-type">HMapM'</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#MakeIndependent"><span class="hs-identifier hs-type">MakeIndependent</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700505"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700507"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-92"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-93"></span><span>  </span><span class="annot"><a href="#local-6989586621679700509"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-94"></span><span>  </span><span class="annot"><a href="#local-6989586621679700508"><span class="hs-identifier hs-type">optim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-95"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700503"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700504"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-96"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700506"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-97"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700509"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700508"><span class="hs-identifier hs-type">optim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span id="runStep%27"><span class="annot"><span class="annottext">runStep' :: model
-&gt; optim
-&gt; LearningRate device dtype
-&gt; HList gradients
-&gt; IO (model, optim)
</span><a href="Torch.Typed.Optim.html#runStep%27"><span class="hs-identifier hs-var hs-var">runStep'</span></a></span></span><span> </span><span id="local-6989586621679700502"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700502"><span class="hs-identifier hs-var">model</span></a></span></span><span> </span><span id="local-6989586621679700501"><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">optim</span></a></span></span><span> </span><span id="local-6989586621679700500"><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700500"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span> </span><span id="local-6989586621679700499"><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700499"><span class="hs-identifier hs-var">gradients</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-99"></span><span>  </span><span class="annot"><span class="annottext">IO ()
</span><span class="hs-identifier hs-var">performGC</span></span><span>
</span><span id="line-100"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700498"><span class="annot"><span class="annottext">parameters :: HList (Parameters model)
</span><a href="#local-6989586621679700498"><span class="hs-identifier hs-var hs-var">parameters</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; HList (Parameters model)
forall f. Parameterized f =&gt; f -&gt; HList (Parameters f)
</span><a href="Torch.Typed.Parameter.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700502"><span class="hs-identifier hs-var">model</span></a></span><span>
</span><span id="line-101"></span><span>      </span><span id="local-6989586621679700497"><span class="annot"><span class="annottext">tensors :: HList gradients
</span><a href="#local-6989586621679700497"><span class="hs-identifier hs-var hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ToDependent -&gt; HList parameters -&gt; HList gradients
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ToDependent
</span><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-var">ToDependent</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
HList (Parameters model)
</span><a href="#local-6989586621679700498"><span class="hs-identifier hs-var">parameters</span></a></span><span>
</span><span id="line-102"></span><span>      </span><span class="hs-special">(</span><span id="local-6989586621679700496"><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700496"><span class="hs-identifier hs-var">tensors'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700495"><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700495"><span class="hs-identifier hs-var">optim'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
-&gt; HList gradients
-&gt; HList gradients
-&gt; optim
-&gt; (HList gradients, optim)
forall k k optim (gradients :: [k]) (tensors :: [k])
       (dtype :: DType) (device :: (DeviceType, Nat)).
Optimizer optim gradients tensors dtype device =&gt;
LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; optim
-&gt; (HList tensors, optim)
</span><a href="Torch.Typed.Optim.html#step"><span class="hs-identifier hs-var">step</span></a></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700500"><span class="hs-identifier hs-var">learningRate</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700499"><span class="hs-identifier hs-var">gradients</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700497"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">optim</span></a></span><span>
</span><span id="line-103"></span><span>  </span><span id="local-6989586621679700494"><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679700494"><span class="hs-identifier hs-var">parameters'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">MakeIndependent -&gt; HList gradients -&gt; IO (HList parameters)
forall k (m :: Type -&gt; Type) f (xs :: [k]) (ys :: [k]).
HMapM' m f xs ys =&gt;
f -&gt; HList xs -&gt; m (HList ys)
</span><a href="Torch.HList.html#hmapM%27"><span class="hs-identifier hs-var">hmapM'</span></a></span><span> </span><span class="annot"><span class="annottext">MakeIndependent
</span><a href="Torch.Typed.Parameter.html#MakeIndependent"><span class="hs-identifier hs-var">MakeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700496"><span class="hs-identifier hs-var">tensors'</span></a></span><span>
</span><span id="line-104"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700493"><span class="annot"><span class="annottext">model' :: model
</span><a href="#local-6989586621679700493"><span class="hs-identifier hs-var hs-var">model'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; HList (Parameters model) -&gt; model
forall f. Parameterized f =&gt; f -&gt; HList (Parameters f) -&gt; f
</span><a href="Torch.Typed.Parameter.html#replaceParameters"><span class="hs-identifier hs-var">replaceParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700502"><span class="hs-identifier hs-var">model</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
HList (Parameters model)
</span><a href="#local-6989586621679700494"><span class="hs-identifier hs-var">parameters'</span></a></span><span>
</span><span id="line-105"></span><span>  </span><span class="annot"><span class="annottext">(model, optim) -&gt; IO (model, optim)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700493"><span class="hs-identifier hs-var">model'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">optim
</span><a href="#local-6989586621679700495"><span class="hs-identifier hs-var">optim'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>
</span><span id="line-107"></span><span class="hs-comment">--</span><span>
</span><span id="line-108"></span><span class="hs-comment">-- Gradient Descent (GD)</span><span>
</span><span id="line-109"></span><span class="hs-comment">--</span><span>
</span><span id="line-110"></span><span>
</span><span id="line-111"></span><span class="hs-comment">-- | Dummy state representation for GD Optimizer</span><span>
</span><span id="line-112"></span><span class="hs-keyword">data</span><span> </span><span id="GD"><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-var">GD</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="GD"><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-var">GD</span></a></span></span><span>
</span><span id="line-113"></span><span>
</span><span id="line-114"></span><span class="annot"><a href="Torch.Typed.Optim.html#mkGD"><span class="hs-identifier hs-type">mkGD</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-type">GD</span></a></span><span>
</span><span id="line-115"></span><span id="mkGD"><span class="annot"><span class="annottext">mkGD :: GD
</span><a href="Torch.Typed.Optim.html#mkGD"><span class="hs-identifier hs-var hs-var">mkGD</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">GD
</span><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-var">GD</span></a></span><span>
</span><span id="line-116"></span><span>
</span><span id="line-117"></span><span class="hs-keyword">newtype</span><span> </span><span id="GDStep"><span class="annot"><a href="Torch.Typed.Optim.html#GDStep"><span class="hs-identifier hs-var">GDStep</span></a></span></span><span> </span><span id="local-6989586621679700713"><span class="annot"><a href="#local-6989586621679700713"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679700712"><span class="annot"><a href="#local-6989586621679700712"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="GDStep"><span class="annot"><a href="Torch.Typed.Optim.html#GDStep"><span class="hs-identifier hs-var">GDStep</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700713"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700712"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>
</span><span id="line-119"></span><span id="local-6989586621679700485"><span id="local-6989586621679700486"><span id="local-6989586621679700487"><span id="local-6989586621679700488"><span id="local-6989586621679700489"><span class="hs-keyword">instance</span><span>
</span><span id="line-120"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679700489"><span class="hs-identifier hs-type">parameter</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700488"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700487"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700486"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-121"></span><span>    </span><span class="annot"><a href="#local-6989586621679700485"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700488"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700487"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700486"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-122"></span><span>    </span><span class="annot"><a href="#local-6989586621679700486"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679700486"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-123"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700488"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700487"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-124"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700488"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-125"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-126"></span><span>  </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDStep"><span class="hs-identifier hs-type">GDStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700488"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700487"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700489"><span class="hs-identifier hs-type">parameter</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700485"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700489"><span class="hs-identifier hs-type">parameter</span></a></span><span>
</span><span id="line-127"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-128"></span><span>  </span><span id="local-6989586621679700483"><span class="annot"><span class="annottext">apply' :: GDStep device dtype -&gt; (parameter, gradient) -&gt; parameter
</span><a href="#local-6989586621679700483"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDStep"><span class="hs-identifier hs-type">GDStep</span></a></span><span> </span><span id="local-6989586621679700482"><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700482"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700481"><span class="annot"><span class="annottext">parameter
</span><a href="#local-6989586621679700481"><span class="hs-identifier hs-var">parameter</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700480"><span class="annot"><span class="annottext">gradient
</span><a href="#local-6989586621679700480"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><span class="annottext">parameter
</span><a href="#local-6989586621679700481"><span class="hs-identifier hs-var">parameter</span></a></span><span> </span><span class="annot"><span class="annottext">parameter -&gt; parameter -&gt; parameter
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#mul"><span class="hs-identifier hs-var">mul</span></a></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700482"><span class="hs-identifier hs-var">learningRate</span></a></span><span> </span><span class="annot"><span class="annottext">gradient
Tensor device dtype shape
</span><a href="#local-6989586621679700480"><span class="hs-identifier hs-var">gradient</span></a></span></span></span></span></span></span><span>
</span><span id="line-130"></span><span>
</span><span id="line-131"></span><span class="hs-comment">-- | Gradient descent step with a dummy state variable</span><span>
</span><span id="line-132"></span><span class="annot"><a href="Torch.Typed.Optim.html#gd"><span class="hs-identifier hs-type">gd</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-133"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679700702"><span class="annot"><a href="#local-6989586621679700702"><span class="hs-identifier hs-type">gradients</span></a></span></span><span> </span><span id="local-6989586621679700703"><span class="annot"><a href="#local-6989586621679700703"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span id="local-6989586621679700704"><span class="annot"><a href="#local-6989586621679700704"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679700705"><span class="annot"><a href="#local-6989586621679700705"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-134"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HZipWith"><span class="hs-identifier hs-type">HZipWith</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDStep"><span class="hs-identifier hs-type">GDStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700705"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700704"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700703"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700702"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700703"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-135"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700705"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700704"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-136"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700702"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-137"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700703"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-138"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-type">GD</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-139"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700703"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-type">GD</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-140"></span><span id="gd"><span class="annot"><span class="annottext">gd :: LearningRate device dtype
-&gt; HList gradients -&gt; HList tensors -&gt; GD -&gt; (HList tensors, GD)
</span><a href="Torch.Typed.Optim.html#gd"><span class="hs-identifier hs-var hs-var">gd</span></a></span></span><span> </span><span id="local-6989586621679700477"><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span> </span><span id="local-6989586621679700476"><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700476"><span class="hs-identifier hs-var">gradients</span></a></span></span><span> </span><span id="local-6989586621679700475"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700475"><span class="hs-identifier hs-var">parameters</span></a></span></span><span> </span><span id="local-6989586621679700474"><span class="annot"><span class="annottext">GD
</span><a href="#local-6989586621679700474"><span class="hs-identifier hs-var">gd</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-141"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700473"><span class="annot"><span class="annottext">step :: HList tensors
</span><a href="#local-6989586621679700473"><span class="hs-identifier hs-var hs-var">step</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">GDStep device dtype
-&gt; HList tensors -&gt; HList gradients -&gt; HList tensors
forall k f (xs :: [k]) (ys :: [k]) (zs :: [k]).
HZipWith f xs ys zs =&gt;
f -&gt; HList xs -&gt; HList ys -&gt; HList zs
</span><a href="Torch.HList.html#hzipWith"><span class="hs-identifier hs-var">hzipWith</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LearningRate device dtype -&gt; GDStep device dtype
forall (device :: (DeviceType, Nat)) (dtype :: DType).
LearningRate device dtype -&gt; GDStep device dtype
</span><a href="Torch.Typed.Optim.html#GDStep"><span class="hs-identifier hs-var">GDStep</span></a></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">learningRate</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700475"><span class="hs-identifier hs-var">parameters</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700476"><span class="hs-identifier hs-var">gradients</span></a></span><span> </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700473"><span class="hs-identifier hs-var">step</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">GD
</span><a href="#local-6989586621679700474"><span class="hs-identifier hs-var">gd</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>
</span><span id="line-143"></span><span id="local-6989586621679700468"><span id="local-6989586621679700469"><span id="local-6989586621679700470"><span id="local-6989586621679700471"><span class="hs-keyword">instance</span><span>
</span><span id="line-144"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWith"><span class="hs-identifier hs-type">HZipWith</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDStep"><span class="hs-identifier hs-type">GDStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700471"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700470"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700469"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700468"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700469"><span class="hs-identifier hs-type">tensors</span></a></span><span>
</span><span id="line-145"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-146"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#Optimizer"><span class="hs-identifier hs-type">Optimizer</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-type">GD</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700468"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700469"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700470"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700471"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-147"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-148"></span><span>  </span><span id="local-6989586621679700465"><span class="annot"><span class="annottext">step :: LearningRate device dtype
-&gt; HList gradients -&gt; HList tensors -&gt; GD -&gt; (HList tensors, GD)
</span><a href="#local-6989586621679700465"><span class="hs-identifier hs-var hs-var hs-var hs-var">step</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
-&gt; HList gradients -&gt; HList tensors -&gt; GD -&gt; (HList tensors, GD)
forall k (gradients :: [k]) (tensors :: [k]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
HZipWith (GDStep device dtype) tensors gradients tensors =&gt;
LearningRate device dtype
-&gt; HList gradients -&gt; HList tensors -&gt; GD -&gt; (HList tensors, GD)
</span><a href="Torch.Typed.Optim.html#gd"><span class="hs-identifier hs-var">gd</span></a></span></span></span></span></span><span>
</span><span id="line-149"></span><span>
</span><span id="line-150"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-type">GD</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-151"></span><span>  </span><span class="hs-keyword">type</span><span> </span><span id="Parameters"><span class="annot"><a href="Torch.Typed.Parameter.html#Parameters"><span class="hs-identifier hs-var">Parameters</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#GD"><span class="hs-identifier hs-type">GD</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-152"></span><span>  </span><span id="local-6989586621679700461"><span class="annot"><span class="annottext">flattenParameters :: GD -&gt; HList (Parameters GD)
</span><a href="#local-6989586621679700461"><span class="hs-identifier hs-var hs-var hs-var hs-var">flattenParameters</span></a></span></span><span> </span><span class="annot"><span class="annottext">GD
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList (Parameters GD)
forall k. HList '[]
</span><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-var">HNil</span></a></span><span>
</span><span id="line-153"></span><span>  </span><span id="local-6989586621679700459"><span class="annot"><span class="annottext">replaceParameters :: GD -&gt; HList (Parameters GD) -&gt; GD
</span><a href="#local-6989586621679700459"><span class="hs-identifier hs-var hs-var hs-var hs-var">replaceParameters</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">GD -&gt; HList (Parameters GD) -&gt; GD
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span>
</span><span id="line-154"></span><span>
</span><span id="line-155"></span><span class="hs-comment">--</span><span>
</span><span id="line-156"></span><span class="hs-comment">-- Gradient Descent with Momentum (GDM)</span><span>
</span><span id="line-157"></span><span class="hs-comment">--</span><span>
</span><span id="line-158"></span><span>
</span><span id="line-159"></span><span class="hs-comment">-- | State representation for GDM Optimizer</span><span>
</span><span id="line-160"></span><span class="hs-keyword">data</span><span> </span><span id="GDM"><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-var">GDM</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700693"><span class="annot"><a href="#local-6989586621679700693"><span class="hs-identifier hs-type">momenta</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span id="GDM"><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-var">GDM</span></a></span></span><span>
</span><span id="line-161"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="beta"><span class="annot"><span class="annottext">GDM momenta -&gt; Float
</span><a href="Torch.Typed.Optim.html#beta"><span class="hs-identifier hs-var hs-var">beta</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span class="hs-comment">-- moment forgetting factor</span><span>
</span><span id="line-162"></span><span>    </span><span id="momenta"><span class="annot"><span class="annottext">GDM momenta -&gt; HList momenta
</span><a href="Torch.Typed.Optim.html#momenta"><span class="hs-identifier hs-var hs-var">momenta</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700693"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="hs-comment">-- momenta</span><span>
</span><span id="line-163"></span><span>  </span><span class="hs-special">}</span><span>
</span><span id="line-164"></span><span>
</span><span id="line-165"></span><span class="annot"><a href="Torch.Typed.Optim.html#mkGDM"><span class="hs-identifier hs-type">mkGDM</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-166"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679700453"><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-type">parameters</span></a></span></span><span> </span><span id="local-6989586621679700452"><span class="annot"><a href="#local-6989586621679700452"><span class="hs-identifier hs-type">momenta</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-167"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-type">ZerosLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700452"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-168"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-169"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-170"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700452"><span class="hs-identifier hs-type">momenta</span></a></span><span>
</span><span id="line-171"></span><span id="mkGDM"><span class="annot"><span class="annottext">mkGDM :: Float -&gt; HList parameters -&gt; GDM momenta
</span><a href="Torch.Typed.Optim.html#mkGDM"><span class="hs-identifier hs-var hs-var">mkGDM</span></a></span></span><span> </span><span id="local-6989586621679700451"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700451"><span class="hs-identifier hs-var">beta</span></a></span></span><span> </span><span id="local-6989586621679700450"><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679700450"><span class="hs-identifier hs-var">parameters</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; HList momenta -&gt; GDM momenta
forall (momenta :: [Type]). Float -&gt; HList momenta -&gt; GDM momenta
</span><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-var">GDM</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700451"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ZerosLike -&gt; HList parameters -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ZerosLike
</span><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-var">ZerosLike</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679700450"><span class="hs-identifier hs-var">parameters</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-172"></span><span>
</span><span id="line-173"></span><span class="hs-keyword">data</span><span> </span><span id="GDMStep"><span class="annot"><a href="Torch.Typed.Optim.html#GDMStep"><span class="hs-identifier hs-var">GDMStep</span></a></span></span><span> </span><span id="local-6989586621679700667"><span class="annot"><a href="#local-6989586621679700667"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679700666"><span class="annot"><a href="#local-6989586621679700666"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="GDMStep"><span class="annot"><a href="Torch.Typed.Optim.html#GDMStep"><span class="hs-identifier hs-var">GDMStep</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700667"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700666"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-174"></span><span>
</span><span id="line-175"></span><span id="local-6989586621679700443"><span id="local-6989586621679700444"><span id="local-6989586621679700445"><span id="local-6989586621679700446"><span id="local-6989586621679700447"><span id="local-6989586621679700448"><span class="hs-keyword">instance</span><span>
</span><span id="line-176"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679700448"><span class="hs-identifier hs-type">parameter</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700447"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700446"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700445"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-177"></span><span>    </span><span class="annot"><a href="#local-6989586621679700444"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700447"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700446"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700445"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-178"></span><span>    </span><span class="annot"><a href="#local-6989586621679700443"><span class="hs-identifier hs-type">momentum</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700447"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700446"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700445"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-179"></span><span>    </span><span class="annot"><a href="#local-6989586621679700445"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679700445"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-180"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700447"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-181"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700447"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700446"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-182"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-183"></span><span>  </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDMStep"><span class="hs-identifier hs-type">GDMStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700447"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700446"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700448"><span class="hs-identifier hs-type">parameter</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700444"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700443"><span class="hs-identifier hs-type">momentum</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700448"><span class="hs-identifier hs-type">parameter</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700443"><span class="hs-identifier hs-type">momentum</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-184"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-185"></span><span>  </span><span id="local-6989586621679700441"><span class="annot"><span class="annottext">apply' :: GDMStep device dtype
-&gt; (parameter, gradient, momentum) -&gt; (parameter, momentum)
</span><a href="#local-6989586621679700441"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDMStep"><span class="hs-identifier hs-type">GDMStep</span></a></span><span> </span><span id="local-6989586621679700440"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700440"><span class="hs-identifier hs-var">beta</span></a></span></span><span> </span><span id="local-6989586621679700439"><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700439"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700438"><span class="annot"><span class="annottext">parameter
</span><a href="#local-6989586621679700438"><span class="hs-identifier hs-var">parameter</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700437"><span class="annot"><span class="annottext">gradient
</span><a href="#local-6989586621679700437"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700436"><span class="annot"><span class="annottext">momentum
</span><a href="#local-6989586621679700436"><span class="hs-identifier hs-var">momentum</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-186"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700435"><span class="annot"><span class="annottext">momentum' :: Tensor device dtype shape
</span><a href="#local-6989586621679700435"><span class="hs-identifier hs-var hs-var">momentum'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700440"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="annot"><span class="annottext">momentum
Tensor device dtype shape
</span><a href="#local-6989586621679700436"><span class="hs-identifier hs-var">momentum</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">gradient
Tensor device dtype shape
</span><a href="#local-6989586621679700437"><span class="hs-identifier hs-var">gradient</span></a></span><span>
</span><span id="line-187"></span><span>        </span><span id="local-6989586621679700432"><span class="annot"><span class="annottext">parameter' :: parameter
</span><a href="#local-6989586621679700432"><span class="hs-identifier hs-var hs-var">parameter'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">parameter
</span><a href="#local-6989586621679700438"><span class="hs-identifier hs-var">parameter</span></a></span><span> </span><span class="annot"><span class="annottext">parameter -&gt; parameter -&gt; parameter
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#mul"><span class="hs-identifier hs-var">mul</span></a></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700439"><span class="hs-identifier hs-var">learningRate</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679700435"><span class="hs-identifier hs-var">momentum'</span></a></span><span>
</span><span id="line-188"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">parameter
</span><a href="#local-6989586621679700432"><span class="hs-identifier hs-var">parameter'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">momentum
Tensor device dtype shape
</span><a href="#local-6989586621679700435"><span class="hs-identifier hs-var">momentum'</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-189"></span><span>
</span><span id="line-190"></span><span class="hs-comment">-- | gradient descent with momentum step</span><span>
</span><span id="line-191"></span><span class="annot"><a href="Torch.Typed.Optim.html#gdm"><span class="hs-identifier hs-type">gdm</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-192"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679700654"><span class="annot"><a href="#local-6989586621679700654"><span class="hs-identifier hs-type">gradients</span></a></span></span><span> </span><span id="local-6989586621679700655"><span class="annot"><a href="#local-6989586621679700655"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span id="local-6989586621679700653"><span class="annot"><a href="#local-6989586621679700653"><span class="hs-identifier hs-type">momenta</span></a></span></span><span> </span><span id="local-6989586621679700652"><span class="annot"><a href="#local-6989586621679700652"><span class="hs-identifier hs-type">gdmStep</span></a></span></span><span> </span><span id="local-6989586621679700656"><span class="annot"><a href="#local-6989586621679700656"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679700657"><span class="annot"><a href="#local-6989586621679700657"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-193"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWith3"><span class="hs-identifier hs-type">HZipWith3</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDMStep"><span class="hs-identifier hs-type">GDMStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700657"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700656"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700655"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700654"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700653"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700652"><span class="hs-identifier hs-type">gdmStep</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-194"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#AFst"><span class="hs-identifier hs-type">AFst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700652"><span class="hs-identifier hs-type">gdmStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700655"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-195"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#ASnd"><span class="hs-identifier hs-type">ASnd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700652"><span class="hs-identifier hs-type">gdmStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700653"><span class="hs-identifier hs-type">momenta</span></a></span><span>
</span><span id="line-196"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-197"></span><span>  </span><span class="hs-comment">-- | learning rate</span><span>
</span><span id="line-198"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700657"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700656"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-199"></span><span>  </span><span class="hs-comment">-- | model parameter gradient tensors</span><span>
</span><span id="line-200"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700654"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-201"></span><span>  </span><span class="hs-comment">-- | model parameter tensors</span><span>
</span><span id="line-202"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700655"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-203"></span><span>  </span><span class="hs-comment">-- | beta and model parameter momentum tensors</span><span>
</span><span id="line-204"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700653"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-205"></span><span>  </span><span class="hs-comment">-- | returns updated parameters and momenta</span><span>
</span><span id="line-206"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700655"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700653"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-207"></span><span id="gdm"><span class="annot"><span class="annottext">gdm :: LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; GDM momenta
-&gt; (HList tensors, GDM momenta)
</span><a href="Torch.Typed.Optim.html#gdm"><span class="hs-identifier hs-var hs-var">gdm</span></a></span></span><span> </span><span id="local-6989586621679700430"><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700430"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span> </span><span id="local-6989586621679700429"><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700429"><span class="hs-identifier hs-var">gradients</span></a></span></span><span> </span><span id="local-6989586621679700428"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700428"><span class="hs-identifier hs-var">parameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span id="local-6989586621679700427"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700427"><span class="hs-identifier hs-var">beta</span></a></span></span><span> </span><span id="local-6989586621679700426"><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700426"><span class="hs-identifier hs-var">momenta</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-208"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700425"><span class="annot"><span class="annottext">step :: HList gdmStep
</span><a href="#local-6989586621679700425"><span class="hs-identifier hs-var hs-var">step</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">GDMStep device dtype
-&gt; HList tensors
-&gt; HList gradients
-&gt; HList momenta
-&gt; HList gdmStep
forall k f (as :: [k]) (bs :: [k]) (cs :: [k]) (ds :: [k]).
HZipWith3 f as bs cs ds =&gt;
f -&gt; HList as -&gt; HList bs -&gt; HList cs -&gt; HList ds
</span><a href="Torch.HList.html#hzipWith3"><span class="hs-identifier hs-var">hzipWith3</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; LearningRate device dtype -&gt; GDMStep device dtype
forall (device :: (DeviceType, Nat)) (dtype :: DType).
Float -&gt; LearningRate device dtype -&gt; GDMStep device dtype
</span><a href="Torch.Typed.Optim.html#GDMStep"><span class="hs-identifier hs-var">GDMStep</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700427"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700430"><span class="hs-identifier hs-var">learningRate</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700428"><span class="hs-identifier hs-var">parameters</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700429"><span class="hs-identifier hs-var">gradients</span></a></span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700426"><span class="hs-identifier hs-var">momenta</span></a></span><span>
</span><span id="line-209"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">AFst -&gt; HList gdmStep -&gt; HList tensors
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">AFst
</span><a href="Torch.HList.html#AFst"><span class="hs-identifier hs-var">AFst</span></a></span><span> </span><span class="annot"><span class="annottext">HList gdmStep
</span><a href="#local-6989586621679700425"><span class="hs-identifier hs-var">step</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float -&gt; HList momenta -&gt; GDM momenta
forall (momenta :: [Type]). Float -&gt; HList momenta -&gt; GDM momenta
</span><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-var">GDM</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700427"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ASnd -&gt; HList gdmStep -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ASnd
</span><a href="Torch.HList.html#ASnd"><span class="hs-identifier hs-var">ASnd</span></a></span><span> </span><span class="annot"><span class="annottext">HList gdmStep
</span><a href="#local-6989586621679700425"><span class="hs-identifier hs-var">step</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-210"></span><span>
</span><span id="line-211"></span><span id="local-6989586621679700416"><span id="local-6989586621679700417"><span id="local-6989586621679700418"><span id="local-6989586621679700419"><span id="local-6989586621679700420"><span id="local-6989586621679700421"><span class="hs-keyword">instance</span><span>
</span><span id="line-212"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWith3"><span class="hs-identifier hs-type">HZipWith3</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDMStep"><span class="hs-identifier hs-type">GDMStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700420"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700419"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700418"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700417"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700416"><span class="hs-identifier hs-type">gdmStep</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-213"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#AFst"><span class="hs-identifier hs-type">AFst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700416"><span class="hs-identifier hs-type">gdmStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700419"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-214"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#ASnd"><span class="hs-identifier hs-type">ASnd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700416"><span class="hs-identifier hs-type">gdmStep</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700417"><span class="hs-identifier hs-type">momenta</span></a></span><span>
</span><span id="line-215"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-216"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#Optimizer"><span class="hs-identifier hs-type">Optimizer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700417"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700418"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700419"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700420"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-218"></span><span>  </span><span id="local-6989586621679700414"><span class="annot"><span class="annottext">step :: LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; GDM momenta
-&gt; (HList tensors, GDM momenta)
</span><a href="#local-6989586621679700414"><span class="hs-identifier hs-var hs-var hs-var hs-var">step</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; GDM momenta
-&gt; (HList tensors, GDM momenta)
forall (gradients :: [Type]) (tensors :: [Type])
       (momenta :: [Type]) (gdmStep :: [Type]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(HZipWith3
   (GDMStep device dtype) tensors gradients momenta gdmStep,
 HMap' AFst gdmStep tensors, HMap' ASnd gdmStep momenta) =&gt;
LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; GDM momenta
-&gt; (HList tensors, GDM momenta)
</span><a href="Torch.Typed.Optim.html#gdm"><span class="hs-identifier hs-var">gdm</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-219"></span><span>
</span><span id="line-220"></span><span id="local-6989586621679700413"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700413"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-221"></span><span>  </span><span class="hs-keyword">type</span><span> </span><span id="Parameters"><span class="annot"><a href="Torch.Typed.Parameter.html#Parameters"><span class="hs-identifier hs-var">Parameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700413"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679700413"><span class="hs-identifier hs-type">momenta</span></a></span><span>
</span><span id="line-222"></span><span>  </span><span id="local-6989586621679700410"><span class="annot"><span class="annottext">flattenParameters :: GDM momenta -&gt; HList (Parameters (GDM momenta))
</span><a href="#local-6989586621679700410"><span class="hs-identifier hs-var hs-var hs-var hs-var">flattenParameters</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#GDM"><span class="hs-identifier hs-type">GDM</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679700408"><span id="local-6989586621679700409"><span class="annot"><span class="annottext">Float
HList momenta
momenta :: HList momenta
beta :: Float
momenta :: forall (momenta :: [Type]). GDM momenta -&gt; HList momenta
beta :: forall (momenta :: [Type]). GDM momenta -&gt; Float
</span><a href="#local-6989586621679700408"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList momenta
HList (Parameters (GDM momenta))
</span><a href="#local-6989586621679700408"><span class="hs-identifier hs-var">momenta</span></a></span><span>
</span><span id="line-223"></span><span>  </span><span id="local-6989586621679700407"><span class="annot"><span class="annottext">replaceParameters :: GDM momenta -&gt; HList (Parameters (GDM momenta)) -&gt; GDM momenta
</span><a href="#local-6989586621679700407"><span class="hs-identifier hs-var hs-var hs-var hs-var">replaceParameters</span></a></span></span><span> </span><span id="local-6989586621679700406"><span class="annot"><span class="annottext">GDM momenta
</span><a href="#local-6989586621679700406"><span class="hs-identifier hs-var">gdm</span></a></span></span><span> </span><span id="local-6989586621679700405"><span class="annot"><span class="annottext">HList (Parameters (GDM momenta))
</span><a href="#local-6989586621679700405"><span class="hs-identifier hs-var">momenta</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">GDM momenta
</span><a href="#local-6989586621679700406"><span class="hs-identifier hs-var">gdm</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">momenta :: HList momenta
</span><a href="Torch.Typed.Optim.html#momenta"><span class="hs-identifier hs-var">momenta</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList momenta
HList (Parameters (GDM momenta))
</span><a href="#local-6989586621679700405"><span class="hs-identifier hs-var">momenta</span></a></span><span class="hs-special">}</span></span><span>
</span><span id="line-224"></span><span>
</span><span id="line-225"></span><span class="hs-comment">--</span><span>
</span><span id="line-226"></span><span class="hs-comment">-- Adam</span><span>
</span><span id="line-227"></span><span class="hs-comment">-- https://arxiv.org/pdf/1412.6980.pdf</span><span>
</span><span id="line-228"></span><span class="hs-comment">--</span><span>
</span><span id="line-229"></span><span>
</span><span id="line-230"></span><span class="hs-keyword">type</span><span> </span><span id="AdamIter"><span class="annot"><a href="Torch.Typed.Optim.html#AdamIter"><span class="hs-identifier hs-var">AdamIter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-231"></span><span>
</span><span id="line-232"></span><span class="hs-comment">-- | State representation for Adam Optimizer</span><span>
</span><span id="line-233"></span><span class="hs-keyword">data</span><span> </span><span id="Adam"><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-var">Adam</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700641"><span class="annot"><a href="#local-6989586621679700641"><span class="hs-identifier hs-type">momenta</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span id="Adam"><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-var">Adam</span></a></span></span><span>
</span><span id="line-234"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="iter"><span class="annot"><span class="annottext">Adam momenta -&gt; AdamIter
</span><a href="Torch.Typed.Optim.html#iter"><span class="hs-identifier hs-var hs-var">iter</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamIter"><span class="hs-identifier hs-type">AdamIter</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-comment">-- iteration</span><span>
</span><span id="line-235"></span><span>    </span><span id="beta1"><span class="annot"><span class="annottext">Adam momenta -&gt; Float
</span><a href="Torch.Typed.Optim.html#beta1"><span class="hs-identifier hs-var hs-var">beta1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span class="hs-comment">-- 1st moment forgetting factor</span><span>
</span><span id="line-236"></span><span>    </span><span id="beta2"><span class="annot"><span class="annottext">Adam momenta -&gt; Float
</span><a href="Torch.Typed.Optim.html#beta2"><span class="hs-identifier hs-var hs-var">beta2</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span class="hs-comment">-- 2nd moment forgetting factor</span><span>
</span><span id="line-237"></span><span>    </span><span id="momenta1"><span class="annot"><span class="annottext">Adam momenta -&gt; HList momenta
</span><a href="Torch.Typed.Optim.html#momenta1"><span class="hs-identifier hs-var hs-var">momenta1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700641"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-comment">-- 1st momenta</span><span>
</span><span id="line-238"></span><span>    </span><span id="momenta2"><span class="annot"><span class="annottext">Adam momenta -&gt; HList momenta
</span><a href="Torch.Typed.Optim.html#momenta2"><span class="hs-identifier hs-var hs-var">momenta2</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700641"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="hs-comment">-- 2nd momenta</span><span>
</span><span id="line-239"></span><span>  </span><span class="hs-special">}</span><span>
</span><span id="line-240"></span><span>
</span><span id="line-241"></span><span class="annot"><a href="Torch.Typed.Optim.html#mkAdam"><span class="hs-identifier hs-type">mkAdam</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-242"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679700397"><span class="annot"><a href="#local-6989586621679700397"><span class="hs-identifier hs-type">parameters</span></a></span></span><span> </span><span id="local-6989586621679700396"><span class="annot"><a href="#local-6989586621679700396"><span class="hs-identifier hs-type">momenta</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-243"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-type">ZerosLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700397"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700396"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-244"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamIter"><span class="hs-identifier hs-type">AdamIter</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-245"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-246"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-247"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700397"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-248"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700396"><span class="hs-identifier hs-type">momenta</span></a></span><span>
</span><span id="line-249"></span><span id="mkAdam"><span class="annot"><span class="annottext">mkAdam :: AdamIter -&gt; Float -&gt; Float -&gt; HList parameters -&gt; Adam momenta
</span><a href="Torch.Typed.Optim.html#mkAdam"><span class="hs-identifier hs-var hs-var">mkAdam</span></a></span></span><span> </span><span id="local-6989586621679700395"><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700395"><span class="hs-identifier hs-var">iter</span></a></span></span><span> </span><span id="local-6989586621679700394"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700394"><span class="hs-identifier hs-var">beta1</span></a></span></span><span> </span><span id="local-6989586621679700393"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700393"><span class="hs-identifier hs-var">beta2</span></a></span></span><span> </span><span id="local-6989586621679700392"><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679700392"><span class="hs-identifier hs-var">parameters</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-250"></span><span>  </span><span class="annot"><span class="annottext">AdamIter
-&gt; Float -&gt; Float -&gt; HList momenta -&gt; HList momenta -&gt; Adam momenta
forall (momenta :: [Type]).
AdamIter
-&gt; Float -&gt; Float -&gt; HList momenta -&gt; HList momenta -&gt; Adam momenta
</span><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-var">Adam</span></a></span><span>
</span><span id="line-251"></span><span>    </span><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700395"><span class="hs-identifier hs-var">iter</span></a></span><span>
</span><span id="line-252"></span><span>    </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700394"><span class="hs-identifier hs-var">beta1</span></a></span><span>
</span><span id="line-253"></span><span>    </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700393"><span class="hs-identifier hs-var">beta2</span></a></span><span>
</span><span id="line-254"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ZerosLike -&gt; HList parameters -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ZerosLike
</span><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-var">ZerosLike</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679700392"><span class="hs-identifier hs-var">parameters</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ZerosLike -&gt; HList parameters -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ZerosLike
</span><a href="Torch.Typed.Optim.html#ZerosLike"><span class="hs-identifier hs-var">ZerosLike</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679700392"><span class="hs-identifier hs-var">parameters</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>
</span><span id="line-257"></span><span class="hs-keyword">newtype</span><span> </span><span id="AdamMomentum1Update"><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum1Update"><span class="hs-identifier hs-var">AdamMomentum1Update</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="AdamMomentum1Update"><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum1Update"><span class="hs-identifier hs-var">AdamMomentum1Update</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span>
</span><span id="line-258"></span><span>
</span><span id="line-259"></span><span class="hs-comment">-- | decaying average of the first momenta</span><span>
</span><span id="line-260"></span><span id="local-6989586621679700386"><span id="local-6989586621679700387"><span id="local-6989586621679700388"><span id="local-6989586621679700389"><span id="local-6989586621679700390"><span class="hs-keyword">instance</span><span>
</span><span id="line-261"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679700390"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700389"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700388"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700387"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-262"></span><span>    </span><span class="annot"><a href="#local-6989586621679700386"><span class="hs-identifier hs-type">momentum1</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700389"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700388"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700387"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-263"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700389"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-264"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-265"></span><span>  </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum1Update"><span class="hs-identifier hs-type">AdamMomentum1Update</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700386"><span class="hs-identifier hs-type">momentum1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700390"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700386"><span class="hs-identifier hs-type">momentum1</span></a></span><span>
</span><span id="line-266"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-267"></span><span>  </span><span id="local-6989586621679700384"><span class="annot"><span class="annottext">apply' :: AdamMomentum1Update -&gt; (momentum1, gradient) -&gt; momentum1
</span><a href="#local-6989586621679700384"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum1Update"><span class="hs-identifier hs-type">AdamMomentum1Update</span></a></span><span> </span><span id="local-6989586621679700383"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700383"><span class="hs-identifier hs-var">beta1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700382"><span class="annot"><span class="annottext">momentum1
</span><a href="#local-6989586621679700382"><span class="hs-identifier hs-var">momentum1</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700381"><span class="annot"><span class="annottext">gradient
</span><a href="#local-6989586621679700381"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-268"></span><span>    </span><span class="annot"><span class="annottext">Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700383"><span class="hs-identifier hs-var">beta1</span></a></span><span> </span><span class="annot"><span class="annottext">momentum1
Tensor device dtype shape
</span><a href="#local-6989586621679700382"><span class="hs-identifier hs-var">momentum1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700383"><span class="hs-identifier hs-var">beta1</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">gradient
Tensor device dtype shape
</span><a href="#local-6989586621679700381"><span class="hs-identifier hs-var">gradient</span></a></span></span></span></span></span></span><span>
</span><span id="line-269"></span><span>
</span><span id="line-270"></span><span class="hs-keyword">newtype</span><span> </span><span id="AdamMomentum2Update"><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum2Update"><span class="hs-identifier hs-var">AdamMomentum2Update</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="AdamMomentum2Update"><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum2Update"><span class="hs-identifier hs-var">AdamMomentum2Update</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span>
</span><span id="line-271"></span><span>
</span><span id="line-272"></span><span class="hs-comment">-- | decaying average of the second momenta</span><span>
</span><span id="line-273"></span><span id="local-6989586621679700375"><span id="local-6989586621679700376"><span id="local-6989586621679700377"><span id="local-6989586621679700378"><span id="local-6989586621679700379"><span class="hs-keyword">instance</span><span>
</span><span id="line-274"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679700379"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700378"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700377"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700376"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-275"></span><span>    </span><span class="annot"><a href="#local-6989586621679700375"><span class="hs-identifier hs-type">momentum2</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700378"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700377"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700376"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-276"></span><span>    </span><span class="annot"><a href="#local-6989586621679700376"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700376"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700376"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-277"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700378"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-278"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700378"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700377"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-280"></span><span>  </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum2Update"><span class="hs-identifier hs-type">AdamMomentum2Update</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700375"><span class="hs-identifier hs-type">momentum2</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700379"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700375"><span class="hs-identifier hs-type">momentum2</span></a></span><span>
</span><span id="line-281"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-282"></span><span>  </span><span id="local-6989586621679700373"><span class="annot"><span class="annottext">apply' :: AdamMomentum2Update -&gt; (momentum2, gradient) -&gt; momentum2
</span><a href="#local-6989586621679700373"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum2Update"><span class="hs-identifier hs-type">AdamMomentum2Update</span></a></span><span> </span><span id="local-6989586621679700372"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700372"><span class="hs-identifier hs-var">beta2</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700371"><span class="annot"><span class="annottext">momentum2
</span><a href="#local-6989586621679700371"><span class="hs-identifier hs-var">momentum2</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700370"><span class="annot"><span class="annottext">gradient
</span><a href="#local-6989586621679700370"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-283"></span><span>    </span><span class="annot"><span class="annottext">Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700372"><span class="hs-identifier hs-var">beta2</span></a></span><span> </span><span class="annot"><span class="annottext">momentum2
Tensor device dtype shape
</span><a href="#local-6989586621679700371"><span class="hs-identifier hs-var">momentum2</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700372"><span class="hs-identifier hs-var">beta2</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype shape
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#mul"><span class="hs-identifier hs-var">mul</span></a></span><span> </span><span class="annot"><span class="annottext">gradient
Tensor device dtype shape
</span><a href="#local-6989586621679700370"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">gradient
Tensor device dtype shape
</span><a href="#local-6989586621679700370"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-284"></span><span>
</span><span id="line-285"></span><span class="hs-keyword">data</span><span> </span><span id="AdamBiasAdjustment"><span class="annot"><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-var">AdamBiasAdjustment</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="AdamBiasAdjustment"><span class="annot"><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-var">AdamBiasAdjustment</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamIter"><span class="hs-identifier hs-type">AdamIter</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span>
</span><span id="line-286"></span><span>
</span><span id="line-287"></span><span class="hs-comment">-- | bias adjustment</span><span>
</span><span id="line-288"></span><span id="local-6989586621679700365"><span id="local-6989586621679700366"><span id="local-6989586621679700367"><span id="local-6989586621679700368"><span class="hs-keyword">instance</span><span>
</span><span id="line-289"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679700368"><span class="hs-identifier hs-type">momentum</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700367"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700366"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700365"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-290"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700367"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-291"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700366"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-292"></span><span>    </span><span class="annot"><a href="#local-6989586621679700365"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700365"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-293"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700367"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700366"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-294"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-295"></span><span>  </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-type">AdamBiasAdjustment</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700368"><span class="hs-identifier hs-type">momentum</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700368"><span class="hs-identifier hs-type">momentum</span></a></span><span>
</span><span id="line-296"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-297"></span><span>  </span><span id="local-6989586621679700363"><span class="annot"><span class="annottext">apply' :: AdamBiasAdjustment -&gt; momentum -&gt; momentum
</span><a href="#local-6989586621679700363"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-type">AdamBiasAdjustment</span></a></span><span> </span><span id="local-6989586621679700362"><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700362"><span class="hs-identifier hs-var">iter</span></a></span></span><span> </span><span id="local-6989586621679700361"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700361"><span class="hs-identifier hs-var">beta</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679700360"><span class="annot"><span class="annottext">momentum
</span><a href="#local-6989586621679700360"><span class="hs-identifier hs-var">momentum</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-298"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700359"><span class="annot"><span class="annottext">iter' :: Tensor device dtype '[]
</span><a href="#local-6989586621679700359"><span class="hs-identifier hs-var hs-var">iter'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (device' :: (DeviceType, Nat)) (device :: (DeviceType, Nat))
       (dtype :: DType) (shape :: [Nat]).
KnownDevice device' =&gt;
Tensor device dtype shape -&gt; Tensor device' dtype shape
forall (dtype :: DType) (shape :: [Nat]).
KnownDevice device =&gt;
Tensor '( 'CPU, 0) dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Tensor.html#toDevice"><span class="hs-identifier hs-var">toDevice</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679700367"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor '( 'CPU, 0) dtype '[] -&gt; Tensor device dtype '[])
-&gt; (AdamIter -&gt; Tensor '( 'CPU, 0) dtype '[])
-&gt; AdamIter
-&gt; Tensor device dtype '[]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (device :: (DeviceType, Nat)) (shape :: [Nat]).
KnownDType dtype =&gt;
Tensor device 'Int64 shape -&gt; Tensor device dtype shape
forall (dtype' :: DType) (dtype :: DType)
       (device :: (DeviceType, Nat)) (shape :: [Nat]).
KnownDType dtype' =&gt;
Tensor device dtype shape -&gt; Tensor device dtype' shape
</span><a href="Torch.Typed.Tensor.html#toDType"><span class="hs-identifier hs-var">toDType</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679700366"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><span class="annottext">(AdamIter -&gt; Tensor device dtype '[])
-&gt; AdamIter -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700362"><span class="hs-identifier hs-var">iter</span></a></span><span> </span><span class="annot"><span class="annottext">AdamIter -&gt; AdamIter -&gt; AdamIter
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">AdamIter
</span><span class="hs-number">1</span></span><span>
</span><span id="line-299"></span><span>        </span><span id="local-6989586621679700355"><span class="annot"><span class="annottext">beta' :: Tensor device dtype '[]
</span><a href="#local-6989586621679700355"><span class="hs-identifier hs-var hs-var">beta'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Tensor device dtype '[]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)) a.
(TensorOptions shape dtype device, Scalar a) =&gt;
a -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#full"><span class="hs-identifier hs-var">full</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679700366"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679700367"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700361"><span class="hs-identifier hs-var">beta</span></a></span><span>
</span><span id="line-300"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">momentum
Tensor device dtype shape
</span><a href="#local-6989586621679700360"><span class="hs-identifier hs-var">momentum</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
-&gt; Tensor device dtype '[] -&gt; Tensor device dtype shape
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#div"><span class="hs-operator hs-var">`div`</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[]
</span><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[]
-&gt; Tensor device dtype '[] -&gt; Tensor device dtype '[]
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[]
-&gt; Tensor device dtype '[] -&gt; Tensor device dtype '[]
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(BasicArithmeticDTypeIsValid device dtype,
 shape'' ~ Broadcast shape shape') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype shape' -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Functional.html#pow"><span class="hs-identifier hs-var">pow</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[]
</span><a href="#local-6989586621679700359"><span class="hs-identifier hs-var">iter'</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[]
</span><a href="#local-6989586621679700355"><span class="hs-identifier hs-var">beta'</span></a></span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-301"></span><span>
</span><span id="line-302"></span><span class="hs-keyword">data</span><span> </span><span id="AdamParameterUpdate"><span class="annot"><a href="Torch.Typed.Optim.html#AdamParameterUpdate"><span class="hs-identifier hs-var">AdamParameterUpdate</span></a></span></span><span> </span><span id="local-6989586621679700580"><span class="annot"><a href="#local-6989586621679700580"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679700579"><span class="annot"><a href="#local-6989586621679700579"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="AdamParameterUpdate"><span class="annot"><a href="Torch.Typed.Optim.html#AdamParameterUpdate"><span class="hs-identifier hs-var">AdamParameterUpdate</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700580"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700579"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>
</span><span id="line-304"></span><span class="hs-comment">-- | parameter update</span><span>
</span><span id="line-305"></span><span id="local-6989586621679700346"><span id="local-6989586621679700347"><span id="local-6989586621679700348"><span id="local-6989586621679700349"><span id="local-6989586621679700350"><span class="hs-keyword">instance</span><span>
</span><span id="line-306"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679700350"><span class="hs-identifier hs-type">parameter</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700348"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700347"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-307"></span><span>    </span><span class="annot"><a href="#local-6989586621679700346"><span class="hs-identifier hs-type">momentum</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700348"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700347"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-308"></span><span>    </span><span class="annot"><a href="#local-6989586621679700347"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679700347"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-309"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700349"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-310"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700348"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-311"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700348"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-312"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-313"></span><span>  </span><span class="annot"><a href="Torch.HList.html#Apply%27"><span class="hs-identifier hs-type">Apply'</span></a></span><span>
</span><span id="line-314"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#AdamParameterUpdate"><span class="hs-identifier hs-type">AdamParameterUpdate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700348"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700350"><span class="hs-identifier hs-type">parameter</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700346"><span class="hs-identifier hs-type">momentum</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679700346"><span class="hs-identifier hs-type">momentum</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>    </span><span class="annot"><a href="#local-6989586621679700350"><span class="hs-identifier hs-type">parameter</span></a></span><span>
</span><span id="line-317"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-318"></span><span>  </span><span id="local-6989586621679700344"><span class="annot"><span class="annottext">apply' :: AdamParameterUpdate device dtype
-&gt; (parameter, momentum, momentum) -&gt; parameter
</span><a href="#local-6989586621679700344"><span class="hs-identifier hs-var hs-var hs-var hs-var">apply'</span></a></span></span><span>
</span><span id="line-319"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#AdamParameterUpdate"><span class="hs-identifier hs-type">AdamParameterUpdate</span></a></span><span> </span><span id="local-6989586621679700343"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700343"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span id="local-6989586621679700342"><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700342"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700341"><span class="annot"><span class="annottext">parameter
</span><a href="#local-6989586621679700341"><span class="hs-identifier hs-var">parameter</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700340"><span class="annot"><span class="annottext">momentum
</span><a href="#local-6989586621679700340"><span class="hs-identifier hs-var">biasAdjustedMomentum1</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700339"><span class="annot"><span class="annottext">momentum
</span><a href="#local-6989586621679700339"><span class="hs-identifier hs-var">biasAdjustedMomentum2</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-321"></span><span>      </span><span class="annot"><span class="annottext">parameter
</span><a href="#local-6989586621679700341"><span class="hs-identifier hs-var">parameter</span></a></span><span> </span><span class="annot"><span class="annottext">parameter -&gt; parameter -&gt; parameter
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#mul"><span class="hs-identifier hs-var">mul</span></a></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700342"><span class="hs-identifier hs-var">learningRate</span></a></span><span> </span><span class="annot"><span class="annottext">momentum
Tensor device dtype shape
</span><a href="#local-6989586621679700340"><span class="hs-identifier hs-var">biasAdjustedMomentum1</span></a></span><span>
</span><span id="line-322"></span><span>        </span><span class="annot"><span class="annottext">Tensor device dtype shape
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#addScalar"><span class="hs-identifier hs-var">addScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700343"><span class="hs-identifier hs-var">eps</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype shape -&gt; Tensor device dtype shape
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#sqrt"><span class="hs-identifier hs-var">sqrt</span></a></span><span> </span><span class="annot"><span class="annottext">momentum
Tensor device dtype shape
</span><a href="#local-6989586621679700339"><span class="hs-identifier hs-var">biasAdjustedMomentum2</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-323"></span><span>
</span><span id="line-324"></span><span class="hs-comment">-- | Adam step</span><span>
</span><span id="line-325"></span><span class="annot"><a href="Torch.Typed.Optim.html#adam"><span class="hs-identifier hs-type">adam</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-326"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679700571"><span class="annot"><a href="#local-6989586621679700571"><span class="hs-identifier hs-type">gradients</span></a></span></span><span> </span><span id="local-6989586621679700568"><span class="annot"><a href="#local-6989586621679700568"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span id="local-6989586621679700572"><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span></span><span> </span><span id="local-6989586621679700567"><span class="annot"><a href="#local-6989586621679700567"><span class="hs-identifier hs-type">adamStep</span></a></span></span><span> </span><span id="local-6989586621679700569"><span class="annot"><a href="#local-6989586621679700569"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679700570"><span class="annot"><a href="#local-6989586621679700570"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWith"><span class="hs-identifier hs-type">HZipWith</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum1Update"><span class="hs-identifier hs-type">AdamMomentum1Update</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700571"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-328"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HZipWith"><span class="hs-identifier hs-type">HZipWith</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum2Update"><span class="hs-identifier hs-type">AdamMomentum2Update</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700571"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-329"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-type">AdamBiasAdjustment</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-330"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HZipWith3"><span class="hs-identifier hs-type">HZipWith3</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#AdamParameterUpdate"><span class="hs-identifier hs-type">AdamParameterUpdate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700570"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700569"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700568"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700568"><span class="hs-identifier hs-type">tensors</span></a></span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-332"></span><span>  </span><span class="hs-comment">-- | learning rate</span><span>
</span><span id="line-333"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#LearningRate"><span class="hs-identifier hs-type">LearningRate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700570"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700569"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-334"></span><span>  </span><span class="hs-comment">-- | model parameter gradient tensors</span><span>
</span><span id="line-335"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700571"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-336"></span><span>  </span><span class="hs-comment">-- | model parameter tensors</span><span>
</span><span id="line-337"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700568"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-338"></span><span>  </span><span class="hs-comment">-- | adam parameters - beta1, beta2, momenta1, momenta2, iteration</span><span>
</span><span id="line-339"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-340"></span><span>  </span><span class="hs-comment">-- | returns new parameters + updated adam parameters</span><span>
</span><span id="line-341"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700568"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-342"></span><span id="adam"><span class="annot"><span class="annottext">adam :: LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; Adam momenta
-&gt; (HList tensors, Adam momenta)
</span><a href="Torch.Typed.Optim.html#adam"><span class="hs-identifier hs-var hs-var">adam</span></a></span></span><span> </span><span id="local-6989586621679700334"><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700334"><span class="hs-identifier hs-var">learningRate</span></a></span></span><span> </span><span id="local-6989586621679700333"><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700333"><span class="hs-identifier hs-var">gradients</span></a></span></span><span> </span><span id="local-6989586621679700332"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700332"><span class="hs-identifier hs-var">parameters</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679700327"><span id="local-6989586621679700328"><span id="local-6989586621679700329"><span id="local-6989586621679700330"><span id="local-6989586621679700331"><span class="annot"><span class="annottext">Float
HList momenta
AdamIter
momenta2 :: HList momenta
momenta1 :: HList momenta
beta2 :: Float
beta1 :: Float
iter :: AdamIter
momenta2 :: forall (momenta :: [Type]). Adam momenta -&gt; HList momenta
momenta1 :: forall (momenta :: [Type]). Adam momenta -&gt; HList momenta
beta2 :: forall (momenta :: [Type]). Adam momenta -&gt; Float
beta1 :: forall (momenta :: [Type]). Adam momenta -&gt; Float
iter :: forall (momenta :: [Type]). Adam momenta -&gt; AdamIter
</span><a href="#local-6989586621679700327"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-343"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700326"><span class="hs-identifier hs-var">parameters'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">AdamIter
-&gt; Float -&gt; Float -&gt; HList momenta -&gt; HList momenta -&gt; Adam momenta
forall (momenta :: [Type]).
AdamIter
-&gt; Float -&gt; Float -&gt; HList momenta -&gt; HList momenta -&gt; Adam momenta
</span><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-var">Adam</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700331"><span class="hs-identifier hs-var">iter</span></a></span><span> </span><span class="annot"><span class="annottext">AdamIter -&gt; AdamIter -&gt; AdamIter
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">AdamIter
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700330"><span class="hs-identifier hs-var">beta1</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700329"><span class="hs-identifier hs-var">beta2</span></a></span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700325"><span class="hs-identifier hs-var">momenta1'</span></a></span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700324"><span class="hs-identifier hs-var">momenta2'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-344"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-345"></span><span>    </span><span id="local-6989586621679700325"><span class="annot"><span class="annottext">momenta1' :: HList momenta
</span><a href="#local-6989586621679700325"><span class="hs-identifier hs-var hs-var">momenta1'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamMomentum1Update
-&gt; HList momenta -&gt; HList gradients -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]) (zs :: [k]).
HZipWith f xs ys zs =&gt;
f -&gt; HList xs -&gt; HList ys -&gt; HList zs
</span><a href="Torch.HList.html#hzipWith"><span class="hs-identifier hs-var">hzipWith</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; AdamMomentum1Update
</span><a href="Torch.Typed.Optim.html#AdamMomentum1Update"><span class="hs-identifier hs-var">AdamMomentum1Update</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700330"><span class="hs-identifier hs-var">beta1</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700328"><span class="hs-identifier hs-var">momenta1</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700333"><span class="hs-identifier hs-var">gradients</span></a></span><span>
</span><span id="line-346"></span><span>    </span><span id="local-6989586621679700324"><span class="annot"><span class="annottext">momenta2' :: HList momenta
</span><a href="#local-6989586621679700324"><span class="hs-identifier hs-var hs-var">momenta2'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamMomentum2Update
-&gt; HList momenta -&gt; HList gradients -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]) (zs :: [k]).
HZipWith f xs ys zs =&gt;
f -&gt; HList xs -&gt; HList ys -&gt; HList zs
</span><a href="Torch.HList.html#hzipWith"><span class="hs-identifier hs-var">hzipWith</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; AdamMomentum2Update
</span><a href="Torch.Typed.Optim.html#AdamMomentum2Update"><span class="hs-identifier hs-var">AdamMomentum2Update</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700329"><span class="hs-identifier hs-var">beta2</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700327"><span class="hs-identifier hs-var">momenta2</span></a></span><span> </span><span class="annot"><span class="annottext">HList gradients
</span><a href="#local-6989586621679700333"><span class="hs-identifier hs-var">gradients</span></a></span><span>
</span><span id="line-347"></span><span>    </span><span id="local-6989586621679700323"><span class="annot"><span class="annottext">biasAdjustedMomenta1 :: HList momenta
</span><a href="#local-6989586621679700323"><span class="hs-identifier hs-var hs-var">biasAdjustedMomenta1</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamBiasAdjustment -&gt; HList momenta -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">AdamIter -&gt; Float -&gt; AdamBiasAdjustment
</span><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-var">AdamBiasAdjustment</span></a></span><span> </span><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700331"><span class="hs-identifier hs-var">iter</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700330"><span class="hs-identifier hs-var">beta1</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700325"><span class="hs-identifier hs-var">momenta1'</span></a></span><span>
</span><span id="line-348"></span><span>    </span><span id="local-6989586621679700322"><span class="annot"><span class="annottext">biasAdjustedMomenta2 :: HList momenta
</span><a href="#local-6989586621679700322"><span class="hs-identifier hs-var hs-var">biasAdjustedMomenta2</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamBiasAdjustment -&gt; HList momenta -&gt; HList momenta
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">AdamIter -&gt; Float -&gt; AdamBiasAdjustment
</span><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-var">AdamBiasAdjustment</span></a></span><span> </span><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700331"><span class="hs-identifier hs-var">iter</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679700329"><span class="hs-identifier hs-var">beta2</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700324"><span class="hs-identifier hs-var">momenta2'</span></a></span><span>
</span><span id="line-349"></span><span>    </span><span id="local-6989586621679700326"><span class="annot"><span class="annottext">parameters' :: HList tensors
</span><a href="#local-6989586621679700326"><span class="hs-identifier hs-var hs-var">parameters'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-350"></span><span>      </span><span class="annot"><span class="annottext">AdamParameterUpdate device dtype
-&gt; HList tensors -&gt; HList momenta -&gt; HList momenta -&gt; HList tensors
forall k f (as :: [k]) (bs :: [k]) (cs :: [k]) (ds :: [k]).
HZipWith3 f as bs cs ds =&gt;
f -&gt; HList as -&gt; HList bs -&gt; HList cs -&gt; HList ds
</span><a href="Torch.HList.html#hzipWith3"><span class="hs-identifier hs-var">hzipWith3</span></a></span><span>
</span><span id="line-351"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
-&gt; LearningRate device dtype -&gt; AdamParameterUpdate device dtype
forall (device :: (DeviceType, Nat)) (dtype :: DType).
Float
-&gt; LearningRate device dtype -&gt; AdamParameterUpdate device dtype
</span><a href="Torch.Typed.Optim.html#AdamParameterUpdate"><span class="hs-identifier hs-var">AdamParameterUpdate</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1e-37</span></span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
</span><a href="#local-6989586621679700334"><span class="hs-identifier hs-var">learningRate</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span>        </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679700332"><span class="hs-identifier hs-var">parameters</span></a></span><span>
</span><span id="line-353"></span><span>        </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700323"><span class="hs-identifier hs-var">biasAdjustedMomenta1</span></a></span><span>
</span><span id="line-354"></span><span>        </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700322"><span class="hs-identifier hs-var">biasAdjustedMomenta2</span></a></span><span>
</span><span id="line-355"></span><span>
</span><span id="line-356"></span><span id="local-6989586621679700317"><span id="local-6989586621679700318"><span id="local-6989586621679700319"><span id="local-6989586621679700320"><span id="local-6989586621679700321"><span class="hs-keyword">instance</span><span>
</span><span id="line-357"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.HList.html#HZipWith"><span class="hs-identifier hs-type">HZipWith</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum1Update"><span class="hs-identifier hs-type">AdamMomentum1Update</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700320"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-358"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HZipWith"><span class="hs-identifier hs-type">HZipWith</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamMomentum2Update"><span class="hs-identifier hs-type">AdamMomentum2Update</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700320"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-359"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamBiasAdjustment"><span class="hs-identifier hs-type">AdamBiasAdjustment</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-360"></span><span>    </span><span class="annot"><a href="Torch.HList.html#HZipWith3"><span class="hs-identifier hs-type">HZipWith3</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#AdamParameterUpdate"><span class="hs-identifier hs-type">AdamParameterUpdate</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700319"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700318"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700317"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700317"><span class="hs-identifier hs-type">tensors</span></a></span><span>
</span><span id="line-361"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-362"></span><span>  </span><span class="annot"><a href="Torch.Typed.Optim.html#Optimizer"><span class="hs-identifier hs-type">Optimizer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700321"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700320"><span class="hs-identifier hs-type">gradients</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700317"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700318"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700319"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-363"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-364"></span><span>  </span><span id="local-6989586621679700315"><span class="annot"><span class="annottext">step :: LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; Adam momenta
-&gt; (HList tensors, Adam momenta)
</span><a href="#local-6989586621679700315"><span class="hs-identifier hs-var hs-var hs-var hs-var">step</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; Adam momenta
-&gt; (HList tensors, Adam momenta)
forall k (gradients :: [Type]) (tensors :: [Type])
       (momenta :: [Type]) (adamStep :: k) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(HZipWith AdamMomentum1Update momenta gradients momenta,
 HZipWith AdamMomentum2Update momenta gradients momenta,
 HMap' AdamBiasAdjustment momenta momenta,
 HZipWith3
   (AdamParameterUpdate device dtype)
   tensors
   momenta
   momenta
   tensors) =&gt;
LearningRate device dtype
-&gt; HList gradients
-&gt; HList tensors
-&gt; Adam momenta
-&gt; (HList tensors, Adam momenta)
</span><a href="Torch.Typed.Optim.html#adam"><span class="hs-identifier hs-var">adam</span></a></span></span></span></span></span></span><span>
</span><span id="line-365"></span><span>
</span><span id="line-366"></span><span id="local-6989586621679700314"><span class="hs-keyword">instance</span><span>
</span><span id="line-367"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HAppendFD"><span class="hs-identifier hs-type">HAppendFD</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-368"></span><span>  </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-369"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-370"></span><span>  </span><span class="hs-keyword">type</span><span> </span><span id="Parameters"><span class="annot"><a href="Torch.Typed.Parameter.html#Parameters"><span class="hs-identifier hs-var">Parameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#AdamIter"><span class="hs-identifier hs-type">AdamIter</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700314"><span class="hs-identifier hs-type">momenta</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-371"></span><span>  </span><span id="local-6989586621679700311"><span class="annot"><span class="annottext">flattenParameters :: Adam momenta -&gt; HList (Parameters (Adam momenta))
</span><a href="#local-6989586621679700311"><span class="hs-identifier hs-var hs-var hs-var hs-var">flattenParameters</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Optim.html#Adam"><span class="hs-identifier hs-type">Adam</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679700306"><span id="local-6989586621679700307"><span id="local-6989586621679700308"><span id="local-6989586621679700309"><span id="local-6989586621679700310"><span class="annot"><span class="annottext">Float
HList momenta
AdamIter
momenta2 :: HList momenta
momenta1 :: HList momenta
beta2 :: Float
beta1 :: Float
iter :: AdamIter
momenta2 :: forall (momenta :: [Type]). Adam momenta -&gt; HList momenta
momenta1 :: forall (momenta :: [Type]). Adam momenta -&gt; HList momenta
beta2 :: forall (momenta :: [Type]). Adam momenta -&gt; Float
beta1 :: forall (momenta :: [Type]). Adam momenta -&gt; Float
iter :: forall (momenta :: [Type]). Adam momenta -&gt; AdamIter
</span><a href="#local-6989586621679700306"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700310"><span class="hs-identifier hs-var">iter</span></a></span><span> </span><span class="annot"><span class="annottext">AdamIter
-&gt; HList (momenta ++ momenta)
-&gt; HList (AdamIter : (momenta ++ momenta))
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700307"><span class="hs-identifier hs-var">momenta1</span></a></span><span> </span><span class="annot"><span class="annottext">HList momenta -&gt; HList momenta -&gt; HList (momenta ++ momenta)
forall k (a :: [k]) (b :: [k]) (ab :: [k]).
HAppendFD a b ab =&gt;
HList a -&gt; HList b -&gt; HList ab
</span><a href="Torch.HList.html#happendFD"><span class="hs-operator hs-var">`happendFD`</span></a></span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700306"><span class="hs-identifier hs-var">momenta2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-372"></span><span>  </span><span id="local-6989586621679700303"><span class="annot"><span class="annottext">replaceParameters :: Adam momenta -&gt; HList (Parameters (Adam momenta)) -&gt; Adam momenta
</span><a href="#local-6989586621679700303"><span class="hs-identifier hs-var hs-var hs-var hs-var">replaceParameters</span></a></span></span><span> </span><span id="local-6989586621679700302"><span class="annot"><span class="annottext">Adam momenta
</span><a href="#local-6989586621679700302"><span class="hs-identifier hs-var">adam</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700301"><span class="annot"><a href="#local-6989586621679700301"><span class="hs-identifier hs-var">iter</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679700300"><span class="annot"><a href="#local-6989586621679700300"><span class="hs-identifier hs-var">momenta</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-373"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700299"><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700299"><span class="hs-identifier hs-var">momenta1</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700298"><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700298"><span class="hs-identifier hs-var">momenta2</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList (momenta ++ momenta) -&gt; (HList momenta, HList momenta)
forall k (a :: [k]) (b :: [k]) (ab :: [k]).
HAppendFD a b ab =&gt;
HList ab -&gt; (HList a, HList b)
</span><a href="Torch.HList.html#hunappendFD"><span class="hs-identifier hs-var">hunappendFD</span></a></span><span> </span><span class="annot"><span class="annottext">HList (momenta ++ momenta)
</span><a href="#local-6989586621679700300"><span class="hs-identifier hs-var">momenta</span></a></span><span>
</span><span id="line-374"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Adam momenta
</span><a href="#local-6989586621679700302"><span class="hs-identifier hs-var">adam</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">iter :: AdamIter
</span><a href="Torch.Typed.Optim.html#iter"><span class="hs-identifier hs-var">iter</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamIter
</span><a href="#local-6989586621679700301"><span class="hs-identifier hs-var">iter</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">momenta1 :: HList momenta
</span><a href="Torch.Typed.Optim.html#momenta1"><span class="hs-identifier hs-var">momenta1</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700299"><span class="hs-identifier hs-var">momenta1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">momenta2 :: HList momenta
</span><a href="Torch.Typed.Optim.html#momenta2"><span class="hs-identifier hs-var">momenta2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList momenta
</span><a href="#local-6989586621679700298"><span class="hs-identifier hs-var">momenta2</span></a></span><span class="hs-special">}</span></span><span>
</span><span id="line-375"></span></pre></body></html>