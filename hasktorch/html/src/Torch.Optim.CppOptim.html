<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FunctionalDependencies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-9"></span><span>
</span><span id="line-10"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Optim.CppOptim</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-11"></span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign.ForeignPtr</span></span><span>
</span><span id="line-13"></span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Castable</span></a></span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">CppTuple2</span></a></span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">CppTuple3</span></a></span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">CppTuple4</span></a></span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">CppObject</span></a></span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.GC</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">mallocTrim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Optim</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">LibTorch</span></span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Optim.html"><span class="hs-identifier">Torch.Optim</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Optim</span></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.Mem</span></span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">performGC</span></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Autograd.html"><span class="hs-identifier">Torch.Autograd</span></a></span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.NN.html"><span class="hs-identifier">Torch.NN</span></a></span><span>
</span><span id="line-25"></span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier">Data.Default.Class</span></a></span><span>
</span><span id="line-27"></span><span>
</span><span id="line-28"></span><span class="hs-keyword">type</span><span> </span><span id="CppOptimizerRef"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerRef"><span class="hs-identifier hs-var">CppOptimizerRef</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Optimizer</span></a></span><span>
</span><span id="line-29"></span><span class="hs-keyword">data</span><span> </span><span id="CppOptimizerState"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span></span><span> </span><span id="local-6989586621679626750"><span class="annot"><a href="#local-6989586621679626750"><span class="hs-identifier hs-type">option</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="CppOptimizerState"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span></span><span> </span><span class="annot"><a href="#local-6989586621679626750"><span class="hs-identifier hs-type">option</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerRef"><span class="hs-identifier hs-type">CppOptimizerRef</span></a></span><span>
</span><span id="line-30"></span><span>
</span><span id="line-31"></span><span class="hs-comment">-- class Optimizer option where</span><span>
</span><span id="line-32"></span><span class="hs-comment">--   initOptimizer :: Parameterized model =&gt; option -&gt; model -&gt; IO (OptimizerState option model)</span><span>
</span><span id="line-33"></span><span class="hs-comment">--   step :: Parameterized model =&gt; OptimizerState option model -&gt; (model -&gt; IO Tensor) -&gt; IO Tensor</span><span>
</span><span id="line-34"></span><span class="hs-comment">--   -- Returned d depends on the state of optimizer.</span><span>
</span><span id="line-35"></span><span class="hs-comment">--   -- Do not call step function after this function is called.</span><span>
</span><span id="line-36"></span><span class="hs-comment">--   getParams :: Parameterized model =&gt; OptimizerState option model -&gt; IO model</span><span>
</span><span id="line-37"></span><span class="hs-comment">--   step (OptimizerState _ optimizer initParams) loss = cast0 (LibTorch.step optimizer trans)</span><span>
</span><span id="line-38"></span><span class="hs-comment">--     where</span><span>
</span><span id="line-39"></span><span class="hs-comment">--       trans :: ForeignPtr ATen.TensorList -&gt; IO (ForeignPtr ATen.Tensor)</span><span>
</span><span id="line-40"></span><span class="hs-comment">--       trans inputs =</span><span>
</span><span id="line-41"></span><span class="hs-comment">--         uncast inputs $ \inputs' -&gt; do</span><span>
</span><span id="line-42"></span><span class="hs-comment">--           (Unsafe ret) &lt;- loss $ replaceParameters initParams $  map (IndependentTensor . Unsafe) inputs'</span><span>
</span><span id="line-43"></span><span class="hs-comment">--           cast ret return</span><span>
</span><span id="line-44"></span><span class="hs-comment">--   getParams (OptimizerState _ optimizer initParams) = fmap (replaceParameters initParams . map (IndependentTensor . Unsafe)) $ cast0 (LibTorch.getParams optimizer)</span><span>
</span><span id="line-45"></span><span>
</span><span id="line-46"></span><span class="hs-keyword">class</span><span> </span><span id="CppOptimizer"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-var">CppOptimizer</span></a></span></span><span> </span><span id="local-6989586621679626818"><span class="annot"><a href="#local-6989586621679626818"><span class="hs-identifier hs-type">option</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-47"></span><span>  </span><span id="local-6989586621679626768"><span id="initOptimizer"><span class="annot"><a href="Torch.Optim.CppOptim.html#initOptimizer"><span class="hs-identifier hs-type">initOptimizer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.NN.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626768"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679626818"><span class="hs-identifier hs-type">option</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679626768"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626818"><span class="hs-identifier hs-type">option</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-48"></span><span>  </span><span id="local-6989586621679626776"><span id="unsafeStep"><span class="annot"><a href="Torch.Optim.CppOptim.html#unsafeStep"><span class="hs-identifier hs-type">unsafeStep</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.NN.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626776"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679626776"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626818"><span class="hs-identifier hs-type">option</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679626776"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626818"><span class="hs-identifier hs-type">option</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-49"></span><span>  </span><span id="local-6989586621679626673"><span class="annot"><a href="Torch.Optim.CppOptim.html#unsafeStep"><span class="hs-identifier hs-var hs-var">unsafeStep</span></a></span><span> </span><span id="local-6989586621679626672"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626672"><span class="hs-identifier hs-var">model</span></a></span></span><span> </span><span id="local-6989586621679626671"><span class="annot"><span class="annottext">o :: CppOptimizerState option
</span><a href="#local-6989586621679626671"><span class="hs-identifier hs-var">o</span></a></span></span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">option
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679626670"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626670"><span class="hs-identifier hs-var">optimizer</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679626669"><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679626669"><span class="hs-identifier hs-var">loss</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-50"></span><span>    </span><span id="local-6989586621679626668"><span class="annot"><span class="annottext">[ATenTensor]
</span><a href="#local-6989586621679626668"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(CppOptimizerRef
 -&gt; ForeignPtr TensorList
 -&gt; ATenTensor
 -&gt; IO (ForeignPtr TensorList))
-&gt; CppOptimizerRef -&gt; [Tensor] -&gt; Tensor -&gt; IO [ATenTensor]
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
-&gt; ForeignPtr TensorList
-&gt; ATenTensor
-&gt; IO (ForeignPtr TensorList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.unsafeStep</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626670"><span class="hs-identifier hs-var">optimizer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(IndependentTensor -&gt; Tensor) -&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="annot"><span class="annottext">IndependentTensor -&gt; Tensor
</span><a href="Torch.Autograd.html#toDependent"><span class="hs-identifier hs-var hs-var">toDependent</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; [Tensor])
-&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor]
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626672"><span class="hs-identifier hs-var">model</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679626669"><span class="hs-identifier hs-var">loss</span></a></span><span>
</span><span id="line-51"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679626663"><span class="annot"><span class="annottext">newModel :: model
</span><a href="#local-6989586621679626663"><span class="hs-identifier hs-var hs-var">newModel</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor] -&gt; model
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor] -&gt; f
</span><a href="Torch.NN.html#replaceParameters"><span class="hs-identifier hs-var">replaceParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626672"><span class="hs-identifier hs-var">model</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; model) -&gt; [IndependentTensor] -&gt; model
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ATenTensor -&gt; IndependentTensor)
-&gt; [ATenTensor] -&gt; [IndependentTensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor -&gt; IndependentTensor
</span><a href="Torch.Autograd.html#IndependentTensor"><span class="hs-identifier hs-var">IndependentTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor -&gt; IndependentTensor)
-&gt; (ATenTensor -&gt; Tensor) -&gt; ATenTensor -&gt; IndependentTensor
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ATenTensor -&gt; Tensor
</span><a href="Torch.Tensor.html#Unsafe"><span class="hs-identifier hs-var">Unsafe</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[ATenTensor]
</span><a href="#local-6989586621679626668"><span class="hs-identifier hs-var">v</span></a></span><span>  </span><span>
</span><span id="line-52"></span><span>    </span><span class="annot"><span class="annottext">(model, CppOptimizerState option)
-&gt; IO (model, CppOptimizerState option)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626663"><span class="hs-identifier hs-var">newModel</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">CppOptimizerState option
</span><a href="#local-6989586621679626671"><span class="hs-identifier hs-var">o</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-53"></span><span>
</span><span id="line-54"></span><span id="local-6989586621679626658"><span class="hs-keyword">instance</span><span> </span><span class="hs-pragma">{-# OVERLAPS</span><span> </span><span class="hs-pragma">#-}</span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-type">CppOptimizer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626658"><span class="hs-identifier hs-type">option</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Optim.html#Optimizer"><span class="hs-identifier hs-type">Optim.Optimizer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626658"><span class="hs-identifier hs-type">option</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-55"></span><span>  </span><span id="local-6989586621679626653"><span class="annot"><span class="annottext">step :: Tensor
-&gt; Gradients
-&gt; [Tensor]
-&gt; CppOptimizerState option
-&gt; ([Tensor], CppOptimizerState option)
</span><a href="Torch.Optim.html#step"><span class="hs-identifier hs-var hs-var hs-var hs-var">step</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Char]
-&gt; Tensor
-&gt; Gradients
-&gt; [Tensor]
-&gt; CppOptimizerState option
-&gt; ([Tensor], CppOptimizerState option)
forall a. HasCallStack =&gt; [Char] -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span>  </span><span class="annot"><span class="annottext">[Char]
</span><span class="hs-string">&quot;step is not implemented for CppOptimizer.&quot;</span></span><span>
</span><span id="line-56"></span><span>  </span><span id="local-6989586621679626650"><span class="annot"><span class="annottext">runStep :: model
-&gt; CppOptimizerState option
-&gt; Tensor
-&gt; Tensor
-&gt; IO (model, CppOptimizerState option)
</span><a href="Torch.Optim.html#runStep"><span class="hs-identifier hs-var hs-var hs-var hs-var">runStep</span></a></span></span><span> </span><span id="local-6989586621679626648"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626648"><span class="hs-identifier hs-var">paramState</span></a></span></span><span> </span><span id="local-6989586621679626647"><span class="annot"><span class="annottext">CppOptimizerState option
</span><a href="#local-6989586621679626647"><span class="hs-identifier hs-var">optState</span></a></span></span><span> </span><span id="local-6989586621679626646"><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679626646"><span class="hs-identifier hs-var">lossValue</span></a></span></span><span> </span><span id="local-6989586621679626645"><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679626645"><span class="hs-identifier hs-var">lr</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-57"></span><span>    </span><span class="annot"><span class="annottext">IO ()
</span><span class="hs-identifier hs-var">performGC</span></span><span>
</span><span id="line-58"></span><span>    </span><span class="annot"><span class="annottext">CInt -&gt; IO ()
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">mallocTrim</span></a></span><span> </span><span class="annot"><span class="annottext">CInt
</span><span class="hs-number">0</span></span><span>
</span><span id="line-59"></span><span>    </span><span class="annot"><span class="annottext">model
-&gt; CppOptimizerState option
-&gt; Tensor
-&gt; IO (model, CppOptimizerState option)
forall option model.
(CppOptimizer option, Parameterized model) =&gt;
model
-&gt; CppOptimizerState option
-&gt; Tensor
-&gt; IO (model, CppOptimizerState option)
</span><a href="Torch.Optim.CppOptim.html#unsafeStep"><span class="hs-identifier hs-var">unsafeStep</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626648"><span class="hs-identifier hs-var">paramState</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerState option
</span><a href="#local-6989586621679626647"><span class="hs-identifier hs-var">optState</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679626646"><span class="hs-identifier hs-var">lossValue</span></a></span><span>
</span><span id="line-60"></span><span>
</span><span id="line-61"></span><span>  </span><span id="local-6989586621679626644"><span class="annot"><span class="annottext">runStep' :: model
-&gt; CppOptimizerState option
-&gt; Gradients
-&gt; Tensor
-&gt; IO (model, CppOptimizerState option)
</span><a href="Torch.Optim.html#runStep%27"><span class="hs-identifier hs-var hs-var hs-var hs-var">runStep'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Char]
-&gt; model
-&gt; CppOptimizerState option
-&gt; Gradients
-&gt; Tensor
-&gt; IO (model, CppOptimizerState option)
forall a. HasCallStack =&gt; [Char] -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span>  </span><span class="annot"><span class="annottext">[Char]
</span><span class="hs-string">&quot;runStep' is not implemented for CppOptimizer.&quot;</span></span></span><span>
</span><span id="line-62"></span><span>
</span><span id="line-63"></span><span class="hs-keyword">data</span><span> </span><span id="AdagradOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#AdagradOptions"><span class="hs-identifier hs-var">AdagradOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="AdagradOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#AdagradOptions"><span class="hs-identifier hs-var">AdagradOptions</span></a></span></span><span>
</span><span id="line-64"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="adagradLr"><span class="annot"><span class="annottext">AdagradOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adagradLr"><span class="hs-identifier hs-var hs-var">adagradLr</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-65"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adagradLrDecay"><span class="annot"><span class="annottext">AdagradOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adagradLrDecay"><span class="hs-identifier hs-var hs-var">adagradLrDecay</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-66"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adagradWeightDecay"><span class="annot"><span class="annottext">AdagradOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adagradWeightDecay"><span class="hs-identifier hs-var hs-var">adagradWeightDecay</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-67"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adagradInitialAccumulatorValue"><span class="annot"><span class="annottext">AdagradOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adagradInitialAccumulatorValue"><span class="hs-identifier hs-var hs-var">adagradInitialAccumulatorValue</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-68"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adagradEps"><span class="annot"><span class="annottext">AdagradOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adagradEps"><span class="hs-identifier hs-var hs-var">adagradEps</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-69"></span><span>  </span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679626631"><span id="local-6989586621679626633"><span id="local-6989586621679626635"><span class="annot"><span class="annottext">Int -&gt; AdagradOptions -&gt; ShowS
[AdagradOptions] -&gt; ShowS
AdagradOptions -&gt; [Char]
(Int -&gt; AdagradOptions -&gt; ShowS)
-&gt; (AdagradOptions -&gt; [Char])
-&gt; ([AdagradOptions] -&gt; ShowS)
-&gt; Show AdagradOptions
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; [Char]) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [AdagradOptions] -&gt; ShowS
$cshowList :: [AdagradOptions] -&gt; ShowS
show :: AdagradOptions -&gt; [Char]
$cshow :: AdagradOptions -&gt; [Char]
showsPrec :: Int -&gt; AdagradOptions -&gt; ShowS
$cshowsPrec :: Int -&gt; AdagradOptions -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679626626"><span id="local-6989586621679626628"><span class="annot"><span class="annottext">AdagradOptions -&gt; AdagradOptions -&gt; Bool
(AdagradOptions -&gt; AdagradOptions -&gt; Bool)
-&gt; (AdagradOptions -&gt; AdagradOptions -&gt; Bool) -&gt; Eq AdagradOptions
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: AdagradOptions -&gt; AdagradOptions -&gt; Bool
$c/= :: AdagradOptions -&gt; AdagradOptions -&gt; Bool
== :: AdagradOptions -&gt; AdagradOptions -&gt; Bool
$c== :: AdagradOptions -&gt; AdagradOptions -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span>
</span><span id="line-71"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier hs-type">Default</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdagradOptions"><span class="hs-identifier hs-type">AdagradOptions</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-72"></span><span>  </span><span id="local-6989586621679626622"><span class="annot"><span class="annottext">def :: AdagradOptions
</span><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">def</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdagradOptions :: Double -&gt; Double -&gt; Double -&gt; Double -&gt; Double -&gt; AdagradOptions
</span><a href="Torch.Optim.CppOptim.html#AdagradOptions"><span class="hs-identifier hs-type">AdagradOptions</span></a></span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">adagradLr :: Double
</span><a href="Torch.Optim.CppOptim.html#adagradLr"><span class="hs-identifier hs-var">adagradLr</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-2</span></span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adagradLrDecay :: Double
</span><a href="Torch.Optim.CppOptim.html#adagradLrDecay"><span class="hs-identifier hs-var">adagradLrDecay</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adagradWeightDecay :: Double
</span><a href="Torch.Optim.CppOptim.html#adagradWeightDecay"><span class="hs-identifier hs-var">adagradWeightDecay</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adagradInitialAccumulatorValue :: Double
</span><a href="Torch.Optim.CppOptim.html#adagradInitialAccumulatorValue"><span class="hs-identifier hs-var">adagradInitialAccumulatorValue</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adagradEps :: Double
</span><a href="Torch.Optim.CppOptim.html#adagradEps"><span class="hs-identifier hs-var">adagradEps</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-10</span></span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">}</span><span> </span><span>
</span><span id="line-79"></span><span>
</span><span id="line-80"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679626618"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-type">CppOptimizer</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdagradOptions"><span class="hs-identifier hs-type">AdagradOptions</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-81"></span><span>  </span><span id="local-6989586621679626616"><span class="annot"><span class="annottext">initOptimizer :: AdagradOptions -&gt; model -&gt; IO (CppOptimizerState AdagradOptions)
</span><a href="#local-6989586621679626616"><span class="hs-identifier hs-var hs-var hs-var hs-var">initOptimizer</span></a></span></span><span>  </span><span id="local-6989586621679626615"><span class="annot"><span class="annottext">opt :: AdagradOptions
</span><a href="#local-6989586621679626615"><span class="hs-identifier hs-var">opt</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdagradOptions"><span class="hs-identifier hs-type">AdagradOptions</span></a></span><span class="hs-special">{</span><span id="local-6989586621679626610"><span id="local-6989586621679626611"><span id="local-6989586621679626612"><span id="local-6989586621679626613"><span id="local-6989586621679626614"><span class="annot"><span class="annottext">Double
adagradEps :: Double
adagradInitialAccumulatorValue :: Double
adagradWeightDecay :: Double
adagradLrDecay :: Double
adagradLr :: Double
adagradEps :: AdagradOptions -&gt; Double
adagradInitialAccumulatorValue :: AdagradOptions -&gt; Double
adagradWeightDecay :: AdagradOptions -&gt; Double
adagradLrDecay :: AdagradOptions -&gt; Double
adagradLr :: AdagradOptions -&gt; Double
</span><a href="#local-6989586621679626610"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679626609"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626609"><span class="hs-identifier hs-var">initParams</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-82"></span><span>    </span><span id="local-6989586621679626608"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626608"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; ForeignPtr TensorList
 -&gt; IO CppOptimizerRef)
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; [Tensor]
-&gt; IO CppOptimizerRef
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; ForeignPtr TensorList
-&gt; IO CppOptimizerRef
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.adagrad</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626614"><span class="hs-identifier hs-var">adagradLr</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626613"><span class="hs-identifier hs-var">adagradLrDecay</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626612"><span class="hs-identifier hs-var">adagradWeightDecay</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626611"><span class="hs-identifier hs-var">adagradInitialAccumulatorValue</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626610"><span class="hs-identifier hs-var">adagradEps</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679626605"><span class="hs-identifier hs-var">initParams'</span></a></span><span>
</span><span id="line-83"></span><span>    </span><span class="annot"><span class="annottext">CppOptimizerState AdagradOptions
-&gt; IO (CppOptimizerState AdagradOptions)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(CppOptimizerState AdagradOptions
 -&gt; IO (CppOptimizerState AdagradOptions))
-&gt; CppOptimizerState AdagradOptions
-&gt; IO (CppOptimizerState AdagradOptions)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">AdagradOptions
-&gt; CppOptimizerRef -&gt; CppOptimizerState AdagradOptions
forall option.
option -&gt; CppOptimizerRef -&gt; CppOptimizerState option
</span><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">AdagradOptions
</span><a href="#local-6989586621679626615"><span class="hs-identifier hs-var">opt</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626608"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-85"></span><span>      </span><span id="local-6989586621679626605"><span class="annot"><span class="annottext">initParams' :: [Tensor]
</span><a href="#local-6989586621679626605"><span class="hs-identifier hs-var hs-var">initParams'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(IndependentTensor -&gt; Tensor) -&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="annot"><span class="annottext">IndependentTensor -&gt; Tensor
</span><a href="Torch.Autograd.html#toDependent"><span class="hs-identifier hs-var hs-var">toDependent</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; [Tensor])
-&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor]
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626609"><span class="hs-identifier hs-var">initParams</span></a></span><span>
</span><span id="line-86"></span><span>
</span><span id="line-87"></span><span class="hs-keyword">data</span><span> </span><span id="AdamOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamOptions"><span class="hs-identifier hs-var">AdamOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="AdamOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamOptions"><span class="hs-identifier hs-var">AdamOptions</span></a></span></span><span>
</span><span id="line-88"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="adamLr"><span class="annot"><span class="annottext">AdamOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adamLr"><span class="hs-identifier hs-var hs-var">adamLr</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-89"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamBetas"><span class="annot"><span class="annottext">AdamOptions -&gt; (Double, Double)
</span><a href="Torch.Optim.CppOptim.html#adamBetas"><span class="hs-identifier hs-var hs-var">adamBetas</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamEps"><span class="annot"><span class="annottext">AdamOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adamEps"><span class="hs-identifier hs-var hs-var">adamEps</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-91"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamWeightDecay"><span class="annot"><span class="annottext">AdamOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adamWeightDecay"><span class="hs-identifier hs-var hs-var">adamWeightDecay</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-92"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamAmsgrad"><span class="annot"><span class="annottext">AdamOptions -&gt; Bool
</span><a href="Torch.Optim.CppOptim.html#adamAmsgrad"><span class="hs-identifier hs-var hs-var">adamAmsgrad</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-93"></span><span>  </span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679626593"><span id="local-6989586621679626595"><span id="local-6989586621679626597"><span class="annot"><span class="annottext">Int -&gt; AdamOptions -&gt; ShowS
[AdamOptions] -&gt; ShowS
AdamOptions -&gt; [Char]
(Int -&gt; AdamOptions -&gt; ShowS)
-&gt; (AdamOptions -&gt; [Char])
-&gt; ([AdamOptions] -&gt; ShowS)
-&gt; Show AdamOptions
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; [Char]) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [AdamOptions] -&gt; ShowS
$cshowList :: [AdamOptions] -&gt; ShowS
show :: AdamOptions -&gt; [Char]
$cshow :: AdamOptions -&gt; [Char]
showsPrec :: Int -&gt; AdamOptions -&gt; ShowS
$cshowsPrec :: Int -&gt; AdamOptions -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679626589"><span id="local-6989586621679626591"><span class="annot"><span class="annottext">AdamOptions -&gt; AdamOptions -&gt; Bool
(AdamOptions -&gt; AdamOptions -&gt; Bool)
-&gt; (AdamOptions -&gt; AdamOptions -&gt; Bool) -&gt; Eq AdamOptions
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: AdamOptions -&gt; AdamOptions -&gt; Bool
$c/= :: AdamOptions -&gt; AdamOptions -&gt; Bool
== :: AdamOptions -&gt; AdamOptions -&gt; Bool
$c== :: AdamOptions -&gt; AdamOptions -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>
</span><span id="line-95"></span><span>
</span><span id="line-96"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier hs-type">Default</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamOptions"><span class="hs-identifier hs-type">AdamOptions</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-97"></span><span>  </span><span id="local-6989586621679626587"><span class="annot"><span class="annottext">def :: AdamOptions
</span><a href="#local-6989586621679626587"><span class="hs-identifier hs-var hs-var hs-var hs-var">def</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamOptions :: Double
-&gt; (Double, Double) -&gt; Double -&gt; Double -&gt; Bool -&gt; AdamOptions
</span><a href="Torch.Optim.CppOptim.html#AdamOptions"><span class="hs-identifier hs-type">AdamOptions</span></a></span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">adamLr :: Double
</span><a href="Torch.Optim.CppOptim.html#adamLr"><span class="hs-identifier hs-var">adamLr</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-3</span></span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamBetas :: (Double, Double)
</span><a href="Torch.Optim.CppOptim.html#adamBetas"><span class="hs-identifier hs-var">adamBetas</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.9</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.999</span></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamEps :: Double
</span><a href="Torch.Optim.CppOptim.html#adamEps"><span class="hs-identifier hs-var">adamEps</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-8</span></span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamWeightDecay :: Double
</span><a href="Torch.Optim.CppOptim.html#adamWeightDecay"><span class="hs-identifier hs-var">adamWeightDecay</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamAmsgrad :: Bool
</span><a href="Torch.Optim.CppOptim.html#adamAmsgrad"><span class="hs-identifier hs-var">adamAmsgrad</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">}</span><span> </span><span>
</span><span id="line-104"></span><span>
</span><span id="line-105"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679626584"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-type">CppOptimizer</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamOptions"><span class="hs-identifier hs-type">AdamOptions</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-106"></span><span>  </span><span id="local-6989586621679626583"><span class="annot"><span class="annottext">initOptimizer :: AdamOptions -&gt; model -&gt; IO (CppOptimizerState AdamOptions)
</span><a href="#local-6989586621679626583"><span class="hs-identifier hs-var hs-var hs-var hs-var">initOptimizer</span></a></span></span><span>  </span><span id="local-6989586621679626582"><span class="annot"><span class="annottext">opt :: AdamOptions
</span><a href="#local-6989586621679626582"><span class="hs-identifier hs-var">opt</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamOptions"><span class="hs-identifier hs-type">AdamOptions</span></a></span><span class="hs-special">{</span><span id="local-6989586621679626577"><span id="local-6989586621679626578"><span id="local-6989586621679626579"><span id="local-6989586621679626580"><span id="local-6989586621679626581"><span class="annot"><span class="annottext">Bool
Double
(Double, Double)
adamAmsgrad :: Bool
adamWeightDecay :: Double
adamEps :: Double
adamBetas :: (Double, Double)
adamLr :: Double
adamAmsgrad :: AdamOptions -&gt; Bool
adamWeightDecay :: AdamOptions -&gt; Double
adamEps :: AdamOptions -&gt; Double
adamBetas :: AdamOptions -&gt; (Double, Double)
adamLr :: AdamOptions -&gt; Double
</span><a href="#local-6989586621679626577"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679626576"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626576"><span class="hs-identifier hs-var">initParams</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-107"></span><span>    </span><span id="local-6989586621679626575"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626575"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CBool
 -&gt; ForeignPtr TensorList
 -&gt; IO CppOptimizerRef)
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Bool
-&gt; [Tensor]
-&gt; IO CppOptimizerRef
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast7</span></a></span><span> </span><span class="annot"><span class="annottext">CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CBool
-&gt; ForeignPtr TensorList
-&gt; IO CppOptimizerRef
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.adam</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626581"><span class="hs-identifier hs-var">adamLr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Double, Double) -&gt; Double
forall a b. (a, b) -&gt; a
</span><span class="hs-identifier hs-var">fst</span></span><span> </span><span class="annot"><span class="annottext">(Double, Double)
</span><a href="#local-6989586621679626580"><span class="hs-identifier hs-var">adamBetas</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Double, Double) -&gt; Double
forall a b. (a, b) -&gt; b
</span><span class="hs-identifier hs-var">snd</span></span><span> </span><span class="annot"><span class="annottext">(Double, Double)
</span><a href="#local-6989586621679626580"><span class="hs-identifier hs-var">adamBetas</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626579"><span class="hs-identifier hs-var">adamEps</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626578"><span class="hs-identifier hs-var">adamWeightDecay</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679626577"><span class="hs-identifier hs-var">adamAmsgrad</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679626572"><span class="hs-identifier hs-var">initParams'</span></a></span><span>
</span><span id="line-108"></span><span>    </span><span class="annot"><span class="annottext">CppOptimizerState AdamOptions -&gt; IO (CppOptimizerState AdamOptions)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(CppOptimizerState AdamOptions
 -&gt; IO (CppOptimizerState AdamOptions))
-&gt; CppOptimizerState AdamOptions
-&gt; IO (CppOptimizerState AdamOptions)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">AdamOptions -&gt; CppOptimizerRef -&gt; CppOptimizerState AdamOptions
forall option.
option -&gt; CppOptimizerRef -&gt; CppOptimizerState option
</span><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">AdamOptions
</span><a href="#local-6989586621679626582"><span class="hs-identifier hs-var">opt</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626575"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-110"></span><span>      </span><span id="local-6989586621679626572"><span class="annot"><span class="annottext">initParams' :: [Tensor]
</span><a href="#local-6989586621679626572"><span class="hs-identifier hs-var hs-var">initParams'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(IndependentTensor -&gt; Tensor) -&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="annot"><span class="annottext">IndependentTensor -&gt; Tensor
</span><a href="Torch.Autograd.html#toDependent"><span class="hs-identifier hs-var hs-var">toDependent</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; [Tensor])
-&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor]
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626576"><span class="hs-identifier hs-var">initParams</span></a></span><span>
</span><span id="line-111"></span><span>
</span><span id="line-112"></span><span class="hs-keyword">data</span><span> </span><span id="AdamwOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamwOptions"><span class="hs-identifier hs-var">AdamwOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="AdamwOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamwOptions"><span class="hs-identifier hs-var">AdamwOptions</span></a></span></span><span>
</span><span id="line-113"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="adamwLr"><span class="annot"><span class="annottext">AdamwOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adamwLr"><span class="hs-identifier hs-var hs-var">adamwLr</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-114"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamwBetas"><span class="annot"><span class="annottext">AdamwOptions -&gt; (Double, Double)
</span><a href="Torch.Optim.CppOptim.html#adamwBetas"><span class="hs-identifier hs-var hs-var">adamwBetas</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">,</span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamwEps"><span class="annot"><span class="annottext">AdamwOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adamwEps"><span class="hs-identifier hs-var hs-var">adamwEps</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-116"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamwWeightDecay"><span class="annot"><span class="annottext">AdamwOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#adamwWeightDecay"><span class="hs-identifier hs-var hs-var">adamwWeightDecay</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-117"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="adamwAmsgrad"><span class="annot"><span class="annottext">AdamwOptions -&gt; Bool
</span><a href="Torch.Optim.CppOptim.html#adamwAmsgrad"><span class="hs-identifier hs-var hs-var">adamwAmsgrad</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-118"></span><span>  </span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679626560"><span id="local-6989586621679626562"><span id="local-6989586621679626564"><span class="annot"><span class="annottext">Int -&gt; AdamwOptions -&gt; ShowS
[AdamwOptions] -&gt; ShowS
AdamwOptions -&gt; [Char]
(Int -&gt; AdamwOptions -&gt; ShowS)
-&gt; (AdamwOptions -&gt; [Char])
-&gt; ([AdamwOptions] -&gt; ShowS)
-&gt; Show AdamwOptions
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; [Char]) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [AdamwOptions] -&gt; ShowS
$cshowList :: [AdamwOptions] -&gt; ShowS
show :: AdamwOptions -&gt; [Char]
$cshow :: AdamwOptions -&gt; [Char]
showsPrec :: Int -&gt; AdamwOptions -&gt; ShowS
$cshowsPrec :: Int -&gt; AdamwOptions -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679626556"><span id="local-6989586621679626558"><span class="annot"><span class="annottext">AdamwOptions -&gt; AdamwOptions -&gt; Bool
(AdamwOptions -&gt; AdamwOptions -&gt; Bool)
-&gt; (AdamwOptions -&gt; AdamwOptions -&gt; Bool) -&gt; Eq AdamwOptions
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: AdamwOptions -&gt; AdamwOptions -&gt; Bool
$c/= :: AdamwOptions -&gt; AdamwOptions -&gt; Bool
== :: AdamwOptions -&gt; AdamwOptions -&gt; Bool
$c== :: AdamwOptions -&gt; AdamwOptions -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>
</span><span id="line-120"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier hs-type">Default</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamwOptions"><span class="hs-identifier hs-type">AdamwOptions</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-121"></span><span>  </span><span id="local-6989586621679626554"><span class="annot"><span class="annottext">def :: AdamwOptions
</span><a href="#local-6989586621679626554"><span class="hs-identifier hs-var hs-var hs-var hs-var">def</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">AdamwOptions :: Double
-&gt; (Double, Double) -&gt; Double -&gt; Double -&gt; Bool -&gt; AdamwOptions
</span><a href="Torch.Optim.CppOptim.html#AdamwOptions"><span class="hs-identifier hs-type">AdamwOptions</span></a></span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">adamwLr :: Double
</span><a href="Torch.Optim.CppOptim.html#adamwLr"><span class="hs-identifier hs-var">adamwLr</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-3</span></span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamwBetas :: (Double, Double)
</span><a href="Torch.Optim.CppOptim.html#adamwBetas"><span class="hs-identifier hs-var">adamwBetas</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.9</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.999</span></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamwEps :: Double
</span><a href="Torch.Optim.CppOptim.html#adamwEps"><span class="hs-identifier hs-var">adamwEps</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-8</span></span><span>
</span><span id="line-125"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamwWeightDecay :: Double
</span><a href="Torch.Optim.CppOptim.html#adamwWeightDecay"><span class="hs-identifier hs-var">adamwWeightDecay</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-2</span></span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">adamwAmsgrad :: Bool
</span><a href="Torch.Optim.CppOptim.html#adamwAmsgrad"><span class="hs-identifier hs-var">adamwAmsgrad</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">}</span><span> </span><span>
</span><span id="line-128"></span><span>
</span><span id="line-129"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679626551"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-type">CppOptimizer</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamwOptions"><span class="hs-identifier hs-type">AdamwOptions</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-130"></span><span>  </span><span id="local-6989586621679626550"><span class="annot"><span class="annottext">initOptimizer :: AdamwOptions -&gt; model -&gt; IO (CppOptimizerState AdamwOptions)
</span><a href="#local-6989586621679626550"><span class="hs-identifier hs-var hs-var hs-var hs-var">initOptimizer</span></a></span></span><span>  </span><span id="local-6989586621679626549"><span class="annot"><span class="annottext">opt :: AdamwOptions
</span><a href="#local-6989586621679626549"><span class="hs-identifier hs-var">opt</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.Optim.CppOptim.html#AdamwOptions"><span class="hs-identifier hs-type">AdamwOptions</span></a></span><span class="hs-special">{</span><span id="local-6989586621679626544"><span id="local-6989586621679626545"><span id="local-6989586621679626546"><span id="local-6989586621679626547"><span id="local-6989586621679626548"><span class="annot"><span class="annottext">Bool
Double
(Double, Double)
adamwAmsgrad :: Bool
adamwWeightDecay :: Double
adamwEps :: Double
adamwBetas :: (Double, Double)
adamwLr :: Double
adamwAmsgrad :: AdamwOptions -&gt; Bool
adamwWeightDecay :: AdamwOptions -&gt; Double
adamwEps :: AdamwOptions -&gt; Double
adamwBetas :: AdamwOptions -&gt; (Double, Double)
adamwLr :: AdamwOptions -&gt; Double
</span><a href="#local-6989586621679626544"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679626543"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626543"><span class="hs-identifier hs-var">initParams</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-131"></span><span>    </span><span id="local-6989586621679626542"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626542"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CBool
 -&gt; ForeignPtr TensorList
 -&gt; IO CppOptimizerRef)
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Bool
-&gt; [Tensor]
-&gt; IO CppOptimizerRef
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast7</span></a></span><span> </span><span class="annot"><span class="annottext">CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CBool
-&gt; ForeignPtr TensorList
-&gt; IO CppOptimizerRef
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.adamw</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626548"><span class="hs-identifier hs-var">adamwLr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Double, Double) -&gt; Double
forall a b. (a, b) -&gt; a
</span><span class="hs-identifier hs-var">fst</span></span><span> </span><span class="annot"><span class="annottext">(Double, Double)
</span><a href="#local-6989586621679626547"><span class="hs-identifier hs-var">adamwBetas</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Double, Double) -&gt; Double
forall a b. (a, b) -&gt; b
</span><span class="hs-identifier hs-var">snd</span></span><span> </span><span class="annot"><span class="annottext">(Double, Double)
</span><a href="#local-6989586621679626547"><span class="hs-identifier hs-var">adamwBetas</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626546"><span class="hs-identifier hs-var">adamwEps</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626545"><span class="hs-identifier hs-var">adamwWeightDecay</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679626544"><span class="hs-identifier hs-var">adamwAmsgrad</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679626540"><span class="hs-identifier hs-var">initParams'</span></a></span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><span class="annottext">CppOptimizerState AdamwOptions
-&gt; IO (CppOptimizerState AdamwOptions)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(CppOptimizerState AdamwOptions
 -&gt; IO (CppOptimizerState AdamwOptions))
-&gt; CppOptimizerState AdamwOptions
-&gt; IO (CppOptimizerState AdamwOptions)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">AdamwOptions -&gt; CppOptimizerRef -&gt; CppOptimizerState AdamwOptions
forall option.
option -&gt; CppOptimizerRef -&gt; CppOptimizerState option
</span><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">AdamwOptions
</span><a href="#local-6989586621679626549"><span class="hs-identifier hs-var">opt</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626542"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-133"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-134"></span><span>      </span><span id="local-6989586621679626540"><span class="annot"><span class="annottext">initParams' :: [Tensor]
</span><a href="#local-6989586621679626540"><span class="hs-identifier hs-var hs-var">initParams'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(IndependentTensor -&gt; Tensor) -&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="annot"><span class="annottext">IndependentTensor -&gt; Tensor
</span><a href="Torch.Autograd.html#toDependent"><span class="hs-identifier hs-var hs-var">toDependent</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; [Tensor])
-&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor]
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626543"><span class="hs-identifier hs-var">initParams</span></a></span><span>
</span><span id="line-135"></span><span>
</span><span id="line-136"></span><span class="hs-keyword">data</span><span> </span><span id="LbfgsOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#LbfgsOptions"><span class="hs-identifier hs-var">LbfgsOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="LbfgsOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#LbfgsOptions"><span class="hs-identifier hs-var">LbfgsOptions</span></a></span></span><span>
</span><span id="line-137"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="lbfgsLr"><span class="annot"><span class="annottext">LbfgsOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#lbfgsLr"><span class="hs-identifier hs-var hs-var">lbfgsLr</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-138"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="lbfgsMaxIter"><span class="annot"><span class="annottext">LbfgsOptions -&gt; Int
</span><a href="Torch.Optim.CppOptim.html#lbfgsMaxIter"><span class="hs-identifier hs-var hs-var">lbfgsMaxIter</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-139"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="lbfgsMaxEval"><span class="annot"><span class="annottext">LbfgsOptions -&gt; Int
</span><a href="Torch.Optim.CppOptim.html#lbfgsMaxEval"><span class="hs-identifier hs-var hs-var">lbfgsMaxEval</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-140"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="lbfgsToleranceGrad"><span class="annot"><span class="annottext">LbfgsOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#lbfgsToleranceGrad"><span class="hs-identifier hs-var hs-var">lbfgsToleranceGrad</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-141"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="lbfgsToleranceChange"><span class="annot"><span class="annottext">LbfgsOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#lbfgsToleranceChange"><span class="hs-identifier hs-var hs-var">lbfgsToleranceChange</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-142"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="lbfgsHistorySize"><span class="annot"><span class="annottext">LbfgsOptions -&gt; Int
</span><a href="Torch.Optim.CppOptim.html#lbfgsHistorySize"><span class="hs-identifier hs-var hs-var">lbfgsHistorySize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-143"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="lbfgsLineSearchFn"><span class="annot"><span class="annottext">LbfgsOptions -&gt; Maybe [Char]
</span><a href="Torch.Optim.CppOptim.html#lbfgsLineSearchFn"><span class="hs-identifier hs-var hs-var">lbfgsLineSearchFn</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span>
</span><span id="line-144"></span><span>  </span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679626525"><span id="local-6989586621679626527"><span id="local-6989586621679626529"><span class="annot"><span class="annottext">Int -&gt; LbfgsOptions -&gt; ShowS
[LbfgsOptions] -&gt; ShowS
LbfgsOptions -&gt; [Char]
(Int -&gt; LbfgsOptions -&gt; ShowS)
-&gt; (LbfgsOptions -&gt; [Char])
-&gt; ([LbfgsOptions] -&gt; ShowS)
-&gt; Show LbfgsOptions
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; [Char]) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [LbfgsOptions] -&gt; ShowS
$cshowList :: [LbfgsOptions] -&gt; ShowS
show :: LbfgsOptions -&gt; [Char]
$cshow :: LbfgsOptions -&gt; [Char]
showsPrec :: Int -&gt; LbfgsOptions -&gt; ShowS
$cshowsPrec :: Int -&gt; LbfgsOptions -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679626521"><span id="local-6989586621679626523"><span class="annot"><span class="annottext">LbfgsOptions -&gt; LbfgsOptions -&gt; Bool
(LbfgsOptions -&gt; LbfgsOptions -&gt; Bool)
-&gt; (LbfgsOptions -&gt; LbfgsOptions -&gt; Bool) -&gt; Eq LbfgsOptions
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: LbfgsOptions -&gt; LbfgsOptions -&gt; Bool
$c/= :: LbfgsOptions -&gt; LbfgsOptions -&gt; Bool
== :: LbfgsOptions -&gt; LbfgsOptions -&gt; Bool
$c== :: LbfgsOptions -&gt; LbfgsOptions -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>  </span><span>
</span><span id="line-146"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier hs-type">Default</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#LbfgsOptions"><span class="hs-identifier hs-type">LbfgsOptions</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-147"></span><span>  </span><span id="local-6989586621679626519"><span class="annot"><span class="annottext">def :: LbfgsOptions
</span><a href="#local-6989586621679626519"><span class="hs-identifier hs-var hs-var hs-var hs-var">def</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LbfgsOptions :: Double
-&gt; Int
-&gt; Int
-&gt; Double
-&gt; Double
-&gt; Int
-&gt; Maybe [Char]
-&gt; LbfgsOptions
</span><a href="Torch.Optim.CppOptim.html#LbfgsOptions"><span class="hs-identifier hs-type">LbfgsOptions</span></a></span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">lbfgsLr :: Double
</span><a href="Torch.Optim.CppOptim.html#lbfgsLr"><span class="hs-identifier hs-var">lbfgsLr</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1</span></span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lbfgsMaxIter :: Int
</span><a href="Torch.Optim.CppOptim.html#lbfgsMaxIter"><span class="hs-identifier hs-var">lbfgsMaxIter</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">20</span></span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lbfgsMaxEval :: Int
</span><a href="Torch.Optim.CppOptim.html#lbfgsMaxEval"><span class="hs-identifier hs-var">lbfgsMaxEval</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">20</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">5</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">4</span></span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lbfgsToleranceGrad :: Double
</span><a href="Torch.Optim.CppOptim.html#lbfgsToleranceGrad"><span class="hs-identifier hs-var">lbfgsToleranceGrad</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-7</span></span><span>
</span><span id="line-152"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lbfgsToleranceChange :: Double
</span><a href="Torch.Optim.CppOptim.html#lbfgsToleranceChange"><span class="hs-identifier hs-var">lbfgsToleranceChange</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-9</span></span><span>
</span><span id="line-153"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lbfgsHistorySize :: Int
</span><a href="Torch.Optim.CppOptim.html#lbfgsHistorySize"><span class="hs-identifier hs-var">lbfgsHistorySize</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">100</span></span><span>
</span><span id="line-154"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lbfgsLineSearchFn :: Maybe [Char]
</span><a href="Torch.Optim.CppOptim.html#lbfgsLineSearchFn"><span class="hs-identifier hs-var">lbfgsLineSearchFn</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe [Char]
forall a. Maybe a
</span><span class="hs-identifier hs-var">Nothing</span></span><span>
</span><span id="line-155"></span><span>    </span><span class="hs-special">}</span><span> </span><span>
</span><span id="line-156"></span><span>
</span><span id="line-157"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679626514"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-type">CppOptimizer</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#LbfgsOptions"><span class="hs-identifier hs-type">LbfgsOptions</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-158"></span><span>  </span><span id="local-6989586621679626513"><span class="annot"><span class="annottext">initOptimizer :: LbfgsOptions -&gt; model -&gt; IO (CppOptimizerState LbfgsOptions)
</span><a href="#local-6989586621679626513"><span class="hs-identifier hs-var hs-var hs-var hs-var">initOptimizer</span></a></span></span><span> </span><span id="local-6989586621679626512"><span class="annot"><span class="annottext">opt :: LbfgsOptions
</span><a href="#local-6989586621679626512"><span class="hs-identifier hs-var">opt</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.Optim.CppOptim.html#LbfgsOptions"><span class="hs-identifier hs-type">LbfgsOptions</span></a></span><span class="hs-special">{</span><span id="local-6989586621679626505"><span id="local-6989586621679626506"><span id="local-6989586621679626507"><span id="local-6989586621679626508"><span id="local-6989586621679626509"><span id="local-6989586621679626510"><span id="local-6989586621679626511"><span class="annot"><span class="annottext">Double
Int
Maybe [Char]
lbfgsLineSearchFn :: Maybe [Char]
lbfgsHistorySize :: Int
lbfgsToleranceChange :: Double
lbfgsToleranceGrad :: Double
lbfgsMaxEval :: Int
lbfgsMaxIter :: Int
lbfgsLr :: Double
lbfgsLineSearchFn :: LbfgsOptions -&gt; Maybe [Char]
lbfgsHistorySize :: LbfgsOptions -&gt; Int
lbfgsToleranceChange :: LbfgsOptions -&gt; Double
lbfgsToleranceGrad :: LbfgsOptions -&gt; Double
lbfgsMaxEval :: LbfgsOptions -&gt; Int
lbfgsMaxIter :: LbfgsOptions -&gt; Int
lbfgsLr :: LbfgsOptions -&gt; Double
</span><a href="#local-6989586621679626505"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679626504"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626504"><span class="hs-identifier hs-var">initParams</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-159"></span><span>    </span><span id="local-6989586621679626503"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626503"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(CDouble
 -&gt; CInt
 -&gt; CInt
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CInt
 -&gt; Maybe (ForeignPtr StdString)
 -&gt; ForeignPtr TensorList
 -&gt; IO CppOptimizerRef)
-&gt; Double
-&gt; Int
-&gt; Int
-&gt; Double
-&gt; Double
-&gt; Int
-&gt; Maybe [Char]
-&gt; [Tensor]
-&gt; IO CppOptimizerRef
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 x7 cx7 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6, Castable x7 cx7,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; cx7 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; x7 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast8</span></a></span><span> </span><span class="annot"><span class="annottext">CDouble
-&gt; CInt
-&gt; CInt
-&gt; CDouble
-&gt; CDouble
-&gt; CInt
-&gt; Maybe (ForeignPtr StdString)
-&gt; ForeignPtr TensorList
-&gt; IO CppOptimizerRef
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.lbfgs</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626511"><span class="hs-identifier hs-var">lbfgsLr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679626510"><span class="hs-identifier hs-var">lbfgsMaxIter</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679626509"><span class="hs-identifier hs-var">lbfgsMaxEval</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626508"><span class="hs-identifier hs-var">lbfgsToleranceGrad</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626507"><span class="hs-identifier hs-var">lbfgsToleranceChange</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679626506"><span class="hs-identifier hs-var">lbfgsHistorySize</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe [Char]
</span><a href="#local-6989586621679626505"><span class="hs-identifier hs-var">lbfgsLineSearchFn</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679626500"><span class="hs-identifier hs-var">initParams'</span></a></span><span>
</span><span id="line-160"></span><span>    </span><span class="annot"><span class="annottext">CppOptimizerState LbfgsOptions
-&gt; IO (CppOptimizerState LbfgsOptions)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(CppOptimizerState LbfgsOptions
 -&gt; IO (CppOptimizerState LbfgsOptions))
-&gt; CppOptimizerState LbfgsOptions
-&gt; IO (CppOptimizerState LbfgsOptions)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LbfgsOptions -&gt; CppOptimizerRef -&gt; CppOptimizerState LbfgsOptions
forall option.
option -&gt; CppOptimizerRef -&gt; CppOptimizerState option
</span><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">LbfgsOptions
</span><a href="#local-6989586621679626512"><span class="hs-identifier hs-var">opt</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626503"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-162"></span><span>      </span><span id="local-6989586621679626500"><span class="annot"><span class="annottext">initParams' :: [Tensor]
</span><a href="#local-6989586621679626500"><span class="hs-identifier hs-var hs-var">initParams'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(IndependentTensor -&gt; Tensor) -&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="annot"><span class="annottext">IndependentTensor -&gt; Tensor
</span><a href="Torch.Autograd.html#toDependent"><span class="hs-identifier hs-var hs-var">toDependent</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; [Tensor])
-&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor]
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626504"><span class="hs-identifier hs-var">initParams</span></a></span><span>
</span><span id="line-163"></span><span>
</span><span id="line-164"></span><span class="hs-keyword">data</span><span> </span><span id="RmspropOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#RmspropOptions"><span class="hs-identifier hs-var">RmspropOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="RmspropOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#RmspropOptions"><span class="hs-identifier hs-var">RmspropOptions</span></a></span></span><span>
</span><span id="line-165"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="rmspropLr"><span class="annot"><span class="annottext">RmspropOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#rmspropLr"><span class="hs-identifier hs-var hs-var">rmspropLr</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-166"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="rmspropAlpha"><span class="annot"><span class="annottext">RmspropOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#rmspropAlpha"><span class="hs-identifier hs-var hs-var">rmspropAlpha</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-167"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="rmspropEps"><span class="annot"><span class="annottext">RmspropOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#rmspropEps"><span class="hs-identifier hs-var hs-var">rmspropEps</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-168"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="rmspropWeightDecay"><span class="annot"><span class="annottext">RmspropOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#rmspropWeightDecay"><span class="hs-identifier hs-var hs-var">rmspropWeightDecay</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-169"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="rmspropMomentum"><span class="annot"><span class="annottext">RmspropOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#rmspropMomentum"><span class="hs-identifier hs-var hs-var">rmspropMomentum</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-170"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="rmspropCentered"><span class="annot"><span class="annottext">RmspropOptions -&gt; Bool
</span><a href="Torch.Optim.CppOptim.html#rmspropCentered"><span class="hs-identifier hs-var hs-var">rmspropCentered</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-171"></span><span>  </span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679626487"><span id="local-6989586621679626489"><span id="local-6989586621679626491"><span class="annot"><span class="annottext">Int -&gt; RmspropOptions -&gt; ShowS
[RmspropOptions] -&gt; ShowS
RmspropOptions -&gt; [Char]
(Int -&gt; RmspropOptions -&gt; ShowS)
-&gt; (RmspropOptions -&gt; [Char])
-&gt; ([RmspropOptions] -&gt; ShowS)
-&gt; Show RmspropOptions
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; [Char]) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [RmspropOptions] -&gt; ShowS
$cshowList :: [RmspropOptions] -&gt; ShowS
show :: RmspropOptions -&gt; [Char]
$cshow :: RmspropOptions -&gt; [Char]
showsPrec :: Int -&gt; RmspropOptions -&gt; ShowS
$cshowsPrec :: Int -&gt; RmspropOptions -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679626483"><span id="local-6989586621679626485"><span class="annot"><span class="annottext">RmspropOptions -&gt; RmspropOptions -&gt; Bool
(RmspropOptions -&gt; RmspropOptions -&gt; Bool)
-&gt; (RmspropOptions -&gt; RmspropOptions -&gt; Bool) -&gt; Eq RmspropOptions
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: RmspropOptions -&gt; RmspropOptions -&gt; Bool
$c/= :: RmspropOptions -&gt; RmspropOptions -&gt; Bool
== :: RmspropOptions -&gt; RmspropOptions -&gt; Bool
$c== :: RmspropOptions -&gt; RmspropOptions -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-172"></span><span>
</span><span id="line-173"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier hs-type">Default</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#RmspropOptions"><span class="hs-identifier hs-type">RmspropOptions</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-174"></span><span>  </span><span id="local-6989586621679626481"><span class="annot"><span class="annottext">def :: RmspropOptions
</span><a href="#local-6989586621679626481"><span class="hs-identifier hs-var hs-var hs-var hs-var">def</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">RmspropOptions :: Double
-&gt; Double -&gt; Double -&gt; Double -&gt; Double -&gt; Bool -&gt; RmspropOptions
</span><a href="Torch.Optim.CppOptim.html#RmspropOptions"><span class="hs-identifier hs-type">RmspropOptions</span></a></span><span>
</span><span id="line-175"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">rmspropLr :: Double
</span><a href="Torch.Optim.CppOptim.html#rmspropLr"><span class="hs-identifier hs-var">rmspropLr</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-2</span></span><span>
</span><span id="line-176"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">rmspropAlpha :: Double
</span><a href="Torch.Optim.CppOptim.html#rmspropAlpha"><span class="hs-identifier hs-var">rmspropAlpha</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.99</span></span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">rmspropEps :: Double
</span><a href="Torch.Optim.CppOptim.html#rmspropEps"><span class="hs-identifier hs-var">rmspropEps</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-8</span></span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">rmspropWeightDecay :: Double
</span><a href="Torch.Optim.CppOptim.html#rmspropWeightDecay"><span class="hs-identifier hs-var">rmspropWeightDecay</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-179"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">rmspropMomentum :: Double
</span><a href="Torch.Optim.CppOptim.html#rmspropMomentum"><span class="hs-identifier hs-var">rmspropMomentum</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-180"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">rmspropCentered :: Bool
</span><a href="Torch.Optim.CppOptim.html#rmspropCentered"><span class="hs-identifier hs-var">rmspropCentered</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-181"></span><span>    </span><span class="hs-special">}</span><span> </span><span>
</span><span id="line-182"></span><span>
</span><span id="line-183"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679626478"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-type">CppOptimizer</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#RmspropOptions"><span class="hs-identifier hs-type">RmspropOptions</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-184"></span><span>  </span><span id="local-6989586621679626477"><span class="annot"><span class="annottext">initOptimizer :: RmspropOptions -&gt; model -&gt; IO (CppOptimizerState RmspropOptions)
</span><a href="#local-6989586621679626477"><span class="hs-identifier hs-var hs-var hs-var hs-var">initOptimizer</span></a></span></span><span> </span><span id="local-6989586621679626476"><span class="annot"><span class="annottext">opt :: RmspropOptions
</span><a href="#local-6989586621679626476"><span class="hs-identifier hs-var">opt</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.Optim.CppOptim.html#RmspropOptions"><span class="hs-identifier hs-type">RmspropOptions</span></a></span><span class="hs-special">{</span><span id="local-6989586621679626470"><span id="local-6989586621679626471"><span id="local-6989586621679626472"><span id="local-6989586621679626473"><span id="local-6989586621679626474"><span id="local-6989586621679626475"><span class="annot"><span class="annottext">Bool
Double
rmspropCentered :: Bool
rmspropMomentum :: Double
rmspropWeightDecay :: Double
rmspropEps :: Double
rmspropAlpha :: Double
rmspropLr :: Double
rmspropCentered :: RmspropOptions -&gt; Bool
rmspropMomentum :: RmspropOptions -&gt; Double
rmspropWeightDecay :: RmspropOptions -&gt; Double
rmspropEps :: RmspropOptions -&gt; Double
rmspropAlpha :: RmspropOptions -&gt; Double
rmspropLr :: RmspropOptions -&gt; Double
</span><a href="#local-6989586621679626470"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679626469"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626469"><span class="hs-identifier hs-var">initParams</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-185"></span><span>    </span><span id="local-6989586621679626468"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626468"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CBool
 -&gt; ForeignPtr TensorList
 -&gt; IO CppOptimizerRef)
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Bool
-&gt; [Tensor]
-&gt; IO CppOptimizerRef
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast7</span></a></span><span> </span><span class="annot"><span class="annottext">CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CBool
-&gt; ForeignPtr TensorList
-&gt; IO CppOptimizerRef
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.rmsprop</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626475"><span class="hs-identifier hs-var">rmspropLr</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626474"><span class="hs-identifier hs-var">rmspropAlpha</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626473"><span class="hs-identifier hs-var">rmspropEps</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626472"><span class="hs-identifier hs-var">rmspropWeightDecay</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626471"><span class="hs-identifier hs-var">rmspropMomentum</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679626470"><span class="hs-identifier hs-var">rmspropCentered</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679626466"><span class="hs-identifier hs-var">initParams'</span></a></span><span>
</span><span id="line-186"></span><span>    </span><span class="annot"><span class="annottext">CppOptimizerState RmspropOptions
-&gt; IO (CppOptimizerState RmspropOptions)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(CppOptimizerState RmspropOptions
 -&gt; IO (CppOptimizerState RmspropOptions))
-&gt; CppOptimizerState RmspropOptions
-&gt; IO (CppOptimizerState RmspropOptions)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">RmspropOptions
-&gt; CppOptimizerRef -&gt; CppOptimizerState RmspropOptions
forall option.
option -&gt; CppOptimizerRef -&gt; CppOptimizerState option
</span><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">RmspropOptions
</span><a href="#local-6989586621679626476"><span class="hs-identifier hs-var">opt</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626468"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-188"></span><span>      </span><span id="local-6989586621679626466"><span class="annot"><span class="annottext">initParams' :: [Tensor]
</span><a href="#local-6989586621679626466"><span class="hs-identifier hs-var hs-var">initParams'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(IndependentTensor -&gt; Tensor) -&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="annot"><span class="annottext">IndependentTensor -&gt; Tensor
</span><a href="Torch.Autograd.html#toDependent"><span class="hs-identifier hs-var hs-var">toDependent</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; [Tensor])
-&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor]
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626469"><span class="hs-identifier hs-var">initParams</span></a></span><span>
</span><span id="line-189"></span><span class="hs-keyword">data</span><span> </span><span id="SGDOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#SGDOptions"><span class="hs-identifier hs-var">SGDOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="SGDOptions"><span class="annot"><a href="Torch.Optim.CppOptim.html#SGDOptions"><span class="hs-identifier hs-var">SGDOptions</span></a></span></span><span>
</span><span id="line-190"></span><span>  </span><span class="hs-special">{</span><span> </span><span id="sgdLr"><span class="annot"><span class="annottext">SGDOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#sgdLr"><span class="hs-identifier hs-var hs-var">sgdLr</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-191"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="sgdMomentum"><span class="annot"><span class="annottext">SGDOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#sgdMomentum"><span class="hs-identifier hs-var hs-var">sgdMomentum</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-192"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="sgdDampening"><span class="annot"><span class="annottext">SGDOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#sgdDampening"><span class="hs-identifier hs-var hs-var">sgdDampening</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-193"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="sgdWeightDecay"><span class="annot"><span class="annottext">SGDOptions -&gt; Double
</span><a href="Torch.Optim.CppOptim.html#sgdWeightDecay"><span class="hs-identifier hs-var hs-var">sgdWeightDecay</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-194"></span><span>  </span><span class="hs-special">,</span><span> </span><span id="sgdNesterov"><span class="annot"><span class="annottext">SGDOptions -&gt; Bool
</span><a href="Torch.Optim.CppOptim.html#sgdNesterov"><span class="hs-identifier hs-var hs-var">sgdNesterov</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-195"></span><span>  </span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679626454"><span id="local-6989586621679626456"><span id="local-6989586621679626458"><span class="annot"><span class="annottext">Int -&gt; SGDOptions -&gt; ShowS
[SGDOptions] -&gt; ShowS
SGDOptions -&gt; [Char]
(Int -&gt; SGDOptions -&gt; ShowS)
-&gt; (SGDOptions -&gt; [Char])
-&gt; ([SGDOptions] -&gt; ShowS)
-&gt; Show SGDOptions
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; [Char]) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [SGDOptions] -&gt; ShowS
$cshowList :: [SGDOptions] -&gt; ShowS
show :: SGDOptions -&gt; [Char]
$cshow :: SGDOptions -&gt; [Char]
showsPrec :: Int -&gt; SGDOptions -&gt; ShowS
$cshowsPrec :: Int -&gt; SGDOptions -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679626450"><span id="local-6989586621679626452"><span class="annot"><span class="annottext">SGDOptions -&gt; SGDOptions -&gt; Bool
(SGDOptions -&gt; SGDOptions -&gt; Bool)
-&gt; (SGDOptions -&gt; SGDOptions -&gt; Bool) -&gt; Eq SGDOptions
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: SGDOptions -&gt; SGDOptions -&gt; Bool
$c/= :: SGDOptions -&gt; SGDOptions -&gt; Bool
== :: SGDOptions -&gt; SGDOptions -&gt; Bool
$c== :: SGDOptions -&gt; SGDOptions -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-196"></span><span>
</span><span id="line-197"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../file:///nix/store/j0l75aqa8ha4nzx7ribjq9ywcgg3p0a0-data-default-class-lib-data-default-class-0.1.2.0-haddock-doc/share/doc/data-default-class/html/src"><span class="hs-identifier hs-type">Default</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#SGDOptions"><span class="hs-identifier hs-type">SGDOptions</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-198"></span><span>  </span><span id="local-6989586621679626448"><span class="annot"><span class="annottext">def :: SGDOptions
</span><a href="#local-6989586621679626448"><span class="hs-identifier hs-var hs-var hs-var hs-var">def</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGDOptions :: Double -&gt; Double -&gt; Double -&gt; Double -&gt; Bool -&gt; SGDOptions
</span><a href="Torch.Optim.CppOptim.html#SGDOptions"><span class="hs-identifier hs-type">SGDOptions</span></a></span><span>
</span><span id="line-199"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">sgdLr :: Double
</span><a href="Torch.Optim.CppOptim.html#sgdLr"><span class="hs-identifier hs-var">sgdLr</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-3</span></span><span>
</span><span id="line-200"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">sgdMomentum :: Double
</span><a href="Torch.Optim.CppOptim.html#sgdMomentum"><span class="hs-identifier hs-var">sgdMomentum</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-201"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">sgdDampening :: Double
</span><a href="Torch.Optim.CppOptim.html#sgdDampening"><span class="hs-identifier hs-var">sgdDampening</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-202"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">sgdWeightDecay :: Double
</span><a href="Torch.Optim.CppOptim.html#sgdWeightDecay"><span class="hs-identifier hs-var">sgdWeightDecay</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0</span></span><span>
</span><span id="line-203"></span><span>    </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">sgdNesterov :: Bool
</span><a href="Torch.Optim.CppOptim.html#sgdNesterov"><span class="hs-identifier hs-var">sgdNesterov</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-204"></span><span>    </span><span class="hs-special">}</span><span> </span><span>
</span><span id="line-205"></span><span>
</span><span id="line-206"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679626445"><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizer"><span class="hs-identifier hs-type">CppOptimizer</span></a></span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#SGDOptions"><span class="hs-identifier hs-type">SGDOptions</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-207"></span><span>  </span><span id="local-6989586621679626444"><span class="annot"><span class="annottext">initOptimizer :: SGDOptions -&gt; model -&gt; IO (CppOptimizerState SGDOptions)
</span><a href="#local-6989586621679626444"><span class="hs-identifier hs-var hs-var hs-var hs-var">initOptimizer</span></a></span></span><span>  </span><span id="local-6989586621679626443"><span class="annot"><span class="annottext">opt :: SGDOptions
</span><a href="#local-6989586621679626443"><span class="hs-identifier hs-var">opt</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.Optim.CppOptim.html#SGDOptions"><span class="hs-identifier hs-type">SGDOptions</span></a></span><span class="hs-special">{</span><span id="local-6989586621679626438"><span id="local-6989586621679626439"><span id="local-6989586621679626440"><span id="local-6989586621679626441"><span id="local-6989586621679626442"><span class="annot"><span class="annottext">Bool
Double
sgdNesterov :: Bool
sgdWeightDecay :: Double
sgdDampening :: Double
sgdMomentum :: Double
sgdLr :: Double
sgdNesterov :: SGDOptions -&gt; Bool
sgdWeightDecay :: SGDOptions -&gt; Double
sgdDampening :: SGDOptions -&gt; Double
sgdMomentum :: SGDOptions -&gt; Double
sgdLr :: SGDOptions -&gt; Double
</span><a href="#local-6989586621679626438"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679626437"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626437"><span class="hs-identifier hs-var">initParams</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-208"></span><span>    </span><span id="local-6989586621679626436"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626436"><span class="hs-identifier hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CBool
 -&gt; ForeignPtr TensorList
 -&gt; IO CppOptimizerRef)
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Double
-&gt; Bool
-&gt; [Tensor]
-&gt; IO CppOptimizerRef
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="annot"><span class="annottext">CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CDouble
-&gt; CBool
-&gt; ForeignPtr TensorList
-&gt; IO CppOptimizerRef
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.sgd</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626442"><span class="hs-identifier hs-var">sgdLr</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626441"><span class="hs-identifier hs-var">sgdMomentum</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626440"><span class="hs-identifier hs-var">sgdDampening</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679626439"><span class="hs-identifier hs-var">sgdWeightDecay</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679626438"><span class="hs-identifier hs-var">sgdNesterov</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor]
</span><a href="#local-6989586621679626434"><span class="hs-identifier hs-var">initParams'</span></a></span><span>
</span><span id="line-209"></span><span>    </span><span class="annot"><span class="annottext">CppOptimizerState SGDOptions -&gt; IO (CppOptimizerState SGDOptions)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(CppOptimizerState SGDOptions -&gt; IO (CppOptimizerState SGDOptions))
-&gt; CppOptimizerState SGDOptions
-&gt; IO (CppOptimizerState SGDOptions)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGDOptions -&gt; CppOptimizerRef -&gt; CppOptimizerState SGDOptions
forall option.
option -&gt; CppOptimizerRef -&gt; CppOptimizerState option
</span><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-var">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">SGDOptions
</span><a href="#local-6989586621679626443"><span class="hs-identifier hs-var">opt</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626436"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-210"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-211"></span><span>      </span><span id="local-6989586621679626434"><span class="annot"><span class="annottext">initParams' :: [Tensor]
</span><a href="#local-6989586621679626434"><span class="hs-identifier hs-var hs-var">initParams'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(IndependentTensor -&gt; Tensor) -&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="annot"><span class="annottext">IndependentTensor -&gt; Tensor
</span><a href="Torch.Autograd.html#toDependent"><span class="hs-identifier hs-var hs-var">toDependent</span></a></span><span> </span><span class="annot"><span class="annottext">([IndependentTensor] -&gt; [Tensor])
-&gt; [IndependentTensor] -&gt; [Tensor]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">model -&gt; [IndependentTensor]
forall f. Parameterized f =&gt; f -&gt; [IndependentTensor]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679626437"><span class="hs-identifier hs-var">initParams</span></a></span><span>
</span><span id="line-212"></span><span>
</span><span id="line-213"></span><span id="local-6989586621679626433"><span class="annot"><a href="Torch.Optim.CppOptim.html#save"><span class="hs-identifier hs-type">save</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626433"><span class="hs-identifier hs-type">option</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">FilePath</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-214"></span><span id="save"><span class="annot"><span class="annottext">save :: CppOptimizerState option -&gt; [Char] -&gt; IO ()
</span><a href="Torch.Optim.CppOptim.html#save"><span class="hs-identifier hs-var hs-var">save</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">option
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679626430"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626430"><span class="hs-identifier hs-var">optimizer</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679626429"><span class="annot"><span class="annottext">[Char]
</span><a href="#local-6989586621679626429"><span class="hs-identifier hs-var">file</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(CppOptimizerRef -&gt; ForeignPtr StdString -&gt; IO ())
-&gt; CppOptimizerRef -&gt; [Char] -&gt; IO ()
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef -&gt; ForeignPtr StdString -&gt; IO ()
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.save</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626430"><span class="hs-identifier hs-var">optimizer</span></a></span><span> </span><span class="annot"><span class="annottext">[Char]
</span><a href="#local-6989586621679626429"><span class="hs-identifier hs-var">file</span></a></span><span>
</span><span id="line-215"></span><span>
</span><span id="line-216"></span><span id="local-6989586621679626426"><span class="annot"><a href="Torch.Optim.CppOptim.html#load"><span class="hs-identifier hs-type">load</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679626426"><span class="hs-identifier hs-type">option</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">FilePath</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-217"></span><span id="load"><span class="annot"><span class="annottext">load :: CppOptimizerState option -&gt; [Char] -&gt; IO ()
</span><a href="Torch.Optim.CppOptim.html#load"><span class="hs-identifier hs-var hs-var">load</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Optim.CppOptim.html#CppOptimizerState"><span class="hs-identifier hs-type">CppOptimizerState</span></a></span><span> </span><span class="annot"><span class="annottext">option
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679626424"><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626424"><span class="hs-identifier hs-var">optimizer</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679626423"><span class="annot"><span class="annottext">[Char]
</span><a href="#local-6989586621679626423"><span class="hs-identifier hs-var">file</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(CppOptimizerRef -&gt; ForeignPtr StdString -&gt; IO ())
-&gt; CppOptimizerRef -&gt; [Char] -&gt; IO ()
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef -&gt; ForeignPtr StdString -&gt; IO ()
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">LibTorch.load</span></a></span><span> </span><span class="annot"><span class="annottext">CppOptimizerRef
</span><a href="#local-6989586621679626424"><span class="hs-identifier hs-var">optimizer</span></a></span><span> </span><span class="annot"><span class="annottext">[Char]
</span><a href="#local-6989586621679626423"><span class="hs-identifier hs-var">file</span></a></span><span>
</span><span id="line-218"></span></pre></body></html>