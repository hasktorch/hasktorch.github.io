<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE UndecidableSuperClasses #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE NoStarIsType #-}</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Typed.Functional</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-20"></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Arrow</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-operator">(&amp;&amp;&amp;)</span></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/7wrms0kf71gy57b58krylw06n7m418cv-finite-typelits-lib-finite-typelits-0.1.4.2-haddock-doc/share/doc/finite-typelits/html/src"><span class="hs-identifier">Data.Finite</span></a></span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Data.Int</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">I</span></span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span>
</span><span id="line-25"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier">Constraint</span></span><span class="hs-special">,</span><span>
</span><span id="line-26"></span><span>    </span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">,</span><span>
</span><span id="line-27"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Maybe</span></span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Proxy</span></span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/zrl3kdrpbhxqs3qd1g1mhjdnhnvkji84-reflection-lib-reflection-2.1.6-haddock-doc/share/doc/reflection/html/src"><span class="hs-identifier">Data.Reflection</span></a></span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/1mdaip8k8g5d1ha6705l1v4i4d6l2c03-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/1mdaip8k8g5d1ha6705l1v4i4d6l2c03-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Product</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign.ForeignPtr</span></span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Natural</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Natural</span></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier">GHC.TypeLits.Extra</span></a></span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.DType.html"><span class="hs-identifier">Torch.DType</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Device.html"><span class="hs-identifier">Torch.Device</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Functional.html"><span class="hs-identifier">Torch.Functional</span></a></span><span>
</span><span id="line-41"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier">Reduction</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-42"></span><span>    </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier">Tri</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-43"></span><span>    </span><span class="annot"><a href="Torch.Functional.html#isUpper"><span class="hs-identifier">isUpper</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-44"></span><span>    </span><span class="annot"><a href="Torch.Functional.html#kOne"><span class="hs-identifier">kOne</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-45"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.HList.html"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Const</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Cast</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen.Managed</span></span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen.Managed</span></span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Scalar</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen.Managed</span></span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen.Managed</span></span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tuple</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen.Managed</span></span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Scalar.html"><span class="hs-identifier">Torch.Scalar</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.TensorFactories.html"><span class="hs-identifier">Torch.TensorFactories</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.TensorOptions.html"><span class="hs-identifier">Torch.TensorOptions</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html"><span class="hs-identifier">Torch.Typed.Aux</span></a></span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html"><span class="hs-identifier">Torch.Typed.Factories</span></a></span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html"><span class="hs-identifier">Torch.Typed.Tensor</span></a></span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span>
</span><span id="line-64"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier">abs</span></span><span class="hs-special">,</span><span>
</span><span id="line-65"></span><span>    </span><span class="annot"><span class="hs-identifier">acos</span></span><span class="hs-special">,</span><span>
</span><span id="line-66"></span><span>    </span><span class="annot"><span class="hs-identifier">acosh</span></span><span class="hs-special">,</span><span>
</span><span id="line-67"></span><span>    </span><span class="annot"><span class="hs-identifier">all</span></span><span class="hs-special">,</span><span>
</span><span id="line-68"></span><span>    </span><span class="annot"><span class="hs-identifier">any</span></span><span class="hs-special">,</span><span>
</span><span id="line-69"></span><span>    </span><span class="annot"><span class="hs-identifier">asin</span></span><span class="hs-special">,</span><span>
</span><span id="line-70"></span><span>    </span><span class="annot"><span class="hs-identifier">asinh</span></span><span class="hs-special">,</span><span>
</span><span id="line-71"></span><span>    </span><span class="annot"><span class="hs-identifier">atan</span></span><span class="hs-special">,</span><span>
</span><span id="line-72"></span><span>    </span><span class="annot"><span class="hs-identifier">atanh</span></span><span class="hs-special">,</span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-identifier">ceil</span><span class="hs-special">,</span><span>
</span><span id="line-74"></span><span>    </span><span class="annot"><span class="hs-identifier">cos</span></span><span class="hs-special">,</span><span>
</span><span id="line-75"></span><span>    </span><span class="annot"><span class="hs-identifier">cosh</span></span><span class="hs-special">,</span><span>
</span><span id="line-76"></span><span>    </span><span class="annot"><span class="hs-identifier">exp</span></span><span class="hs-special">,</span><span>
</span><span id="line-77"></span><span>    </span><span class="annot"><span class="hs-identifier">floor</span></span><span class="hs-special">,</span><span>
</span><span id="line-78"></span><span>    </span><span class="annot"><span class="hs-identifier">isNaN</span></span><span class="hs-special">,</span><span>
</span><span id="line-79"></span><span>    </span><span class="annot"><span class="hs-identifier">log</span></span><span class="hs-special">,</span><span>
</span><span id="line-80"></span><span>    </span><span class="annot"><span class="hs-identifier">max</span></span><span class="hs-special">,</span><span>
</span><span id="line-81"></span><span>    </span><span class="annot"><span class="hs-identifier">min</span></span><span class="hs-special">,</span><span>
</span><span id="line-82"></span><span>    </span><span class="annot"><span class="hs-identifier">round</span></span><span class="hs-special">,</span><span>
</span><span id="line-83"></span><span>    </span><span class="annot"><span class="hs-identifier">sin</span></span><span class="hs-special">,</span><span>
</span><span id="line-84"></span><span>    </span><span class="annot"><span class="hs-identifier">sinh</span></span><span class="hs-special">,</span><span>
</span><span id="line-85"></span><span>    </span><span class="annot"><span class="hs-identifier">tan</span></span><span class="hs-special">,</span><span>
</span><span id="line-86"></span><span>    </span><span class="annot"><span class="hs-identifier">tanh</span></span><span class="hs-special">,</span><span>
</span><span id="line-87"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>
</span><span id="line-89"></span><span class="hs-comment">-- $setup</span><span>
</span><span id="line-90"></span><span class="hs-comment">--</span><span>
</span><span id="line-91"></span><span class="hs-comment">-- &gt;&gt;&gt; :set -XOverloadedLists</span><span>
</span><span id="line-92"></span><span>
</span><span id="line-93"></span><span class="hs-comment">-- | Computes the bitwise NOT of the given input tensor.</span><span>
</span><span id="line-94"></span><span class="hs-comment">-- The input tensor must be of integral or Boolean types.</span><span>
</span><span id="line-95"></span><span class="hs-comment">-- For bool tensors, it computes the logical NOT.</span><span>
</span><span id="line-96"></span><span class="hs-comment">--</span><span>
</span><span id="line-97"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ bitwiseNot (ones :: CPUTensor 'D.Bool [3,3])</span><span>
</span><span id="line-98"></span><span class="hs-comment">-- (Bool,[3,3])</span><span>
</span><span id="line-99"></span><span class="annot"><a href="Torch.Typed.Functional.html#bitwiseNot"><span class="hs-identifier hs-type">bitwiseNot</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-100"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710312"><span class="annot"><a href="#local-6989586621679710312"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679710311"><span class="annot"><a href="#local-6989586621679710311"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-101"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-102"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710312"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710311"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-103"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-104"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710312"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710311"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-105"></span><span id="bitwiseNot"><span class="annot"><span class="annottext">bitwiseNot :: Tensor device 'Bool shape -&gt; Tensor device 'Bool shape
</span><a href="Torch.Typed.Functional.html#bitwiseNot"><span class="hs-identifier hs-var hs-var">bitwiseNot</span></a></span></span><span> </span><span id="local-6989586621679710310"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710310"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape)
-&gt; IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape -&gt; IO (Tensor device 'Bool shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.bitwise_not_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710310"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-106"></span><span>
</span><span id="line-107"></span><span class="hs-comment">-- | Computes the element-wise logical NOT of the given input tensor.</span><span>
</span><span id="line-108"></span><span class="hs-comment">-- If not specified, the output tensor will have the bool dtype.</span><span>
</span><span id="line-109"></span><span class="hs-comment">-- If the input tensor is not a bool tensor, zeros are treated as False and non-zeros are treated as True.</span><span>
</span><span id="line-110"></span><span class="annot"><a href="Torch.Typed.Functional.html#logicalNot"><span class="hs-identifier hs-type">logicalNot</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-111"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710305"><span class="annot"><a href="#local-6989586621679710305"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679710304"><span class="annot"><a href="#local-6989586621679710304"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-112"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-113"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710305"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710304"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-114"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-115"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710305"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710304"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-116"></span><span id="logicalNot"><span class="annot"><span class="annottext">logicalNot :: Tensor device 'Bool shape -&gt; Tensor device 'Bool shape
</span><a href="Torch.Typed.Functional.html#logicalNot"><span class="hs-identifier hs-var hs-var">logicalNot</span></a></span></span><span> </span><span id="local-6989586621679710303"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710303"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape)
-&gt; IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape -&gt; IO (Tensor device 'Bool shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.logical_not_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710303"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-117"></span><span>
</span><span id="line-118"></span><span class="annot"><a href="Torch.Typed.Functional.html#logicalXor"><span class="hs-identifier hs-type">logicalXor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-119"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710300"><span class="annot"><a href="#local-6989586621679710300"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679710299"><span class="annot"><a href="#local-6989586621679710299"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-120"></span><span>  </span><span class="hs-comment">-- | self</span><span>
</span><span id="line-121"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710300"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710299"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-122"></span><span>  </span><span class="hs-comment">-- | other</span><span>
</span><span id="line-123"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710300"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710299"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-124"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710300"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710299"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-125"></span><span id="logicalXor"><span class="annot"><span class="annottext">logicalXor :: Tensor device 'Bool shape
-&gt; Tensor device 'Bool shape -&gt; Tensor device 'Bool shape
</span><a href="Torch.Typed.Functional.html#logicalXor"><span class="hs-identifier hs-var hs-var">logicalXor</span></a></span></span><span> </span><span id="local-6989586621679710298"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710298"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679710297"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710297"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape)
-&gt; IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape
-&gt; Tensor device 'Bool shape
-&gt; IO (Tensor device 'Bool shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.logical_xor_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710298"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710297"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-126"></span><span>
</span><span id="line-127"></span><span class="annot"><a href="Torch.Typed.Functional.html#logicalAnd"><span class="hs-identifier hs-type">logicalAnd</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-128"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710293"><span class="annot"><a href="#local-6989586621679710293"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679710292"><span class="annot"><a href="#local-6989586621679710292"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-129"></span><span>  </span><span class="hs-comment">-- | self</span><span>
</span><span id="line-130"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710293"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710292"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-131"></span><span>  </span><span class="hs-comment">-- | other</span><span>
</span><span id="line-132"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710293"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710292"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-133"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710293"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710292"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-134"></span><span id="logicalAnd"><span class="annot"><span class="annottext">logicalAnd :: Tensor device 'Bool shape
-&gt; Tensor device 'Bool shape -&gt; Tensor device 'Bool shape
</span><a href="Torch.Typed.Functional.html#logicalAnd"><span class="hs-identifier hs-var hs-var">logicalAnd</span></a></span></span><span> </span><span id="local-6989586621679710291"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710291"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679710290"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710290"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape)
-&gt; IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape
-&gt; Tensor device 'Bool shape
-&gt; IO (Tensor device 'Bool shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.logical_and_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710291"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710290"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-135"></span><span>
</span><span id="line-136"></span><span class="annot"><a href="Torch.Typed.Functional.html#logicalOr"><span class="hs-identifier hs-type">logicalOr</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-137"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710287"><span class="annot"><a href="#local-6989586621679710287"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679710286"><span class="annot"><a href="#local-6989586621679710286"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-138"></span><span>  </span><span class="hs-comment">-- | self</span><span>
</span><span id="line-139"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710287"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710286"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-140"></span><span>  </span><span class="hs-comment">-- | other</span><span>
</span><span id="line-141"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710287"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710286"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-142"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710287"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710286"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-143"></span><span id="logicalOr"><span class="annot"><span class="annottext">logicalOr :: Tensor device 'Bool shape
-&gt; Tensor device 'Bool shape -&gt; Tensor device 'Bool shape
</span><a href="Torch.Typed.Functional.html#logicalOr"><span class="hs-identifier hs-var hs-var">logicalOr</span></a></span></span><span> </span><span id="local-6989586621679710285"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710285"><span class="hs-identifier hs-var">self</span></a></span></span><span> </span><span id="local-6989586621679710284"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710284"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape)
-&gt; IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape
-&gt; Tensor device 'Bool shape
-&gt; IO (Tensor device 'Bool shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.logical_or_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710285"><span class="hs-identifier hs-var">self</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679710284"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-144"></span><span>
</span><span id="line-145"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710281"><span class="annot"><a href="#local-6989586621679710281"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-146"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-147"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#UInt8"><span class="hs-identifier hs-type">D.UInt8</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-148"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Int8"><span class="hs-identifier hs-type">D.Int8</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-149"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Int16"><span class="hs-identifier hs-type">D.Int16</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-150"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Int32"><span class="hs-identifier hs-type">D.Int32</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-151"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span>
</span><span id="line-152"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Half"><span class="hs-identifier hs-type">D.Half</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Half"><span class="hs-identifier hs-type">D.Half</span></a></span><span>
</span><span id="line-153"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Float"><span class="hs-identifier hs-type">D.Float</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Float"><span class="hs-identifier hs-type">D.Float</span></a></span><span>
</span><span id="line-154"></span><span>  </span><span id="SumDType"><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-var">SumDType</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Double"><span class="hs-identifier hs-type">D.Double</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.DType.html#Double"><span class="hs-identifier hs-type">D.Double</span></a></span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SumDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-var">SumDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710272"><span class="annot"><a href="#local-6989586621679710272"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710271"><span class="annot"><a href="#local-6989586621679710271"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-157"></span><span>  </span><span id="SumDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-var">SumDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679710269"><span class="annot"><a href="#local-6989586621679710269"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679710269"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-158"></span><span>  </span><span id="SumDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-var">SumDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679710266"><span class="annot"><a href="#local-6989586621679710266"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-159"></span><span>  </span><span id="SumDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-var">SumDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679710265"><span class="annot"><a href="#local-6989586621679710265"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679710264"><span class="annot"><a href="#local-6989586621679710264"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710265"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710264"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-160"></span><span>
</span><span id="line-161"></span><span class="hs-comment">-- | sumAll</span><span>
</span><span id="line-162"></span><span class="hs-comment">--</span><span>
</span><span id="line-163"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Int) $ sumAll (ones :: CPUTensor 'D.Bool '[2, 3])</span><span>
</span><span id="line-164"></span><span class="hs-comment">-- (Int64,([],6))</span><span>
</span><span id="line-165"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Int) $ sumAll (ones :: CPUTensor 'D.UInt8 '[2, 3])</span><span>
</span><span id="line-166"></span><span class="hs-comment">-- (Int64,([],6))</span><span>
</span><span id="line-167"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Int) $ sumAll (ones :: CPUTensor 'D.Int8 '[2, 3])</span><span>
</span><span id="line-168"></span><span class="hs-comment">-- (Int64,([],6))</span><span>
</span><span id="line-169"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Int) $ sumAll (ones :: CPUTensor 'D.Int16 '[2, 3])</span><span>
</span><span id="line-170"></span><span class="hs-comment">-- (Int64,([],6))</span><span>
</span><span id="line-171"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Int) $ sumAll (ones :: CPUTensor 'D.Int32 '[2, 3])</span><span>
</span><span id="line-172"></span><span class="hs-comment">-- (Int64,([],6))</span><span>
</span><span id="line-173"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Int) $ sumAll (ones :: CPUTensor 'D.Int64 '[2, 3])</span><span>
</span><span id="line-174"></span><span class="hs-comment">-- (Int64,([],6))</span><span>
</span><span id="line-175"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Float) $ sumAll (ones :: CPUTensor 'D.Float '[2, 3])</span><span>
</span><span id="line-176"></span><span class="hs-comment">-- (Float,([],6.0))</span><span>
</span><span id="line-177"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: Double) $ sumAll (ones :: CPUTensor 'D.Double '[2, 3])</span><span>
</span><span id="line-178"></span><span class="hs-comment">-- (Double,([],6.0))</span><span>
</span><span id="line-179"></span><span class="annot"><a href="Torch.Typed.Functional.html#sumAll"><span class="hs-identifier hs-type">sumAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-180"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710261"><span class="annot"><a href="#local-6989586621679710261"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710260"><span class="annot"><a href="#local-6989586621679710260"><span class="hs-identifier hs-type">dtype'</span></a></span></span><span> </span><span id="local-6989586621679710259"><span class="annot"><a href="#local-6989586621679710259"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710258"><span class="annot"><a href="#local-6989586621679710258"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-181"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-type">SumDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710258"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710259"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-182"></span><span>    </span><span class="annot"><a href="#local-6989586621679710260"><span class="hs-identifier hs-type">dtype'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-type">SumDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710259"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-183"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-184"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-185"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710258"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710259"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710261"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-186"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-187"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710258"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710260"><span class="hs-identifier hs-type">dtype'</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-188"></span><span id="sumAll"><span class="annot"><span class="annottext">sumAll :: Tensor device dtype shape -&gt; Tensor device dtype' '[]
</span><a href="Torch.Typed.Functional.html#sumAll"><span class="hs-identifier hs-var hs-var">sumAll</span></a></span></span><span> </span><span id="local-6989586621679710257"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710257"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype' '[]) -&gt; Tensor device dtype' '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype' '[]) -&gt; Tensor device dtype' '[])
-&gt; IO (Tensor device dtype' '[]) -&gt; Tensor device dtype' '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype' '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sum_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710257"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-189"></span><span>
</span><span id="line-190"></span><span class="hs-comment">-- | sumDim</span><span>
</span><span id="line-191"></span><span class="hs-comment">--</span><span>
</span><span id="line-192"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ sumDim @0 (ones :: CPUTensor 'D.Float '[3,4,5])</span><span>
</span><span id="line-193"></span><span class="hs-comment">-- (Float,[4,5])</span><span>
</span><span id="line-194"></span><span class="hs-comment">-- &gt;&gt;&gt; sumDim @1 (ones :: CPUTensor 'D.Float '[2,4])</span><span>
</span><span id="line-195"></span><span class="hs-comment">-- Tensor Float [2] [ 4.0000   ,  4.0000   ]</span><span>
</span><span id="line-196"></span><span class="annot"><a href="Torch.Typed.Functional.html#sumDim"><span class="hs-identifier hs-type">sumDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-197"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710254"><span class="annot"><a href="#local-6989586621679710254"><span class="hs-identifier hs-type">d</span></a></span></span><span> </span><span id="local-6989586621679710253"><span class="annot"><a href="#local-6989586621679710253"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710252"><span class="annot"><a href="#local-6989586621679710252"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679710251"><span class="annot"><a href="#local-6989586621679710251"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710250"><span class="annot"><a href="#local-6989586621679710250"><span class="hs-identifier hs-type">dtype'</span></a></span></span><span> </span><span id="local-6989586621679710249"><span class="annot"><a href="#local-6989586621679710249"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-198"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679710254"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-199"></span><span>    </span><span class="annot"><a href="#local-6989586621679710252"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710253"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710254"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-200"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDTypeIsValid"><span class="hs-identifier hs-type">SumDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710249"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710251"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-201"></span><span>    </span><span class="annot"><a href="#local-6989586621679710250"><span class="hs-identifier hs-type">dtype'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SumDType"><span class="hs-identifier hs-type">SumDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710251"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-202"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-203"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-204"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710249"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710251"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710253"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-205"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-206"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710249"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710250"><span class="hs-identifier hs-type">dtype'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710252"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-207"></span><span id="sumDim"><span class="annot"><span class="annottext">sumDim :: Tensor device dtype shape -&gt; Tensor device dtype' shape'
</span><a href="Torch.Typed.Functional.html#sumDim"><span class="hs-identifier hs-var hs-var">sumDim</span></a></span></span><span> </span><span id="local-6989586621679710248"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710248"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype' shape') -&gt; Tensor device dtype' shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype' shape') -&gt; Tensor device dtype' shape')
-&gt; IO (Tensor device dtype' shape') -&gt; Tensor device dtype' shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype' shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sum_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710248"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat d =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710254"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>
</span><span id="line-209"></span><span class="hs-comment">-- | abs</span><span>
</span><span id="line-210"></span><span class="hs-comment">--</span><span>
</span><span id="line-211"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ abs (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-212"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-213"></span><span class="annot"><a href="Torch.Typed.Functional.html#abs"><span class="hs-identifier hs-type">abs</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-214"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710244"><span class="annot"><a href="#local-6989586621679710244"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710243"><span class="annot"><a href="#local-6989586621679710243"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710242"><span class="annot"><a href="#local-6989586621679710242"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-215"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710242"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710243"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-216"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-217"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710242"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710243"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710244"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-218"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-219"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710242"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710243"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710244"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-220"></span><span id="abs"><span class="annot"><span class="annottext">abs :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#abs"><span class="hs-identifier hs-var hs-var">abs</span></a></span></span><span> </span><span id="local-6989586621679710240"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710240"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.abs_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710240"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-221"></span><span>
</span><span id="line-222"></span><span class="hs-comment">-- | ceil</span><span>
</span><span id="line-223"></span><span class="hs-comment">--</span><span>
</span><span id="line-224"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ ceil (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-225"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-226"></span><span class="annot"><a href="Torch.Typed.Functional.html#ceil"><span class="hs-identifier hs-type">ceil</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-227"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710237"><span class="annot"><a href="#local-6989586621679710237"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710236"><span class="annot"><a href="#local-6989586621679710236"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710235"><span class="annot"><a href="#local-6989586621679710235"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-228"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710235"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710236"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-229"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-230"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710235"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710236"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710237"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-231"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-232"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710235"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710236"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710237"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-233"></span><span id="ceil"><span class="annot"><span class="annottext">ceil :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#ceil"><span class="hs-identifier hs-var hs-var">ceil</span></a></span></span><span> </span><span id="local-6989586621679710234"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710234"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.ceil_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710234"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-234"></span><span>
</span><span id="line-235"></span><span class="hs-comment">-- | floor</span><span>
</span><span id="line-236"></span><span class="hs-comment">--</span><span>
</span><span id="line-237"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ floor (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-238"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-239"></span><span class="annot"><a href="Torch.Typed.Functional.html#floor"><span class="hs-identifier hs-type">floor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-240"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710231"><span class="annot"><a href="#local-6989586621679710231"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710230"><span class="annot"><a href="#local-6989586621679710230"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710229"><span class="annot"><a href="#local-6989586621679710229"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-241"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710229"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710230"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-242"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-243"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710229"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710230"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710231"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-244"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-245"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710229"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710230"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710231"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-246"></span><span id="floor"><span class="annot"><span class="annottext">floor :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#floor"><span class="hs-identifier hs-var hs-var">floor</span></a></span></span><span> </span><span id="local-6989586621679710228"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710228"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.floor_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710228"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-247"></span><span>
</span><span id="line-248"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MinMaxDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#MinMaxDTypeIsValid"><span class="hs-identifier hs-var">MinMaxDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710225"><span class="annot"><a href="#local-6989586621679710225"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710224"><span class="annot"><a href="#local-6989586621679710224"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-249"></span><span>  </span><span id="MinMaxDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#MinMaxDTypeIsValid"><span class="hs-identifier hs-var">MinMaxDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679710223"><span class="annot"><a href="#local-6989586621679710223"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679710223"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-250"></span><span>  </span><span id="MinMaxDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#MinMaxDTypeIsValid"><span class="hs-identifier hs-var">MinMaxDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679710222"><span class="annot"><a href="#local-6989586621679710222"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span>  </span><span id="MinMaxDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#MinMaxDTypeIsValid"><span class="hs-identifier hs-var">MinMaxDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679710221"><span class="annot"><a href="#local-6989586621679710221"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679710220"><span class="annot"><a href="#local-6989586621679710220"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710221"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710220"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-252"></span><span>
</span><span id="line-253"></span><span class="hs-comment">-- | min</span><span>
</span><span id="line-254"></span><span class="hs-comment">--</span><span>
</span><span id="line-255"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ min (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-256"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-257"></span><span class="annot"><a href="Torch.Typed.Functional.html#min"><span class="hs-identifier hs-type">min</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-258"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710218"><span class="annot"><a href="#local-6989586621679710218"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710217"><span class="annot"><a href="#local-6989586621679710217"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710216"><span class="annot"><a href="#local-6989586621679710216"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-259"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#MinMaxDTypeIsValid"><span class="hs-identifier hs-type">MinMaxDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710216"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710217"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-260"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710218"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-261"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-262"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-263"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710216"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710217"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710218"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-264"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-265"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710216"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710217"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-266"></span><span id="min"><span class="annot"><span class="annottext">min :: Tensor device dtype shape -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#min"><span class="hs-identifier hs-var hs-var">min</span></a></span></span><span> </span><span id="local-6989586621679710214"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710214"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.min_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710214"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-267"></span><span>
</span><span id="line-268"></span><span class="hs-comment">-- | max</span><span>
</span><span id="line-269"></span><span class="hs-comment">--</span><span>
</span><span id="line-270"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ max (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-271"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-272"></span><span class="annot"><a href="Torch.Typed.Functional.html#max"><span class="hs-identifier hs-type">max</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-273"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710211"><span class="annot"><a href="#local-6989586621679710211"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710210"><span class="annot"><a href="#local-6989586621679710210"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710209"><span class="annot"><a href="#local-6989586621679710209"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-274"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#MinMaxDTypeIsValid"><span class="hs-identifier hs-type">MinMaxDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710209"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710210"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-275"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710211"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-276"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-277"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-278"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710209"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710210"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710211"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-280"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710209"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710210"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-281"></span><span id="max"><span class="annot"><span class="annottext">max :: Tensor device dtype shape -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#max"><span class="hs-identifier hs-var hs-var">max</span></a></span></span><span> </span><span id="local-6989586621679710208"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710208"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.max_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710208"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-282"></span><span>
</span><span id="line-283"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MeanDTypeValidation"><span class="annot"><a href="Torch.Typed.Functional.html#MeanDTypeValidation"><span class="hs-identifier hs-var">MeanDTypeValidation</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710205"><span class="annot"><a href="#local-6989586621679710205"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710204"><span class="annot"><a href="#local-6989586621679710204"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-284"></span><span>  </span><span id="MeanDTypeValidation"><span class="annot"><a href="Torch.Typed.Functional.html#MeanDTypeValidation"><span class="hs-identifier hs-var">MeanDTypeValidation</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679710203"><span class="annot"><a href="#local-6989586621679710203"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679710202"><span class="annot"><a href="#local-6989586621679710202"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679710201"><span class="annot"><a href="#local-6989586621679710201"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-285"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679710203"><span class="hs-identifier hs-type">deviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679710202"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679710201"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-286"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679710203"><span class="hs-identifier hs-type">deviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679710202"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679710201"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-287"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>
</span><span id="line-289"></span><span class="hs-comment">-- | Computes the mean while carrying out a full reduction of all tensor dimensions.</span><span>
</span><span id="line-290"></span><span class="hs-comment">--</span><span>
</span><span id="line-291"></span><span class="hs-comment">-- &gt;&gt;&gt; meanAll (ones :: CPUTensor 'D.Float '[])</span><span>
</span><span id="line-292"></span><span class="hs-comment">-- Tensor Float []  1.0000</span><span>
</span><span id="line-293"></span><span class="hs-comment">-- &gt;&gt;&gt; meanAll (zeros :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-294"></span><span class="hs-comment">-- Tensor Float []  0.0000</span><span>
</span><span id="line-295"></span><span class="annot"><a href="Torch.Typed.Functional.html#meanAll"><span class="hs-identifier hs-type">meanAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-296"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710198"><span class="annot"><a href="#local-6989586621679710198"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710197"><span class="annot"><a href="#local-6989586621679710197"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710196"><span class="annot"><a href="#local-6989586621679710196"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-297"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#MeanDTypeValidation"><span class="hs-identifier hs-type">MeanDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710196"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710197"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-298"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710198"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-299"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-300"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-301"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710196"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710197"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710198"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-302"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-303"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710196"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710197"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-304"></span><span id="meanAll"><span class="annot"><span class="annottext">meanAll :: Tensor device dtype shape -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#meanAll"><span class="hs-identifier hs-var hs-var">meanAll</span></a></span></span><span> </span><span id="local-6989586621679710195"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710195"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mean_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710195"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-305"></span><span>
</span><span id="line-306"></span><span class="hs-comment">-- | Computes the mean while carrying out a full reduction of all tensor dimensions.</span><span>
</span><span id="line-307"></span><span class="hs-comment">-- This version is not restricted and can return NaN.</span><span>
</span><span id="line-308"></span><span class="hs-comment">--</span><span>
</span><span id="line-309"></span><span class="hs-comment">-- &gt;&gt;&gt; unsafeMeanAll (ones :: CPUTensor 'D.Float '[])</span><span>
</span><span id="line-310"></span><span class="hs-comment">-- Tensor Float []  1.0000</span><span>
</span><span id="line-311"></span><span class="hs-comment">-- &gt;&gt;&gt; unsafeMeanAll (ones :: CPUTensor 'D.Float '[0])</span><span>
</span><span id="line-312"></span><span class="hs-comment">-- Tensor Float [] NaN</span><span>
</span><span id="line-313"></span><span class="hs-comment">-- &gt;&gt;&gt; unsafeMeanAll (zeros :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-314"></span><span class="hs-comment">-- Tensor Float []  0.0000</span><span>
</span><span id="line-315"></span><span class="annot"><a href="Torch.Typed.Functional.html#unsafeMeanAll"><span class="hs-identifier hs-type">unsafeMeanAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-316"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710192"><span class="annot"><a href="#local-6989586621679710192"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710191"><span class="annot"><a href="#local-6989586621679710191"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710190"><span class="annot"><a href="#local-6989586621679710190"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-317"></span><span>  </span><span class="annot"><a href="Torch.Typed.Functional.html#MeanDTypeValidation"><span class="hs-identifier hs-type">MeanDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710190"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710191"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-318"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-319"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710190"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710191"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710192"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-321"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710190"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710191"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-322"></span><span id="unsafeMeanAll"><span class="annot"><span class="annottext">unsafeMeanAll :: Tensor device dtype shape -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#unsafeMeanAll"><span class="hs-identifier hs-var hs-var">unsafeMeanAll</span></a></span></span><span>
</span><span id="line-323"></span><span>  </span><span id="local-6989586621679710189"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710189"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mean_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710189"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-324"></span><span>
</span><span id="line-325"></span><span class="hs-comment">-- | Computes the mean and reduces the tensor over the specified dimension.</span><span>
</span><span id="line-326"></span><span class="hs-comment">--</span><span>
</span><span id="line-327"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3,4,5]</span><span>
</span><span id="line-328"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ meanDim @0 t</span><span>
</span><span id="line-329"></span><span class="hs-comment">-- (Float,[4,5])</span><span>
</span><span id="line-330"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ meanDim @1 t</span><span>
</span><span id="line-331"></span><span class="hs-comment">-- (Float,[3,5])</span><span>
</span><span id="line-332"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ meanDim @2 t</span><span>
</span><span id="line-333"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-334"></span><span class="annot"><a href="Torch.Typed.Functional.html#meanDim"><span class="hs-identifier hs-type">meanDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-335"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710187"><span class="annot"><a href="#local-6989586621679710187"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679710186"><span class="annot"><a href="#local-6989586621679710186"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679710185"><span class="annot"><a href="#local-6989586621679710185"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710184"><span class="annot"><a href="#local-6989586621679710184"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710183"><span class="annot"><a href="#local-6989586621679710183"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-336"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679710187"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-337"></span><span>    </span><span class="annot"><a href="#local-6989586621679710186"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710185"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710187"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-338"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#MeanDTypeValidation"><span class="hs-identifier hs-type">MeanDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710183"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710184"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-339"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710185"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-340"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-341"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-342"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710183"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710184"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710185"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-343"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-344"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710183"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710184"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710186"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-345"></span><span id="meanDim"><span class="annot"><span class="annottext">meanDim :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#meanDim"><span class="hs-identifier hs-var hs-var">meanDim</span></a></span></span><span> </span><span id="local-6989586621679710182"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710182"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mean_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710182"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710187"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-346"></span><span>
</span><span id="line-347"></span><span class="hs-comment">-- | Computes the mean and optionally reduces the tensor over the specified dimension.</span><span>
</span><span id="line-348"></span><span class="hs-comment">--</span><span>
</span><span id="line-349"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/torch.html#torch.mean for more information.</span><span>
</span><span id="line-350"></span><span class="hs-comment">--</span><span>
</span><span id="line-351"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[5, 1], [3, 2], [4, 1], [2, 7]] :: CPUTensor 'D.Float '[4, 2]</span><span>
</span><span id="line-352"></span><span class="hs-comment">-- &gt;&gt;&gt; mean @0 @KeepDim t</span><span>
</span><span id="line-353"></span><span class="hs-comment">-- Tensor Float [1,2] [[ 3.5000   ,  2.7500   ]]</span><span>
</span><span id="line-354"></span><span class="annot"><a href="Torch.Typed.Functional.html#mean"><span class="hs-identifier hs-type">mean</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-355"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710179"><span class="annot"><a href="#local-6989586621679710179"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679710178"><span class="annot"><a href="#local-6989586621679710178"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679710177"><span class="annot"><a href="#local-6989586621679710177"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679710176"><span class="annot"><a href="#local-6989586621679710176"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710175"><span class="annot"><a href="#local-6989586621679710175"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710174"><span class="annot"><a href="#local-6989586621679710174"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-356"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679710179"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-357"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710178"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-358"></span><span>    </span><span class="annot"><a href="#local-6989586621679710177"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710176"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710179"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710178"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-359"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#MeanDTypeValidation"><span class="hs-identifier hs-type">MeanDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710174"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710175"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-360"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710176"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-361"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-362"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710174"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710175"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710176"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-363"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710174"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710175"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710177"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-364"></span><span id="mean"><span class="annot"><span class="annottext">mean :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#mean"><span class="hs-identifier hs-var hs-var">mean</span></a></span></span><span> </span><span id="local-6989586621679710172"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710172"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-365"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-366"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-367"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mean_tlb</span></a></span><span>
</span><span id="line-368"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710172"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-369"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710179"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-370"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710178"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-371"></span><span>
</span><span id="line-372"></span><span class="hs-comment">-- | Computes the median while carrying out a full reduction of all tensor dimensions.</span><span>
</span><span id="line-373"></span><span class="hs-comment">--</span><span>
</span><span id="line-374"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ medianAll (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-375"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-376"></span><span class="annot"><a href="Torch.Typed.Functional.html#medianAll"><span class="hs-identifier hs-type">medianAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-377"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710167"><span class="annot"><a href="#local-6989586621679710167"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710166"><span class="annot"><a href="#local-6989586621679710166"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710165"><span class="annot"><a href="#local-6989586621679710165"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-378"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710165"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710166"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-379"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710167"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-380"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-381"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-382"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710165"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710166"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710167"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-383"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-384"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710165"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710166"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-385"></span><span id="medianAll"><span class="annot"><span class="annottext">medianAll :: Tensor device dtype shape -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#medianAll"><span class="hs-identifier hs-var hs-var">medianAll</span></a></span></span><span> </span><span id="local-6989586621679710164"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710164"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.median_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710164"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-386"></span><span>
</span><span id="line-387"></span><span class="hs-comment">-- | Computes the median and reduces the tensor over the specified dimension.</span><span>
</span><span id="line-388"></span><span class="hs-comment">--</span><span>
</span><span id="line-389"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3,4,5]</span><span>
</span><span id="line-390"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ medianDim @0 t</span><span>
</span><span id="line-391"></span><span class="hs-comment">-- (Float,[4,5])</span><span>
</span><span id="line-392"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ medianDim @1 t</span><span>
</span><span id="line-393"></span><span class="hs-comment">-- (Float,[3,5])</span><span>
</span><span id="line-394"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ medianDim @2 t</span><span>
</span><span id="line-395"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-396"></span><span class="annot"><a href="Torch.Typed.Functional.html#medianDim"><span class="hs-identifier hs-type">medianDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-397"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710161"><span class="annot"><a href="#local-6989586621679710161"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679710160"><span class="annot"><a href="#local-6989586621679710160"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679710159"><span class="annot"><a href="#local-6989586621679710159"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710158"><span class="annot"><a href="#local-6989586621679710158"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710157"><span class="annot"><a href="#local-6989586621679710157"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-398"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679710161"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-399"></span><span>    </span><span class="annot"><a href="#local-6989586621679710160"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710159"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710161"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-400"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710157"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710158"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-401"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710159"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-402"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-403"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-404"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710157"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710158"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710159"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-405"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-406"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710157"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710158"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710160"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-407"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710157"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710160"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-408"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-409"></span><span id="medianDim"><span class="annot"><span class="annottext">medianDim :: Tensor device dtype shape
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
</span><a href="Torch.Typed.Functional.html#medianDim"><span class="hs-identifier hs-var hs-var">medianDim</span></a></span></span><span> </span><span id="local-6989586621679710156"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710156"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape', Tensor device 'Int64 shape')
 -&gt; (Tensor device dtype shape', Tensor device 'Int64 shape'))
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.median_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710156"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710161"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-410"></span><span>
</span><span id="line-411"></span><span class="hs-comment">-- | Computes the median and optionally reduces the tensor over the specified dimension.</span><span>
</span><span id="line-412"></span><span class="hs-comment">--</span><span>
</span><span id="line-413"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/torch.html#torch.median for more information.</span><span>
</span><span id="line-414"></span><span class="hs-comment">--</span><span>
</span><span id="line-415"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[5, 1], [3, 2], [4, 1], [2, 7]] :: CPUTensor 'D.Float '[4, 2]</span><span>
</span><span id="line-416"></span><span class="hs-comment">-- &gt;&gt;&gt; median @0 @KeepDim t</span><span>
</span><span id="line-417"></span><span class="hs-comment">-- (Tensor Float [1,2] [[ 3.0000   ,  1.0000   ]],Tensor Int64 [1,2] [[ 1,  0]])</span><span>
</span><span id="line-418"></span><span class="annot"><a href="Torch.Typed.Functional.html#median"><span class="hs-identifier hs-type">median</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-419"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710153"><span class="annot"><a href="#local-6989586621679710153"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679710152"><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679710151"><span class="annot"><a href="#local-6989586621679710151"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679710150"><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710149"><span class="annot"><a href="#local-6989586621679710149"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710148"><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-420"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679710153"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-421"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-422"></span><span>    </span><span class="annot"><a href="#local-6989586621679710151"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710153"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-423"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710149"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-424"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-425"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-426"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-427"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710149"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710150"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-428"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-429"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710149"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710151"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710151"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-430"></span><span id="median"><span class="annot"><span class="annottext">median :: Tensor device dtype shape
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
</span><a href="Torch.Typed.Functional.html#median"><span class="hs-identifier hs-var hs-var">median</span></a></span></span><span> </span><span id="local-6989586621679710147"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710147"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-431"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape', Tensor device 'Int64 shape')
 -&gt; (Tensor device dtype shape', Tensor device 'Int64 shape'))
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-432"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-433"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.median_tlb</span></a></span><span>
</span><span id="line-434"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710147"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-435"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710153"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-436"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710152"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-437"></span><span>
</span><span id="line-438"></span><span class="hs-comment">-- | Returns a tuple '(modes, indices)' where 'modes' is the mode value of each row of the 'input' tensor</span><span>
</span><span id="line-439"></span><span class="hs-comment">-- in the given dimension 'dim', i.e. a value which appears most often in that row,</span><span>
</span><span id="line-440"></span><span class="hs-comment">-- and 'indices' is the index location of each mode value found.</span><span>
</span><span id="line-441"></span><span class="hs-comment">--</span><span>
</span><span id="line-442"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/torch.html#torch.mode for more information.</span><span>
</span><span id="line-443"></span><span class="hs-comment">--</span><span>
</span><span id="line-444"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[0, 5], [0, 2], [3, 5]] :: CPUTensor 'D.Int64 '[3, 2]</span><span>
</span><span id="line-445"></span><span class="hs-comment">--</span><span>
</span><span id="line-446"></span><span class="hs-comment">-- &gt;&gt;&gt; (modes :: CPUTensor 'D.Int64 '[2], indices :: CPUTensor 'D.Int64 '[2]) = mode @0 @DropDim t</span><span>
</span><span id="line-447"></span><span class="hs-comment">-- &gt;&gt;&gt; (dtype modes, shape modes, D.asValue (toDynamic modes) :: [Int])</span><span>
</span><span id="line-448"></span><span class="hs-comment">-- (Int64,[2],[0,5])</span><span>
</span><span id="line-449"></span><span class="hs-comment">-- &gt;&gt;&gt; (dtype indices, shape indices, D.asValue (toDynamic indices) :: [Int])</span><span>
</span><span id="line-450"></span><span class="hs-comment">-- (Int64,[2],[1,2])</span><span>
</span><span id="line-451"></span><span class="hs-comment">--</span><span>
</span><span id="line-452"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[0, 0], [0, 1], [3, 3]] :: CPUTensor 'D.Float '[3, 2]</span><span>
</span><span id="line-453"></span><span class="hs-comment">--</span><span>
</span><span id="line-454"></span><span class="hs-comment">-- &gt;&gt;&gt; (modes :: CPUTensor 'D.Float '[3,1], indices :: CPUTensor 'D.Int64 '[3,1]) = mode @1 @KeepDim t</span><span>
</span><span id="line-455"></span><span class="hs-comment">-- &gt;&gt;&gt; (dtype modes, shape modes, D.asValue (toDynamic modes) :: [[Float]])</span><span>
</span><span id="line-456"></span><span class="hs-comment">-- (Float,[3,1],[[0.0],[0.0],[3.0]])</span><span>
</span><span id="line-457"></span><span class="hs-comment">-- &gt;&gt;&gt; (dtype indices, shape indices, D.asValue (toDynamic indices) :: [[Int]])</span><span>
</span><span id="line-458"></span><span class="hs-comment">-- (Int64,[3,1],[[1],[0],[1]])</span><span>
</span><span id="line-459"></span><span class="annot"><a href="Torch.Typed.Functional.html#mode"><span class="hs-identifier hs-type">mode</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-460"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710144"><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679710143"><span class="annot"><a href="#local-6989586621679710143"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679710142"><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679710141"><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710140"><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710139"><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-461"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-462"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710143"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-463"></span><span>    </span><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710143"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-464"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-465"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-466"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-467"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-468"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710141"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-469"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-470"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710140"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710139"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710142"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span id="mode"><span class="annot"><span class="annottext">mode :: Tensor device dtype shape
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
</span><a href="Torch.Typed.Functional.html#mode"><span class="hs-identifier hs-var hs-var">mode</span></a></span></span><span> </span><span id="local-6989586621679710138"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710138"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-472"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape', Tensor device 'Int64 shape')
 -&gt; (Tensor device dtype shape', Tensor device 'Int64 shape'))
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-473"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-474"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mode_tlb</span></a></span><span>
</span><span id="line-475"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710138"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-476"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710144"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-477"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679710143"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-478"></span><span>
</span><span id="line-479"></span><span class="hs-comment">-- | addScalar</span><span>
</span><span id="line-480"></span><span class="hs-comment">-- TODO: what dtypes is this defined for?</span><span>
</span><span id="line-481"></span><span class="hs-comment">-- TODO: what scalar types is this defined for?</span><span>
</span><span id="line-482"></span><span class="hs-comment">--</span><span>
</span><span id="line-483"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ addScalar 1 (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-484"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-485"></span><span class="annot"><a href="Torch.Typed.Functional.html#addScalar"><span class="hs-identifier hs-type">addScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-486"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710135"><span class="annot"><a href="#local-6989586621679710135"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679710134"><span class="annot"><a href="#local-6989586621679710134"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710133"><span class="annot"><a href="#local-6989586621679710133"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710132"><span class="annot"><a href="#local-6989586621679710132"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-487"></span><span>  </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710135"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-488"></span><span>  </span><span class="hs-comment">-- | scalar input</span><span>
</span><span id="line-489"></span><span>  </span><span class="annot"><a href="#local-6989586621679710135"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-490"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-491"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710132"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710133"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710134"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-492"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-493"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710132"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710133"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710134"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-494"></span><span id="addScalar"><span class="annot"><span class="annottext">addScalar :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#addScalar"><span class="hs-identifier hs-var hs-var">addScalar</span></a></span></span><span> </span><span id="local-6989586621679710131"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710131"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679710130"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710130"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.add_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710130"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710131"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-495"></span><span>
</span><span id="line-496"></span><span class="hs-comment">-- | subScalar</span><span>
</span><span id="line-497"></span><span class="hs-comment">-- TODO: what dtypes is this defined for?</span><span>
</span><span id="line-498"></span><span class="hs-comment">-- TODO: what scalar types is this defined for?</span><span>
</span><span id="line-499"></span><span class="hs-comment">--</span><span>
</span><span id="line-500"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ subScalar 1 (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-501"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-502"></span><span class="annot"><a href="Torch.Typed.Functional.html#subScalar"><span class="hs-identifier hs-type">subScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-503"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710127"><span class="annot"><a href="#local-6989586621679710127"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679710126"><span class="annot"><a href="#local-6989586621679710126"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710125"><span class="annot"><a href="#local-6989586621679710125"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710124"><span class="annot"><a href="#local-6989586621679710124"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-504"></span><span>  </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710127"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-505"></span><span>  </span><span class="hs-comment">-- | scalar input</span><span>
</span><span id="line-506"></span><span>  </span><span class="annot"><a href="#local-6989586621679710127"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-507"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-508"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710124"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710125"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710126"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-509"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-510"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710124"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710125"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710126"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-511"></span><span id="subScalar"><span class="annot"><span class="annottext">subScalar :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#subScalar"><span class="hs-identifier hs-var hs-var">subScalar</span></a></span></span><span> </span><span id="local-6989586621679710123"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710123"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679710122"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710122"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sub_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710122"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710123"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-512"></span><span>
</span><span id="line-513"></span><span class="hs-comment">-- | mulScalar</span><span>
</span><span id="line-514"></span><span class="hs-comment">-- TODO: what dtypes is this defined for?</span><span>
</span><span id="line-515"></span><span class="hs-comment">-- TODO: what scalar types is this defined for?</span><span>
</span><span id="line-516"></span><span class="hs-comment">--</span><span>
</span><span id="line-517"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ mulScalar 2 (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-518"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-519"></span><span class="annot"><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-type">mulScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-520"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710119"><span class="annot"><a href="#local-6989586621679710119"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679710118"><span class="annot"><a href="#local-6989586621679710118"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710117"><span class="annot"><a href="#local-6989586621679710117"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710116"><span class="annot"><a href="#local-6989586621679710116"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-521"></span><span>  </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710119"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-522"></span><span>  </span><span class="hs-comment">-- | scalar input</span><span>
</span><span id="line-523"></span><span>  </span><span class="annot"><a href="#local-6989586621679710119"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-524"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-525"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710116"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710117"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710118"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-526"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-527"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710116"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710117"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710118"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-528"></span><span id="mulScalar"><span class="annot"><span class="annottext">mulScalar :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mulScalar"><span class="hs-identifier hs-var hs-var">mulScalar</span></a></span></span><span> </span><span id="local-6989586621679710115"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710115"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679710114"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710114"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mul_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710114"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710115"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-529"></span><span>
</span><span id="line-530"></span><span class="hs-comment">-- | divScalar</span><span>
</span><span id="line-531"></span><span class="hs-comment">-- TODO: what dtypes is this defined for?</span><span>
</span><span id="line-532"></span><span class="hs-comment">-- TODO: what scalar types is this defined for?</span><span>
</span><span id="line-533"></span><span class="hs-comment">--</span><span>
</span><span id="line-534"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ divScalar 2 (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-535"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-536"></span><span class="annot"><a href="Torch.Typed.Functional.html#divScalar"><span class="hs-identifier hs-type">divScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-537"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710111"><span class="annot"><a href="#local-6989586621679710111"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679710110"><span class="annot"><a href="#local-6989586621679710110"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710109"><span class="annot"><a href="#local-6989586621679710109"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710108"><span class="annot"><a href="#local-6989586621679710108"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-538"></span><span>  </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710111"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-539"></span><span>  </span><span class="hs-comment">-- | scalar input</span><span>
</span><span id="line-540"></span><span>  </span><span class="annot"><a href="#local-6989586621679710111"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-541"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-542"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710108"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710109"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710110"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-543"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-544"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710108"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710109"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710110"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-545"></span><span id="divScalar"><span class="annot"><span class="annottext">divScalar :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#divScalar"><span class="hs-identifier hs-var hs-var">divScalar</span></a></span></span><span> </span><span id="local-6989586621679710107"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710107"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679710106"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710106"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.div_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710106"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710107"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-546"></span><span>
</span><span id="line-547"></span><span class="hs-comment">-- | powScalar</span><span>
</span><span id="line-548"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-549"></span><span class="hs-comment">--</span><span>
</span><span id="line-550"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ powScalar 2 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-551"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-552"></span><span class="annot"><a href="Torch.Typed.Functional.html#powScalar"><span class="hs-identifier hs-type">powScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-553"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710103"><span class="annot"><a href="#local-6989586621679710103"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679710102"><span class="annot"><a href="#local-6989586621679710102"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710101"><span class="annot"><a href="#local-6989586621679710101"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710100"><span class="annot"><a href="#local-6989586621679710100"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-554"></span><span>  </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710103"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-555"></span><span>  </span><span class="hs-comment">-- | power</span><span>
</span><span id="line-556"></span><span>  </span><span class="annot"><a href="#local-6989586621679710103"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-557"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-558"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710100"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710101"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710102"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-559"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-560"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710100"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710101"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710102"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-561"></span><span id="powScalar"><span class="annot"><span class="annottext">powScalar :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#powScalar"><span class="hs-identifier hs-var hs-var">powScalar</span></a></span></span><span> </span><span id="local-6989586621679710099"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710099"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679710098"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710098"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.pow_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710098"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679710099"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-562"></span><span>
</span><span id="line-563"></span><span class="hs-comment">-- | erf</span><span>
</span><span id="line-564"></span><span class="hs-comment">--</span><span>
</span><span id="line-565"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ erf (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-566"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-567"></span><span class="annot"><a href="Torch.Typed.Functional.html#erf"><span class="hs-identifier hs-type">erf</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-568"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710095"><span class="annot"><a href="#local-6989586621679710095"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710094"><span class="annot"><a href="#local-6989586621679710094"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710093"><span class="annot"><a href="#local-6989586621679710093"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-569"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710093"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710094"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-570"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-571"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710093"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710094"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710095"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-572"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-573"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710093"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710094"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710095"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-574"></span><span id="erf"><span class="annot"><span class="annottext">erf :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#erf"><span class="hs-identifier hs-var hs-var">erf</span></a></span></span><span> </span><span id="local-6989586621679710092"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710092"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.erf_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710092"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-575"></span><span>
</span><span id="line-576"></span><span class="hs-comment">-- | exp</span><span>
</span><span id="line-577"></span><span class="hs-comment">--</span><span>
</span><span id="line-578"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ exp (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-579"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-580"></span><span class="annot"><a href="Torch.Typed.Functional.html#exp"><span class="hs-identifier hs-type">exp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-581"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710089"><span class="annot"><a href="#local-6989586621679710089"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710088"><span class="annot"><a href="#local-6989586621679710088"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710087"><span class="annot"><a href="#local-6989586621679710087"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-582"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710087"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710088"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-583"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-584"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710087"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710088"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710089"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-585"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-586"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710087"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710088"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710089"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-587"></span><span id="exp"><span class="annot"><span class="annottext">exp :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#exp"><span class="hs-identifier hs-var hs-var">exp</span></a></span></span><span> </span><span id="local-6989586621679710086"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710086"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.exp_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710086"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-588"></span><span>
</span><span id="line-589"></span><span class="hs-comment">-- | log1p</span><span>
</span><span id="line-590"></span><span class="hs-comment">--</span><span>
</span><span id="line-591"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ log1p (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-592"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-593"></span><span class="annot"><a href="Torch.Typed.Functional.html#log1p"><span class="hs-identifier hs-type">log1p</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-594"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710083"><span class="annot"><a href="#local-6989586621679710083"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710082"><span class="annot"><a href="#local-6989586621679710082"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710081"><span class="annot"><a href="#local-6989586621679710081"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-595"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710081"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710082"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-596"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-597"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710081"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710082"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710083"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-598"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-599"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710081"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710082"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710083"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-600"></span><span id="log1p"><span class="annot"><span class="annottext">log1p :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#log1p"><span class="hs-identifier hs-var hs-var">log1p</span></a></span></span><span> </span><span id="local-6989586621679710080"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710080"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.log1p_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710080"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-601"></span><span>
</span><span id="line-602"></span><span class="hs-comment">-- | log2</span><span>
</span><span id="line-603"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ log2 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-604"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-605"></span><span class="annot"><a href="Torch.Typed.Functional.html#log2"><span class="hs-identifier hs-type">log2</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-606"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710077"><span class="annot"><a href="#local-6989586621679710077"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710076"><span class="annot"><a href="#local-6989586621679710076"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710075"><span class="annot"><a href="#local-6989586621679710075"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-607"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710075"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710076"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-608"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-609"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710075"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710076"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710077"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-610"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-611"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710075"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710076"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710077"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-612"></span><span id="log2"><span class="annot"><span class="annottext">log2 :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#log2"><span class="hs-identifier hs-var hs-var">log2</span></a></span></span><span> </span><span id="local-6989586621679710074"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710074"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.log2_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710074"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-613"></span><span>
</span><span id="line-614"></span><span class="hs-comment">-- | log10</span><span>
</span><span id="line-615"></span><span class="hs-comment">--</span><span>
</span><span id="line-616"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ log10 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-617"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-618"></span><span class="annot"><a href="Torch.Typed.Functional.html#log10"><span class="hs-identifier hs-type">log10</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-619"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710071"><span class="annot"><a href="#local-6989586621679710071"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710070"><span class="annot"><a href="#local-6989586621679710070"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710069"><span class="annot"><a href="#local-6989586621679710069"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-620"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710069"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710070"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-621"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-622"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710069"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710070"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710071"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-623"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-624"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710069"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710070"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710071"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-625"></span><span id="log10"><span class="annot"><span class="annottext">log10 :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#log10"><span class="hs-identifier hs-var hs-var">log10</span></a></span></span><span> </span><span id="local-6989586621679710068"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710068"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.log10_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710068"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-626"></span><span>
</span><span id="line-627"></span><span class="hs-comment">-- | pow</span><span>
</span><span id="line-628"></span><span class="hs-comment">-- this operation supports broadcasting</span><span>
</span><span id="line-629"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-630"></span><span class="hs-comment">--</span><span>
</span><span id="line-631"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ pow (2 :: CPUTensor 'D.Float '[]) (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-632"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-633"></span><span class="annot"><a href="Torch.Typed.Functional.html#pow"><span class="hs-identifier hs-type">pow</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-634"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710065"><span class="annot"><a href="#local-6989586621679710065"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679710064"><span class="annot"><a href="#local-6989586621679710064"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710063"><span class="annot"><a href="#local-6989586621679710063"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679710062"><span class="annot"><a href="#local-6989586621679710062"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710061"><span class="annot"><a href="#local-6989586621679710061"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-635"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710061"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710062"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-636"></span><span>    </span><span class="annot"><a href="#local-6989586621679710065"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710064"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710063"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-637"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-638"></span><span>  </span><span class="hs-comment">-- | power</span><span>
</span><span id="line-639"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710061"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710062"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710064"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-640"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-641"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710061"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710062"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710063"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-642"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-643"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710061"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710062"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710065"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-644"></span><span id="pow"><span class="annot"><span class="annottext">pow :: Tensor device dtype shape
-&gt; Tensor device dtype shape' -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Functional.html#pow"><span class="hs-identifier hs-var hs-var">pow</span></a></span></span><span> </span><span id="local-6989586621679710060"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710060"><span class="hs-identifier hs-var">exponent</span></a></span></span><span> </span><span id="local-6989586621679710059"><span class="annot"><span class="annottext">Tensor device dtype shape'
</span><a href="#local-6989586621679710059"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape'') -&gt; Tensor device dtype shape''
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape'') -&gt; Tensor device dtype shape'')
-&gt; IO (Tensor device dtype shape'') -&gt; Tensor device dtype shape''
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape'
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.pow_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape'
</span><a href="#local-6989586621679710059"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710060"><span class="hs-identifier hs-var">exponent</span></a></span><span>
</span><span id="line-645"></span><span>
</span><span id="line-646"></span><span class="hs-comment">-- | relu activation function</span><span>
</span><span id="line-647"></span><span class="hs-comment">--</span><span>
</span><span id="line-648"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ relu (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-649"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-650"></span><span class="annot"><a href="Torch.Typed.Functional.html#relu"><span class="hs-identifier hs-type">relu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-651"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710056"><span class="annot"><a href="#local-6989586621679710056"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710055"><span class="annot"><a href="#local-6989586621679710055"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710054"><span class="annot"><a href="#local-6989586621679710054"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-652"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710054"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710055"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-653"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-654"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710054"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710055"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710056"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-655"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-656"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710054"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710055"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710056"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-657"></span><span id="relu"><span class="annot"><span class="annottext">relu :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#relu"><span class="hs-identifier hs-var hs-var">relu</span></a></span></span><span> </span><span id="local-6989586621679710053"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710053"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.relu_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710053"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-658"></span><span>
</span><span id="line-659"></span><span class="hs-comment">-- | selu</span><span>
</span><span id="line-660"></span><span class="hs-comment">--</span><span>
</span><span id="line-661"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ selu (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-662"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-663"></span><span class="annot"><a href="Torch.Typed.Functional.html#selu"><span class="hs-identifier hs-type">selu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-664"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710050"><span class="annot"><a href="#local-6989586621679710050"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710049"><span class="annot"><a href="#local-6989586621679710049"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710048"><span class="annot"><a href="#local-6989586621679710048"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-665"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710048"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710049"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-666"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-667"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710048"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710049"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710050"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-668"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-669"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710048"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710049"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710050"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-670"></span><span id="selu"><span class="annot"><span class="annottext">selu :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#selu"><span class="hs-identifier hs-var hs-var">selu</span></a></span></span><span> </span><span id="local-6989586621679710047"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710047"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.selu_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710047"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-671"></span><span>
</span><span id="line-672"></span><span class="hs-comment">-- | mish</span><span>
</span><span id="line-673"></span><span class="hs-comment">-- `mish` is a smooth activation function, see https://arxiv.org/abs/1908.08681 for details.</span><span>
</span><span id="line-674"></span><span class="hs-comment">--</span><span>
</span><span id="line-675"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t -&gt; D.asValue (toDynamic t) :: [[Float]]) $ mish (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-676"></span><span class="hs-comment">-- (Float,([3,2],[[0.86509836,0.86509836],[0.86509836,0.86509836],[0.86509836,0.86509836]]))</span><span>
</span><span id="line-677"></span><span class="annot"><a href="Torch.Typed.Functional.html#mish"><span class="hs-identifier hs-type">mish</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-678"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710044"><span class="annot"><a href="#local-6989586621679710044"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710043"><span class="annot"><a href="#local-6989586621679710043"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710042"><span class="annot"><a href="#local-6989586621679710042"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-679"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710043"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-680"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#BasicArithmeticDTypeIsValid"><span class="hs-identifier hs-type">BasicArithmeticDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710043"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-681"></span><span>    </span><span class="annot"><a href="#local-6989586621679710044"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710044"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710044"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-682"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-683"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710043"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710044"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-684"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710043"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710044"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-685"></span><span id="mish"><span class="annot"><span class="annottext">mish :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#mish"><span class="hs-identifier hs-var hs-var">mish</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall (shape'' :: [Nat]) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (dtype' :: DType) (dtype'' :: DType)
       (device :: (DeviceType, Nat)).
(dtype'' ~ DTypePromotion dtype dtype',
 shape'' ~ Broadcast shape shape',
 BasicArithmeticDTypeIsValid device dtype,
 BasicArithmeticDTypeIsValid device dtype',
 BasicArithmeticDTypeIsValid device dtype'') =&gt;
Tensor device dtype shape
-&gt; Tensor device dtype' shape' -&gt; Tensor device dtype'' shape''
</span><a href="Torch.Typed.Tensor.html#mul"><span class="hs-identifier hs-var">mul</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype shape
 -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape)
-&gt; (Tensor device dtype shape -&gt; Tensor device dtype shape)
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape -&gt; Tensor device dtype shape
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
StandardFloatingPointDTypeValidation device dtype =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#tanh"><span class="hs-identifier hs-var">tanh</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype shape -&gt; Tensor device dtype shape)
-&gt; (Tensor device dtype shape -&gt; Tensor device dtype shape)
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Float
-&gt; Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
forall a (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Scalar a =&gt;
a -&gt; a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#softplus"><span class="hs-identifier hs-var">softplus</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">20</span></span><span>
</span><span id="line-686"></span><span>
</span><span id="line-687"></span><span class="hs-comment">-- | sigmoid</span><span>
</span><span id="line-688"></span><span class="hs-comment">--</span><span>
</span><span id="line-689"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ sigmoid (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-690"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-691"></span><span class="annot"><a href="Torch.Typed.Functional.html#sigmoid"><span class="hs-identifier hs-type">sigmoid</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-692"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710035"><span class="annot"><a href="#local-6989586621679710035"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710034"><span class="annot"><a href="#local-6989586621679710034"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710033"><span class="annot"><a href="#local-6989586621679710033"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-693"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710033"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710034"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-694"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-695"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710033"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710034"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710035"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-696"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-697"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710033"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710034"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710035"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-698"></span><span id="sigmoid"><span class="annot"><span class="annottext">sigmoid :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#sigmoid"><span class="hs-identifier hs-var hs-var">sigmoid</span></a></span></span><span> </span><span id="local-6989586621679710032"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710032"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sigmoid_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710032"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-699"></span><span>
</span><span id="line-700"></span><span class="hs-comment">-- | sin</span><span>
</span><span id="line-701"></span><span class="hs-comment">--</span><span>
</span><span id="line-702"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ sin (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-703"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-704"></span><span class="annot"><a href="Torch.Typed.Functional.html#sin"><span class="hs-identifier hs-type">sin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-705"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710029"><span class="annot"><a href="#local-6989586621679710029"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710028"><span class="annot"><a href="#local-6989586621679710028"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710027"><span class="annot"><a href="#local-6989586621679710027"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-706"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710027"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710028"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-707"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-708"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710027"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710028"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710029"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-709"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-710"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710027"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710028"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710029"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-711"></span><span id="sin"><span class="annot"><span class="annottext">sin :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#sin"><span class="hs-identifier hs-var hs-var">sin</span></a></span></span><span> </span><span id="local-6989586621679710026"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710026"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sin_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710026"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-712"></span><span>
</span><span id="line-713"></span><span class="hs-comment">-- | sinh</span><span>
</span><span id="line-714"></span><span class="hs-comment">--</span><span>
</span><span id="line-715"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ sinh (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-716"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-717"></span><span class="annot"><a href="Torch.Typed.Functional.html#sinh"><span class="hs-identifier hs-type">sinh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-718"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710023"><span class="annot"><a href="#local-6989586621679710023"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710022"><span class="annot"><a href="#local-6989586621679710022"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710021"><span class="annot"><a href="#local-6989586621679710021"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-719"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710021"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710022"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-720"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-721"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710021"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710022"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710023"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-722"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-723"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710021"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710022"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710023"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-724"></span><span id="sinh"><span class="annot"><span class="annottext">sinh :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#sinh"><span class="hs-identifier hs-var hs-var">sinh</span></a></span></span><span> </span><span id="local-6989586621679710020"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710020"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sinh_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710020"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-725"></span><span>
</span><span id="line-726"></span><span class="hs-comment">-- | cos</span><span>
</span><span id="line-727"></span><span class="hs-comment">--</span><span>
</span><span id="line-728"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ cos (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-729"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-730"></span><span class="annot"><a href="Torch.Typed.Functional.html#cos"><span class="hs-identifier hs-type">cos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-731"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710017"><span class="annot"><a href="#local-6989586621679710017"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710016"><span class="annot"><a href="#local-6989586621679710016"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710015"><span class="annot"><a href="#local-6989586621679710015"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-732"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710016"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-733"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-734"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710016"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710017"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-735"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-736"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710016"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710017"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-737"></span><span id="cos"><span class="annot"><span class="annottext">cos :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#cos"><span class="hs-identifier hs-var hs-var">cos</span></a></span></span><span> </span><span id="local-6989586621679710014"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710014"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.cos_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710014"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-738"></span><span>
</span><span id="line-739"></span><span class="hs-comment">-- | sqrt</span><span>
</span><span id="line-740"></span><span class="annot"><a href="Torch.Typed.Functional.html#sqrt"><span class="hs-identifier hs-type">sqrt</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-741"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710011"><span class="annot"><a href="#local-6989586621679710011"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710010"><span class="annot"><a href="#local-6989586621679710010"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710009"><span class="annot"><a href="#local-6989586621679710009"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-742"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710009"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710010"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-743"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-744"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710009"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710010"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710011"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-745"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-746"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710009"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710010"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710011"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-747"></span><span id="sqrt"><span class="annot"><span class="annottext">sqrt :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#sqrt"><span class="hs-identifier hs-var hs-var">sqrt</span></a></span></span><span> </span><span id="local-6989586621679710008"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710008"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sqrt_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710008"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-748"></span><span>
</span><span id="line-749"></span><span class="hs-comment">-- | tanh</span><span>
</span><span id="line-750"></span><span class="annot"><a href="Torch.Typed.Functional.html#tanh"><span class="hs-identifier hs-type">tanh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-751"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679711292"><span class="annot"><a href="#local-6989586621679711292"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679711294"><span class="annot"><a href="#local-6989586621679711294"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679711295"><span class="annot"><a href="#local-6989586621679711295"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-752"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711295"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711294"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-753"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-754"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711295"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711294"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711292"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-755"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-756"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711295"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711294"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711292"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-757"></span><span id="tanh"><span class="annot"><span class="annottext">tanh :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#tanh"><span class="hs-identifier hs-var hs-var">tanh</span></a></span></span><span> </span><span id="local-6989586621679710006"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710006"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.tanh_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679710006"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-758"></span><span>
</span><span id="line-759"></span><span class="hs-comment">-- | ConditionalReduction</span><span>
</span><span id="line-760"></span><span class="hs-comment">--</span><span>
</span><span id="line-761"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! ConditionalReduction '[3,2] ReduceNone</span><span>
</span><span id="line-762"></span><span class="hs-comment">-- ConditionalReduction '[3,2] ReduceNone :: [Nat]</span><span>
</span><span id="line-763"></span><span class="hs-comment">-- = '[3, 2]</span><span>
</span><span id="line-764"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! ConditionalReduction '[3,2] ReduceMean</span><span>
</span><span id="line-765"></span><span class="hs-comment">-- ConditionalReduction '[3,2] ReduceMean :: [Nat]</span><span>
</span><span id="line-766"></span><span class="hs-comment">-- = '[]</span><span>
</span><span id="line-767"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ConditionalReduction"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-var">ConditionalReduction</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710004"><span class="annot"><a href="#local-6989586621679710004"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710003"><span class="annot"><a href="#local-6989586621679710003"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-768"></span><span>  </span><span id="ConditionalReduction"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-var">ConditionalReduction</span></a></span></span><span> </span><span id="local-6989586621679710002"><span class="annot"><a href="#local-6989586621679710002"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="annot"><a href="Torch.Functional.html#ReduceNone"><span class="hs-identifier hs-type">ReduceNone</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679710002"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-769"></span><span>  </span><span id="ConditionalReduction"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-var">ConditionalReduction</span></a></span></span><span> </span><span id="local-6989586621679710001"><span class="annot"><a href="#local-6989586621679710001"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-770"></span><span>
</span><span id="line-771"></span><span class="hs-keyword">class</span><span> </span><span id="KnownReduction"><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-var">KnownReduction</span></a></span></span><span> </span><span id="local-6989586621679711261"><span class="annot"><a href="#local-6989586621679711261"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-772"></span><span>  </span><span id="reductionVal"><span class="annot"><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-type">reductionVal</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-773"></span><span>
</span><span id="line-774"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#ReduceNone"><span class="hs-identifier hs-type">ReduceNone</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-775"></span><span>  </span><span id="local-6989586621679709997"><span class="annot"><span class="annottext">reductionVal :: Int
</span><a href="#local-6989586621679709997"><span class="hs-identifier hs-var hs-var hs-var hs-var">reductionVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span>
</span><span id="line-776"></span><span>
</span><span id="line-777"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#ReduceMean"><span class="hs-identifier hs-type">ReduceMean</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-778"></span><span>  </span><span id="local-6989586621679709995"><span class="annot"><span class="annottext">reductionVal :: Int
</span><a href="#local-6989586621679709995"><span class="hs-identifier hs-var hs-var hs-var hs-var">reductionVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span>
</span><span id="line-779"></span><span>
</span><span id="line-780"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#ReduceSum"><span class="hs-identifier hs-type">ReduceSum</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-781"></span><span>  </span><span id="local-6989586621679709993"><span class="annot"><span class="annottext">reductionVal :: Int
</span><a href="#local-6989586621679709993"><span class="hs-identifier hs-var hs-var hs-var hs-var">reductionVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-782"></span><span>
</span><span id="line-783"></span><span class="hs-comment">-- | binary cross entropy</span><span>
</span><span id="line-784"></span><span class="hs-comment">--</span><span>
</span><span id="line-785"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2,2]</span><span>
</span><span id="line-786"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ binaryCrossEntropy @ReduceNone t t t</span><span>
</span><span id="line-787"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-788"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ binaryCrossEntropy @ReduceMean t t t</span><span>
</span><span id="line-789"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-790"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ binaryCrossEntropy @ReduceSum t t t</span><span>
</span><span id="line-791"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-792"></span><span class="annot"><a href="Torch.Typed.Functional.html#binaryCrossEntropy"><span class="hs-identifier hs-type">binaryCrossEntropy</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-793"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709991"><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709990"><span class="annot"><a href="#local-6989586621679709990"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709989"><span class="annot"><a href="#local-6989586621679709989"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709988"><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709987"><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-794"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-795"></span><span>    </span><span class="annot"><a href="#local-6989586621679709989"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-type">ConditionalReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709990"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-796"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-797"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-798"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-799"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709990"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-800"></span><span>  </span><span class="hs-comment">-- | prediction</span><span>
</span><span id="line-801"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709990"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-802"></span><span>  </span><span class="hs-comment">-- | target</span><span>
</span><span id="line-803"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709990"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-804"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-805"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709987"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709988"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709989"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-806"></span><span id="binaryCrossEntropy"><span class="annot"><span class="annottext">binaryCrossEntropy :: Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#binaryCrossEntropy"><span class="hs-identifier hs-var hs-var">binaryCrossEntropy</span></a></span></span><span> </span><span id="local-6989586621679709986"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709986"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679709985"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709985"><span class="hs-identifier hs-var">prediction</span></a></span></span><span> </span><span id="local-6989586621679709984"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709984"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-807"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-808"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span>
</span><span id="line-809"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.binary_cross_entropy_tttl</span></a></span><span>
</span><span id="line-810"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709985"><span class="hs-identifier hs-var">prediction</span></a></span><span>
</span><span id="line-811"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709984"><span class="hs-identifier hs-var">target</span></a></span><span>
</span><span id="line-812"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709986"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-813"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709991"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-814"></span><span>
</span><span id="line-815"></span><span class="hs-comment">-- | mseLoss</span><span>
</span><span id="line-816"></span><span class="hs-comment">--</span><span>
</span><span id="line-817"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2,2]</span><span>
</span><span id="line-818"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ mseLoss @ReduceNone t t</span><span>
</span><span id="line-819"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-820"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ mseLoss @ReduceMean t t</span><span>
</span><span id="line-821"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-822"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ mseLoss @ReduceSum t t</span><span>
</span><span id="line-823"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-824"></span><span class="annot"><a href="Torch.Typed.Functional.html#mseLoss"><span class="hs-identifier hs-type">mseLoss</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-825"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709980"><span class="annot"><a href="#local-6989586621679709980"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Reduction"><span class="hs-identifier hs-type">Reduction</span></a></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709979"><span class="annot"><a href="#local-6989586621679709979"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709978"><span class="annot"><a href="#local-6989586621679709978"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709977"><span class="annot"><a href="#local-6989586621679709977"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709976"><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-826"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709980"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-827"></span><span>    </span><span class="annot"><a href="#local-6989586621679709978"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-type">ConditionalReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709979"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709980"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-828"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709977"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-829"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-830"></span><span>  </span><span class="hs-comment">-- | prediction</span><span>
</span><span id="line-831"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709977"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709979"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-832"></span><span>  </span><span class="hs-comment">-- | target</span><span>
</span><span id="line-833"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709977"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709979"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-834"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-835"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709977"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709978"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-836"></span><span id="mseLoss"><span class="annot"><span class="annottext">mseLoss :: Tensor device dtype shape
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#mseLoss"><span class="hs-identifier hs-var hs-var">mseLoss</span></a></span></span><span> </span><span id="local-6989586621679709975"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709975"><span class="hs-identifier hs-var">prediction</span></a></span></span><span> </span><span id="local-6989586621679709974"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709974"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-837"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-838"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-839"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mse_loss_ttl</span></a></span><span>
</span><span id="line-840"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709975"><span class="hs-identifier hs-var">prediction</span></a></span><span>
</span><span id="line-841"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709974"><span class="hs-identifier hs-var">target</span></a></span><span>
</span><span id="line-842"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709980"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-843"></span><span>
</span><span id="line-844"></span><span class="hs-comment">-- | softmax</span><span>
</span><span id="line-845"></span><span class="hs-comment">--</span><span>
</span><span id="line-846"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2,2]</span><span>
</span><span id="line-847"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ softmax @0 t</span><span>
</span><span id="line-848"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-849"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ softmax @1 t</span><span>
</span><span id="line-850"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-851"></span><span class="annot"><a href="Torch.Typed.Functional.html#softmax"><span class="hs-identifier hs-type">softmax</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-852"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709971"><span class="annot"><a href="#local-6989586621679709971"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709970"><span class="annot"><a href="#local-6989586621679709970"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709969"><span class="annot"><a href="#local-6989586621679709969"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709968"><span class="annot"><a href="#local-6989586621679709968"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-853"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709971"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-854"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#DimOutOfBoundCheck"><span class="hs-identifier hs-type">DimOutOfBoundCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709970"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709971"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-855"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709969"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-856"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709968"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709969"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-857"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-858"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-859"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709968"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709969"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709970"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-860"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-861"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709968"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709969"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709970"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-862"></span><span id="softmax"><span class="annot"><span class="annottext">softmax :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#softmax"><span class="hs-identifier hs-var hs-var">softmax</span></a></span></span><span> </span><span id="local-6989586621679709966"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709966"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-863"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-864"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; DType
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.softmax_tls</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709966"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709971"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownDType dtype =&gt; DType
forall (dtype :: DType). KnownDType dtype =&gt; DType
</span><a href="Torch.Typed.Tensor.html#dtypeVal"><span class="hs-identifier hs-var">dtypeVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709969"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-865"></span><span>
</span><span id="line-866"></span><span class="hs-comment">-- | logSoftmax</span><span>
</span><span id="line-867"></span><span class="hs-comment">--</span><span>
</span><span id="line-868"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2,2]</span><span>
</span><span id="line-869"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ logSoftmax @0 t</span><span>
</span><span id="line-870"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-871"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ logSoftmax @1 t</span><span>
</span><span id="line-872"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-873"></span><span class="annot"><a href="Torch.Typed.Functional.html#logSoftmax"><span class="hs-identifier hs-type">logSoftmax</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-874"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709962"><span class="annot"><a href="#local-6989586621679709962"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709961"><span class="annot"><a href="#local-6989586621679709961"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709960"><span class="annot"><a href="#local-6989586621679709960"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709959"><span class="annot"><a href="#local-6989586621679709959"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-875"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709962"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-876"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#DimOutOfBoundCheck"><span class="hs-identifier hs-type">DimOutOfBoundCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709961"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709962"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-877"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709960"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-878"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709960"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-879"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-880"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-881"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709960"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709961"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-882"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-883"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709960"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709961"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-884"></span><span id="logSoftmax"><span class="annot"><span class="annottext">logSoftmax :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#logSoftmax"><span class="hs-identifier hs-var hs-var">logSoftmax</span></a></span></span><span> </span><span id="local-6989586621679709958"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709958"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-885"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-886"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; DType
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.log_softmax_tls</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709958"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709962"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownDType dtype =&gt; DType
forall (dtype :: DType). KnownDType dtype =&gt; DType
</span><a href="Torch.Typed.Tensor.html#dtypeVal"><span class="hs-identifier hs-var">dtypeVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709960"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-887"></span><span>
</span><span id="line-888"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="Square"><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-var">Square</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709955"><span class="annot"><a href="#local-6989586621679709955"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-889"></span><span>  </span><span id="Square"><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-var">Square</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709954"><span class="annot"><a href="#local-6989586621679709954"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679709954"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709954"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709954"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-890"></span><span>  </span><span id="Square"><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-var">Square</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709953"><span class="annot"><a href="#local-6989586621679709953"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709952"><span class="annot"><a href="#local-6989586621679709952"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679709952"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709953"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709952"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709952"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-891"></span><span>  </span><span id="Square"><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-var">Square</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;This shape must be square matrix or batch + square matrix.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-892"></span><span>
</span><span id="line-893"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="VectorOfSquare"><span class="annot"><a href="Torch.Typed.Functional.html#VectorOfSquare"><span class="hs-identifier hs-var">VectorOfSquare</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709950"><span class="annot"><a href="#local-6989586621679709950"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-894"></span><span>  </span><span id="VectorOfSquare"><span class="annot"><a href="Torch.Typed.Functional.html#VectorOfSquare"><span class="hs-identifier hs-var">VectorOfSquare</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709949"><span class="annot"><a href="#local-6989586621679709949"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679709949"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709949"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-895"></span><span>  </span><span id="VectorOfSquare"><span class="annot"><a href="Torch.Typed.Functional.html#VectorOfSquare"><span class="hs-identifier hs-var">VectorOfSquare</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709948"><span class="annot"><a href="#local-6989586621679709948"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709947"><span class="annot"><a href="#local-6989586621679709947"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679709947"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709948"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709947"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-896"></span><span>  </span><span id="VectorOfSquare"><span class="annot"><a href="Torch.Typed.Functional.html#VectorOfSquare"><span class="hs-identifier hs-var">VectorOfSquare</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;This shape must be square matrix or batch + square matrix.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-897"></span><span>
</span><span id="line-898"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="FstSquareDim"><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-var">FstSquareDim</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709945"><span class="annot"><a href="#local-6989586621679709945"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-899"></span><span>  </span><span id="FstSquareDim"><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-var">FstSquareDim</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709944"><span class="annot"><a href="#local-6989586621679709944"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709943"><span class="annot"><a href="#local-6989586621679709943"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709944"><span class="hs-identifier hs-type">n</span></a></span><span>
</span><span id="line-900"></span><span>  </span><span id="FstSquareDim"><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-var">FstSquareDim</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709942"><span class="annot"><a href="#local-6989586621679709942"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709941"><span class="annot"><a href="#local-6989586621679709941"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709940"><span class="annot"><a href="#local-6989586621679709940"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709941"><span class="hs-identifier hs-type">n</span></a></span><span>
</span><span id="line-901"></span><span>  </span><span id="FstSquareDim"><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-var">FstSquareDim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Can not get first dimention of matrix or batch + matrix.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-902"></span><span>
</span><span id="line-903"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="InverseShapeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#InverseShapeIsValid"><span class="hs-identifier hs-var">InverseShapeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709938"><span class="annot"><a href="#local-6989586621679709938"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709937"><span class="annot"><a href="#local-6989586621679709937"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-904"></span><span>  </span><span id="InverseShapeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#InverseShapeIsValid"><span class="hs-identifier hs-var">InverseShapeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-905"></span><span>  </span><span id="InverseShapeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#InverseShapeIsValid"><span class="hs-identifier hs-var">InverseShapeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709936"><span class="annot"><a href="#local-6989586621679709936"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AllDimsPositive"><span class="hs-identifier hs-type">AllDimsPositive</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709936"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-906"></span><span>
</span><span id="line-907"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="InverseDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#InverseDTypeIsValid"><span class="hs-identifier hs-var">InverseDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709934"><span class="annot"><a href="#local-6989586621679709934"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709933"><span class="annot"><a href="#local-6989586621679709933"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-908"></span><span>  </span><span id="InverseDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#InverseDTypeIsValid"><span class="hs-identifier hs-var">InverseDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709932"><span class="annot"><a href="#local-6989586621679709932"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-909"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709932"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-910"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709932"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-911"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-912"></span><span>  </span><span id="InverseDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#InverseDTypeIsValid"><span class="hs-identifier hs-var">InverseDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709931"><span class="annot"><a href="#local-6989586621679709931"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709930"><span class="annot"><a href="#local-6989586621679709930"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-913"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709931"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709930"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-914"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709931"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709930"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-915"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-916"></span><span>  </span><span id="InverseDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#InverseDTypeIsValid"><span class="hs-identifier hs-var">InverseDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709929"><span class="annot"><a href="#local-6989586621679709929"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709928"><span class="annot"><a href="#local-6989586621679709928"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709929"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709928"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-917"></span><span>
</span><span id="line-918"></span><span class="hs-comment">-- | inverse</span><span>
</span><span id="line-919"></span><span class="hs-comment">-- TODO: if rank &lt; n for any tensors in the batch, then this will not work. we can't decide this statically, but we should prevent runtime errors. therefore, return Maybe?</span><span>
</span><span id="line-920"></span><span class="hs-comment">--</span><span>
</span><span id="line-921"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- randn :: IO (CPUTensor 'D.Float '[3,2,2])</span><span>
</span><span id="line-922"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ inverse t</span><span>
</span><span id="line-923"></span><span class="hs-comment">-- (Float,[3,2,2])</span><span>
</span><span id="line-924"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- randn :: IO (CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-925"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ inverse t</span><span>
</span><span id="line-926"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-927"></span><span class="annot"><a href="Torch.Typed.Functional.html#inverse"><span class="hs-identifier hs-type">inverse</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-928"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709926"><span class="annot"><a href="#local-6989586621679709926"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709925"><span class="annot"><a href="#local-6989586621679709925"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709924"><span class="annot"><a href="#local-6989586621679709924"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709923"><span class="annot"><a href="#local-6989586621679709923"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-929"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679709925"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-type">Square</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709926"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-930"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#InverseShapeIsValid"><span class="hs-identifier hs-type">InverseShapeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709923"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709926"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-931"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#InverseDTypeIsValid"><span class="hs-identifier hs-type">InverseDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709923"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709924"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-932"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-933"></span><span>  </span><span class="hs-comment">-- | inverse</span><span>
</span><span id="line-934"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709923"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709924"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709926"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-935"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-936"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709923"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709924"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709925"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-937"></span><span id="inverse"><span class="annot"><span class="annottext">inverse :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#inverse"><span class="hs-identifier hs-var hs-var">inverse</span></a></span></span><span> </span><span id="local-6989586621679709922"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709922"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape')
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.inverse_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709922"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-938"></span><span>
</span><span id="line-939"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SymeigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SymeigDTypeIsValid"><span class="hs-identifier hs-var">SymeigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709919"><span class="annot"><a href="#local-6989586621679709919"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709918"><span class="annot"><a href="#local-6989586621679709918"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-940"></span><span>  </span><span id="SymeigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SymeigDTypeIsValid"><span class="hs-identifier hs-var">SymeigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709917"><span class="annot"><a href="#local-6989586621679709917"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-941"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709917"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-942"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709917"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-943"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-944"></span><span>  </span><span id="SymeigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SymeigDTypeIsValid"><span class="hs-identifier hs-var">SymeigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709916"><span class="annot"><a href="#local-6989586621679709916"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709915"><span class="annot"><a href="#local-6989586621679709915"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-945"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709916"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709915"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-946"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709916"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709915"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-947"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-948"></span><span>  </span><span id="SymeigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SymeigDTypeIsValid"><span class="hs-identifier hs-var">SymeigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709914"><span class="annot"><a href="#local-6989586621679709914"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709913"><span class="annot"><a href="#local-6989586621679709913"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709914"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709913"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-949"></span><span>
</span><span id="line-950"></span><span class="hs-comment">-- | symeig</span><span>
</span><span id="line-951"></span><span class="hs-comment">--</span><span>
</span><span id="line-952"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- rand :: IO (CPUTensor 'D.Float '[3,2,2])</span><span>
</span><span id="line-953"></span><span class="hs-comment">-- &gt;&gt;&gt; (eigenVals,eigenVecs) = symeig Upper t</span><span>
</span><span id="line-954"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVals</span><span>
</span><span id="line-955"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-956"></span><span class="hs-comment">-- &gt;&gt;&gt; :t eigenVals</span><span>
</span><span id="line-957"></span><span class="hs-comment">-- eigenVals :: Tensor '( 'D.CPU, 0) 'D.Float '[3, 2]</span><span>
</span><span id="line-958"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVecs</span><span>
</span><span id="line-959"></span><span class="hs-comment">-- (Float,[3,2,2])</span><span>
</span><span id="line-960"></span><span class="hs-comment">-- &gt;&gt;&gt; :t eigenVecs</span><span>
</span><span id="line-961"></span><span class="hs-comment">-- eigenVecs :: Tensor '( 'D.CPU, 0) 'D.Float '[3, 2, 2]</span><span>
</span><span id="line-962"></span><span class="hs-comment">-- &gt;&gt;&gt; (eigenVals,eigenVecs) = symeig Lower t</span><span>
</span><span id="line-963"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVals</span><span>
</span><span id="line-964"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-965"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVecs</span><span>
</span><span id="line-966"></span><span class="hs-comment">-- (Float,[3,2,2])</span><span>
</span><span id="line-967"></span><span class="annot"><a href="Torch.Typed.Functional.html#symeig"><span class="hs-identifier hs-type">symeig</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-968"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709911"><span class="annot"><a href="#local-6989586621679709911"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709910"><span class="annot"><a href="#local-6989586621679709910"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709909"><span class="annot"><a href="#local-6989586621679709909"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679709908"><span class="annot"><a href="#local-6989586621679709908"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709907"><span class="annot"><a href="#local-6989586621679709907"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-969"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679709910"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#VectorOfSquare"><span class="hs-identifier hs-type">VectorOfSquare</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709911"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-970"></span><span>    </span><span class="annot"><a href="#local-6989586621679709909"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-type">Square</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709911"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-971"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#SymeigDTypeIsValid"><span class="hs-identifier hs-type">SymeigDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709907"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709908"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-972"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-973"></span><span>  </span><span class="hs-comment">-- | upper or lower triagonal</span><span>
</span><span id="line-974"></span><span>  </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-975"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-976"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709907"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709908"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709911"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-977"></span><span>  </span><span class="hs-comment">-- | eigenvalues and eigenvectors</span><span>
</span><span id="line-978"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709907"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709908"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709910"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-979"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709907"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709908"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709909"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-980"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-981"></span><span id="symeig"><span class="annot"><span class="annottext">symeig :: Tri
-&gt; Tensor device dtype shape
-&gt; (Tensor device dtype shape', Tensor device dtype shape'')
</span><a href="Torch.Typed.Functional.html#symeig"><span class="hs-identifier hs-var hs-var">symeig</span></a></span></span><span> </span><span id="local-6989586621679709906"><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709906"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679709905"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709905"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-982"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape', Tensor device dtype shape'')
-&gt; (Tensor device dtype shape', Tensor device dtype shape'')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape', Tensor device dtype shape'')
 -&gt; (Tensor device dtype shape', Tensor device dtype shape''))
-&gt; IO (Tensor device dtype shape', Tensor device dtype shape'')
-&gt; (Tensor device dtype shape', Tensor device dtype shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-983"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Bool
-&gt; Bool
-&gt; IO (Tensor device dtype shape', Tensor device dtype shape'')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.symeig_tbb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709905"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709903"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-984"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-985"></span><span>    </span><span id="local-6989586621679709903"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679709903"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709906"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-986"></span><span>
</span><span id="line-987"></span><span class="hs-comment">-- | symeigvalues</span><span>
</span><span id="line-988"></span><span class="hs-comment">--</span><span>
</span><span id="line-989"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- rand :: IO (CPUTensor 'D.Float '[3,2,2])</span><span>
</span><span id="line-990"></span><span class="hs-comment">-- &gt;&gt;&gt; eigenVals = symeigvalues Upper t</span><span>
</span><span id="line-991"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVals</span><span>
</span><span id="line-992"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-993"></span><span class="hs-comment">-- &gt;&gt;&gt; :t eigenVals</span><span>
</span><span id="line-994"></span><span class="hs-comment">-- eigenVals :: Tensor '( 'D.CPU, 0) 'D.Float '[3, 2]</span><span>
</span><span id="line-995"></span><span class="annot"><a href="Torch.Typed.Functional.html#symeigvalues"><span class="hs-identifier hs-type">symeigvalues</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-996"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709901"><span class="annot"><a href="#local-6989586621679709901"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709900"><span class="annot"><a href="#local-6989586621679709900"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709899"><span class="annot"><a href="#local-6989586621679709899"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709898"><span class="annot"><a href="#local-6989586621679709898"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-997"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679709900"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#VectorOfSquare"><span class="hs-identifier hs-type">VectorOfSquare</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709901"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-998"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#SymeigDTypeIsValid"><span class="hs-identifier hs-type">SymeigDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709899"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-999"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1000"></span><span>  </span><span class="hs-comment">-- | upper or lower triagonal</span><span>
</span><span id="line-1001"></span><span>  </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1002"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1003"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709899"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709901"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1004"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709899"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709900"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1005"></span><span id="symeigvalues"><span class="annot"><span class="annottext">symeigvalues :: Tri -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#symeigvalues"><span class="hs-identifier hs-var hs-var">symeigvalues</span></a></span></span><span> </span><span id="local-6989586621679709897"><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709897"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679709896"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709896"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype shape', Tensor device dtype Any)
-&gt; Tensor device dtype shape'
forall a b. (a, b) -&gt; a
</span><span class="hs-identifier hs-var">fst</span></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype shape', Tensor device dtype Any)
forall (shape'' :: [Nat]).
(Tensor device dtype shape', Tensor device dtype shape'')
</span><a href="#local-6989586621679709895"><span class="hs-identifier hs-var">symeig'</span></a></span><span>
</span><span id="line-1006"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1007"></span><span>    </span><span id="local-6989586621679709894"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679709894"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709897"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-1008"></span><span>    </span><span id="local-6989586621679711211"><span class="annot"><a href="#local-6989586621679709895"><span class="hs-identifier hs-type">symeig'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709899"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709900"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709899"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711211"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-1009"></span><span>    </span><span id="local-6989586621679709895"><span class="annot"><span class="annottext">symeig' :: (Tensor device dtype shape', Tensor device dtype shape'')
</span><a href="#local-6989586621679709895"><span class="hs-identifier hs-var hs-var">symeig'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape', Tensor device dtype shape'')
-&gt; (Tensor device dtype shape', Tensor device dtype shape'')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape', Tensor device dtype shape'')
 -&gt; (Tensor device dtype shape', Tensor device dtype shape''))
-&gt; IO (Tensor device dtype shape', Tensor device dtype shape'')
-&gt; (Tensor device dtype shape', Tensor device dtype shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Bool
-&gt; Bool
-&gt; IO (Tensor device dtype shape', Tensor device dtype shape'')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.symeig_tbb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709896"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709894"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-1010"></span><span>
</span><span id="line-1011"></span><span class="hs-keyword">data</span><span> </span><span id="EigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#EigenVectors"><span class="hs-identifier hs-var">EigenVectors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="EnableEigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#EnableEigenVectors"><span class="hs-identifier hs-var">EnableEigenVectors</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="DisableEigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#DisableEigenVectors"><span class="hs-identifier hs-var">DisableEigenVectors</span></a></span></span><span>
</span><span id="line-1012"></span><span>
</span><span id="line-1013"></span><span class="hs-keyword">class</span><span> </span><span id="KnownEigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#KnownEigenVectors"><span class="hs-identifier hs-var">KnownEigenVectors</span></a></span></span><span> </span><span id="local-6989586621679711205"><span class="annot"><a href="#local-6989586621679711205"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1014"></span><span>  </span><span id="enableEigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#enableEigenVectors"><span class="hs-identifier hs-type">enableEigenVectors</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-1015"></span><span>
</span><span id="line-1016"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownEigenVectors"><span class="hs-identifier hs-type">KnownEigenVectors</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#EnableEigenVectors"><span class="hs-identifier hs-type">EnableEigenVectors</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1017"></span><span>  </span><span id="local-6989586621679709890"><span class="annot"><span class="annottext">enableEigenVectors :: Bool
</span><a href="#local-6989586621679709890"><span class="hs-identifier hs-var hs-var hs-var hs-var">enableEigenVectors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-1018"></span><span>
</span><span id="line-1019"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownEigenVectors"><span class="hs-identifier hs-type">KnownEigenVectors</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DisableEigenVectors"><span class="hs-identifier hs-type">DisableEigenVectors</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1020"></span><span>  </span><span id="local-6989586621679709888"><span class="annot"><span class="annottext">enableEigenVectors :: Bool
</span><a href="#local-6989586621679709888"><span class="hs-identifier hs-var hs-var hs-var hs-var">enableEigenVectors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1021"></span><span>
</span><span id="line-1022"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ConditionalEigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalEigenVectors"><span class="hs-identifier hs-var">ConditionalEigenVectors</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709886"><span class="annot"><a href="#local-6989586621679709886"><span class="hs-identifier hs-type">eigenvectors</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#EigenVectors"><span class="hs-identifier hs-type">EigenVectors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709885"><span class="annot"><a href="#local-6989586621679709885"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1023"></span><span>  </span><span id="ConditionalEigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalEigenVectors"><span class="hs-identifier hs-var">ConditionalEigenVectors</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#EnableEigenVectors"><span class="hs-identifier hs-type">EnableEigenVectors</span></a></span><span> </span><span id="local-6989586621679709884"><span class="annot"><a href="#local-6989586621679709884"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709884"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709884"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1024"></span><span>  </span><span id="ConditionalEigenVectors"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalEigenVectors"><span class="hs-identifier hs-var">ConditionalEigenVectors</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DisableEigenVectors"><span class="hs-identifier hs-type">DisableEigenVectors</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">]</span><span>
</span><span id="line-1025"></span><span>
</span><span id="line-1026"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="EigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#EigDTypeIsValid"><span class="hs-identifier hs-var">EigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709882"><span class="annot"><a href="#local-6989586621679709882"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709881"><span class="annot"><a href="#local-6989586621679709881"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1027"></span><span>  </span><span id="EigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#EigDTypeIsValid"><span class="hs-identifier hs-var">EigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709880"><span class="annot"><a href="#local-6989586621679709880"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1028"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709880"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1029"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709880"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1030"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1031"></span><span>  </span><span id="EigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#EigDTypeIsValid"><span class="hs-identifier hs-var">EigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709879"><span class="annot"><a href="#local-6989586621679709879"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709878"><span class="annot"><a href="#local-6989586621679709878"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1032"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709879"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709878"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1033"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709879"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709878"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1034"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1035"></span><span>  </span><span id="EigDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#EigDTypeIsValid"><span class="hs-identifier hs-var">EigDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709877"><span class="annot"><a href="#local-6989586621679709877"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709876"><span class="annot"><a href="#local-6989586621679709876"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709877"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709876"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1036"></span><span>
</span><span id="line-1037"></span><span class="hs-comment">-- | eig</span><span>
</span><span id="line-1038"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- rand :: IO (CPUTensor 'D.Float '[3,3])</span><span>
</span><span id="line-1039"></span><span class="hs-comment">-- &gt;&gt;&gt; (eigenVals,eigenVecs) = eig @EnableEigenVectors t</span><span>
</span><span id="line-1040"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVals</span><span>
</span><span id="line-1041"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1042"></span><span class="hs-comment">-- &gt;&gt;&gt; :t eigenVals</span><span>
</span><span id="line-1043"></span><span class="hs-comment">-- eigenVals :: Tensor '( 'D.CPU, 0) 'D.Float '[3, 2]</span><span>
</span><span id="line-1044"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVecs</span><span>
</span><span id="line-1045"></span><span class="hs-comment">-- (Float,[3,3])</span><span>
</span><span id="line-1046"></span><span class="hs-comment">-- &gt;&gt;&gt; :t eigenVecs</span><span>
</span><span id="line-1047"></span><span class="hs-comment">-- eigenVecs :: Tensor '( 'D.CPU, 0) 'D.Float '[3, 3]</span><span>
</span><span id="line-1048"></span><span class="hs-comment">-- &gt;&gt;&gt; (eigenVals,eigenVecs) = eig @DisableEigenVectors t</span><span>
</span><span id="line-1049"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVals</span><span>
</span><span id="line-1050"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1051"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ eigenVecs</span><span>
</span><span id="line-1052"></span><span class="hs-comment">-- (Float,[0])</span><span>
</span><span id="line-1053"></span><span class="hs-comment">-- &gt;&gt;&gt; :t eigenVecs</span><span>
</span><span id="line-1054"></span><span class="hs-comment">-- eigenVecs :: Tensor '( 'D.CPU, 0) 'D.Float '[0]</span><span>
</span><span id="line-1055"></span><span class="annot"><a href="Torch.Typed.Functional.html#eig"><span class="hs-identifier hs-type">eig</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1056"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709874"><span class="annot"><a href="#local-6989586621679709874"><span class="hs-identifier hs-type">eigenvectors</span></a></span></span><span> </span><span id="local-6989586621679709873"><span class="annot"><a href="#local-6989586621679709873"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709872"><span class="annot"><a href="#local-6989586621679709872"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709871"><span class="annot"><a href="#local-6989586621679709871"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709870"><span class="annot"><a href="#local-6989586621679709870"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1057"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709873"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1058"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownEigenVectors"><span class="hs-identifier hs-type">KnownEigenVectors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709874"><span class="hs-identifier hs-type">eigenvectors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1059"></span><span>    </span><span class="annot"><a href="#local-6989586621679709872"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalEigenVectors"><span class="hs-identifier hs-type">ConditionalEigenVectors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709874"><span class="hs-identifier hs-type">eigenvectors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709873"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1060"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#EigDTypeIsValid"><span class="hs-identifier hs-type">EigDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709870"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709871"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1061"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1062"></span><span>  </span><span class="hs-comment">-- | input matrix</span><span>
</span><span id="line-1063"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709870"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709871"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709873"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709873"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1064"></span><span>  </span><span class="hs-comment">-- | eigenvalues and eigenvectors</span><span>
</span><span id="line-1065"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709870"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709871"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709873"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-1066"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709870"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709871"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709872"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1067"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-1068"></span><span id="eig"><span class="annot"><span class="annottext">eig :: Tensor device dtype '[n, n]
-&gt; (Tensor device dtype '[n, 2], Tensor device dtype shape)
</span><a href="Torch.Typed.Functional.html#eig"><span class="hs-identifier hs-var hs-var">eig</span></a></span></span><span> </span><span id="local-6989586621679709869"><span class="annot"><span class="annottext">Tensor device dtype '[n, n]
</span><a href="#local-6989586621679709869"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1069"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[n, 2], Tensor device dtype shape)
-&gt; (Tensor device dtype '[n, 2], Tensor device dtype shape)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[n, 2], Tensor device dtype shape)
 -&gt; (Tensor device dtype '[n, 2], Tensor device dtype shape))
-&gt; IO (Tensor device dtype '[n, 2], Tensor device dtype shape)
-&gt; (Tensor device dtype '[n, 2], Tensor device dtype shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype '[n, n]
-&gt; Bool
-&gt; IO (Tensor device dtype '[n, 2], Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.eig_tb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[n, n]
</span><a href="#local-6989586621679709869"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownEigenVectors eigenvectors =&gt; Bool
forall k (a :: k). KnownEigenVectors a =&gt; Bool
</span><a href="Torch.Typed.Functional.html#enableEigenVectors"><span class="hs-identifier hs-var">enableEigenVectors</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709874"><span class="hs-identifier hs-type">eigenvectors</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1070"></span><span>
</span><span id="line-1071"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709866"><span class="annot"><a href="#local-6989586621679709866"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709865"><span class="annot"><a href="#local-6989586621679709865"><span class="hs-identifier hs-type">reduced</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ReducedSVD"><span class="hs-identifier hs-type">ReducedSVD</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1072"></span><span>  </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709864"><span class="annot"><a href="#local-6989586621679709864"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#ThinSVD"><span class="hs-identifier hs-type">ThinSVD</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709864"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709864"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1073"></span><span>  </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span id="local-6989586621679709863"><span class="annot"><a href="#local-6989586621679709863"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709862"><span class="annot"><a href="#local-6989586621679709862"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#ThinSVD"><span class="hs-identifier hs-type">ThinSVD</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709863"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709863"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709862"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709863"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709862"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709862"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709863"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709862"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1074"></span><span>  </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span id="local-6989586621679709861"><span class="annot"><a href="#local-6989586621679709861"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709860"><span class="annot"><a href="#local-6989586621679709860"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#FullSVD"><span class="hs-identifier hs-type">FullSVD</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709861"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709861"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709861"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709860"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709860"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709860"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1075"></span><span>  </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span id="local-6989586621679709859"><span class="annot"><a href="#local-6989586621679709859"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709858"><span class="annot"><a href="#local-6989586621679709858"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#ThinSVD"><span class="hs-identifier hs-type">ThinSVD</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709859"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709859"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709859"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709858"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709858"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1076"></span><span>  </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span id="local-6989586621679709857"><span class="annot"><a href="#local-6989586621679709857"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709856"><span class="annot"><a href="#local-6989586621679709856"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709855"><span class="annot"><a href="#local-6989586621679709855"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#ThinSVD"><span class="hs-identifier hs-type">ThinSVD</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709857"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709856"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709856"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709855"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709857"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709856"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709855"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709857"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709855"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709856"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709855"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1077"></span><span>  </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span id="local-6989586621679709854"><span class="annot"><a href="#local-6989586621679709854"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709853"><span class="annot"><a href="#local-6989586621679709853"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709852"><span class="annot"><a href="#local-6989586621679709852"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#FullSVD"><span class="hs-identifier hs-type">FullSVD</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709854"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709853"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709853"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709854"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709853"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709852"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709854"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709852"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709852"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1078"></span><span>  </span><span id="SVDShapes"><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-var">SVDShapes</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;A singular value decomposition can only be computed for 2D matrices for at most one batch dimension.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-1079"></span><span>
</span><span id="line-1080"></span><span class="hs-keyword">data</span><span> </span><span id="ReducedSVD"><span class="annot"><a href="Torch.Typed.Functional.html#ReducedSVD"><span class="hs-identifier hs-var">ReducedSVD</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ThinSVD"><span class="annot"><a href="Torch.Typed.Functional.html#ThinSVD"><span class="hs-identifier hs-var">ThinSVD</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="FullSVD"><span class="annot"><a href="Torch.Typed.Functional.html#FullSVD"><span class="hs-identifier hs-var">FullSVD</span></a></span></span><span>
</span><span id="line-1081"></span><span>
</span><span id="line-1082"></span><span class="hs-keyword">class</span><span> </span><span id="KnownReducedSVD"><span class="annot"><a href="Torch.Typed.Functional.html#KnownReducedSVD"><span class="hs-identifier hs-var">KnownReducedSVD</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679711195"><span class="annot"><a href="#local-6989586621679711195"><span class="hs-identifier hs-type">reduced</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ReducedSVD"><span class="hs-identifier hs-type">ReducedSVD</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1083"></span><span>  </span><span id="reducedSVD"><span class="annot"><a href="Torch.Typed.Functional.html#reducedSVD"><span class="hs-identifier hs-type">reducedSVD</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-1084"></span><span>
</span><span id="line-1085"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReducedSVD"><span class="hs-identifier hs-type">KnownReducedSVD</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ThinSVD"><span class="hs-identifier hs-type">ThinSVD</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1086"></span><span>  </span><span id="local-6989586621679709848"><span class="annot"><span class="annottext">reducedSVD :: Bool
</span><a href="#local-6989586621679709848"><span class="hs-identifier hs-var hs-var hs-var hs-var">reducedSVD</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-1087"></span><span>
</span><span id="line-1088"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReducedSVD"><span class="hs-identifier hs-type">KnownReducedSVD</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#FullSVD"><span class="hs-identifier hs-type">FullSVD</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1089"></span><span>  </span><span id="local-6989586621679709846"><span class="annot"><span class="annottext">reducedSVD :: Bool
</span><a href="#local-6989586621679709846"><span class="hs-identifier hs-var hs-var hs-var hs-var">reducedSVD</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1090"></span><span>
</span><span id="line-1091"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SVDDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SVDDTypeIsValid"><span class="hs-identifier hs-var">SVDDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709844"><span class="annot"><a href="#local-6989586621679709844"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709843"><span class="annot"><a href="#local-6989586621679709843"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1092"></span><span>  </span><span id="SVDDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SVDDTypeIsValid"><span class="hs-identifier hs-var">SVDDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709842"><span class="annot"><a href="#local-6989586621679709842"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1093"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709842"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1094"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709842"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1095"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1096"></span><span>  </span><span id="SVDDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SVDDTypeIsValid"><span class="hs-identifier hs-var">SVDDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709841"><span class="annot"><a href="#local-6989586621679709841"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709840"><span class="annot"><a href="#local-6989586621679709840"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1097"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709841"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709840"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1098"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709841"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709840"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1099"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1100"></span><span>  </span><span id="SVDDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SVDDTypeIsValid"><span class="hs-identifier hs-var">SVDDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709839"><span class="annot"><a href="#local-6989586621679709839"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709838"><span class="annot"><a href="#local-6989586621679709838"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709839"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709838"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1101"></span><span>
</span><span id="line-1102"></span><span class="hs-comment">-- | Singular Value Decomposition</span><span>
</span><span id="line-1103"></span><span class="hs-comment">-- TODO: When `compute_uv` is `False`, backward cannot be performed since `u` and `v` from the forward pass are required for the backward operation. There is no way to encode in the types at this point in time. Thus, only `True` is supported currently.</span><span>
</span><span id="line-1104"></span><span class="hs-comment">--</span><span>
</span><span id="line-1105"></span><span class="hs-comment">-- This function returns a tuple `(u, s, v)`</span><span>
</span><span id="line-1106"></span><span class="hs-comment">-- which is the singular value decomposition of a input real matrix</span><span>
</span><span id="line-1107"></span><span class="hs-comment">-- or batches of real matrices input such that</span><span>
</span><span id="line-1108"></span><span class="hs-comment">-- `input = U&#215;diag(S)&#215;V^T`.</span><span>
</span><span id="line-1109"></span><span class="hs-comment">--</span><span>
</span><span id="line-1110"></span><span class="hs-comment">-- &gt;&gt;&gt; a &lt;- randn :: IO (CPUTensor 'D.Float '[3, 5])</span><span>
</span><span id="line-1111"></span><span class="hs-comment">-- &gt;&gt;&gt; (u, s, v) = svd @'ThinSVD a</span><span>
</span><span id="line-1112"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ u</span><span>
</span><span id="line-1113"></span><span class="hs-comment">-- (Float,[3,3])</span><span>
</span><span id="line-1114"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ s</span><span>
</span><span id="line-1115"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-1116"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ v</span><span>
</span><span id="line-1117"></span><span class="hs-comment">-- (Float,[5,3])</span><span>
</span><span id="line-1118"></span><span class="hs-comment">-- &gt;&gt;&gt; (u, s, v) = svd @'FullSVD a</span><span>
</span><span id="line-1119"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ u</span><span>
</span><span id="line-1120"></span><span class="hs-comment">-- (Float,[3,3])</span><span>
</span><span id="line-1121"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ s</span><span>
</span><span id="line-1122"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-1123"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ v</span><span>
</span><span id="line-1124"></span><span class="hs-comment">-- (Float,[5,5])</span><span>
</span><span id="line-1125"></span><span class="hs-comment">-- &gt;&gt;&gt; a &lt;- randn :: IO (CPUTensor 'D.Float '[5, 3])</span><span>
</span><span id="line-1126"></span><span class="hs-comment">-- &gt;&gt;&gt; (u, s, v) = svd @'ThinSVD a</span><span>
</span><span id="line-1127"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ u</span><span>
</span><span id="line-1128"></span><span class="hs-comment">-- (Float,[5,3])</span><span>
</span><span id="line-1129"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ s</span><span>
</span><span id="line-1130"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-1131"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ v</span><span>
</span><span id="line-1132"></span><span class="hs-comment">-- (Float,[3,3])</span><span>
</span><span id="line-1133"></span><span class="hs-comment">-- &gt;&gt;&gt; (u, s, v) = svd @'FullSVD a</span><span>
</span><span id="line-1134"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ u</span><span>
</span><span id="line-1135"></span><span class="hs-comment">-- (Float,[5,5])</span><span>
</span><span id="line-1136"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ s</span><span>
</span><span id="line-1137"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-1138"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ v</span><span>
</span><span id="line-1139"></span><span class="hs-comment">-- (Float,[3,3])</span><span>
</span><span id="line-1140"></span><span class="annot"><a href="Torch.Typed.Functional.html#svd"><span class="hs-identifier hs-type">svd</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1141"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709836"><span class="annot"><a href="#local-6989586621679709836"><span class="hs-identifier hs-type">reduced</span></a></span></span><span> </span><span id="local-6989586621679709835"><span class="annot"><a href="#local-6989586621679709835"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709834"><span class="annot"><a href="#local-6989586621679709834"><span class="hs-identifier hs-type">shapeU</span></a></span></span><span> </span><span id="local-6989586621679709833"><span class="annot"><a href="#local-6989586621679709833"><span class="hs-identifier hs-type">shapeS</span></a></span></span><span> </span><span id="local-6989586621679709832"><span class="annot"><a href="#local-6989586621679709832"><span class="hs-identifier hs-type">shapeV</span></a></span></span><span> </span><span id="local-6989586621679709831"><span class="annot"><a href="#local-6989586621679709831"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709830"><span class="annot"><a href="#local-6989586621679709830"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1142"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReducedSVD"><span class="hs-identifier hs-type">KnownReducedSVD</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709836"><span class="hs-identifier hs-type">reduced</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1143"></span><span>    </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709834"><span class="hs-identifier hs-type">shapeU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709833"><span class="hs-identifier hs-type">shapeS</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709832"><span class="hs-identifier hs-type">shapeV</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SVDShapes"><span class="hs-identifier hs-type">SVDShapes</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709835"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709836"><span class="hs-identifier hs-type">reduced</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1144"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#SVDDTypeIsValid"><span class="hs-identifier hs-type">SVDDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709830"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709831"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1145"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1146"></span><span>  </span><span class="hs-comment">-- | (batched) input real matrix</span><span>
</span><span id="line-1147"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709830"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709831"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709835"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1148"></span><span>  </span><span class="hs-comment">-- | (batched) output tuple of `u`, `s`, and `v`</span><span>
</span><span id="line-1149"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709830"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709831"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709834"><span class="hs-identifier hs-type">shapeU</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1150"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709830"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709831"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709833"><span class="hs-identifier hs-type">shapeS</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1151"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709830"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709831"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709832"><span class="hs-identifier hs-type">shapeV</span></a></span><span>
</span><span id="line-1152"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-1153"></span><span id="svd"><span class="annot"><span class="annottext">svd :: Tensor device dtype shape
-&gt; (Tensor device dtype shapeU, Tensor device dtype shapeS,
    Tensor device dtype shapeV)
</span><a href="Torch.Typed.Functional.html#svd"><span class="hs-identifier hs-var hs-var">svd</span></a></span></span><span> </span><span id="local-6989586621679709829"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709829"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1154"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype shapeU, Tensor device dtype shapeS,
   Tensor device dtype shapeV)
-&gt; (Tensor device dtype shapeU, Tensor device dtype shapeS,
    Tensor device dtype shapeV)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype shapeU, Tensor device dtype shapeS,
    Tensor device dtype shapeV)
 -&gt; (Tensor device dtype shapeU, Tensor device dtype shapeS,
     Tensor device dtype shapeV))
-&gt; IO
     (Tensor device dtype shapeU, Tensor device dtype shapeS,
      Tensor device dtype shapeV)
-&gt; (Tensor device dtype shapeU, Tensor device dtype shapeS,
    Tensor device dtype shapeV)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Bool
-&gt; Bool
-&gt; IO
     (Tensor device dtype shapeU, Tensor device dtype shapeS,
      Tensor device dtype shapeV)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.svd_tbb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709829"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReducedSVD reduced =&gt; Bool
forall (reduced :: ReducedSVD). KnownReducedSVD reduced =&gt; Bool
</span><a href="Torch.Typed.Functional.html#reducedSVD"><span class="hs-identifier hs-var">reducedSVD</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709836"><span class="hs-identifier hs-type">reduced</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-1155"></span><span>
</span><span id="line-1156"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="CholeskyDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#CholeskyDTypeIsValid"><span class="hs-identifier hs-var">CholeskyDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709826"><span class="annot"><a href="#local-6989586621679709826"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709825"><span class="annot"><a href="#local-6989586621679709825"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1157"></span><span>  </span><span id="CholeskyDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#CholeskyDTypeIsValid"><span class="hs-identifier hs-var">CholeskyDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709824"><span class="annot"><a href="#local-6989586621679709824"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1158"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709824"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1159"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709824"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1160"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1161"></span><span>  </span><span id="CholeskyDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#CholeskyDTypeIsValid"><span class="hs-identifier hs-var">CholeskyDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709823"><span class="annot"><a href="#local-6989586621679709823"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709822"><span class="annot"><a href="#local-6989586621679709822"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1162"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709823"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709822"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1163"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709823"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709822"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1164"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1165"></span><span>  </span><span id="CholeskyDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#CholeskyDTypeIsValid"><span class="hs-identifier hs-var">CholeskyDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709821"><span class="annot"><a href="#local-6989586621679709821"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709820"><span class="annot"><a href="#local-6989586621679709820"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709821"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709820"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1166"></span><span>
</span><span id="line-1167"></span><span class="hs-comment">-- | cholesky</span><span>
</span><span id="line-1168"></span><span class="hs-comment">-- TODO: cholesky can throw if the input is not positive-definite.</span><span>
</span><span id="line-1169"></span><span class="hs-comment">-- Computes the Cholesky decomposition of a symmetric positive-definite matrix.</span><span>
</span><span id="line-1170"></span><span class="hs-comment">-- The operation supports batching.</span><span>
</span><span id="line-1171"></span><span class="hs-comment">--</span><span>
</span><span id="line-1172"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- rand :: IO (CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-1173"></span><span class="hs-comment">-- &gt;&gt;&gt; u = cholesky Upper (t `matmul` transpose2D t)</span><span>
</span><span id="line-1174"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ u</span><span>
</span><span id="line-1175"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-1176"></span><span class="hs-comment">-- &gt;&gt;&gt; :t u</span><span>
</span><span id="line-1177"></span><span class="hs-comment">-- u :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 2]</span><span>
</span><span id="line-1178"></span><span class="annot"><a href="Torch.Typed.Functional.html#cholesky"><span class="hs-identifier hs-type">cholesky</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1179"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709818"><span class="annot"><a href="#local-6989586621679709818"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709817"><span class="annot"><a href="#local-6989586621679709817"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709816"><span class="annot"><a href="#local-6989586621679709816"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709815"><span class="annot"><a href="#local-6989586621679709815"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1180"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679709817"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-type">Square</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709818"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1181"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#CholeskyDTypeIsValid"><span class="hs-identifier hs-type">CholeskyDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709815"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709816"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1182"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1183"></span><span>  </span><span class="hs-comment">-- | indicate whether to return an upper or lower triangular matrix.</span><span>
</span><span id="line-1184"></span><span>  </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1185"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1186"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709815"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709816"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709818"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1187"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1188"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709815"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709816"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709817"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1189"></span><span id="cholesky"><span class="annot"><span class="annottext">cholesky :: Tri -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#cholesky"><span class="hs-identifier hs-var hs-var">cholesky</span></a></span></span><span> </span><span id="local-6989586621679709814"><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709814"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679709813"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709813"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Bool
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.cholesky_tb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709813"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709811"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-1190"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1191"></span><span>    </span><span id="local-6989586621679709811"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679709811"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709814"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-1192"></span><span>
</span><span id="line-1193"></span><span class="hs-comment">-- | choleskyInverse</span><span>
</span><span id="line-1194"></span><span class="hs-comment">-- Computes the inverse of a symmetric positive-definite matrix</span><span>
</span><span id="line-1195"></span><span class="hs-comment">-- using its Cholesky factor, returned, e.g., by `cholesky`.</span><span>
</span><span id="line-1196"></span><span class="hs-comment">-- Unlike `cholesky`, this operation does not support batching.</span><span>
</span><span id="line-1197"></span><span class="hs-comment">-- The inverse is computed using the LAPACK routine `?potri`.</span><span>
</span><span id="line-1198"></span><span class="hs-comment">--</span><span>
</span><span id="line-1199"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- rand :: IO (CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-1200"></span><span class="hs-comment">-- &gt;&gt;&gt; tri = Upper</span><span>
</span><span id="line-1201"></span><span class="hs-comment">-- &gt;&gt;&gt; u = cholesky tri (t `matmul` transpose2D t)</span><span>
</span><span id="line-1202"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ choleskyInverse tri u</span><span>
</span><span id="line-1203"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-1204"></span><span class="annot"><a href="Torch.Typed.Functional.html#choleskyInverse"><span class="hs-identifier hs-type">choleskyInverse</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1205"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709809"><span class="annot"><a href="#local-6989586621679709809"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709808"><span class="annot"><a href="#local-6989586621679709808"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709807"><span class="annot"><a href="#local-6989586621679709807"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1206"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679709809"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1207"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#CholeskyDTypeIsValid"><span class="hs-identifier hs-type">CholeskyDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709807"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709808"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1208"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1209"></span><span>  </span><span class="hs-comment">-- | decides whether the upper or the lower triangular part of the input tensor is used</span><span>
</span><span id="line-1210"></span><span>  </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1211"></span><span>  </span><span class="hs-comment">-- | the input 2-D tensor `u`, an upper or lower triangular Cholesky factor</span><span>
</span><span id="line-1212"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709807"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709808"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709809"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709809"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1213"></span><span>  </span><span class="hs-comment">-- | the output 2-D tensor</span><span>
</span><span id="line-1214"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709807"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709808"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709809"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709809"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1215"></span><span id="choleskyInverse"><span class="annot"><span class="annottext">choleskyInverse :: Tri -&gt; Tensor device dtype '[n, n] -&gt; Tensor device dtype '[n, n]
</span><a href="Torch.Typed.Functional.html#choleskyInverse"><span class="hs-identifier hs-var hs-var">choleskyInverse</span></a></span></span><span> </span><span id="local-6989586621679709805"><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709805"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679709804"><span class="annot"><span class="annottext">Tensor device dtype '[n, n]
</span><a href="#local-6989586621679709804"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1216"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[n, n]) -&gt; Tensor device dtype '[n, n]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[n, n]) -&gt; Tensor device dtype '[n, n])
-&gt; IO (Tensor device dtype '[n, n]) -&gt; Tensor device dtype '[n, n]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1217"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[n, n]
-&gt; Bool
-&gt; IO (Tensor device dtype '[n, n])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.cholesky_inverse_tb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[n, n]
</span><a href="#local-6989586621679709804"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709802"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-1218"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1219"></span><span>    </span><span id="local-6989586621679709802"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679709802"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709805"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-1220"></span><span>
</span><span id="line-1221"></span><span class="hs-comment">-- | choleskySolve</span><span>
</span><span id="line-1222"></span><span class="hs-comment">-- Solves the system of linear equations represented by `a c = b`</span><span>
</span><span id="line-1223"></span><span class="hs-comment">-- using the Cholesky factor matrix `u` of `a` (returned, e.g., by `cholesky`),</span><span>
</span><span id="line-1224"></span><span class="hs-comment">-- where `a` is a positive semidefinite matrix.</span><span>
</span><span id="line-1225"></span><span class="hs-comment">-- The operation supports batching.</span><span>
</span><span id="line-1226"></span><span class="hs-comment">--</span><span>
</span><span id="line-1227"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- rand :: IO (CPUTensor 'D.Float '[3,3])</span><span>
</span><span id="line-1228"></span><span class="hs-comment">-- &gt;&gt;&gt; a = t `matmul` transpose2D t</span><span>
</span><span id="line-1229"></span><span class="hs-comment">-- &gt;&gt;&gt; b &lt;- rand :: IO (CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1230"></span><span class="hs-comment">-- &gt;&gt;&gt; tri = Upper</span><span>
</span><span id="line-1231"></span><span class="hs-comment">-- &gt;&gt;&gt; u = cholesky tri a</span><span>
</span><span id="line-1232"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ choleskySolve tri b u</span><span>
</span><span id="line-1233"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1234"></span><span class="annot"><a href="Torch.Typed.Functional.html#choleskySolve"><span class="hs-identifier hs-type">choleskySolve</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1235"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709800"><span class="annot"><a href="#local-6989586621679709800"><span class="hs-identifier hs-type">m_k</span></a></span></span><span> </span><span id="local-6989586621679709799"><span class="annot"><a href="#local-6989586621679709799"><span class="hs-identifier hs-type">m_m</span></a></span></span><span> </span><span id="local-6989586621679709798"><span class="annot"><a href="#local-6989586621679709798"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709797"><span class="annot"><a href="#local-6989586621679709797"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1236"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-type">Square</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709799"><span class="hs-identifier hs-type">m_m</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679709799"><span class="hs-identifier hs-type">m_m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1237"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-type">FstSquareDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709799"><span class="hs-identifier hs-type">m_m</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-type">FstSquareDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709800"><span class="hs-identifier hs-type">m_k</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1238"></span><span>    </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-type">FstSquareDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709799"><span class="hs-identifier hs-type">m_m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1239"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#CholeskyDTypeIsValid"><span class="hs-identifier hs-type">CholeskyDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709797"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709798"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1240"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1241"></span><span>  </span><span class="hs-comment">-- | decides whether the upper or the lower triangular part of the input tensor `u` is used</span><span>
</span><span id="line-1242"></span><span>  </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1243"></span><span>  </span><span class="hs-comment">-- | the (batched) RHS tensor `b`</span><span>
</span><span id="line-1244"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709797"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709798"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709800"><span class="hs-identifier hs-type">m_k</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1245"></span><span>  </span><span class="hs-comment">-- | the (batched) input 2-D tensor `u`, an upper or lower triangular Cholesky factor</span><span>
</span><span id="line-1246"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709797"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709798"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709799"><span class="hs-identifier hs-type">m_m</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1247"></span><span>  </span><span class="hs-comment">-- | the (batched) output 2-D tensor</span><span>
</span><span id="line-1248"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709797"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709798"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709800"><span class="hs-identifier hs-type">m_k</span></a></span><span>
</span><span id="line-1249"></span><span id="choleskySolve"><span class="annot"><span class="annottext">choleskySolve :: Tri
-&gt; Tensor device dtype m_k
-&gt; Tensor device dtype m_m
-&gt; Tensor device dtype m_k
</span><a href="Torch.Typed.Functional.html#choleskySolve"><span class="hs-identifier hs-var hs-var">choleskySolve</span></a></span></span><span> </span><span id="local-6989586621679709796"><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709796"><span class="hs-identifier hs-var">upper</span></a></span></span><span> </span><span id="local-6989586621679709795"><span class="annot"><span class="annottext">Tensor device dtype m_k
</span><a href="#local-6989586621679709795"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span id="local-6989586621679709794"><span class="annot"><span class="annottext">Tensor device dtype m_m
</span><a href="#local-6989586621679709794"><span class="hs-identifier hs-var">u</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1250"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype m_k) -&gt; Tensor device dtype m_k
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype m_k) -&gt; Tensor device dtype m_k)
-&gt; IO (Tensor device dtype m_k) -&gt; Tensor device dtype m_k
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1251"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype m_k
-&gt; Tensor device dtype m_m
-&gt; Bool
-&gt; IO (Tensor device dtype m_k)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.cholesky_solve_ttb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype m_k
</span><a href="#local-6989586621679709795"><span class="hs-identifier hs-var">b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype m_m
</span><a href="#local-6989586621679709794"><span class="hs-identifier hs-var">u</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709792"><span class="hs-identifier hs-var">boolUpper</span></a></span><span>
</span><span id="line-1252"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1253"></span><span>    </span><span id="local-6989586621679709792"><span class="annot"><span class="annottext">boolUpper :: Bool
</span><a href="#local-6989586621679709792"><span class="hs-identifier hs-var hs-var">boolUpper</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709796"><span class="hs-identifier hs-var">upper</span></a></span><span>
</span><span id="line-1254"></span><span>
</span><span id="line-1255"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SolveDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SolveDTypeIsValid"><span class="hs-identifier hs-var">SolveDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709790"><span class="annot"><a href="#local-6989586621679709790"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709789"><span class="annot"><a href="#local-6989586621679709789"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1256"></span><span>  </span><span id="SolveDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SolveDTypeIsValid"><span class="hs-identifier hs-var">SolveDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709788"><span class="annot"><a href="#local-6989586621679709788"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1257"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709788"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1258"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709788"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1259"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1260"></span><span>  </span><span id="SolveDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SolveDTypeIsValid"><span class="hs-identifier hs-var">SolveDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709787"><span class="annot"><a href="#local-6989586621679709787"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709786"><span class="annot"><a href="#local-6989586621679709786"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1261"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709787"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709786"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1262"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709787"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709786"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1263"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1264"></span><span>  </span><span id="SolveDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#SolveDTypeIsValid"><span class="hs-identifier hs-var">SolveDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709785"><span class="annot"><a href="#local-6989586621679709785"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709784"><span class="annot"><a href="#local-6989586621679709784"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709785"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709784"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1265"></span><span>
</span><span id="line-1266"></span><span class="hs-comment">-- | solve</span><span>
</span><span id="line-1267"></span><span class="hs-comment">-- Solves the system of linear equations represented by `a c = b` and also returns the LU decomposition of `a`.</span><span>
</span><span id="line-1268"></span><span class="hs-comment">-- `a` has to be a positive semidefinite matrix.</span><span>
</span><span id="line-1269"></span><span class="hs-comment">-- The operation supports batching.</span><span>
</span><span id="line-1270"></span><span class="hs-comment">--</span><span>
</span><span id="line-1271"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- rand :: IO (CPUTensor 'D.Float '[10,10])</span><span>
</span><span id="line-1272"></span><span class="hs-comment">-- &gt;&gt;&gt; a = t `matmul` transpose2D t</span><span>
</span><span id="line-1273"></span><span class="hs-comment">-- &gt;&gt;&gt; b &lt;- rand :: IO (CPUTensor 'D.Float '[10,3])</span><span>
</span><span id="line-1274"></span><span class="hs-comment">-- &gt;&gt;&gt; (c,lu) = solve b a</span><span>
</span><span id="line-1275"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ c</span><span>
</span><span id="line-1276"></span><span class="hs-comment">-- (Float,[10,3])</span><span>
</span><span id="line-1277"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ lu</span><span>
</span><span id="line-1278"></span><span class="hs-comment">-- (Float,[10,10])</span><span>
</span><span id="line-1279"></span><span class="hs-comment">-- &gt;&gt;&gt; :t c</span><span>
</span><span id="line-1280"></span><span class="hs-comment">-- c :: Tensor '( 'D.CPU, 0) 'D.Float '[10, 3]</span><span>
</span><span id="line-1281"></span><span class="hs-comment">-- &gt;&gt;&gt; :t lu</span><span>
</span><span id="line-1282"></span><span class="hs-comment">-- lu :: Tensor '( 'D.CPU, 0) 'D.Float '[10, 10]</span><span>
</span><span id="line-1283"></span><span class="annot"><a href="Torch.Typed.Functional.html#solve"><span class="hs-identifier hs-type">solve</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1284"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709782"><span class="annot"><a href="#local-6989586621679709782"><span class="hs-identifier hs-type">m_k</span></a></span></span><span> </span><span id="local-6989586621679709781"><span class="annot"><a href="#local-6989586621679709781"><span class="hs-identifier hs-type">m_m</span></a></span></span><span> </span><span id="local-6989586621679709780"><span class="annot"><a href="#local-6989586621679709780"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709779"><span class="annot"><a href="#local-6989586621679709779"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1285"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-type">Square</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709781"><span class="hs-identifier hs-type">m_m</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679709781"><span class="hs-identifier hs-type">m_m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1286"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-type">FstSquareDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709781"><span class="hs-identifier hs-type">m_m</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-type">FstSquareDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709782"><span class="hs-identifier hs-type">m_k</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1287"></span><span>    </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#FstSquareDim"><span class="hs-identifier hs-type">FstSquareDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709781"><span class="hs-identifier hs-type">m_m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1288"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#SolveDTypeIsValid"><span class="hs-identifier hs-type">SolveDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709779"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709780"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1289"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1290"></span><span>  </span><span class="hs-comment">-- | the (batched) RHS tensor `b`</span><span>
</span><span id="line-1291"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709779"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709780"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709782"><span class="hs-identifier hs-type">m_k</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1292"></span><span>  </span><span class="hs-comment">-- | the (batched) positive semidefinite matrix `a`</span><span>
</span><span id="line-1293"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709779"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709780"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709781"><span class="hs-identifier hs-type">m_m</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1294"></span><span>  </span><span class="hs-comment">-- | the (batched) outputs c and lu</span><span>
</span><span id="line-1295"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709779"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709780"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709782"><span class="hs-identifier hs-type">m_k</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1296"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709779"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709780"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709781"><span class="hs-identifier hs-type">m_m</span></a></span><span>
</span><span id="line-1297"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-1298"></span><span id="solve"><span class="annot"><span class="annottext">solve :: Tensor device dtype m_k
-&gt; Tensor device dtype m_m
-&gt; (Tensor device dtype m_k, Tensor device dtype m_m)
</span><a href="Torch.Typed.Functional.html#solve"><span class="hs-identifier hs-var hs-var">solve</span></a></span></span><span> </span><span id="local-6989586621679709778"><span class="annot"><span class="annottext">Tensor device dtype m_k
</span><a href="#local-6989586621679709778"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span id="local-6989586621679709777"><span class="annot"><span class="annottext">Tensor device dtype m_m
</span><a href="#local-6989586621679709777"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype m_k, Tensor device dtype m_m)
-&gt; (Tensor device dtype m_k, Tensor device dtype m_m)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype m_k, Tensor device dtype m_m)
 -&gt; (Tensor device dtype m_k, Tensor device dtype m_m))
-&gt; IO (Tensor device dtype m_k, Tensor device dtype m_m)
-&gt; (Tensor device dtype m_k, Tensor device dtype m_m)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype m_k
-&gt; Tensor device dtype m_m
-&gt; IO (Tensor device dtype m_k, Tensor device dtype m_m)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.solve_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype m_k
</span><a href="#local-6989586621679709778"><span class="hs-identifier hs-var">b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype m_m
</span><a href="#local-6989586621679709777"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-1299"></span><span>
</span><span id="line-1300"></span><span class="hs-comment">-- | geqrf</span><span>
</span><span id="line-1301"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1302"></span><span class="hs-comment">-- `geqrf` computes a QR decomposition of the given `input` matrix,</span><span>
</span><span id="line-1303"></span><span class="hs-comment">-- but without constructing `Q` and `R` as explicit separate matrices.</span><span>
</span><span id="line-1304"></span><span class="hs-comment">-- Rather, this function directly calls the underlying LAPACK function `?geqrf`</span><span>
</span><span id="line-1305"></span><span class="hs-comment">-- which produces a tuple `(a, tau)` of intermediate results as defined in</span><span>
</span><span id="line-1306"></span><span class="hs-comment">-- the LAPACK documentation for `?geqrf`.</span><span>
</span><span id="line-1307"></span><span class="hs-comment">--</span><span>
</span><span id="line-1308"></span><span class="hs-comment">-- You can use `orgqr` on `(a, tau)` to compute the real orthogonal matrix `Q`,</span><span>
</span><span id="line-1309"></span><span class="hs-comment">-- but in general you may just want to use `qr` instead.</span><span>
</span><span id="line-1310"></span><span class="hs-comment">--</span><span>
</span><span id="line-1311"></span><span class="hs-comment">-- See the LAPACK documentation for `?geqrf` for further details,</span><span>
</span><span id="line-1312"></span><span class="hs-comment">-- https://software.intel.com/en-us/node/521004.</span><span>
</span><span id="line-1313"></span><span class="hs-comment">--</span><span>
</span><span id="line-1314"></span><span class="hs-comment">-- &gt;&gt;&gt; (a, tau) = geqrf (ones :: CPUTensor 'D.Float '[3,4])</span><span>
</span><span id="line-1315"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ a</span><span>
</span><span id="line-1316"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-1317"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ tau</span><span>
</span><span id="line-1318"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-1319"></span><span class="hs-comment">-- &gt;&gt;&gt; (a, tau) = geqrf (ones :: CPUTensor 'D.Float '[4,3])</span><span>
</span><span id="line-1320"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ a</span><span>
</span><span id="line-1321"></span><span class="hs-comment">-- (Float,[4,3])</span><span>
</span><span id="line-1322"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ tau</span><span>
</span><span id="line-1323"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-1324"></span><span class="annot"><a href="Torch.Typed.Functional.html#geqrf"><span class="hs-identifier hs-type">geqrf</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1325"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709774"><span class="annot"><a href="#local-6989586621679709774"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679709773"><span class="annot"><a href="#local-6989586621679709773"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709772"><span class="annot"><a href="#local-6989586621679709772"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709771"><span class="annot"><a href="#local-6989586621679709771"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1326"></span><span>  </span><span class="hs-comment">-- | input matrix</span><span>
</span><span id="line-1327"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709771"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709772"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709774"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709773"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1328"></span><span>  </span><span class="hs-comment">-- | tuple `(a, tau)` of output matrices</span><span>
</span><span id="line-1329"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709771"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709772"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709774"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709773"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-1330"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709771"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709772"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709774"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709773"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1331"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-1332"></span><span id="geqrf"><span class="annot"><span class="annottext">geqrf :: Tensor device dtype '[m, n]
-&gt; (Tensor device dtype '[m, n], Tensor device dtype '[Min m n])
</span><a href="Torch.Typed.Functional.html#geqrf"><span class="hs-identifier hs-var hs-var">geqrf</span></a></span></span><span> </span><span id="local-6989586621679709770"><span class="annot"><span class="annottext">Tensor device dtype '[m, n]
</span><a href="#local-6989586621679709770"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[m, n], Tensor device dtype '[Min m n])
-&gt; (Tensor device dtype '[m, n], Tensor device dtype '[Min m n])
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[m, n], Tensor device dtype '[Min m n])
 -&gt; (Tensor device dtype '[m, n], Tensor device dtype '[Min m n]))
-&gt; IO (Tensor device dtype '[m, n], Tensor device dtype '[Min m n])
-&gt; (Tensor device dtype '[m, n], Tensor device dtype '[Min m n])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype '[m, n]
-&gt; IO (Tensor device dtype '[m, n], Tensor device dtype '[Min m n])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.geqrf_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[m, n]
</span><a href="#local-6989586621679709770"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1333"></span><span>
</span><span id="line-1334"></span><span class="hs-comment">-- | orgqr</span><span>
</span><span id="line-1335"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1336"></span><span class="hs-comment">-- Computes the orthogonal matrix `Q` of a QR factorization</span><span>
</span><span id="line-1337"></span><span class="hs-comment">-- from the `(a, tau)` tuple returned by `geqrf`.</span><span>
</span><span id="line-1338"></span><span class="hs-comment">--</span><span>
</span><span id="line-1339"></span><span class="hs-comment">-- This directly calls the underlying LAPACK function `?orgqr`.</span><span>
</span><span id="line-1340"></span><span class="hs-comment">-- See the LAPACK documentation for `?orgqr` for further details,</span><span>
</span><span id="line-1341"></span><span class="hs-comment">-- https://software.intel.com/en-us/mkl-developer-reference-c-orgqr.</span><span>
</span><span id="line-1342"></span><span class="hs-comment">--</span><span>
</span><span id="line-1343"></span><span class="hs-comment">-- When libtorch-1.7, this function behavior is changed.</span><span>
</span><span id="line-1344"></span><span class="hs-comment">-- First dimention should be greater than second dimention.</span><span>
</span><span id="line-1345"></span><span class="hs-comment">--</span><span>
</span><span id="line-1346"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ orgqr (ones :: CPUTensor 'D.Float '[4,3]) (ones :: CPUTensor 'D.Float '[3])</span><span>
</span><span id="line-1347"></span><span class="hs-comment">-- (Float,[4,3])</span><span>
</span><span id="line-1348"></span><span class="annot"><a href="Torch.Typed.Functional.html#orgqr"><span class="hs-identifier hs-type">orgqr</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1349"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709767"><span class="annot"><a href="#local-6989586621679709767"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679709766"><span class="annot"><a href="#local-6989586621679709766"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709765"><span class="annot"><a href="#local-6989586621679709765"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709764"><span class="annot"><a href="#local-6989586621679709764"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1350"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709766"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1351"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709767"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1352"></span><span>    </span><span class="annot"><a href="#local-6989586621679709766"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679709767"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1353"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1354"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709764"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709765"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709767"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709766"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1355"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709764"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709765"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709766"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1356"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709764"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709765"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709767"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709766"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1357"></span><span id="orgqr"><span class="annot"><span class="annottext">orgqr :: Tensor device dtype '[m, n]
-&gt; Tensor device dtype '[n] -&gt; Tensor device dtype '[m, n]
</span><a href="Torch.Typed.Functional.html#orgqr"><span class="hs-identifier hs-var hs-var">orgqr</span></a></span></span><span> </span><span id="local-6989586621679709763"><span class="annot"><span class="annottext">Tensor device dtype '[m, n]
</span><a href="#local-6989586621679709763"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679709762"><span class="annot"><span class="annottext">Tensor device dtype '[n]
</span><a href="#local-6989586621679709762"><span class="hs-identifier hs-var">tau</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[m, n]) -&gt; Tensor device dtype '[m, n]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[m, n]) -&gt; Tensor device dtype '[m, n])
-&gt; IO (Tensor device dtype '[m, n]) -&gt; Tensor device dtype '[m, n]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[m, n]
-&gt; Tensor device dtype '[n]
-&gt; IO (Tensor device dtype '[m, n])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.orgqr_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[m, n]
</span><a href="#local-6989586621679709763"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[n]
</span><a href="#local-6989586621679709762"><span class="hs-identifier hs-var">tau</span></a></span><span>
</span><span id="line-1358"></span><span>
</span><span id="line-1359"></span><span class="hs-comment">-- | sign</span><span>
</span><span id="line-1360"></span><span class="hs-comment">-- works for all dtypes</span><span>
</span><span id="line-1361"></span><span class="hs-comment">--</span><span>
</span><span id="line-1362"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ sign (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1363"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1364"></span><span class="annot"><a href="Torch.Typed.Functional.html#sign"><span class="hs-identifier hs-type">sign</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1365"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709759"><span class="annot"><a href="#local-6989586621679709759"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709758"><span class="annot"><a href="#local-6989586621679709758"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709757"><span class="annot"><a href="#local-6989586621679709757"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1366"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1367"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709757"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709758"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709759"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1368"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1369"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709757"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709758"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709759"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1370"></span><span id="sign"><span class="annot"><span class="annottext">sign :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#sign"><span class="hs-identifier hs-var hs-var">sign</span></a></span></span><span> </span><span id="local-6989586621679709756"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709756"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.sign_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709756"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1371"></span><span>
</span><span id="line-1372"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SetValue"><span class="annot"><a href="Torch.Typed.Functional.html#SetValue"><span class="hs-identifier hs-var">SetValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709753"><span class="annot"><a href="#local-6989586621679709753"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709752"><span class="annot"><a href="#local-6989586621679709752"><span class="hs-identifier hs-type">i</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709751"><span class="annot"><a href="#local-6989586621679709751"><span class="hs-identifier hs-type">j</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1373"></span><span>  </span><span id="SetValue"><span class="annot"><a href="Torch.Typed.Functional.html#SetValue"><span class="hs-identifier hs-var">SetValue</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-1374"></span><span>  </span><span id="SetValue"><span class="annot"><a href="Torch.Typed.Functional.html#SetValue"><span class="hs-identifier hs-var">SetValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709750"><span class="annot"><a href="#local-6989586621679709750"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709749"><span class="annot"><a href="#local-6989586621679709749"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span id="local-6989586621679709748"><span class="annot"><a href="#local-6989586621679709748"><span class="hs-identifier hs-type hs-type">j</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709748"><span class="hs-identifier hs-type">j</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679709749"><span class="hs-identifier hs-type">xs</span></a></span><span>
</span><span id="line-1375"></span><span>  </span><span id="SetValue"><span class="annot"><a href="Torch.Typed.Functional.html#SetValue"><span class="hs-identifier hs-var">SetValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709747"><span class="annot"><a href="#local-6989586621679709747"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709746"><span class="annot"><a href="#local-6989586621679709746"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709745"><span class="annot"><a href="#local-6989586621679709745"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span id="local-6989586621679709744"><span class="annot"><a href="#local-6989586621679709744"><span class="hs-identifier hs-type hs-type">j</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709747"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SetValue"><span class="hs-identifier hs-type">SetValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709746"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709745"><span class="hs-identifier hs-type">i</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709744"><span class="hs-identifier hs-type">j</span></a></span><span>
</span><span id="line-1376"></span><span>
</span><span id="line-1377"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="GetValue"><span class="annot"><a href="Torch.Typed.Functional.html#GetValue"><span class="hs-identifier hs-var">GetValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709742"><span class="annot"><a href="#local-6989586621679709742"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709741"><span class="annot"><a href="#local-6989586621679709741"><span class="hs-identifier hs-type">i</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1378"></span><span>  </span><span id="GetValue"><span class="annot"><a href="Torch.Typed.Functional.html#GetValue"><span class="hs-identifier hs-var">GetValue</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Can not find a element in the list.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-1379"></span><span>  </span><span id="GetValue"><span class="annot"><a href="Torch.Typed.Functional.html#GetValue"><span class="hs-identifier hs-var">GetValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709740"><span class="annot"><a href="#local-6989586621679709740"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709739"><span class="annot"><a href="#local-6989586621679709739"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709740"><span class="hs-identifier hs-type">x</span></a></span><span>
</span><span id="line-1380"></span><span>  </span><span id="GetValue"><span class="annot"><a href="Torch.Typed.Functional.html#GetValue"><span class="hs-identifier hs-var">GetValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709738"><span class="annot"><a href="#local-6989586621679709738"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709737"><span class="annot"><a href="#local-6989586621679709737"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709736"><span class="annot"><a href="#local-6989586621679709736"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GetValue"><span class="hs-identifier hs-type">GetValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709737"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709736"><span class="hs-identifier hs-type">i</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-1381"></span><span>
</span><span id="line-1382"></span><span class="hs-comment">-- | Transpose</span><span>
</span><span id="line-1383"></span><span class="hs-comment">--</span><span>
</span><span id="line-1384"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Transpose '[3,2] 0 1</span><span>
</span><span id="line-1385"></span><span class="hs-comment">-- Transpose '[3,2] 0 1 :: [Nat]</span><span>
</span><span id="line-1386"></span><span class="hs-comment">-- = '[2, 3]</span><span>
</span><span id="line-1387"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Transpose '[3,2,1] 1 2</span><span>
</span><span id="line-1388"></span><span class="hs-comment">-- Transpose '[3,2,1] 1 2 :: [Nat]</span><span>
</span><span id="line-1389"></span><span class="hs-comment">-- = '[3, 1, 2]</span><span>
</span><span id="line-1390"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="Transpose"><span class="annot"><a href="Torch.Typed.Functional.html#Transpose"><span class="hs-identifier hs-var">Transpose</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709735"><span class="annot"><a href="#local-6989586621679709735"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709734"><span class="annot"><a href="#local-6989586621679709734"><span class="hs-identifier hs-type">dim0</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709733"><span class="annot"><a href="#local-6989586621679709733"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1391"></span><span>  </span><span id="Transpose"><span class="annot"><a href="Torch.Typed.Functional.html#Transpose"><span class="hs-identifier hs-var">Transpose</span></a></span></span><span> </span><span id="local-6989586621679709732"><span class="annot"><a href="#local-6989586621679709732"><span class="hs-identifier hs-type hs-type">s</span></a></span></span><span> </span><span id="local-6989586621679709731"><span class="annot"><a href="#local-6989586621679709731"><span class="hs-identifier hs-type hs-type">d0</span></a></span></span><span> </span><span id="local-6989586621679709730"><span class="annot"><a href="#local-6989586621679709730"><span class="hs-identifier hs-type hs-type">d1</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#SetValue"><span class="hs-identifier hs-type">SetValue</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#SetValue"><span class="hs-identifier hs-type">SetValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709732"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709731"><span class="hs-identifier hs-type">d0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#GetValue"><span class="hs-identifier hs-type">GetValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709732"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709730"><span class="hs-identifier hs-type">d1</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709730"><span class="hs-identifier hs-type">d1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#GetValue"><span class="hs-identifier hs-type">GetValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709732"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709731"><span class="hs-identifier hs-type">d0</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1392"></span><span>
</span><span id="line-1393"></span><span class="hs-comment">-- | transpose</span><span>
</span><span id="line-1394"></span><span class="hs-comment">-- See &quot;../../../../deps/pytorch/aten/src/ATen/native/TensorShape.cpp&quot;.</span><span>
</span><span id="line-1395"></span><span class="hs-comment">--</span><span>
</span><span id="line-1396"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ transpose @0 @1 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1397"></span><span class="hs-comment">-- (Float,[2,3])</span><span>
</span><span id="line-1398"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ transpose @0 @1 (ones :: CPUTensor 'D.Float '[3,2,1])</span><span>
</span><span id="line-1399"></span><span class="hs-comment">-- (Float,[2,3,1])</span><span>
</span><span id="line-1400"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ transpose @1 @2 (ones :: CPUTensor 'D.Float '[3,2,1])</span><span>
</span><span id="line-1401"></span><span class="hs-comment">-- (Float,[3,1,2])</span><span>
</span><span id="line-1402"></span><span class="annot"><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-type">transpose</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1403"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679711144"><span class="annot"><a href="#local-6989586621679711144"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679711143"><span class="annot"><a href="#local-6989586621679711143"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679711148"><span class="annot"><a href="#local-6989586621679711148"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679711149"><span class="annot"><a href="#local-6989586621679711149"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679711145"><span class="annot"><a href="#local-6989586621679711145"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679711146"><span class="annot"><a href="#local-6989586621679711146"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1404"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679711144"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1405"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679711143"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1406"></span><span>    </span><span class="annot"><a href="#local-6989586621679711149"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Transpose"><span class="hs-identifier hs-type">Transpose</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711148"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711144"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711143"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1407"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1408"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1409"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711146"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711145"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711148"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1410"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1411"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711146"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711145"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711149"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1412"></span><span id="transpose"><span class="annot"><span class="annottext">transpose :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var hs-var">transpose</span></a></span></span><span> </span><span id="local-6989586621679709728"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709728"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1413"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.transpose_tll</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709728"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat n =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679711144"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat m =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679711143"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1414"></span><span>
</span><span id="line-1415"></span><span class="hs-comment">-- | transpose2d, special case for a 2D tensor</span><span>
</span><span id="line-1416"></span><span class="hs-comment">--</span><span>
</span><span id="line-1417"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ transpose2D (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1418"></span><span class="hs-comment">-- (Float,[2,3])</span><span>
</span><span id="line-1419"></span><span class="annot"><a href="Torch.Typed.Functional.html#transpose2D"><span class="hs-identifier hs-type">transpose2D</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1420"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709725"><span class="annot"><a href="#local-6989586621679709725"><span class="hs-identifier hs-type">i</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709724"><span class="annot"><a href="#local-6989586621679709724"><span class="hs-identifier hs-type">j</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709723"><span class="annot"><a href="#local-6989586621679709723"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709722"><span class="annot"><a href="#local-6989586621679709722"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1421"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1422"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709722"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709723"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709725"><span class="hs-identifier hs-type">i</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709724"><span class="hs-identifier hs-type">j</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1423"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1424"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709722"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709723"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709724"><span class="hs-identifier hs-type">j</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709725"><span class="hs-identifier hs-type">i</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1425"></span><span id="transpose2D"><span class="annot"><span class="annottext">transpose2D :: Tensor device dtype '[i, j] -&gt; Tensor device dtype '[j, i]
</span><a href="Torch.Typed.Functional.html#transpose2D"><span class="hs-identifier hs-var hs-var">transpose2D</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (shape :: [Nat]) (shape' :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownNat 0, KnownNat 1, shape' ~ Transpose shape 0 1) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (n :: Nat) (m :: Nat) (shape :: [Nat]) (shape' :: [Nat])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat n, KnownNat m, shape' ~ Transpose shape n m) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-1426"></span><span>
</span><span id="line-1427"></span><span class="hs-keyword">class</span><span> </span><span id="KnownTri"><span class="annot"><a href="Torch.Typed.Functional.html#KnownTri"><span class="hs-identifier hs-var">KnownTri</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679711140"><span class="annot"><a href="#local-6989586621679711140"><span class="hs-identifier hs-type">tri</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1428"></span><span>  </span><span id="triVal"><span class="annot"><a href="Torch.Typed.Functional.html#triVal"><span class="hs-identifier hs-type">triVal</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span>
</span><span id="line-1429"></span><span>
</span><span id="line-1430"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownTri"><span class="hs-identifier hs-type">KnownTri</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#Upper"><span class="hs-identifier hs-type">Upper</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1431"></span><span>  </span><span id="local-6989586621679709718"><span class="annot"><span class="annottext">triVal :: Tri
</span><a href="#local-6989586621679709718"><span class="hs-identifier hs-var hs-var hs-var hs-var">triVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="Torch.Functional.html#Upper"><span class="hs-identifier hs-var">Upper</span></a></span><span>
</span><span id="line-1432"></span><span>
</span><span id="line-1433"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownTri"><span class="hs-identifier hs-type">KnownTri</span></a></span><span> </span><span class="annot"><a href="Torch.Functional.html#Lower"><span class="hs-identifier hs-type">Lower</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1434"></span><span>  </span><span id="local-6989586621679709716"><span class="annot"><span class="annottext">triVal :: Tri
</span><a href="#local-6989586621679709716"><span class="hs-identifier hs-var hs-var hs-var hs-var">triVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="Torch.Functional.html#Lower"><span class="hs-identifier hs-var">Lower</span></a></span><span>
</span><span id="line-1435"></span><span>
</span><span id="line-1436"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DiagSize"><span class="annot"><a href="Torch.Typed.Functional.html#DiagSize"><span class="hs-identifier hs-var">DiagSize</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709714"><span class="annot"><a href="#local-6989586621679709714"><span class="hs-identifier hs-type">tri</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709713"><span class="annot"><a href="#local-6989586621679709713"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709712"><span class="annot"><a href="#local-6989586621679709712"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709711"><span class="annot"><a href="#local-6989586621679709711"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1437"></span><span>  </span><span id="DiagSize"><span class="annot"><a href="Torch.Typed.Functional.html#DiagSize"><span class="hs-identifier hs-var">DiagSize</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Functional.html#Upper"><span class="hs-identifier hs-type">Upper</span></a></span><span> </span><span id="local-6989586621679709710"><span class="annot"><a href="#local-6989586621679709710"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span id="local-6989586621679709709"><span class="annot"><a href="#local-6989586621679709709"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679709708"><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1438"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#If"><span class="hs-identifier hs-type">If</span></a></span><span>
</span><span id="line-1439"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709710"><span class="hs-identifier hs-type">i</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=?</span></span><span> </span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1440"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709709"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709710"><span class="hs-identifier hs-type">i</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1441"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-1442"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;For a matrix with shape &quot;</span></span><span>
</span><span id="line-1443"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709709"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1444"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;, the maximum index for an upper diagonal is &quot;</span></span><span>
</span><span id="line-1445"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709708"><span class="hs-identifier hs-type">n</span></a></span><span>
</span><span id="line-1446"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;, but asked for index &quot;</span></span><span>
</span><span id="line-1447"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709710"><span class="hs-identifier hs-type">i</span></a></span><span>
</span><span id="line-1448"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-1449"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-1450"></span><span>  </span><span id="DiagSize"><span class="annot"><a href="Torch.Typed.Functional.html#DiagSize"><span class="hs-identifier hs-var">DiagSize</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Functional.html#Lower"><span class="hs-identifier hs-type">Lower</span></a></span><span> </span><span id="local-6989586621679709706"><span class="annot"><a href="#local-6989586621679709706"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span id="local-6989586621679709705"><span class="annot"><a href="#local-6989586621679709705"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679709704"><span class="annot"><a href="#local-6989586621679709704"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1451"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#If"><span class="hs-identifier hs-type">If</span></a></span><span>
</span><span id="line-1452"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709706"><span class="hs-identifier hs-type">i</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=?</span></span><span> </span><span class="annot"><a href="#local-6989586621679709705"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1453"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lw98clqdrj50cikw05y5c9vwh0k8ly3s-ghc-typelits-extra-lib-ghc-typelits-extra-0.4.1-haddock-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier hs-type">Min</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709705"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709706"><span class="hs-identifier hs-type">i</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709704"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1454"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-1455"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;For a matrix with shape &quot;</span></span><span>
</span><span id="line-1456"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709705"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709704"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1457"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;, the maximum index for a lower diagonal is &quot;</span></span><span>
</span><span id="line-1458"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709705"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1459"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;, but asked for index &quot;</span></span><span>
</span><span id="line-1460"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709706"><span class="hs-identifier hs-type">i</span></a></span><span>
</span><span id="line-1461"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-1462"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-1463"></span><span>
</span><span id="line-1464"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DiagShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagShape"><span class="hs-identifier hs-var">DiagShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709702"><span class="annot"><a href="#local-6989586621679709702"><span class="hs-identifier hs-type">tri</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709701"><span class="annot"><a href="#local-6989586621679709701"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709700"><span class="annot"><a href="#local-6989586621679709700"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1465"></span><span>  </span><span id="DiagShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagShape"><span class="hs-identifier hs-var">DiagShape</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679709699"><span class="annot"><a href="#local-6989586621679709699"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span id="local-6989586621679709698"><span class="annot"><a href="#local-6989586621679709698"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709698"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709699"><span class="hs-identifier hs-type">i</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709698"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709699"><span class="hs-identifier hs-type">i</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1466"></span><span>  </span><span id="DiagShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagShape"><span class="hs-identifier hs-var">DiagShape</span></a></span></span><span> </span><span id="local-6989586621679709697"><span class="annot"><a href="#local-6989586621679709697"><span class="hs-identifier hs-type hs-type">tri</span></a></span></span><span> </span><span id="local-6989586621679709696"><span class="annot"><a href="#local-6989586621679709696"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span id="local-6989586621679709695"><span class="annot"><a href="#local-6989586621679709695"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709694"><span class="annot"><a href="#local-6989586621679709694"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="Torch.Typed.Functional.html#DiagSize"><span class="hs-identifier hs-type">DiagSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709697"><span class="hs-identifier hs-type">tri</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709696"><span class="hs-identifier hs-type">i</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709695"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709694"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1467"></span><span>  </span><span id="DiagShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagShape"><span class="hs-identifier hs-var">DiagShape</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679709693"><span class="annot"><a href="#local-6989586621679709693"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1468"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-1469"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;The input must be a matrix or a vector, but it has &quot;</span></span><span>
</span><span id="line-1470"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#ListLength"><span class="hs-identifier hs-type">ListLength</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709693"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1471"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot; dimensions.&quot;</span></span><span>
</span><span id="line-1472"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-1473"></span><span>
</span><span id="line-1474"></span><span class="hs-comment">-- | diag</span><span>
</span><span id="line-1475"></span><span class="hs-comment">--</span><span>
</span><span id="line-1476"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diag @'Upper @0 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1477"></span><span class="hs-comment">-- (Float,[2])</span><span>
</span><span id="line-1478"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diag @'Upper @1 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1479"></span><span class="hs-comment">-- (Float,[1])</span><span>
</span><span id="line-1480"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diag @'Lower @1 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1481"></span><span class="hs-comment">-- (Float,[2])</span><span>
</span><span id="line-1482"></span><span class="annot"><a href="Torch.Typed.Functional.html#diag"><span class="hs-identifier hs-type">diag</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1483"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709690"><span class="annot"><a href="#local-6989586621679709690"><span class="hs-identifier hs-type">tri</span></a></span></span><span> </span><span id="local-6989586621679709689"><span class="annot"><a href="#local-6989586621679709689"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span id="local-6989586621679709688"><span class="annot"><a href="#local-6989586621679709688"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709687"><span class="annot"><a href="#local-6989586621679709687"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709686"><span class="annot"><a href="#local-6989586621679709686"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709685"><span class="annot"><a href="#local-6989586621679709685"><span class="hs-identifier hs-type">dtype</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1484"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownTri"><span class="hs-identifier hs-type">KnownTri</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709690"><span class="hs-identifier hs-type">tri</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1485"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709689"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1486"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709686"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709685"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1487"></span><span>    </span><span class="annot"><a href="#local-6989586621679709687"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DiagShape"><span class="hs-identifier hs-type">DiagShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709690"><span class="hs-identifier hs-type">tri</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709689"><span class="hs-identifier hs-type">index</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709688"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1488"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1489"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1490"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709686"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709685"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709688"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1491"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1492"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709686"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709685"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709687"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1493"></span><span id="diag"><span class="annot"><span class="annottext">diag :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#diag"><span class="hs-identifier hs-var hs-var">diag</span></a></span></span><span> </span><span id="local-6989586621679709684"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709684"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1494"></span><span>  </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.tensor_diag_l</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709684"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; IO (Tensor device dtype shape'))
-&gt; Int -&gt; IO (Tensor device dtype shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1495"></span><span>    </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">KnownTri tri =&gt; Tri
forall (tri :: Tri). KnownTri tri =&gt; Tri
</span><a href="Torch.Typed.Functional.html#triVal"><span class="hs-identifier hs-var">triVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709690"><span class="hs-identifier hs-type">tri</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-1496"></span><span>      </span><span class="annot"><span class="annottext">Tri
</span><a href="Torch.Functional.html#Upper"><span class="hs-identifier hs-var">Upper</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709689"><span class="hs-identifier hs-type">index</span></a></span><span>
</span><span id="line-1497"></span><span>      </span><span class="annot"><span class="annottext">Tri
</span><a href="Torch.Functional.html#Lower"><span class="hs-identifier hs-var">Lower</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-glyph">-</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709689"><span class="hs-identifier hs-type">index</span></a></span><span>
</span><span id="line-1498"></span><span>
</span><span id="line-1499"></span><span class="hs-comment">-- | all</span><span>
</span><span id="line-1500"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/tensors.html#torch.BoolTensor.all.</span><span>
</span><span id="line-1501"></span><span class="hs-comment">--</span><span>
</span><span id="line-1502"></span><span class="hs-comment">-- &gt;&gt;&gt; t = all (fromJust [False, False] :: CPUTensor 'D.Bool '[2])</span><span>
</span><span id="line-1503"></span><span class="hs-comment">-- &gt;&gt;&gt; toInt t == 1</span><span>
</span><span id="line-1504"></span><span class="hs-comment">-- False</span><span>
</span><span id="line-1505"></span><span class="hs-comment">--</span><span>
</span><span id="line-1506"></span><span class="hs-comment">-- &gt;&gt;&gt; t = all (fromJust [False, True] :: CPUTensor 'D.Bool '[2])</span><span>
</span><span id="line-1507"></span><span class="hs-comment">-- &gt;&gt;&gt; toInt t == 1</span><span>
</span><span id="line-1508"></span><span class="hs-comment">-- False</span><span>
</span><span id="line-1509"></span><span class="hs-comment">--</span><span>
</span><span id="line-1510"></span><span class="hs-comment">-- &gt;&gt;&gt; t = all (fromJust [True, True] :: CPUTensor 'D.Bool '[2])</span><span>
</span><span id="line-1511"></span><span class="hs-comment">-- &gt;&gt;&gt; toInt t == 1</span><span>
</span><span id="line-1512"></span><span class="hs-comment">-- True</span><span>
</span><span id="line-1513"></span><span class="annot"><a href="Torch.Typed.Functional.html#all"><span class="hs-identifier hs-type">all</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1514"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709681"><span class="annot"><a href="#local-6989586621679709681"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709680"><span class="annot"><a href="#local-6989586621679709680"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1515"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1516"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709680"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709681"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1517"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1518"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709680"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-1519"></span><span id="all"><span class="annot"><span class="annottext">all :: Tensor device 'Bool shape -&gt; Tensor device 'Bool '[]
</span><a href="Torch.Typed.Functional.html#all"><span class="hs-identifier hs-var hs-var">all</span></a></span></span><span> </span><span id="local-6989586621679709679"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709679"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool '[]) -&gt; Tensor device 'Bool '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool '[]) -&gt; Tensor device 'Bool '[])
-&gt; IO (Tensor device 'Bool '[]) -&gt; Tensor device 'Bool '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape -&gt; IO (Tensor device 'Bool '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.all_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709679"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1520"></span><span>
</span><span id="line-1521"></span><span class="hs-comment">-- | any</span><span>
</span><span id="line-1522"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/tensors.html#torch.BoolTensor.any.</span><span>
</span><span id="line-1523"></span><span class="hs-comment">--</span><span>
</span><span id="line-1524"></span><span class="hs-comment">-- &gt;&gt;&gt; t = any (fromJust [False, False] :: CPUTensor 'D.Bool '[2])</span><span>
</span><span id="line-1525"></span><span class="hs-comment">-- &gt;&gt;&gt; toInt t == 1</span><span>
</span><span id="line-1526"></span><span class="hs-comment">-- False</span><span>
</span><span id="line-1527"></span><span class="hs-comment">--</span><span>
</span><span id="line-1528"></span><span class="hs-comment">-- &gt;&gt;&gt; t = any (fromJust [False, True] :: CPUTensor 'D.Bool '[2])</span><span>
</span><span id="line-1529"></span><span class="hs-comment">-- &gt;&gt;&gt; toInt t == 1</span><span>
</span><span id="line-1530"></span><span class="hs-comment">-- True</span><span>
</span><span id="line-1531"></span><span class="hs-comment">--</span><span>
</span><span id="line-1532"></span><span class="hs-comment">-- &gt;&gt;&gt; t = any (fromJust [True, True] :: CPUTensor 'D.Bool '[2])</span><span>
</span><span id="line-1533"></span><span class="hs-comment">-- &gt;&gt;&gt; toInt t == 1</span><span>
</span><span id="line-1534"></span><span class="hs-comment">-- True</span><span>
</span><span id="line-1535"></span><span class="annot"><a href="Torch.Typed.Functional.html#any"><span class="hs-identifier hs-type">any</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1536"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709676"><span class="annot"><a href="#local-6989586621679709676"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709675"><span class="annot"><a href="#local-6989586621679709675"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1537"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1538"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709675"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709676"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1539"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1540"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709675"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-1541"></span><span id="any"><span class="annot"><span class="annottext">any :: Tensor device 'Bool shape -&gt; Tensor device 'Bool '[]
</span><a href="Torch.Typed.Functional.html#any"><span class="hs-identifier hs-var hs-var">any</span></a></span></span><span> </span><span id="local-6989586621679709674"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709674"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool '[]) -&gt; Tensor device 'Bool '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool '[]) -&gt; Tensor device 'Bool '[])
-&gt; IO (Tensor device 'Bool '[]) -&gt; Tensor device 'Bool '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape -&gt; IO (Tensor device 'Bool '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.any_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709674"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1542"></span><span>
</span><span id="line-1543"></span><span class="hs-keyword">data</span><span> </span><span id="KeepOrDropDim"><span class="annot"><a href="Torch.Typed.Functional.html#KeepOrDropDim"><span class="hs-identifier hs-var">KeepOrDropDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="KeepDim"><span class="annot"><a href="Torch.Typed.Functional.html#KeepDim"><span class="hs-identifier hs-var">KeepDim</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="DropDim"><span class="annot"><a href="Torch.Typed.Functional.html#DropDim"><span class="hs-identifier hs-var">DropDim</span></a></span></span><span>
</span><span id="line-1544"></span><span>
</span><span id="line-1545"></span><span class="hs-keyword">class</span><span> </span><span id="KnownKeepOrDropDim"><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-var">KnownKeepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679711383"><span class="annot"><a href="#local-6989586621679711383"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1546"></span><span>  </span><span id="keepOrDropDimVal"><span class="annot"><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-type">keepOrDropDimVal</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-1547"></span><span>
</span><span id="line-1548"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1549"></span><span>  </span><span id="local-6989586621679709670"><span class="annot"><span class="annottext">keepOrDropDimVal :: Bool
</span><a href="#local-6989586621679709670"><span class="hs-identifier hs-var hs-var hs-var hs-var">keepOrDropDimVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-1550"></span><span>
</span><span id="line-1551"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DropDim"><span class="hs-identifier hs-type">DropDim</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1552"></span><span>  </span><span id="local-6989586621679709668"><span class="annot"><span class="annottext">keepOrDropDimVal :: Bool
</span><a href="#local-6989586621679709668"><span class="hs-identifier hs-var hs-var hs-var hs-var">keepOrDropDimVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1553"></span><span>
</span><span id="line-1554"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ConditionalDropDimension"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-var">ConditionalDropDimension</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709667"><span class="annot"><a href="#local-6989586621679709667"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709666"><span class="annot"><a href="#local-6989586621679709666"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709665"><span class="annot"><a href="#local-6989586621679709665"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KeepOrDropDim"><span class="hs-identifier hs-type">KeepOrDropDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1555"></span><span>  </span><span id="ConditionalDropDimension"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-var">ConditionalDropDimension</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;The specified dimension is not available.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-1556"></span><span>  </span><span id="ConditionalDropDimension"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-var">ConditionalDropDimension</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709664"><span class="annot"><a href="#local-6989586621679709664"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709663"><span class="annot"><a href="#local-6989586621679709663"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KeepDim"><span class="hs-identifier hs-type">KeepDim</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679709663"><span class="hs-identifier hs-type">xs</span></a></span><span>
</span><span id="line-1557"></span><span>  </span><span id="ConditionalDropDimension"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-var">ConditionalDropDimension</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709662"><span class="annot"><a href="#local-6989586621679709662"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709661"><span class="annot"><a href="#local-6989586621679709661"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DropDim"><span class="hs-identifier hs-type">DropDim</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709661"><span class="hs-identifier hs-type">xs</span></a></span><span>
</span><span id="line-1558"></span><span>  </span><span id="ConditionalDropDimension"><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-var">ConditionalDropDimension</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709660"><span class="annot"><a href="#local-6989586621679709660"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709659"><span class="annot"><a href="#local-6989586621679709659"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709658"><span class="annot"><a href="#local-6989586621679709658"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span id="local-6989586621679709657"><span class="annot"><a href="#local-6989586621679709657"><span class="hs-identifier hs-type hs-type">keepOrDropDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709660"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709659"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709658"><span class="hs-identifier hs-type">i</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709657"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span>
</span><span id="line-1559"></span><span>
</span><span id="line-1560"></span><span class="hs-comment">-- | allDim</span><span>
</span><span id="line-1561"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/tensors.html#torch.BoolTensor.all.</span><span>
</span><span id="line-1562"></span><span class="hs-comment">--</span><span>
</span><span id="line-1563"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[True, True], [True, False], [True, True], [True, True]] :: CPUTensor 'D.Bool '[4, 2]</span><span>
</span><span id="line-1564"></span><span class="hs-comment">--</span><span>
</span><span id="line-1565"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Bool]) $ allDim @1 @DropDim t</span><span>
</span><span id="line-1566"></span><span class="hs-comment">-- (Bool,([4],[True,False,True,True]))</span><span>
</span><span id="line-1567"></span><span class="hs-comment">--</span><span>
</span><span id="line-1568"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Bool]]) $ allDim @1 @KeepDim t</span><span>
</span><span id="line-1569"></span><span class="hs-comment">-- (Bool,([4,1],[[True],[False],[True],[True]]))</span><span>
</span><span id="line-1570"></span><span class="hs-comment">--</span><span>
</span><span id="line-1571"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Bool]) $ allDim @0 @DropDim t</span><span>
</span><span id="line-1572"></span><span class="hs-comment">-- (Bool,([2],[True,False]))</span><span>
</span><span id="line-1573"></span><span class="hs-comment">--</span><span>
</span><span id="line-1574"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Bool]]) $ allDim @0 @KeepDim t</span><span>
</span><span id="line-1575"></span><span class="hs-comment">-- (Bool,([1,2],[[True,False]]))</span><span>
</span><span id="line-1576"></span><span class="annot"><a href="Torch.Typed.Functional.html#allDim"><span class="hs-identifier hs-type">allDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1577"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709655"><span class="annot"><a href="#local-6989586621679709655"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709654"><span class="annot"><a href="#local-6989586621679709654"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679709653"><span class="annot"><a href="#local-6989586621679709653"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709652"><span class="annot"><a href="#local-6989586621679709652"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709651"><span class="annot"><a href="#local-6989586621679709651"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1578"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709655"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1579"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709654"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1580"></span><span>    </span><span class="annot"><a href="#local-6989586621679709653"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709652"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709655"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709654"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span>
</span><span id="line-1581"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1582"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1583"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709651"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709652"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1584"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1585"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709651"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709653"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1586"></span><span id="allDim"><span class="annot"><span class="annottext">allDim :: Tensor device 'Bool shape -&gt; Tensor device 'Bool shape'
</span><a href="Torch.Typed.Functional.html#allDim"><span class="hs-identifier hs-var hs-var">allDim</span></a></span></span><span> </span><span id="local-6989586621679709650"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709650"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1587"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape') -&gt; Tensor device 'Bool shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape') -&gt; Tensor device 'Bool shape')
-&gt; IO (Tensor device 'Bool shape') -&gt; Tensor device 'Bool shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1588"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device 'Bool shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.all_tlb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709650"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709655"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709654"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1589"></span><span>
</span><span id="line-1590"></span><span class="hs-comment">-- | anyDim</span><span>
</span><span id="line-1591"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/tensors.html#torch.BoolTensor.any.</span><span>
</span><span id="line-1592"></span><span class="hs-comment">--</span><span>
</span><span id="line-1593"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[True, True], [True, False], [True, True], [True, True]] :: CPUTensor 'D.Bool '[4, 2]</span><span>
</span><span id="line-1594"></span><span class="hs-comment">--</span><span>
</span><span id="line-1595"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Bool]) $ anyDim @1 @DropDim t</span><span>
</span><span id="line-1596"></span><span class="hs-comment">-- (Bool,([4],[True,True,True,True]))</span><span>
</span><span id="line-1597"></span><span class="hs-comment">--</span><span>
</span><span id="line-1598"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Bool]]) $ anyDim @1 @KeepDim t</span><span>
</span><span id="line-1599"></span><span class="hs-comment">-- (Bool,([4,1],[[True],[True],[True],[True]]))</span><span>
</span><span id="line-1600"></span><span class="hs-comment">--</span><span>
</span><span id="line-1601"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Bool]) $ anyDim @0 @DropDim t</span><span>
</span><span id="line-1602"></span><span class="hs-comment">-- (Bool,([2],[True,True]))</span><span>
</span><span id="line-1603"></span><span class="hs-comment">--</span><span>
</span><span id="line-1604"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Bool]]) $ anyDim @0 @KeepDim t</span><span>
</span><span id="line-1605"></span><span class="hs-comment">-- (Bool,([1,2],[[True,True]]))</span><span>
</span><span id="line-1606"></span><span class="annot"><a href="Torch.Typed.Functional.html#anyDim"><span class="hs-identifier hs-type">anyDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1607"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709647"><span class="annot"><a href="#local-6989586621679709647"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709646"><span class="annot"><a href="#local-6989586621679709646"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679709645"><span class="annot"><a href="#local-6989586621679709645"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709644"><span class="annot"><a href="#local-6989586621679709644"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709643"><span class="annot"><a href="#local-6989586621679709643"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1608"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709647"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1609"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709646"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1610"></span><span>    </span><span class="annot"><a href="#local-6989586621679709645"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709644"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709647"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709646"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span>
</span><span id="line-1611"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1612"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1613"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709643"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709644"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1614"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1615"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709643"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709645"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1616"></span><span id="anyDim"><span class="annot"><span class="annottext">anyDim :: Tensor device 'Bool shape -&gt; Tensor device 'Bool shape'
</span><a href="Torch.Typed.Functional.html#anyDim"><span class="hs-identifier hs-var hs-var">anyDim</span></a></span></span><span> </span><span id="local-6989586621679709642"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709642"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape') -&gt; Tensor device 'Bool shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape') -&gt; Tensor device 'Bool shape')
-&gt; IO (Tensor device 'Bool shape') -&gt; Tensor device 'Bool shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device 'Bool shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device 'Bool shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.any_tlb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679709642"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709647"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709646"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1617"></span><span>
</span><span id="line-1618"></span><span class="hs-comment">-- | dropout</span><span>
</span><span id="line-1619"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1620"></span><span class="hs-comment">-- TODO: get rid of IO by exposing the RNG state</span><span>
</span><span id="line-1621"></span><span class="hs-comment">-- TODO: can we use D.Scalar for the dropout probability?</span><span>
</span><span id="line-1622"></span><span class="hs-comment">--</span><span>
</span><span id="line-1623"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3,2]</span><span>
</span><span id="line-1624"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- dropout 0.5 False t</span><span>
</span><span id="line-1625"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t'</span><span>
</span><span id="line-1626"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1627"></span><span class="hs-comment">-- &gt;&gt;&gt; t'' &lt;- dropout 0.5 False t</span><span>
</span><span id="line-1628"></span><span class="hs-comment">-- &gt;&gt;&gt; t ==. t''</span><span>
</span><span id="line-1629"></span><span class="hs-comment">-- Tensor Bool [3,2] [[ 1,  1],</span><span>
</span><span id="line-1630"></span><span class="hs-comment">--                    [ 1,  1],</span><span>
</span><span id="line-1631"></span><span class="hs-comment">--                    [ 1,  1]]</span><span>
</span><span id="line-1632"></span><span class="hs-comment">-- &gt;&gt;&gt; t''' &lt;- dropout 0.0 True t</span><span>
</span><span id="line-1633"></span><span class="hs-comment">-- &gt;&gt;&gt; t ==. t'''</span><span>
</span><span id="line-1634"></span><span class="hs-comment">-- Tensor Bool [3,2] [[ 1,  1],</span><span>
</span><span id="line-1635"></span><span class="hs-comment">--                    [ 1,  1],</span><span>
</span><span id="line-1636"></span><span class="hs-comment">--                    [ 1,  1]]</span><span>
</span><span id="line-1637"></span><span class="hs-comment">-- &gt;&gt;&gt; t'''' &lt;- dropout 1.0 True t</span><span>
</span><span id="line-1638"></span><span class="hs-comment">-- &gt;&gt;&gt; t''''</span><span>
</span><span id="line-1639"></span><span class="hs-comment">-- Tensor Float [3,2] [[ 0.0000,  0.0000],</span><span>
</span><span id="line-1640"></span><span class="hs-comment">--                     [ 0.0000,  0.0000],</span><span>
</span><span id="line-1641"></span><span class="hs-comment">--                     [ 0.0000,  0.0000]]</span><span>
</span><span id="line-1642"></span><span class="annot"><a href="Torch.Typed.Functional.html#dropout"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1643"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709639"><span class="annot"><a href="#local-6989586621679709639"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709638"><span class="annot"><a href="#local-6989586621679709638"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709637"><span class="annot"><a href="#local-6989586621679709637"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1644"></span><span>  </span><span class="hs-comment">-- | dropout probability</span><span>
</span><span id="line-1645"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1646"></span><span>  </span><span class="hs-comment">-- | whether or not to activate dropout</span><span>
</span><span id="line-1647"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1648"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1649"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709637"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709638"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709639"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1650"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1651"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709637"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709638"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709639"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1652"></span><span id="dropout"><span class="annot"><span class="annottext">dropout :: Double
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.Functional.html#dropout"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span id="local-6989586621679709636"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709636"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679709635"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709635"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679709634"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709634"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Double
-&gt; Bool
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709634"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709636"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709635"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1653"></span><span>
</span><span id="line-1654"></span><span class="hs-comment">-- | featureDropout</span><span>
</span><span id="line-1655"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1656"></span><span class="hs-comment">-- TODO: why not IO?</span><span>
</span><span id="line-1657"></span><span class="hs-comment">-- TODO: can we use D.Scalar for the dropout probability?</span><span>
</span><span id="line-1658"></span><span class="hs-comment">--</span><span>
</span><span id="line-1659"></span><span class="hs-comment">-- &gt;&gt;&gt; c = featureDropout 0.1 True (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-1660"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ c</span><span>
</span><span id="line-1661"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-1662"></span><span class="annot"><a href="Torch.Typed.Functional.html#featureDropout"><span class="hs-identifier hs-type">featureDropout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1663"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709631"><span class="annot"><a href="#local-6989586621679709631"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709630"><span class="annot"><a href="#local-6989586621679709630"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709629"><span class="annot"><a href="#local-6989586621679709629"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1664"></span><span>  </span><span class="hs-comment">-- | dropout probability</span><span>
</span><span id="line-1665"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1666"></span><span>  </span><span class="hs-comment">-- | whether or not to activate dropout</span><span>
</span><span id="line-1667"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1668"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1669"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709629"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709630"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709631"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1670"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1671"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709629"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709630"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709631"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1672"></span><span id="featureDropout"><span class="annot"><span class="annottext">featureDropout :: Double
-&gt; Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#featureDropout"><span class="hs-identifier hs-var hs-var">featureDropout</span></a></span></span><span> </span><span id="local-6989586621679709628"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709628"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679709627"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709627"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679709626"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709626"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1673"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Double
-&gt; Bool
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.feature_dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709626"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709628"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709627"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1674"></span><span>
</span><span id="line-1675"></span><span class="hs-comment">-- | alphaDropout</span><span>
</span><span id="line-1676"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1677"></span><span class="hs-comment">-- TODO: why not IO?</span><span>
</span><span id="line-1678"></span><span class="hs-comment">-- TODO: can we use D.Scalar for the dropout probability?</span><span>
</span><span id="line-1679"></span><span class="hs-comment">--</span><span>
</span><span id="line-1680"></span><span class="hs-comment">-- &gt;&gt;&gt; c = alphaDropout 0.1 True (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-1681"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ c</span><span>
</span><span id="line-1682"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-1683"></span><span class="annot"><a href="Torch.Typed.Functional.html#alphaDropout"><span class="hs-identifier hs-type">alphaDropout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1684"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709623"><span class="annot"><a href="#local-6989586621679709623"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709622"><span class="annot"><a href="#local-6989586621679709622"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709621"><span class="annot"><a href="#local-6989586621679709621"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1685"></span><span>  </span><span class="hs-comment">-- | dropout probability</span><span>
</span><span id="line-1686"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1687"></span><span>  </span><span class="hs-comment">-- | whether or not to activate dropout</span><span>
</span><span id="line-1688"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1689"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1690"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709621"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709622"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709623"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1691"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1692"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709621"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709622"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709623"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1693"></span><span id="alphaDropout"><span class="annot"><span class="annottext">alphaDropout :: Double
-&gt; Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#alphaDropout"><span class="hs-identifier hs-var hs-var">alphaDropout</span></a></span></span><span> </span><span id="local-6989586621679709620"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709620"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679709619"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679709618"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709618"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1694"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Double
-&gt; Bool
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.alpha_dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709618"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709620"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709619"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1695"></span><span>
</span><span id="line-1696"></span><span class="hs-comment">-- | featureAlphaDropout</span><span>
</span><span id="line-1697"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1698"></span><span class="hs-comment">-- TODO: why not IO?</span><span>
</span><span id="line-1699"></span><span class="hs-comment">-- TODO: can we use D.Scalar for the dropout probability?</span><span>
</span><span id="line-1700"></span><span class="hs-comment">--</span><span>
</span><span id="line-1701"></span><span class="hs-comment">-- &gt;&gt;&gt; c = featureAlphaDropout 0.1 True (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-1702"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ c</span><span>
</span><span id="line-1703"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-1704"></span><span class="annot"><a href="Torch.Typed.Functional.html#featureAlphaDropout"><span class="hs-identifier hs-type">featureAlphaDropout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1705"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709615"><span class="annot"><a href="#local-6989586621679709615"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709614"><span class="annot"><a href="#local-6989586621679709614"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709613"><span class="annot"><a href="#local-6989586621679709613"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1706"></span><span>  </span><span class="hs-comment">-- | dropout probability</span><span>
</span><span id="line-1707"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1708"></span><span>  </span><span class="hs-comment">-- | whether or not to activate dropout</span><span>
</span><span id="line-1709"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1710"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1711"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709613"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709614"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709615"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1712"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1713"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709613"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709614"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709615"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1714"></span><span id="featureAlphaDropout"><span class="annot"><span class="annottext">featureAlphaDropout :: Double
-&gt; Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#featureAlphaDropout"><span class="hs-identifier hs-var hs-var">featureAlphaDropout</span></a></span></span><span> </span><span id="local-6989586621679709612"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709612"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679709611"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709611"><span class="hs-identifier hs-var">train</span></a></span></span><span> </span><span id="local-6989586621679709610"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709610"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1715"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Double
-&gt; Bool
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CDouble -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.feature_alpha_dropout_tdb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709610"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709612"><span class="hs-identifier hs-var">p</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709611"><span class="hs-identifier hs-var">train</span></a></span><span>
</span><span id="line-1716"></span><span>
</span><span id="line-1717"></span><span class="hs-comment">-- | acos</span><span>
</span><span id="line-1718"></span><span class="hs-comment">--</span><span>
</span><span id="line-1719"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ acos (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1720"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1721"></span><span class="annot"><a href="Torch.Typed.Functional.html#acos"><span class="hs-identifier hs-type">acos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1722"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709607"><span class="annot"><a href="#local-6989586621679709607"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709606"><span class="annot"><a href="#local-6989586621679709606"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709605"><span class="annot"><a href="#local-6989586621679709605"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1723"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709605"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709606"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1724"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1725"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709605"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709606"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709607"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1726"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1727"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709605"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709606"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709607"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1728"></span><span id="acos"><span class="annot"><span class="annottext">acos :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#acos"><span class="hs-identifier hs-var hs-var">acos</span></a></span></span><span> </span><span id="local-6989586621679709604"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709604"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.acos_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709604"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1729"></span><span>
</span><span id="line-1730"></span><span class="hs-comment">-- | avgPool1d</span><span>
</span><span id="line-1731"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1732"></span><span class="hs-comment">--</span><span>
</span><span id="line-1733"></span><span class="hs-comment">-- &gt;&gt;&gt; t = avgPool1d @1 @1 @0 (ones :: CPUTensor 'D.Float '[1,3,4])</span><span>
</span><span id="line-1734"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-1735"></span><span class="hs-comment">-- [1,3,4]</span><span>
</span><span id="line-1736"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-1737"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 4]</span><span>
</span><span id="line-1738"></span><span class="annot"><a href="Torch.Typed.Functional.html#avgPool1d"><span class="hs-identifier hs-type">avgPool1d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1739"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-1740"></span><span>    </span><span id="local-6989586621679709601"><span class="annot"><a href="#local-6989586621679709601"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span>
</span><span id="line-1741"></span><span>    </span><span id="local-6989586621679709600"><span class="annot"><a href="#local-6989586621679709600"><span class="hs-identifier hs-type">stride</span></a></span></span><span>
</span><span id="line-1742"></span><span>    </span><span id="local-6989586621679709599"><span class="annot"><a href="#local-6989586621679709599"><span class="hs-identifier hs-type">padding</span></a></span></span><span>
</span><span id="line-1743"></span><span>    </span><span id="local-6989586621679709598"><span class="annot"><a href="#local-6989586621679709598"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span>
</span><span id="line-1744"></span><span>    </span><span id="local-6989586621679709597"><span class="annot"><a href="#local-6989586621679709597"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span>
</span><span id="line-1745"></span><span>    </span><span id="local-6989586621679709596"><span class="annot"><a href="#local-6989586621679709596"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-1746"></span><span>    </span><span id="local-6989586621679709595"><span class="annot"><a href="#local-6989586621679709595"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-1747"></span><span>    </span><span id="local-6989586621679709594"><span class="annot"><a href="#local-6989586621679709594"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-1748"></span><span>    </span><span id="local-6989586621679709593"><span class="annot"><a href="#local-6989586621679709593"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1749"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709601"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709600"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709599"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709598"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709597"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709596"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-1750"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709597"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709601"><span class="hs-identifier hs-type">kernelSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709600"><span class="hs-identifier hs-type">stride</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709599"><span class="hs-identifier hs-type">padding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709595"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-1751"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1752"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1753"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709593"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709594"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709596"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709598"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709597"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1754"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1755"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709593"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709594"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709596"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709598"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709595"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1756"></span><span id="avgPool1d"><span class="annot"><span class="annottext">avgPool1d :: Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
</span><a href="Torch.Typed.Functional.html#avgPool1d"><span class="hs-identifier hs-var hs-var">avgPool1d</span></a></span></span><span> </span><span id="local-6989586621679709590"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679709590"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1757"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, channelSize, outputSize])
 -&gt; Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; IO (Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1758"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; Bool
-&gt; Bool
-&gt; IO (Tensor device dtype '[batchSize, channelSize, outputSize])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span>
</span><span id="line-1759"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.avg_pool1d_tlllbb</span></a></span><span>
</span><span id="line-1760"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679709590"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1761"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat kernelSize =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709601"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1762"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat stride =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709600"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1763"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat padding =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709599"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1764"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1765"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-1766"></span><span>
</span><span id="line-1767"></span><span class="hs-comment">-- | adaptiveAvgPool1d</span><span>
</span><span id="line-1768"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1769"></span><span class="hs-comment">--</span><span>
</span><span id="line-1770"></span><span class="hs-comment">-- &gt;&gt;&gt; t = adaptiveAvgPool1d @8 (ones :: CPUTensor 'D.Float '[1,3,16])</span><span>
</span><span id="line-1771"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-1772"></span><span class="hs-comment">-- [1,3,8]</span><span>
</span><span id="line-1773"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-1774"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 8]</span><span>
</span><span id="line-1775"></span><span class="annot"><a href="Torch.Typed.Functional.html#adaptiveAvgPool1d"><span class="hs-identifier hs-type">adaptiveAvgPool1d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1776"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709586"><span class="annot"><a href="#local-6989586621679709586"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span> </span><span id="local-6989586621679709585"><span class="annot"><a href="#local-6989586621679709585"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679709584"><span class="annot"><a href="#local-6989586621679709584"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679709583"><span class="annot"><a href="#local-6989586621679709583"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679709582"><span class="annot"><a href="#local-6989586621679709582"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709581"><span class="annot"><a href="#local-6989586621679709581"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1777"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709585"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709584"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709583"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709586"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1778"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1779"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709581"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709582"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709583"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709585"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709584"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1780"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1781"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709581"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709582"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709583"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709585"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709586"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1782"></span><span id="adaptiveAvgPool1d"><span class="annot"><span class="annottext">adaptiveAvgPool1d :: Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
</span><a href="Torch.Typed.Functional.html#adaptiveAvgPool1d"><span class="hs-identifier hs-var hs-var">adaptiveAvgPool1d</span></a></span></span><span> </span><span id="local-6989586621679709580"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679709580"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1783"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, channelSize, outputSize])
 -&gt; Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; IO (Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1784"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; Int
-&gt; IO (Tensor device dtype '[batchSize, channelSize, outputSize])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.adaptive_avg_pool1d_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679709580"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat outputSize =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709586"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1785"></span><span>
</span><span id="line-1786"></span><span class="hs-comment">-- | adaptiveMaxPool1d</span><span>
</span><span id="line-1787"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1788"></span><span class="hs-comment">--</span><span>
</span><span id="line-1789"></span><span class="hs-comment">-- &gt;&gt;&gt; tt = adaptiveMaxPool1d @8 (ones :: CPUTensor 'D.Float '[1,3,16])</span><span>
</span><span id="line-1790"></span><span class="hs-comment">-- &gt;&gt;&gt; shape . fst $ tt</span><span>
</span><span id="line-1791"></span><span class="hs-comment">-- [1,3,8]</span><span>
</span><span id="line-1792"></span><span class="hs-comment">-- &gt;&gt;&gt; :t tt</span><span>
</span><span id="line-1793"></span><span class="hs-comment">-- tt</span><span>
</span><span id="line-1794"></span><span class="hs-comment">--   :: (Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 8],</span><span>
</span><span id="line-1795"></span><span class="hs-comment">--       Tensor '( 'D.CPU, 0) 'D.Int64 '[1, 3, 8])</span><span>
</span><span id="line-1796"></span><span class="annot"><a href="Torch.Typed.Functional.html#adaptiveMaxPool1d"><span class="hs-identifier hs-type">adaptiveMaxPool1d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1797"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709577"><span class="annot"><a href="#local-6989586621679709577"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span> </span><span id="local-6989586621679709576"><span class="annot"><a href="#local-6989586621679709576"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679709575"><span class="annot"><a href="#local-6989586621679709575"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679709574"><span class="annot"><a href="#local-6989586621679709574"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679709573"><span class="annot"><a href="#local-6989586621679709573"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709572"><span class="annot"><a href="#local-6989586621679709572"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1798"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709576"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709575"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709574"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709577"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1799"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1800"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709572"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709573"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709574"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709576"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709575"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1801"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1802"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709572"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709573"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709574"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709576"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709577"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-1803"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709572"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709574"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709576"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709577"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1804"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-1805"></span><span id="adaptiveMaxPool1d"><span class="annot"><span class="annottext">adaptiveMaxPool1d :: Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; (Tensor device dtype '[batchSize, channelSize, outputSize],
    Tensor device 'Int64 '[batchSize, channelSize, outputSize])
</span><a href="Torch.Typed.Functional.html#adaptiveMaxPool1d"><span class="hs-identifier hs-var hs-var">adaptiveMaxPool1d</span></a></span></span><span> </span><span id="local-6989586621679709571"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679709571"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1806"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype '[batchSize, channelSize, outputSize],
   Tensor device 'Int64 '[batchSize, channelSize, outputSize])
-&gt; (Tensor device dtype '[batchSize, channelSize, outputSize],
    Tensor device 'Int64 '[batchSize, channelSize, outputSize])
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype '[batchSize, channelSize, outputSize],
    Tensor device 'Int64 '[batchSize, channelSize, outputSize])
 -&gt; (Tensor device dtype '[batchSize, channelSize, outputSize],
     Tensor device 'Int64 '[batchSize, channelSize, outputSize]))
-&gt; IO
     (Tensor device dtype '[batchSize, channelSize, outputSize],
      Tensor device 'Int64 '[batchSize, channelSize, outputSize])
-&gt; (Tensor device dtype '[batchSize, channelSize, outputSize],
    Tensor device 'Int64 '[batchSize, channelSize, outputSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1807"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; Int
-&gt; IO
     (Tensor device dtype '[batchSize, channelSize, outputSize],
      Tensor device 'Int64 '[batchSize, channelSize, outputSize])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.adaptive_max_pool1d_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679709571"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat outputSize =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709577"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1808"></span><span>
</span><span id="line-1809"></span><span class="hs-comment">-- | addmv</span><span>
</span><span id="line-1810"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1811"></span><span class="hs-comment">-- TODO: can we use D.Scalar for beta and alpha?</span><span>
</span><span id="line-1812"></span><span class="hs-comment">--</span><span>
</span><span id="line-1813"></span><span class="hs-comment">-- &gt;&gt;&gt; t = addmv 1 1 (ones :: CPUTensor 'D.Float '[3,2]) (zeros :: CPUTensor 'D.Float '[2]) (ones :: CPUTensor 'D.Float '[])</span><span>
</span><span id="line-1814"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-1815"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-1816"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-1817"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[3]</span><span>
</span><span id="line-1818"></span><span class="annot"><a href="Torch.Typed.Functional.html#addmv"><span class="hs-identifier hs-type">addmv</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1819"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709568"><span class="annot"><a href="#local-6989586621679709568"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709567"><span class="annot"><a href="#local-6989586621679709567"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709566"><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709565"><span class="annot"><a href="#local-6989586621679709565"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679709564"><span class="annot"><a href="#local-6989586621679709564"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709563"><span class="annot"><a href="#local-6989586621679709563"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1820"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1821"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709565"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1822"></span><span>    </span><span class="annot"><a href="#local-6989586621679709568"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709567"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1823"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1824"></span><span>  </span><span class="hs-comment">-- | beta</span><span>
</span><span id="line-1825"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1826"></span><span>  </span><span class="hs-comment">-- | alpha</span><span>
</span><span id="line-1827"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1828"></span><span>  </span><span class="hs-comment">-- | matrix</span><span>
</span><span id="line-1829"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709563"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709564"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709566"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709565"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1830"></span><span>  </span><span class="hs-comment">-- | vector</span><span>
</span><span id="line-1831"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709563"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709564"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709565"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1832"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1833"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709563"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709564"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709567"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1834"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1835"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709563"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709564"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709568"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1836"></span><span id="addmv"><span class="annot"><span class="annottext">addmv :: Float
-&gt; Float
-&gt; Tensor device dtype '[n, m]
-&gt; Tensor device dtype '[m]
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#addmv"><span class="hs-identifier hs-var hs-var">addmv</span></a></span></span><span> </span><span id="local-6989586621679709562"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709562"><span class="hs-identifier hs-var">beta</span></a></span></span><span> </span><span id="local-6989586621679709561"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709561"><span class="hs-identifier hs-var">alpha</span></a></span></span><span> </span><span id="local-6989586621679709560"><span class="annot"><span class="annottext">Tensor device dtype '[n, m]
</span><a href="#local-6989586621679709560"><span class="hs-identifier hs-var">mat</span></a></span></span><span> </span><span id="local-6989586621679709559"><span class="annot"><span class="annottext">Tensor device dtype '[m]
</span><a href="#local-6989586621679709559"><span class="hs-identifier hs-var">vec</span></a></span></span><span> </span><span id="local-6989586621679709558"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709558"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype '[n, m]
-&gt; Tensor device dtype '[m]
-&gt; Float
-&gt; Float
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.addmv_tttss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709558"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[n, m]
</span><a href="#local-6989586621679709560"><span class="hs-identifier hs-var">mat</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[m]
</span><a href="#local-6989586621679709559"><span class="hs-identifier hs-var">vec</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709562"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709561"><span class="hs-identifier hs-var">alpha</span></a></span><span>
</span><span id="line-1837"></span><span>
</span><span id="line-1838"></span><span class="hs-comment">-- affine_grid_generator :: Tensor device dtype shape -&gt; [Int] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-1839"></span><span class="hs-comment">-- affine_grid_generator _theta _size = unsafePerformIO $ (ATen.cast2 ATen.Managed.affine_grid_generator_tl) _theta _size</span><span>
</span><span id="line-1840"></span><span>
</span><span id="line-1841"></span><span class="hs-comment">-- | allclose</span><span>
</span><span id="line-1842"></span><span class="hs-comment">--</span><span>
</span><span id="line-1843"></span><span class="hs-comment">-- &gt;&gt;&gt; allclose 0.1 0.1 True (ones :: CPUTensor 'D.Float '[3,3]) (ones :: CPUTensor 'D.Float '[3,3])</span><span>
</span><span id="line-1844"></span><span class="hs-comment">-- True</span><span>
</span><span id="line-1845"></span><span class="annot"><a href="Torch.Typed.Functional.html#allclose"><span class="hs-identifier hs-type">allclose</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1846"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709554"><span class="annot"><a href="#local-6989586621679709554"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709553"><span class="annot"><a href="#local-6989586621679709553"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709552"><span class="annot"><a href="#local-6989586621679709552"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1847"></span><span>  </span><span class="hs-comment">-- | relative tolerance</span><span>
</span><span id="line-1848"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1849"></span><span>  </span><span class="hs-comment">-- | absolute tolerance</span><span>
</span><span id="line-1850"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1851"></span><span>  </span><span class="hs-comment">-- | whether or not NaN equals NaN</span><span>
</span><span id="line-1852"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1853"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1854"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709552"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709553"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709554"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1855"></span><span>  </span><span class="hs-comment">-- | other input tensor</span><span>
</span><span id="line-1856"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709552"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709553"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709554"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1857"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1858"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-1859"></span><span id="allclose"><span class="annot"><span class="annottext">allclose :: Double
-&gt; Double
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Bool
</span><a href="Torch.Typed.Functional.html#allclose"><span class="hs-identifier hs-var hs-var">allclose</span></a></span></span><span> </span><span id="local-6989586621679709551"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709551"><span class="hs-identifier hs-var">rtol</span></a></span></span><span> </span><span id="local-6989586621679709550"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709550"><span class="hs-identifier hs-var">atol</span></a></span></span><span> </span><span id="local-6989586621679709549"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709549"><span class="hs-identifier hs-var">equalNaN</span></a></span></span><span> </span><span id="local-6989586621679709548"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709548"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679709547"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709547"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1860"></span><span>  </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; CDouble -&gt; CDouble -&gt; CBool -&gt; IO CBool)
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Double
-&gt; Double
-&gt; Bool
-&gt; IO Bool
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; CDouble -&gt; CDouble -&gt; CBool -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.allclose_ttddb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709548"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709547"><span class="hs-identifier hs-var">other</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709551"><span class="hs-identifier hs-var">rtol</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679709550"><span class="hs-identifier hs-var">atol</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709549"><span class="hs-identifier hs-var">equalNaN</span></a></span><span>
</span><span id="line-1861"></span><span>
</span><span id="line-1862"></span><span class="hs-comment">-- | argmax</span><span>
</span><span id="line-1863"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/torch.html#torch.argmax.</span><span>
</span><span id="line-1864"></span><span class="hs-comment">--</span><span>
</span><span id="line-1865"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[0, 1], [-1, 2], [0, 1], [0, -2]] :: CPUTensor 'D.Float '[4, 2]</span><span>
</span><span id="line-1866"></span><span class="hs-comment">--</span><span>
</span><span id="line-1867"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Int]) $ argmax @1 @DropDim t</span><span>
</span><span id="line-1868"></span><span class="hs-comment">-- (Int64,([4],[1,1,1,0]))</span><span>
</span><span id="line-1869"></span><span class="hs-comment">--</span><span>
</span><span id="line-1870"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Int]]) $ argmax @1 @KeepDim t</span><span>
</span><span id="line-1871"></span><span class="hs-comment">-- (Int64,([4,1],[[1],[1],[1],[0]]))</span><span>
</span><span id="line-1872"></span><span class="hs-comment">--</span><span>
</span><span id="line-1873"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Int]) $ argmax @0 @DropDim t</span><span>
</span><span id="line-1874"></span><span class="hs-comment">-- (Int64,([2],[0,1]))</span><span>
</span><span id="line-1875"></span><span class="hs-comment">--</span><span>
</span><span id="line-1876"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Int]]) $ argmax @0 @KeepDim t</span><span>
</span><span id="line-1877"></span><span class="hs-comment">-- (Int64,([1,2],[[0,1]]))</span><span>
</span><span id="line-1878"></span><span class="annot"><a href="Torch.Typed.Functional.html#argmax"><span class="hs-identifier hs-type">argmax</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1879"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709544"><span class="annot"><a href="#local-6989586621679709544"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709543"><span class="annot"><a href="#local-6989586621679709543"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679709542"><span class="annot"><a href="#local-6989586621679709542"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709541"><span class="annot"><a href="#local-6989586621679709541"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709540"><span class="annot"><a href="#local-6989586621679709540"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709539"><span class="annot"><a href="#local-6989586621679709539"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1880"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709544"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1881"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709543"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1882"></span><span>    </span><span class="annot"><a href="#local-6989586621679709542"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709541"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709544"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709543"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1883"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709539"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709540"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1884"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1885"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1886"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709539"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709540"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709541"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1887"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1888"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709539"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709542"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1889"></span><span id="argmax"><span class="annot"><span class="annottext">argmax :: Tensor device dtype shape -&gt; Tensor device 'Int64 shape'
</span><a href="Torch.Typed.Functional.html#argmax"><span class="hs-identifier hs-var hs-var">argmax</span></a></span></span><span> </span><span id="local-6989586621679709538"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709538"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1890"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device 'Int64 shape') -&gt; Tensor device 'Int64 shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Int64 shape') -&gt; Tensor device 'Int64 shape')
-&gt; IO (Tensor device 'Int64 shape') -&gt; Tensor device 'Int64 shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1891"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device 'Int64 shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-1892"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.argmax_tlb</span></a></span><span>
</span><span id="line-1893"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709538"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1894"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709544"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1895"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709543"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1896"></span><span>
</span><span id="line-1897"></span><span class="hs-comment">-- | argmin</span><span>
</span><span id="line-1898"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/torch.html#torch.argmin.</span><span>
</span><span id="line-1899"></span><span class="hs-comment">--</span><span>
</span><span id="line-1900"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[0, 1], [-1, 2], [0, 1], [0, -2]] :: CPUTensor 'D.Float '[4, 2]</span><span>
</span><span id="line-1901"></span><span class="hs-comment">--</span><span>
</span><span id="line-1902"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Int]) $ argmin @1 @DropDim t</span><span>
</span><span id="line-1903"></span><span class="hs-comment">-- (Int64,([4],[0,0,0,1]))</span><span>
</span><span id="line-1904"></span><span class="hs-comment">--</span><span>
</span><span id="line-1905"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Int]]) $ argmin @1 @KeepDim t</span><span>
</span><span id="line-1906"></span><span class="hs-comment">-- (Int64,([4,1],[[0],[0],[0],[1]]))</span><span>
</span><span id="line-1907"></span><span class="hs-comment">--</span><span>
</span><span id="line-1908"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Int]) $ argmin @0 @DropDim t</span><span>
</span><span id="line-1909"></span><span class="hs-comment">-- (Int64,([2],[1,3]))</span><span>
</span><span id="line-1910"></span><span class="hs-comment">--</span><span>
</span><span id="line-1911"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Int]]) $ argmin @0 @KeepDim t</span><span>
</span><span id="line-1912"></span><span class="hs-comment">-- (Int64,([1,2],[[1,3]]))</span><span>
</span><span id="line-1913"></span><span class="annot"><a href="Torch.Typed.Functional.html#argmin"><span class="hs-identifier hs-type">argmin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1914"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709535"><span class="annot"><a href="#local-6989586621679709535"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709534"><span class="annot"><a href="#local-6989586621679709534"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679709533"><span class="annot"><a href="#local-6989586621679709533"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709532"><span class="annot"><a href="#local-6989586621679709532"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709531"><span class="annot"><a href="#local-6989586621679709531"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709530"><span class="annot"><a href="#local-6989586621679709530"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1915"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709535"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1916"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709534"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1917"></span><span>    </span><span class="annot"><a href="#local-6989586621679709533"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709532"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709535"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709534"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1918"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709530"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709531"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-1919"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1920"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1921"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709530"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709531"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709532"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1922"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1923"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709530"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709533"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1924"></span><span id="argmin"><span class="annot"><span class="annottext">argmin :: Tensor device dtype shape -&gt; Tensor device 'Int64 shape'
</span><a href="Torch.Typed.Functional.html#argmin"><span class="hs-identifier hs-var hs-var">argmin</span></a></span></span><span> </span><span id="local-6989586621679709529"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709529"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1925"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device 'Int64 shape') -&gt; Tensor device 'Int64 shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Int64 shape') -&gt; Tensor device 'Int64 shape')
-&gt; IO (Tensor device 'Int64 shape') -&gt; Tensor device 'Int64 shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1926"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device 'Int64 shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-1927"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.argmin_tlb</span></a></span><span>
</span><span id="line-1928"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709529"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1929"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709535"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1930"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709534"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1931"></span><span>
</span><span id="line-1932"></span><span class="hs-comment">-- as_strided :: Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-1933"></span><span class="hs-comment">-- as_strided _input _size _stride _storage_offset = unsafePerformIO $ (ATen.cast4 ATen.Managed.as_strided_tlll) _input _size _stride _storage_offset</span><span>
</span><span id="line-1934"></span><span>
</span><span id="line-1935"></span><span class="hs-comment">-- | asin</span><span>
</span><span id="line-1936"></span><span class="hs-comment">--</span><span>
</span><span id="line-1937"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ asin (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1938"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1939"></span><span class="annot"><a href="Torch.Typed.Functional.html#asin"><span class="hs-identifier hs-type">asin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1940"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709526"><span class="annot"><a href="#local-6989586621679709526"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709525"><span class="annot"><a href="#local-6989586621679709525"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709524"><span class="annot"><a href="#local-6989586621679709524"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1941"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709524"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709525"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1942"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709524"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709525"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709526"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1943"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709524"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709525"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709526"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1944"></span><span id="asin"><span class="annot"><span class="annottext">asin :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#asin"><span class="hs-identifier hs-var hs-var">asin</span></a></span></span><span> </span><span id="local-6989586621679709523"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709523"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.asin_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709523"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1945"></span><span>
</span><span id="line-1946"></span><span class="hs-comment">-- | atan</span><span>
</span><span id="line-1947"></span><span class="hs-comment">--</span><span>
</span><span id="line-1948"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ atan (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-1949"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-1950"></span><span class="annot"><a href="Torch.Typed.Functional.html#atan"><span class="hs-identifier hs-type">atan</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1951"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709520"><span class="annot"><a href="#local-6989586621679709520"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709519"><span class="annot"><a href="#local-6989586621679709519"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709518"><span class="annot"><a href="#local-6989586621679709518"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1952"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709518"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709519"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1953"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709518"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709519"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709520"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1954"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709518"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709519"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709520"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1955"></span><span id="atan"><span class="annot"><span class="annottext">atan :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#atan"><span class="hs-identifier hs-var hs-var">atan</span></a></span></span><span> </span><span id="local-6989586621679709517"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709517"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.atan_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709517"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1956"></span><span>
</span><span id="line-1957"></span><span class="hs-comment">-- | baddbmm</span><span>
</span><span id="line-1958"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-1959"></span><span class="hs-comment">--</span><span>
</span><span id="line-1960"></span><span class="hs-comment">-- &gt;&gt;&gt; t = baddbmm 1 1 (ones :: CPUTensor 'D.Float '[5,3,2]) (zeros :: CPUTensor 'D.Float '[5,2,4]) (ones :: CPUTensor 'D.Float '[])</span><span>
</span><span id="line-1961"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-1962"></span><span class="hs-comment">-- (Float,[5,3,4])</span><span>
</span><span id="line-1963"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-1964"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[5, 3, 4]</span><span>
</span><span id="line-1965"></span><span class="annot"><a href="Torch.Typed.Functional.html#baddbmm"><span class="hs-identifier hs-type">baddbmm</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1966"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709514"><span class="annot"><a href="#local-6989586621679709514"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709513"><span class="annot"><a href="#local-6989586621679709513"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709512"><span class="annot"><a href="#local-6989586621679709512"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679709511"><span class="annot"><a href="#local-6989586621679709511"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709510"><span class="annot"><a href="#local-6989586621679709510"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679709509"><span class="annot"><a href="#local-6989586621679709509"><span class="hs-identifier hs-type">k</span></a></span></span><span> </span><span id="local-6989586621679709508"><span class="annot"><a href="#local-6989586621679709508"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709507"><span class="annot"><a href="#local-6989586621679709507"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1967"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709511"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1968"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709510"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1969"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709509"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1970"></span><span>    </span><span class="annot"><a href="#local-6989586621679709514"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709513"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709512"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709511"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709510"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1971"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1972"></span><span>  </span><span class="hs-comment">-- | beta</span><span>
</span><span id="line-1973"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1974"></span><span>  </span><span class="hs-comment">-- | alpha</span><span>
</span><span id="line-1975"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1976"></span><span>  </span><span class="hs-comment">-- | first batch</span><span>
</span><span id="line-1977"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709507"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709512"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709511"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709509"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1978"></span><span>  </span><span class="hs-comment">-- | second batch</span><span>
</span><span id="line-1979"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709507"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709512"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709509"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709510"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1980"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1981"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709507"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709513"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1982"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1983"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709507"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709514"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-1984"></span><span id="baddbmm"><span class="annot"><span class="annottext">baddbmm :: Float
-&gt; Float
-&gt; Tensor device dtype '[batchSize, n, k]
-&gt; Tensor device dtype '[batchSize, k, m]
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#baddbmm"><span class="hs-identifier hs-var hs-var">baddbmm</span></a></span></span><span> </span><span id="local-6989586621679709506"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709506"><span class="hs-identifier hs-var">beta</span></a></span></span><span> </span><span id="local-6989586621679709505"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709505"><span class="hs-identifier hs-var">alpha</span></a></span></span><span> </span><span id="local-6989586621679709504"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, n, k]
</span><a href="#local-6989586621679709504"><span class="hs-identifier hs-var">batch1</span></a></span></span><span> </span><span id="local-6989586621679709503"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, k, m]
</span><a href="#local-6989586621679709503"><span class="hs-identifier hs-var">batch2</span></a></span></span><span> </span><span id="local-6989586621679709502"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709502"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype '[batchSize, n, k]
-&gt; Tensor device dtype '[batchSize, k, m]
-&gt; Float
-&gt; Float
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.baddbmm_tttss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709502"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, n, k]
</span><a href="#local-6989586621679709504"><span class="hs-identifier hs-var">batch1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, k, m]
</span><a href="#local-6989586621679709503"><span class="hs-identifier hs-var">batch2</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709506"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709505"><span class="hs-identifier hs-var">alpha</span></a></span><span>
</span><span id="line-1985"></span><span>
</span><span id="line-1986"></span><span class="hs-comment">-- batch_norm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Double -&gt; Double -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-1987"></span><span class="hs-comment">-- batch_norm _input _weight _bias _running_mean _running_var _training _momentum _eps _cudnn_enabled = unsafePerformIO $ (ATen.cast9 ATen.Managed.batch_norm_tttttbddb) _input _weight _bias _running_mean _running_var _training _momentum _eps _cudnn_enabled</span><span>
</span><span id="line-1988"></span><span>
</span><span id="line-1989"></span><span class="hs-comment">-- bilinear :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-1990"></span><span class="hs-comment">-- bilinear _input1 _input2 _weight _bias = unsafePerformIO $ (ATen.cast4 ATen.Managed.bilinear_tttt) _input1 _input2 _weight _bias</span><span>
</span><span id="line-1991"></span><span>
</span><span id="line-1992"></span><span class="hs-comment">-- binary_cross_entropy_with_logits :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-1993"></span><span class="hs-comment">-- binary_cross_entropy_with_logits _input _target _weight _pos_weight _reduction = unsafePerformIO $ (ATen.cast5 ATen.Managed.binary_cross_entropy_with_logits_ttttl) _input _target _weight _pos_weight _reduction</span><span>
</span><span id="line-1994"></span><span>
</span><span id="line-1995"></span><span class="hs-comment">-- bincount :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-1996"></span><span class="hs-comment">-- bincount _input _weights _minlength = unsafePerformIO $ (ATen.cast3 ATen.Managed.bincount_ttl) _input _weights _minlength</span><span>
</span><span id="line-1997"></span><span>
</span><span id="line-1998"></span><span class="hs-comment">-- | batched matrix multiplication</span><span>
</span><span id="line-1999"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2000"></span><span class="hs-comment">--</span><span>
</span><span id="line-2001"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ bmm (ones :: CPUTensor 'D.Float '[5,3,2]) (zeros :: CPUTensor 'D.Float '[5,2,4])</span><span>
</span><span id="line-2002"></span><span class="hs-comment">-- (Float,[5,3,4])</span><span>
</span><span id="line-2003"></span><span class="annot"><a href="Torch.Typed.Functional.html#bmm"><span class="hs-identifier hs-type">bmm</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2004"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709499"><span class="annot"><a href="#local-6989586621679709499"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679709498"><span class="annot"><a href="#local-6989586621679709498"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709497"><span class="annot"><a href="#local-6989586621679709497"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679709496"><span class="annot"><a href="#local-6989586621679709496"><span class="hs-identifier hs-type">k</span></a></span></span><span> </span><span id="local-6989586621679709495"><span class="annot"><a href="#local-6989586621679709495"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709494"><span class="annot"><a href="#local-6989586621679709494"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2005"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2006"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709494"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709495"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709499"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709498"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709496"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2007"></span><span>  </span><span class="hs-comment">-- | other input</span><span>
</span><span id="line-2008"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709494"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709495"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709499"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709496"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709497"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2009"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2010"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709494"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709495"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709499"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709498"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709497"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2011"></span><span id="bmm"><span class="annot"><span class="annottext">bmm :: Tensor device dtype '[batchSize, n, k]
-&gt; Tensor device dtype '[batchSize, k, m]
-&gt; Tensor device dtype '[batchSize, n, m]
</span><a href="Torch.Typed.Functional.html#bmm"><span class="hs-identifier hs-var hs-var">bmm</span></a></span></span><span> </span><span id="local-6989586621679709493"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, n, k]
</span><a href="#local-6989586621679709493"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679709492"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, k, m]
</span><a href="#local-6989586621679709492"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, n, m])
-&gt; Tensor device dtype '[batchSize, n, m]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, n, m])
 -&gt; Tensor device dtype '[batchSize, n, m])
-&gt; IO (Tensor device dtype '[batchSize, n, m])
-&gt; Tensor device dtype '[batchSize, n, m]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, n, k]
-&gt; Tensor device dtype '[batchSize, k, m]
-&gt; IO (Tensor device dtype '[batchSize, n, m])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.bmm_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, n, k]
</span><a href="#local-6989586621679709493"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, k, m]
</span><a href="#local-6989586621679709492"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-2012"></span><span>
</span><span id="line-2013"></span><span class="hs-comment">-- | BroadcastTensorsImpl</span><span>
</span><span id="line-2014"></span><span class="hs-comment">--</span><span>
</span><span id="line-2015"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = BroadcastTensorsImpl '[] 'Nothing</span><span>
</span><span id="line-2016"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2017"></span><span class="hs-comment">-- Ty :: Maybe ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2018"></span><span class="hs-comment">-- = 'Nothing</span><span>
</span><span id="line-2019"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = BroadcastTensorsImpl '[Tensor '( 'D.CPU, 0) 'D.Float '[1, 3], Tensor '( 'D.CPU, 0) 'D.Float '[2, 1]] 'Nothing</span><span>
</span><span id="line-2020"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2021"></span><span class="hs-comment">-- Ty :: Maybe ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2022"></span><span class="hs-comment">-- = 'Just '( '[2, 3], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-2023"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = BroadcastTensorsImpl '[Tensor '( 'D.CPU, 0) 'D.Float '[1, 3], Tensor '( 'D.CPU, 0) 'D.Float '[2, 1], Tensor '( 'D.CPU, 0) 'D.Float '[5, 1, 1]] 'Nothing</span><span>
</span><span id="line-2024"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2025"></span><span class="hs-comment">-- Ty :: Maybe ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2026"></span><span class="hs-comment">-- = 'Just '( '[5, 2, 3], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-2027"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = BroadcastTensorsImpl '[Tensor '( 'D.CPU, 0) 'D.Float '[1, 3], Tensor '( 'D.CPU, 0) 'D.Float '[2, 1], Tensor '( 'D.CPU, 0) 'D.Float '[1, 5, 1]] 'Nothing</span><span>
</span><span id="line-2028"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2029"></span><span class="hs-comment">-- Ty :: Maybe ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2030"></span><span class="hs-comment">-- = 'Nothing</span><span>
</span><span id="line-2031"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="BroadcastTensorsImpl"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-var">BroadcastTensorsImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709489"><span class="annot"><a href="#local-6989586621679709489"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679709488"><span class="annot"><a href="#local-6989586621679709488"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709487"><span class="annot"><a href="#local-6989586621679709487"><span class="hs-identifier hs-type">acc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2032"></span><span>  </span><span id="BroadcastTensorsImpl"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-var">BroadcastTensorsImpl</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2033"></span><span>  </span><span id="BroadcastTensorsImpl"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-var">BroadcastTensorsImpl</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709486"><span class="annot"><a href="#local-6989586621679709486"><span class="hs-identifier hs-type hs-type">reverseShape</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709485"><span class="annot"><a href="#local-6989586621679709485"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709484"><span class="annot"><a href="#local-6989586621679709484"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709486"><span class="hs-identifier hs-type">reverseShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709485"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709484"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2034"></span><span>  </span><span id="BroadcastTensorsImpl"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-var">BroadcastTensorsImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679709483"><span class="annot"><a href="#local-6989586621679709483"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709482"><span class="annot"><a href="#local-6989586621679709482"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709481"><span class="annot"><a href="#local-6989586621679709481"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709480"><span class="annot"><a href="#local-6989586621679709480"><span class="hs-identifier hs-type hs-type">tensors</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-type">BroadcastTensorsImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709480"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709481"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709482"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709483"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2035"></span><span>  </span><span id="BroadcastTensorsImpl"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-var">BroadcastTensorsImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679709479"><span class="annot"><a href="#local-6989586621679709479"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709478"><span class="annot"><a href="#local-6989586621679709478"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709477"><span class="annot"><a href="#local-6989586621679709477"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709476"><span class="annot"><a href="#local-6989586621679709476"><span class="hs-identifier hs-type hs-type">tensors</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709475"><span class="annot"><a href="#local-6989586621679709475"><span class="hs-identifier hs-type hs-type">reverseShape'</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709478"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709479"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-type">BroadcastTensorsImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709476"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-type">MaybeTriple</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#ComputeBroadcast"><span class="hs-identifier hs-type">ComputeBroadcast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709477"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709475"><span class="hs-identifier hs-type">reverseShape'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709478"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709479"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2036"></span><span>  </span><span id="BroadcastTensorsImpl"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-var">BroadcastTensorsImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679709472"><span class="annot"><a href="#local-6989586621679709472"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709471"><span class="annot"><a href="#local-6989586621679709471"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709470"><span class="annot"><a href="#local-6989586621679709470"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2037"></span><span>
</span><span id="line-2038"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="BroadcastTensorsCheck"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsCheck"><span class="hs-identifier hs-var">BroadcastTensorsCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709468"><span class="annot"><a href="#local-6989586621679709468"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679709467"><span class="annot"><a href="#local-6989586621679709467"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709466"><span class="annot"><a href="#local-6989586621679709466"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709467"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2039"></span><span>  </span><span id="BroadcastTensorsCheck"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsCheck"><span class="hs-identifier hs-var">BroadcastTensorsCheck</span></a></span></span><span> </span><span id="local-6989586621679709465"><span class="annot"><a href="#local-6989586621679709465"><span class="hs-identifier hs-type hs-type">tensors</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2040"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-2041"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Cannot broadcast tensors due to incompatible shapes and/or dtypes: &quot;</span></span><span>
</span><span id="line-2042"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709465"><span class="hs-identifier hs-type">tensors</span></a></span><span>
</span><span id="line-2043"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-2044"></span><span>  </span><span id="BroadcastTensorsCheck"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsCheck"><span class="hs-identifier hs-var">BroadcastTensorsCheck</span></a></span></span><span> </span><span id="local-6989586621679709464"><span class="annot"><a href="#local-6989586621679709464"><span class="hs-identifier hs-type hs-type">tensors</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709463"><span class="annot"><a href="#local-6989586621679709463"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709462"><span class="annot"><a href="#local-6989586621679709462"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709461"><span class="annot"><a href="#local-6989586621679709461"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.HList.html#HReplicateR"><span class="hs-identifier hs-type">HReplicateR</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#ListLength"><span class="hs-identifier hs-type">ListLength</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709464"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709461"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709462"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709463"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2045"></span><span>
</span><span id="line-2046"></span><span class="hs-keyword">type</span><span> </span><span id="BroadcastTensors"><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensors"><span class="hs-identifier hs-var">BroadcastTensors</span></a></span></span><span> </span><span id="local-6989586621679709458"><span class="annot"><a href="#local-6989586621679709458"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2047"></span><span>  </span><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsCheck"><span class="hs-identifier hs-type">BroadcastTensorsCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709458"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensorsImpl"><span class="hs-identifier hs-type">BroadcastTensorsImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709458"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-2048"></span><span>
</span><span id="line-2049"></span><span class="hs-comment">-- | broadcast tensors</span><span>
</span><span id="line-2050"></span><span class="hs-comment">-- TODO: broadcastTensors returns garbage data and is hence broken</span><span>
</span><span id="line-2051"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/_modules/torch/functional.html#broadcast_tensors.</span><span>
</span><span id="line-2052"></span><span class="hs-comment">--</span><span>
</span><span id="line-2053"></span><span class="hs-comment">-- &gt;&gt;&gt; x = ones :: CPUTensor 'D.Float '[1, 3]</span><span>
</span><span id="line-2054"></span><span class="hs-comment">-- &gt;&gt;&gt; y = ones :: CPUTensor 'D.Float '[2, 1]</span><span>
</span><span id="line-2055"></span><span class="hs-comment">-- &gt;&gt;&gt; z = ones :: CPUTensor 'D.Float '[5, 1, 1]</span><span>
</span><span id="line-2056"></span><span class="hs-comment">--</span><span>
</span><span id="line-2057"></span><span class="hs-comment">-- -- &gt;&gt;&gt; x' :. y' :. z' :. HNil = broadcastTensors (x :. y :. z :. HNil)</span><span>
</span><span id="line-2058"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :type x'</span><span>
</span><span id="line-2059"></span><span class="hs-comment">-- -- x' :: Tensor '( 'D.CPU, 0) 'D.Float '[5, 2, 3]</span><span>
</span><span id="line-2060"></span><span class="hs-comment">-- -- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t -&gt; D.asValue (toDynamic t) :: [[[Float]]]) $ x'</span><span>
</span><span id="line-2061"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :type y'</span><span>
</span><span id="line-2062"></span><span class="hs-comment">-- -- y' :: Tensor '( 'D.CPU, 0) 'D.Float '[5, 2, 3]</span><span>
</span><span id="line-2063"></span><span class="hs-comment">-- -- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t -&gt; D.asValue (toDynamic t) :: [[[Float]]]) $ y'</span><span>
</span><span id="line-2064"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :type z'</span><span>
</span><span id="line-2065"></span><span class="hs-comment">-- -- z' :: Tensor '( 'D.CPU, 0) 'D.Float '[5, 2, 3]</span><span>
</span><span id="line-2066"></span><span class="hs-comment">-- -- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t -&gt; D.asValue (toDynamic t) :: [[[Float]]]) $ z'</span><span>
</span><span id="line-2067"></span><span class="annot"><a href="Torch.Typed.Functional.html#broadcastTensors"><span class="hs-identifier hs-type">broadcastTensors</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2068"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709456"><span class="annot"><a href="#local-6989586621679709456"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span id="local-6989586621679709455"><span class="annot"><a href="#local-6989586621679709455"><span class="hs-identifier hs-type">tensors'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2069"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679709455"><span class="hs-identifier hs-type">tensors'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#BroadcastTensors"><span class="hs-identifier hs-type">BroadcastTensors</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709456"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2070"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709456"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-2071"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709455"><span class="hs-identifier hs-type">tensors'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2072"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2073"></span><span>  </span><span class="hs-comment">-- | input list of tensors</span><span>
</span><span id="line-2074"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709456"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2075"></span><span>  </span><span class="hs-comment">-- | output list of tensors</span><span>
</span><span id="line-2076"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709455"><span class="hs-identifier hs-type">tensors'</span></a></span><span>
</span><span id="line-2077"></span><span id="broadcastTensors"><span class="annot"><span class="annottext">broadcastTensors :: HList tensors -&gt; HList tensors'
</span><a href="Torch.Typed.Functional.html#broadcastTensors"><span class="hs-identifier hs-var hs-var">broadcastTensors</span></a></span></span><span> </span><span id="local-6989586621679709453"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679709453"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (HList tensors') -&gt; HList tensors'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (HList tensors') -&gt; HList tensors')
-&gt; IO (HList tensors') -&gt; HList tensors'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr TensorList -&gt; IO (ForeignPtr TensorList))
-&gt; HList tensors -&gt; IO (HList tensors')
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO (ForeignPtr TensorList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.broadcast_tensors_l</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679709453"><span class="hs-identifier hs-var">tensors</span></a></span><span>
</span><span id="line-2078"></span><span>
</span><span id="line-2079"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="CatImpl"><span class="annot"><a href="Torch.Typed.Functional.html#CatImpl"><span class="hs-identifier hs-var">CatImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709450"><span class="annot"><a href="#local-6989586621679709450"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709449"><span class="annot"><a href="#local-6989586621679709449"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679709448"><span class="annot"><a href="#local-6989586621679709448"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709447"><span class="annot"><a href="#local-6989586621679709447"><span class="hs-identifier hs-type">acc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2080"></span><span>  </span><span id="CatImpl"><span class="annot"><a href="Torch.Typed.Functional.html#CatImpl"><span class="hs-identifier hs-var">CatImpl</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679709446"><span class="annot"><a href="#local-6989586621679709446"><span class="hs-identifier hs-type hs-type">acc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709446"><span class="hs-identifier hs-type">acc</span></a></span><span>
</span><span id="line-2081"></span><span>  </span><span id="CatImpl"><span class="annot"><a href="Torch.Typed.Functional.html#CatImpl"><span class="hs-identifier hs-var">CatImpl</span></a></span></span><span> </span><span id="local-6989586621679709445"><span class="annot"><a href="#local-6989586621679709445"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679709444"><span class="annot"><a href="#local-6989586621679709444"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709443"><span class="annot"><a href="#local-6989586621679709443"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709442"><span class="annot"><a href="#local-6989586621679709442"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709441"><span class="annot"><a href="#local-6989586621679709441"><span class="hs-identifier hs-type hs-type">tensors</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709440"><span class="annot"><a href="#local-6989586621679709440"><span class="hs-identifier hs-type hs-type">acc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#CatImpl"><span class="hs-identifier hs-type">CatImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709445"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709441"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-type">MaybeTriple</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-type">ComputeCatShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709445"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709442"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709440"><span class="hs-identifier hs-type">acc</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDType"><span class="hs-identifier hs-type">ComputeCatDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709443"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709440"><span class="hs-identifier hs-type">acc</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDevice"><span class="hs-identifier hs-type">ComputeCatDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709444"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709440"><span class="hs-identifier hs-type">acc</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2082"></span><span>
</span><span id="line-2083"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeCatShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-var">ComputeCatShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709436"><span class="annot"><a href="#local-6989586621679709436"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709435"><span class="annot"><a href="#local-6989586621679709435"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709434"><span class="annot"><a href="#local-6989586621679709434"><span class="hs-identifier hs-type">acc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2084"></span><span>  </span><span id="ComputeCatShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-var">ComputeCatShape</span></a></span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709433"><span class="annot"><a href="#local-6989586621679709433"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709432"><span class="annot"><a href="#local-6989586621679709432"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709433"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679709432"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2085"></span><span>  </span><span id="ComputeCatShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-var">ComputeCatShape</span></a></span></span><span> </span><span id="local-6989586621679709431"><span class="annot"><a href="#local-6989586621679709431"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709430"><span class="annot"><a href="#local-6989586621679709430"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709429"><span class="annot"><a href="#local-6989586621679709429"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe"><span class="hs-identifier hs-type">AppendToMaybe</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709430"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-type">ComputeCatShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709431"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709429"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-2086"></span><span>  </span><span id="ComputeCatShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-var">ComputeCatShape</span></a></span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709427"><span class="annot"><a href="#local-6989586621679709427"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709426"><span class="annot"><a href="#local-6989586621679709426"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709425"><span class="annot"><a href="#local-6989586621679709425"><span class="hs-identifier hs-type hs-type">y</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679709426"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709427"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709425"><span class="hs-identifier hs-type">y</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679709426"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2087"></span><span>  </span><span id="ComputeCatShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-var">ComputeCatShape</span></a></span></span><span> </span><span id="local-6989586621679709424"><span class="annot"><a href="#local-6989586621679709424"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709423"><span class="annot"><a href="#local-6989586621679709423"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709422"><span class="annot"><a href="#local-6989586621679709422"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709423"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709421"><span class="annot"><a href="#local-6989586621679709421"><span class="hs-identifier hs-type hs-type">ys</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709420"><span class="annot"><a href="#local-6989586621679709420"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709419"><span class="annot"><a href="#local-6989586621679709419"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe"><span class="hs-identifier hs-type">AppendToMaybe</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709423"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-type">ComputeCatShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709424"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709422"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709421"><span class="hs-identifier hs-type">ys</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709420"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709419"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2088"></span><span>  </span><span id="ComputeCatShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatShape"><span class="hs-identifier hs-var">ComputeCatShape</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2089"></span><span>
</span><span id="line-2090"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeCatDType"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDType"><span class="hs-identifier hs-var">ComputeCatDType</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709418"><span class="annot"><a href="#local-6989586621679709418"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709417"><span class="annot"><a href="#local-6989586621679709417"><span class="hs-identifier hs-type">acc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2091"></span><span>  </span><span id="ComputeCatDType"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDType"><span class="hs-identifier hs-var">ComputeCatDType</span></a></span></span><span> </span><span id="local-6989586621679709416"><span class="annot"><a href="#local-6989586621679709416"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709416"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2092"></span><span>  </span><span id="ComputeCatDType"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDType"><span class="hs-identifier hs-var">ComputeCatDType</span></a></span></span><span> </span><span id="local-6989586621679709415"><span class="annot"><a href="#local-6989586621679709415"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709415"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709415"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2093"></span><span>  </span><span id="ComputeCatDType"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDType"><span class="hs-identifier hs-var">ComputeCatDType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2094"></span><span>
</span><span id="line-2095"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeCatDevice"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDevice"><span class="hs-identifier hs-var">ComputeCatDevice</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709414"><span class="annot"><a href="#local-6989586621679709414"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709413"><span class="annot"><a href="#local-6989586621679709413"><span class="hs-identifier hs-type">acc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2096"></span><span>  </span><span id="ComputeCatDevice"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDevice"><span class="hs-identifier hs-var">ComputeCatDevice</span></a></span></span><span> </span><span id="local-6989586621679709412"><span class="annot"><a href="#local-6989586621679709412"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709412"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-2097"></span><span>  </span><span id="ComputeCatDevice"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDevice"><span class="hs-identifier hs-var">ComputeCatDevice</span></a></span></span><span> </span><span id="local-6989586621679709411"><span class="annot"><a href="#local-6989586621679709411"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709411"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709411"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-2098"></span><span>  </span><span id="ComputeCatDevice"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeCatDevice"><span class="hs-identifier hs-var">ComputeCatDevice</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2099"></span><span>
</span><span id="line-2100"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="CatCheck"><span class="annot"><a href="Torch.Typed.Functional.html#CatCheck"><span class="hs-identifier hs-var">CatCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709409"><span class="annot"><a href="#local-6989586621679709409"><span class="hs-identifier hs-type">res</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2101"></span><span>  </span><span id="CatCheck"><span class="annot"><a href="Torch.Typed.Functional.html#CatCheck"><span class="hs-identifier hs-var">CatCheck</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Concatenation impossible.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-2102"></span><span>  </span><span id="CatCheck"><span class="annot"><a href="Torch.Typed.Functional.html#CatCheck"><span class="hs-identifier hs-var">CatCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709408"><span class="annot"><a href="#local-6989586621679709408"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709407"><span class="annot"><a href="#local-6989586621679709407"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709406"><span class="annot"><a href="#local-6989586621679709406"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709408"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709407"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709406"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2103"></span><span>
</span><span id="line-2104"></span><span class="hs-comment">-- | Cat</span><span>
</span><span id="line-2105"></span><span class="hs-comment">--</span><span>
</span><span id="line-2106"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Cat 0 '[Tensor '( 'D.CPU, 0) 'D.Float '[1]]</span><span>
</span><span id="line-2107"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2108"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2109"></span><span class="hs-comment">-- = '( '[1], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-2110"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Cat 0 '[Tensor '( 'D.CPU, 0) 'D.Float '[1], Tensor '( 'D.CPU, 0) 'D.Float '[2]]</span><span>
</span><span id="line-2111"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2112"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2113"></span><span class="hs-comment">-- = '( '[3], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-2114"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Cat 0 '[Tensor '( 'D.CPU, 0) 'D.Float '[1, 3], Tensor '( 'D.CPU, 0) 'D.Float '[2, 3]]</span><span>
</span><span id="line-2115"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2116"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2117"></span><span class="hs-comment">-- = '( '[3, 3], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-2118"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Cat 1 '[Tensor '( 'D.CPU, 0) 'D.Float '[3, 1], Tensor '( 'D.CPU, 0) 'D.Float '[3, 2]]</span><span>
</span><span id="line-2119"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2120"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2121"></span><span class="hs-comment">-- = '( '[3, 3], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-2122"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Cat 1 '[Tensor '( 'D.CPU, 0) 'D.Float '[2, 5, 4, 2], Tensor '( 'D.CPU, 0) 'D.Float '[2, 1, 4, 2], Tensor '( 'D.CPU, 0) 'D.Float '[2, 3, 4, 2], Tensor '( 'D.CPU, 0) 'D.Float '[2, 1, 4, 2]]</span><span>
</span><span id="line-2123"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-2124"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-2125"></span><span class="hs-comment">-- = '( '[2, 10, 4, 2], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-2126"></span><span class="hs-keyword">type</span><span> </span><span id="Cat"><span class="annot"><a href="Torch.Typed.Functional.html#Cat"><span class="hs-identifier hs-var">Cat</span></a></span></span><span> </span><span id="local-6989586621679709404"><span class="annot"><a href="#local-6989586621679709404"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709403"><span class="annot"><a href="#local-6989586621679709403"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#CatCheck"><span class="hs-identifier hs-type">CatCheck</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#CatImpl"><span class="hs-identifier hs-type">CatImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709404"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709403"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-2127"></span><span>
</span><span id="line-2128"></span><span class="hs-comment">-- | cat</span><span>
</span><span id="line-2129"></span><span class="hs-comment">--</span><span>
</span><span id="line-2130"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2,2]</span><span>
</span><span id="line-2131"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = cat @0 (t :. HNil)</span><span>
</span><span id="line-2132"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-2133"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 2]</span><span>
</span><span id="line-2134"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[Float]]) $ t'</span><span>
</span><span id="line-2135"></span><span class="hs-comment">-- (Float,([2,2],[[1.0,1.0],[1.0,1.0]]))</span><span>
</span><span id="line-2136"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = cat @1 (t :. HNil)</span><span>
</span><span id="line-2137"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-2138"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 2]</span><span>
</span><span id="line-2139"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[Float]]) $ t'</span><span>
</span><span id="line-2140"></span><span class="hs-comment">-- (Float,([2,2],[[1.0,1.0],[1.0,1.0]]))</span><span>
</span><span id="line-2141"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = cat @0 (t :. t :. t :. HNil)</span><span>
</span><span id="line-2142"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-2143"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[6, 2]</span><span>
</span><span id="line-2144"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[Float]]) $ t'</span><span>
</span><span id="line-2145"></span><span class="hs-comment">-- (Float,([6,2],[[1.0,1.0],[1.0,1.0],[1.0,1.0],[1.0,1.0],[1.0,1.0],[1.0,1.0]]))</span><span>
</span><span id="line-2146"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = cat @1 (t :. t :. t :. HNil)</span><span>
</span><span id="line-2147"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-2148"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 6]</span><span>
</span><span id="line-2149"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[Float]]) $ t'</span><span>
</span><span id="line-2150"></span><span class="hs-comment">-- (Float,([2,6],[[1.0,1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0,1.0]]))</span><span>
</span><span id="line-2151"></span><span class="annot"><a href="Torch.Typed.Functional.html#cat"><span class="hs-identifier hs-type">cat</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2152"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709401"><span class="annot"><a href="#local-6989586621679709401"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709400"><span class="annot"><a href="#local-6989586621679709400"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709399"><span class="annot"><a href="#local-6989586621679709399"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709398"><span class="annot"><a href="#local-6989586621679709398"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709397"><span class="annot"><a href="#local-6989586621679709397"><span class="hs-identifier hs-type">tensors</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2153"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709401"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2154"></span><span>    </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709400"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709399"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709398"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Cat"><span class="hs-identifier hs-type">Cat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709401"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709397"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2155"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709397"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2156"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2157"></span><span>  </span><span class="hs-comment">-- | input list of tensors</span><span>
</span><span id="line-2158"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709397"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2159"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-2160"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709398"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709399"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709400"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2161"></span><span id="cat"><span class="annot"><span class="annottext">cat :: HList tensors -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#cat"><span class="hs-identifier hs-var hs-var">cat</span></a></span></span><span> </span><span id="local-6989586621679709396"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679709396"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; HList tensors -&gt; Int -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.cat_ll</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679709396"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709401"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2162"></span><span>
</span><span id="line-2163"></span><span class="hs-comment">-- chain_matmul :: [Tensor device dtype shape] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2164"></span><span class="hs-comment">-- chain_matmul _matrices = unsafePerformIO $ (ATen.cast1 ATen.Managed.chain_matmul_l) _matrices</span><span>
</span><span id="line-2165"></span><span>
</span><span id="line-2166"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ChunkImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkImpl"><span class="hs-identifier hs-var">ChunkImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709393"><span class="annot"><a href="#local-6989586621679709393"><span class="hs-identifier hs-type">chunkShapes</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709392"><span class="annot"><a href="#local-6989586621679709392"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709391"><span class="annot"><a href="#local-6989586621679709391"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679709390"><span class="annot"><a href="#local-6989586621679709390"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2167"></span><span>  </span><span id="ChunkImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkImpl"><span class="hs-identifier hs-var">ChunkImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-2168"></span><span>  </span><span id="ChunkImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkImpl"><span class="hs-identifier hs-var">ChunkImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709389"><span class="annot"><a href="#local-6989586621679709389"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709388"><span class="annot"><a href="#local-6989586621679709388"><span class="hs-identifier hs-type hs-type">shapes</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709387"><span class="annot"><a href="#local-6989586621679709387"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709386"><span class="annot"><a href="#local-6989586621679709386"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe"><span class="hs-identifier hs-type">AppendToMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709386"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709387"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709389"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ChunkImpl"><span class="hs-identifier hs-type">ChunkImpl</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709388"><span class="hs-identifier hs-type">shapes</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709387"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709386"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2169"></span><span>  </span><span id="ChunkImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkImpl"><span class="hs-identifier hs-var">ChunkImpl</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2170"></span><span>
</span><span id="line-2171"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ChunkCheck"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkCheck"><span class="hs-identifier hs-var">ChunkCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709384"><span class="annot"><a href="#local-6989586621679709384"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709383"><span class="annot"><a href="#local-6989586621679709383"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709382"><span class="annot"><a href="#local-6989586621679709382"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679709381"><span class="annot"><a href="#local-6989586621679709381"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679709381"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2172"></span><span>  </span><span id="ChunkCheck"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkCheck"><span class="hs-identifier hs-var">ChunkCheck</span></a></span></span><span> </span><span id="local-6989586621679709380"><span class="annot"><a href="#local-6989586621679709380"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709379"><span class="annot"><a href="#local-6989586621679709379"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DimOutOfBound"><span class="hs-identifier hs-type">DimOutOfBound</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709380"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709379"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-2173"></span><span>  </span><span id="ChunkCheck"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkCheck"><span class="hs-identifier hs-var">ChunkCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679709377"><span class="annot"><a href="#local-6989586621679709377"><span class="hs-identifier hs-type hs-type">result</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709377"><span class="hs-identifier hs-type">result</span></a></span><span>
</span><span id="line-2174"></span><span>
</span><span id="line-2175"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeChunksChunkGo"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-var">ComputeChunksChunkGo</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709375"><span class="annot"><a href="#local-6989586621679709375"><span class="hs-identifier hs-type">n'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709374"><span class="annot"><a href="#local-6989586621679709374"><span class="hs-identifier hs-type">r</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709373"><span class="annot"><a href="#local-6989586621679709373"><span class="hs-identifier hs-type">cmp</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Ordering</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709372"><span class="annot"><a href="#local-6989586621679709372"><span class="hs-identifier hs-type">cmp'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Ordering</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2176"></span><span>  </span><span id="ComputeChunksChunkGo"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-var">ComputeChunksChunkGo</span></a></span></span><span> </span><span id="local-6989586621679709371"><span class="annot"><a href="#local-6989586621679709371"><span class="hs-identifier hs-type hs-type">n'</span></a></span></span><span> </span><span id="local-6989586621679709370"><span class="annot"><a href="#local-6989586621679709370"><span class="hs-identifier hs-type hs-type">r</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">GT</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709371"><span class="hs-identifier hs-type">n'</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-type">ComputeChunksChunkGo</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709371"><span class="hs-identifier hs-type">n'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709370"><span class="hs-identifier hs-type">r</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709371"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709370"><span class="hs-identifier hs-type">r</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709371"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709371"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709370"><span class="hs-identifier hs-type">r</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709371"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span>
</span><span id="line-2177"></span><span>  </span><span id="ComputeChunksChunkGo"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-var">ComputeChunksChunkGo</span></a></span></span><span> </span><span id="local-6989586621679709369"><span class="annot"><a href="#local-6989586621679709369"><span class="hs-identifier hs-type hs-type">n'</span></a></span></span><span> </span><span id="local-6989586621679709368"><span class="annot"><a href="#local-6989586621679709368"><span class="hs-identifier hs-type hs-type">r</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">EQ</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709369"><span class="hs-identifier hs-type">n'</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-type">ComputeChunksChunkGo</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709369"><span class="hs-identifier hs-type">n'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709368"><span class="hs-identifier hs-type">r</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709369"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709368"><span class="hs-identifier hs-type">r</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709369"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709369"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709368"><span class="hs-identifier hs-type">r</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709369"><span class="hs-identifier hs-type">n'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span>
</span><span id="line-2178"></span><span>  </span><span id="ComputeChunksChunkGo"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-var">ComputeChunksChunkGo</span></a></span></span><span> </span><span id="local-6989586621679709367"><span class="annot"><a href="#local-6989586621679709367"><span class="hs-identifier hs-type hs-type">n'</span></a></span></span><span> </span><span id="local-6989586621679709366"><span class="annot"><a href="#local-6989586621679709366"><span class="hs-identifier hs-type hs-type">r</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">GT</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709366"><span class="hs-identifier hs-type">r</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2179"></span><span>  </span><span id="ComputeChunksChunkGo"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-var">ComputeChunksChunkGo</span></a></span></span><span> </span><span id="local-6989586621679709365"><span class="annot"><a href="#local-6989586621679709365"><span class="hs-identifier hs-type hs-type">n'</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-2180"></span><span>
</span><span id="line-2181"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeChunksChunkGo0"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo0"><span class="hs-identifier hs-var">ComputeChunksChunkGo0</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709363"><span class="annot"><a href="#local-6989586621679709363"><span class="hs-identifier hs-type">n'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709362"><span class="annot"><a href="#local-6989586621679709362"><span class="hs-identifier hs-type">chunks</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2182"></span><span>  </span><span id="ComputeChunksChunkGo0"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo0"><span class="hs-identifier hs-var">ComputeChunksChunkGo0</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-2183"></span><span>  </span><span id="ComputeChunksChunkGo0"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo0"><span class="hs-identifier hs-var">ComputeChunksChunkGo0</span></a></span></span><span> </span><span id="local-6989586621679709361"><span class="annot"><a href="#local-6989586621679709361"><span class="hs-identifier hs-type hs-type">n'</span></a></span></span><span> </span><span id="local-6989586621679709360"><span class="annot"><a href="#local-6989586621679709360"><span class="hs-identifier hs-type hs-type">chunks</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709361"><span class="hs-identifier hs-type">n'</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo0"><span class="hs-identifier hs-type">ComputeChunksChunkGo0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709361"><span class="hs-identifier hs-type">n'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709360"><span class="hs-identifier hs-type">chunks</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2184"></span><span>
</span><span id="line-2185"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeChunks"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks"><span class="hs-identifier hs-var">ComputeChunks</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709358"><span class="annot"><a href="#local-6989586621679709358"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709357"><span class="annot"><a href="#local-6989586621679709357"><span class="hs-identifier hs-type">chunks</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2186"></span><span>  </span><span id="ComputeChunks"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks"><span class="hs-identifier hs-var">ComputeChunks</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679709356"><span class="annot"><a href="#local-6989586621679709356"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709355"><span class="annot"><a href="#local-6989586621679709355"><span class="hs-identifier hs-type hs-type">chunks</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks%27"><span class="hs-identifier hs-type">ComputeChunks'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709356"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709355"><span class="hs-identifier hs-type">chunks</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Mod</span></span><span> </span><span class="annot"><a href="#local-6989586621679709356"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709355"><span class="hs-identifier hs-type">chunks</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2187"></span><span>  </span><span id="ComputeChunks"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks"><span class="hs-identifier hs-var">ComputeChunks</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2188"></span><span>
</span><span id="line-2189"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeChunks%27"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks%27"><span class="hs-identifier hs-var">ComputeChunks'</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709353"><span class="annot"><a href="#local-6989586621679709353"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709352"><span class="annot"><a href="#local-6989586621679709352"><span class="hs-identifier hs-type">chunks</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709351"><span class="annot"><a href="#local-6989586621679709351"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2190"></span><span>  </span><span id="ComputeChunks%27"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks%27"><span class="hs-identifier hs-var">ComputeChunks'</span></a></span></span><span> </span><span id="local-6989586621679709350"><span class="annot"><a href="#local-6989586621679709350"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709349"><span class="annot"><a href="#local-6989586621679709349"><span class="hs-identifier hs-type hs-type">chunks</span></a></span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo0"><span class="hs-identifier hs-type">ComputeChunksChunkGo0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Div</span></span><span> </span><span class="annot"><a href="#local-6989586621679709350"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709349"><span class="hs-identifier hs-type">chunks</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709349"><span class="hs-identifier hs-type">chunks</span></a></span><span>
</span><span id="line-2191"></span><span>  </span><span id="ComputeChunks%27"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks%27"><span class="hs-identifier hs-var">ComputeChunks'</span></a></span></span><span> </span><span id="local-6989586621679709348"><span class="annot"><a href="#local-6989586621679709348"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709347"><span class="annot"><a href="#local-6989586621679709347"><span class="hs-identifier hs-type hs-type">chunks</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunksChunkGo"><span class="hs-identifier hs-type">ComputeChunksChunkGo</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Div</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709348"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709347"><span class="hs-identifier hs-type">chunks</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709347"><span class="hs-identifier hs-type">chunks</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709348"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709348"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Div</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709348"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709347"><span class="hs-identifier hs-type">chunks</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709347"><span class="hs-identifier hs-type">chunks</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709348"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span>
</span><span id="line-2192"></span><span>
</span><span id="line-2193"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ChunkShapesImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapesImpl"><span class="hs-identifier hs-var">ChunkShapesImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709345"><span class="annot"><a href="#local-6989586621679709345"><span class="hs-identifier hs-type">chunks</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709344"><span class="annot"><a href="#local-6989586621679709344"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709343"><span class="annot"><a href="#local-6989586621679709343"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2194"></span><span>  </span><span id="ChunkShapesImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapesImpl"><span class="hs-identifier hs-var">ChunkShapesImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709342"><span class="annot"><a href="#local-6989586621679709342"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679709341"><span class="annot"><a href="#local-6989586621679709341"><span class="hs-identifier hs-type hs-type">ns</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709340"><span class="annot"><a href="#local-6989586621679709340"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709339"><span class="annot"><a href="#local-6989586621679709339"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe%27"><span class="hs-identifier hs-type">AppendToMaybe'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#ReplaceDim"><span class="hs-identifier hs-type">ReplaceDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709340"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709339"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709342"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapesImpl"><span class="hs-identifier hs-type">ChunkShapesImpl</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709341"><span class="hs-identifier hs-type">ns</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709340"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709339"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2195"></span><span>  </span><span id="ChunkShapesImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapesImpl"><span class="hs-identifier hs-var">ChunkShapesImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-2196"></span><span>  </span><span id="ChunkShapesImpl"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapesImpl"><span class="hs-identifier hs-var">ChunkShapesImpl</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-2197"></span><span>
</span><span id="line-2198"></span><span class="hs-keyword">type</span><span> </span><span id="ChunkShapes"><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapes"><span class="hs-identifier hs-var">ChunkShapes</span></a></span></span><span> </span><span id="local-6989586621679709335"><span class="annot"><a href="#local-6989586621679709335"><span class="hs-identifier hs-type">chunks</span></a></span></span><span> </span><span id="local-6989586621679709334"><span class="annot"><a href="#local-6989586621679709334"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709333"><span class="annot"><a href="#local-6989586621679709333"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapesImpl"><span class="hs-identifier hs-type">ChunkShapesImpl</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeChunks"><span class="hs-identifier hs-type">ComputeChunks</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#ExtractDim"><span class="hs-identifier hs-type">ExtractDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709334"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709333"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709335"><span class="hs-identifier hs-type">chunks</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709334"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709333"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2199"></span><span>
</span><span id="line-2200"></span><span class="hs-keyword">type</span><span> </span><span id="Chunk"><span class="annot"><a href="Torch.Typed.Functional.html#Chunk"><span class="hs-identifier hs-var">Chunk</span></a></span></span><span> </span><span id="local-6989586621679709331"><span class="annot"><a href="#local-6989586621679709331"><span class="hs-identifier hs-type">chunks</span></a></span></span><span> </span><span id="local-6989586621679709330"><span class="annot"><a href="#local-6989586621679709330"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709329"><span class="annot"><a href="#local-6989586621679709329"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709328"><span class="annot"><a href="#local-6989586621679709328"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709327"><span class="annot"><a href="#local-6989586621679709327"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ChunkCheck"><span class="hs-identifier hs-type">ChunkCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709329"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709330"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ChunkImpl"><span class="hs-identifier hs-type">ChunkImpl</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ChunkShapes"><span class="hs-identifier hs-type">ChunkShapes</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709331"><span class="hs-identifier hs-type">chunks</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709330"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709329"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709328"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709327"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2201"></span><span>
</span><span id="line-2202"></span><span class="hs-comment">-- | chunk</span><span>
</span><span id="line-2203"></span><span class="hs-comment">--</span><span>
</span><span id="line-2204"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :type chunk @3 @1 (ones :: CPUTensor 'D.Float '[2, 2])</span><span>
</span><span id="line-2205"></span><span class="hs-comment">-- -- chunk @3 @1 (ones :: CPUTensor 'D.Float '[2, 2])</span><span>
</span><span id="line-2206"></span><span class="hs-comment">-- --   :: HList</span><span>
</span><span id="line-2207"></span><span class="hs-comment">-- --        '[Tensor '( 'D.CPU, 0) 'D.Float '[2, 1],</span><span>
</span><span id="line-2208"></span><span class="hs-comment">-- --          Tensor '( 'D.CPU, 0) 'D.Float '[2, 1]]</span><span>
</span><span id="line-2209"></span><span class="hs-comment">-- &gt;&gt;&gt; t0 :. t1 :. HNil = chunk @3 @1 (ones :: CPUTensor 'D.Float '[2, 2])</span><span>
</span><span id="line-2210"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t0</span><span>
</span><span id="line-2211"></span><span class="hs-comment">-- (Float,[2,1])</span><span>
</span><span id="line-2212"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t1</span><span>
</span><span id="line-2213"></span><span class="hs-comment">-- (Float,[2,1])</span><span>
</span><span id="line-2214"></span><span class="hs-comment">--</span><span>
</span><span id="line-2215"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :type chunk @3 @1 (ones :: CPUTensor 'D.Float '[1, 0, 3])</span><span>
</span><span id="line-2216"></span><span class="hs-comment">-- -- chunk @3 @1 (ones :: CPUTensor 'D.Float '[1, 0, 3])</span><span>
</span><span id="line-2217"></span><span class="hs-comment">-- --   :: HList</span><span>
</span><span id="line-2218"></span><span class="hs-comment">-- --        '[Tensor '( 'D.CPU, 0) 'D.Float '[1, 0, 3],</span><span>
</span><span id="line-2219"></span><span class="hs-comment">-- --          Tensor '( 'D.CPU, 0) 'D.Float '[1, 0, 3],</span><span>
</span><span id="line-2220"></span><span class="hs-comment">-- --          Tensor '( 'D.CPU, 0) 'D.Float '[1, 0, 3]]</span><span>
</span><span id="line-2221"></span><span class="hs-comment">-- &gt;&gt;&gt; t0 :. t1 :. t2 :. HNil = chunk @3 @1 (ones :: CPUTensor 'D.Float '[1, 0, 3])</span><span>
</span><span id="line-2222"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t0</span><span>
</span><span id="line-2223"></span><span class="hs-comment">-- (Float,[1,0,3])</span><span>
</span><span id="line-2224"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t1</span><span>
</span><span id="line-2225"></span><span class="hs-comment">-- (Float,[1,0,3])</span><span>
</span><span id="line-2226"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t2</span><span>
</span><span id="line-2227"></span><span class="hs-comment">-- (Float,[1,0,3])</span><span>
</span><span id="line-2228"></span><span class="hs-comment">--</span><span>
</span><span id="line-2229"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :type chunk @6 @0 (ones :: CPUTensor 'D.Float '[19, 4])</span><span>
</span><span id="line-2230"></span><span class="hs-comment">-- -- chunk @6 @0 (ones :: CPUTensor 'D.Float '[19, 4])</span><span>
</span><span id="line-2231"></span><span class="hs-comment">-- --   :: HList</span><span>
</span><span id="line-2232"></span><span class="hs-comment">-- --        '[Tensor '( 'D.CPU, 0) 'D.Float '[4, 4],</span><span>
</span><span id="line-2233"></span><span class="hs-comment">-- --          Tensor '( 'D.CPU, 0) 'D.Float '[4, 4],</span><span>
</span><span id="line-2234"></span><span class="hs-comment">-- --          Tensor '( 'D.CPU, 0) 'D.Float '[4, 4],</span><span>
</span><span id="line-2235"></span><span class="hs-comment">-- --          Tensor '( 'D.CPU, 0) 'D.Float '[4, 4],</span><span>
</span><span id="line-2236"></span><span class="hs-comment">-- --          Tensor '( 'D.CPU, 0) 'D.Float '[3, 4]]</span><span>
</span><span id="line-2237"></span><span class="hs-comment">-- &gt;&gt;&gt; t0 :. t1 :. t2 :. t3 :. t4 :. HNil = chunk @6 @0 (ones :: CPUTensor 'D.Float '[19, 4])</span><span>
</span><span id="line-2238"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t0</span><span>
</span><span id="line-2239"></span><span class="hs-comment">-- (Float,[4,4])</span><span>
</span><span id="line-2240"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t1</span><span>
</span><span id="line-2241"></span><span class="hs-comment">-- (Float,[4,4])</span><span>
</span><span id="line-2242"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t2</span><span>
</span><span id="line-2243"></span><span class="hs-comment">-- (Float,[4,4])</span><span>
</span><span id="line-2244"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t3</span><span>
</span><span id="line-2245"></span><span class="hs-comment">-- (Float,[4,4])</span><span>
</span><span id="line-2246"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t4</span><span>
</span><span id="line-2247"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-2248"></span><span class="annot"><a href="Torch.Typed.Functional.html#chunk"><span class="hs-identifier hs-type">chunk</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2249"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709325"><span class="annot"><a href="#local-6989586621679709325"><span class="hs-identifier hs-type">chunks</span></a></span></span><span> </span><span id="local-6989586621679709324"><span class="annot"><a href="#local-6989586621679709324"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679709323"><span class="annot"><a href="#local-6989586621679709323"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709322"><span class="annot"><a href="#local-6989586621679709322"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709321"><span class="annot"><a href="#local-6989586621679709321"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709320"><span class="annot"><a href="#local-6989586621679709320"><span class="hs-identifier hs-type">tensorChunks</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2250"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709325"><span class="hs-identifier hs-type">chunks</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2251"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709324"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2252"></span><span>    </span><span class="annot"><a href="#local-6989586621679709320"><span class="hs-identifier hs-type">tensorChunks</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Chunk"><span class="hs-identifier hs-type">Chunk</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709325"><span class="hs-identifier hs-type">chunks</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709324"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709323"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709322"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709321"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2253"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709320"><span class="hs-identifier hs-type">tensorChunks</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2254"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2255"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-2256"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709321"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709322"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709323"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2257"></span><span>  </span><span class="hs-comment">-- | output list of tensors</span><span>
</span><span id="line-2258"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709320"><span class="hs-identifier hs-type">tensorChunks</span></a></span><span>
</span><span id="line-2259"></span><span id="chunk"><span class="annot"><span class="annottext">chunk :: Tensor device dtype shape -&gt; HList tensorChunks
</span><a href="Torch.Typed.Functional.html#chunk"><span class="hs-identifier hs-var hs-var">chunk</span></a></span></span><span> </span><span id="local-6989586621679709319"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709319"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2260"></span><span>  </span><span class="annot"><span class="annottext">IO (HList tensorChunks) -&gt; HList tensorChunks
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (HList tensorChunks) -&gt; HList tensorChunks)
-&gt; IO (HList tensorChunks) -&gt; HList tensorChunks
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2261"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr TensorList))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Int
-&gt; IO (HList tensorChunks)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr TensorList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.chunk_tll</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709319"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat chunks =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709325"><span class="hs-identifier hs-type">chunks</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709324"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2262"></span><span>
</span><span id="line-2263"></span><span class="hs-comment">-- | clamp</span><span>
</span><span id="line-2264"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2265"></span><span class="hs-comment">-- TODO: can we use D.Scalar for the minimum and maximum values?</span><span>
</span><span id="line-2266"></span><span class="hs-comment">--</span><span>
</span><span id="line-2267"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ clamp 0 1 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2268"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2269"></span><span class="annot"><a href="Torch.Typed.Functional.html#clamp"><span class="hs-identifier hs-type">clamp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2270"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709316"><span class="annot"><a href="#local-6989586621679709316"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709315"><span class="annot"><a href="#local-6989586621679709315"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709314"><span class="annot"><a href="#local-6989586621679709314"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709313"><span class="annot"><a href="#local-6989586621679709313"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2271"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709313"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2272"></span><span>  </span><span class="hs-comment">-- | minimum value</span><span>
</span><span id="line-2273"></span><span>  </span><span class="annot"><a href="#local-6989586621679709313"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2274"></span><span>  </span><span class="hs-comment">-- | maximum value</span><span>
</span><span id="line-2275"></span><span>  </span><span class="annot"><a href="#local-6989586621679709313"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2276"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2277"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709314"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709315"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709316"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2278"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2279"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709314"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709315"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709316"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2280"></span><span id="clamp"><span class="annot"><span class="annottext">clamp :: a -&gt; a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#clamp"><span class="hs-identifier hs-var hs-var">clamp</span></a></span></span><span> </span><span id="local-6989586621679709312"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709312"><span class="hs-identifier hs-var">min</span></a></span></span><span> </span><span id="local-6989586621679709311"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709311"><span class="hs-identifier hs-var">max</span></a></span></span><span> </span><span id="local-6989586621679709310"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709310"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; a
-&gt; a
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.clamp_tss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709310"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709312"><span class="hs-identifier hs-var">min</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709311"><span class="hs-identifier hs-var">max</span></a></span><span>
</span><span id="line-2281"></span><span>
</span><span id="line-2282"></span><span class="hs-comment">-- | clampMax</span><span>
</span><span id="line-2283"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2284"></span><span class="hs-comment">-- TODO: can we use D.Scalar for the maximum value?</span><span>
</span><span id="line-2285"></span><span class="hs-comment">--</span><span>
</span><span id="line-2286"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ clampMax 1 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2287"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2288"></span><span class="annot"><a href="Torch.Typed.Functional.html#clampMax"><span class="hs-identifier hs-type">clampMax</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2289"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709307"><span class="annot"><a href="#local-6989586621679709307"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709306"><span class="annot"><a href="#local-6989586621679709306"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709305"><span class="annot"><a href="#local-6989586621679709305"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709304"><span class="annot"><a href="#local-6989586621679709304"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2290"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709304"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2291"></span><span>  </span><span class="hs-comment">-- | maximum value</span><span>
</span><span id="line-2292"></span><span>  </span><span class="annot"><a href="#local-6989586621679709304"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2293"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2294"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709305"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709306"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709307"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2295"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2296"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709305"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709306"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709307"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2297"></span><span id="clampMax"><span class="annot"><span class="annottext">clampMax :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#clampMax"><span class="hs-identifier hs-var hs-var">clampMax</span></a></span></span><span> </span><span id="local-6989586621679709303"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709303"><span class="hs-identifier hs-var">max</span></a></span></span><span> </span><span id="local-6989586621679709302"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709302"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.clamp_max_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709302"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709303"><span class="hs-identifier hs-var">max</span></a></span><span>
</span><span id="line-2298"></span><span>
</span><span id="line-2299"></span><span class="hs-comment">-- | clampMin</span><span>
</span><span id="line-2300"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2301"></span><span class="hs-comment">-- TODO: can we use D.Scalar for the minimum value?</span><span>
</span><span id="line-2302"></span><span class="hs-comment">--</span><span>
</span><span id="line-2303"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ clampMin 0 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2304"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2305"></span><span class="annot"><a href="Torch.Typed.Functional.html#clampMin"><span class="hs-identifier hs-type">clampMin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2306"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709299"><span class="annot"><a href="#local-6989586621679709299"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709298"><span class="annot"><a href="#local-6989586621679709298"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709297"><span class="annot"><a href="#local-6989586621679709297"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709296"><span class="annot"><a href="#local-6989586621679709296"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2307"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709296"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2308"></span><span>  </span><span class="hs-comment">-- | minimum value</span><span>
</span><span id="line-2309"></span><span>  </span><span class="annot"><a href="#local-6989586621679709296"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2310"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2311"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709297"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709298"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709299"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2312"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2313"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709297"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709298"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709299"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2314"></span><span id="clampMin"><span class="annot"><span class="annottext">clampMin :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#clampMin"><span class="hs-identifier hs-var hs-var">clampMin</span></a></span></span><span> </span><span id="local-6989586621679709295"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709295"><span class="hs-identifier hs-var">min</span></a></span></span><span> </span><span id="local-6989586621679709294"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709294"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.clamp_min_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709294"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679709295"><span class="hs-identifier hs-var">min</span></a></span><span>
</span><span id="line-2315"></span><span>
</span><span id="line-2316"></span><span class="hs-comment">-- | cudnnIsAcceptable</span><span>
</span><span id="line-2317"></span><span class="hs-comment">-- TODO: calling this probably makes only sense when the device is CUDA</span><span>
</span><span id="line-2318"></span><span class="annot"><a href="Torch.Typed.Functional.html#cudnnIsAcceptable"><span class="hs-identifier hs-type">cudnnIsAcceptable</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2319"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679710801"><span class="annot"><a href="#local-6989586621679710801"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679710802"><span class="annot"><a href="#local-6989586621679710802"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679710803"><span class="annot"><a href="#local-6989586621679710803"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2320"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2321"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710803"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710802"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679710801"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2322"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2323"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-2324"></span><span id="cudnnIsAcceptable"><span class="annot"><span class="annottext">cudnnIsAcceptable :: Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#cudnnIsAcceptable"><span class="hs-identifier hs-var hs-var">cudnnIsAcceptable</span></a></span></span><span> </span><span id="local-6989586621679709291"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709291"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2325"></span><span>  </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor device dtype shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.cudnn_is_acceptable_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709291"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2326"></span><span>
</span><span id="line-2327"></span><span class="hs-comment">-- constant_pad_nd :: Tensor device dtype shape -&gt; [Int] -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2328"></span><span class="hs-comment">-- constant_pad_nd _input _pad _value = unsafePerformIO $ (ATen.cast3 ATen.Managed.constant_pad_nd_tls) _input _pad _value</span><span>
</span><span id="line-2329"></span><span>
</span><span id="line-2330"></span><span class="annot"><a href="Torch.Typed.Functional.html#constantPadNd1d"><span class="hs-identifier hs-type">constantPadNd1d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2331"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709288"><span class="annot"><a href="#local-6989586621679709288"><span class="hs-identifier hs-type">pad</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709287"><span class="annot"><a href="#local-6989586621679709287"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679709286"><span class="annot"><a href="#local-6989586621679709286"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709285"><span class="annot"><a href="#local-6989586621679709285"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2332"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709288"><span class="hs-identifier hs-type">pad</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709288"><span class="hs-identifier hs-type">pad</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709287"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2333"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2334"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709285"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709286"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709287"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2335"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709285"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709286"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709287"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709288"><span class="hs-identifier hs-type">pad</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709288"><span class="hs-identifier hs-type">pad</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2336"></span><span id="constantPadNd1d"><span class="annot"><span class="annottext">constantPadNd1d :: Float
-&gt; Tensor device dtype '[n]
-&gt; Tensor device dtype '[(n + Fst pad) + Snd pad]
</span><a href="Torch.Typed.Functional.html#constantPadNd1d"><span class="hs-identifier hs-var hs-var">constantPadNd1d</span></a></span></span><span> </span><span id="local-6989586621679709284"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709284"><span class="hs-identifier hs-var">value</span></a></span></span><span> </span><span id="local-6989586621679709283"><span class="annot"><span class="annottext">Tensor device dtype '[n]
</span><a href="#local-6989586621679709283"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2337"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[(n + Fst pad) + Snd pad])
-&gt; Tensor device dtype '[(n + Fst pad) + Snd pad]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[(n + Fst pad) + Snd pad])
 -&gt; Tensor device dtype '[(n + Fst pad) + Snd pad])
-&gt; IO (Tensor device dtype '[(n + Fst pad) + Snd pad])
-&gt; Tensor device dtype '[(n + Fst pad) + Snd pad]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2338"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[n]
-&gt; [Int]
-&gt; Float
-&gt; IO (Tensor device dtype '[(n + Fst pad) + Snd pad])
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-2339"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.constant_pad_nd_tls</span></a></span><span>
</span><span id="line-2340"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype '[n]
</span><a href="#local-6989586621679709283"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2341"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst pad) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709288"><span class="hs-identifier hs-type">pad</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd pad) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709288"><span class="hs-identifier hs-type">pad</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-2342"></span><span>      </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679709284"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-2343"></span><span>
</span><span id="line-2344"></span><span class="hs-comment">-- convolution :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; Bool -&gt; [Int] -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2345"></span><span class="hs-comment">-- convolution _input _weight _bias _stride _padding _dilation _transposed _output_padding _groups = unsafePerformIO $ (ATen.cast9 ATen.Managed.convolution_tttlllbll) _input _weight _bias _stride _padding _dilation _transposed _output_padding _groups</span><span>
</span><span id="line-2346"></span><span>
</span><span id="line-2347"></span><span class="hs-keyword">type</span><span> </span><span id="ConvSideCheck"><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-var">ConvSideCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709281"><span class="annot"><a href="#local-6989586621679709281"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709280"><span class="annot"><a href="#local-6989586621679709280"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709279"><span class="annot"><a href="#local-6989586621679709279"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709278"><span class="annot"><a href="#local-6989586621679709278"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709277"><span class="annot"><a href="#local-6989586621679709277"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2348"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="hs-comment">-- kernel size and stride must be &gt; 0</span><span>
</span><span id="line-2349"></span><span>    </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679709280"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2350"></span><span>    </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679709279"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2351"></span><span>    </span><span class="hs-comment">-- kernel size can't be greater than actual input size</span><span>
</span><span id="line-2352"></span><span>    </span><span class="hs-comment">-- ToDo: Do not use '&gt;=' on constraint to avoid reduction-stack-overflow.</span><span>
</span><span id="line-2353"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709280"><span class="hs-identifier hs-type">kernelSize</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709281"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679709278"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-2354"></span><span>    </span><span class="hs-comment">-- output size must be greater than 0</span><span>
</span><span id="line-2355"></span><span>    </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679709277"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2356"></span><span>    </span><span class="hs-comment">-- output formulation:</span><span>
</span><span id="line-2357"></span><span>    </span><span class="annot"><a href="#local-6989586621679709277"><span class="hs-identifier hs-type">outputSize</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvOutputSize"><span class="hs-identifier hs-type">ConvOutputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709281"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709280"><span class="hs-identifier hs-type">kernelSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709279"><span class="hs-identifier hs-type">stride</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709278"><span class="hs-identifier hs-type">padding</span></a></span><span>
</span><span id="line-2358"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-2359"></span><span>
</span><span id="line-2360"></span><span class="hs-comment">-- | ConvOutputSize</span><span>
</span><span id="line-2361"></span><span class="hs-comment">--</span><span>
</span><span id="line-2362"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! ConvOutputSize 4 1 1 0</span><span>
</span><span id="line-2363"></span><span class="hs-comment">-- ConvOutputSize 4 1 1 0 :: Nat</span><span>
</span><span id="line-2364"></span><span class="hs-comment">-- = 4</span><span>
</span><span id="line-2365"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ConvOutputSize"><span class="annot"><a href="Torch.Typed.Functional.html#ConvOutputSize"><span class="hs-identifier hs-var">ConvOutputSize</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709275"><span class="annot"><a href="#local-6989586621679709275"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709274"><span class="annot"><a href="#local-6989586621679709274"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709273"><span class="annot"><a href="#local-6989586621679709273"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709272"><span class="annot"><a href="#local-6989586621679709272"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2366"></span><span>  </span><span id="ConvOutputSize"><span class="annot"><a href="Torch.Typed.Functional.html#ConvOutputSize"><span class="hs-identifier hs-var">ConvOutputSize</span></a></span></span><span> </span><span id="local-6989586621679709271"><span class="annot"><a href="#local-6989586621679709271"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679709270"><span class="annot"><a href="#local-6989586621679709270"><span class="hs-identifier hs-type hs-type">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679709269"><span class="annot"><a href="#local-6989586621679709269"><span class="hs-identifier hs-type hs-type">stride</span></a></span></span><span> </span><span id="local-6989586621679709268"><span class="annot"><a href="#local-6989586621679709268"><span class="hs-identifier hs-type hs-type">padding</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Div</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709271"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679709268"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709270"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709269"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-2367"></span><span>
</span><span id="line-2368"></span><span class="hs-comment">-- | conv1d</span><span>
</span><span id="line-2369"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2370"></span><span class="hs-comment">--</span><span>
</span><span id="line-2371"></span><span class="hs-comment">-- &gt;&gt;&gt; t = conv1d @1 @0 (ones :: CPUTensor 'D.Float '[10, 3, 1]) (ones :: CPUTensor 'D.Float '[10]) (ones :: CPUTensor 'D.Float '[1, 3, 4])</span><span>
</span><span id="line-2372"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-2373"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 10, 4]</span><span>
</span><span id="line-2374"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[[Float]]]) $ t</span><span>
</span><span id="line-2375"></span><span class="hs-comment">-- (Float,([1,10,4],[[[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0]]]))</span><span>
</span><span id="line-2376"></span><span class="annot"><a href="Torch.Typed.Functional.html#conv1d"><span class="hs-identifier hs-type">conv1d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2377"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-2378"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709266"><span class="annot"><a href="#local-6989586621679709266"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-2379"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709265"><span class="annot"><a href="#local-6989586621679709265"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-2380"></span><span>    </span><span id="local-6989586621679709264"><span class="annot"><a href="#local-6989586621679709264"><span class="hs-identifier hs-type">inputChannelSize</span></a></span></span><span>
</span><span id="line-2381"></span><span>    </span><span id="local-6989586621679709263"><span class="annot"><a href="#local-6989586621679709263"><span class="hs-identifier hs-type">outputChannelSize</span></a></span></span><span>
</span><span id="line-2382"></span><span>    </span><span id="local-6989586621679709262"><span class="annot"><a href="#local-6989586621679709262"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span>
</span><span id="line-2383"></span><span>    </span><span id="local-6989586621679709261"><span class="annot"><a href="#local-6989586621679709261"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span>
</span><span id="line-2384"></span><span>    </span><span id="local-6989586621679709260"><span class="annot"><a href="#local-6989586621679709260"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-2385"></span><span>    </span><span id="local-6989586621679709259"><span class="annot"><a href="#local-6989586621679709259"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-2386"></span><span>    </span><span id="local-6989586621679709258"><span class="annot"><a href="#local-6989586621679709258"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-2387"></span><span>    </span><span id="local-6989586621679709257"><span class="annot"><a href="#local-6989586621679709257"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2388"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-2389"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-2390"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="#local-6989586621679709266"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2391"></span><span>         </span><span class="annot"><a href="#local-6989586621679709265"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2392"></span><span>         </span><span class="annot"><a href="#local-6989586621679709264"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2393"></span><span>         </span><span class="annot"><a href="#local-6989586621679709263"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2394"></span><span>         </span><span class="annot"><a href="#local-6989586621679709262"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2395"></span><span>         </span><span class="annot"><a href="#local-6989586621679709261"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2396"></span><span>         </span><span class="annot"><a href="#local-6989586621679709260"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2397"></span><span>         </span><span class="annot"><a href="#local-6989586621679709259"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-2398"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-2399"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709261"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709262"><span class="hs-identifier hs-type">kernelSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709266"><span class="hs-identifier hs-type">stride</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709265"><span class="hs-identifier hs-type">padding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709259"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-2400"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2401"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-2402"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709257"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709258"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709263"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709264"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709262"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2403"></span><span>  </span><span class="hs-comment">-- | bias</span><span>
</span><span id="line-2404"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709257"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709258"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709263"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2405"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2406"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709257"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709258"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709260"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709264"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709261"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2407"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2408"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709257"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709258"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709260"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709263"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709259"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2409"></span><span id="conv1d"><span class="annot"><span class="annottext">conv1d :: Tensor
  device dtype '[outputChannelSize, inputChannelSize, kernelSize]
-&gt; Tensor device dtype '[outputChannelSize]
-&gt; Tensor device dtype '[batchSize, inputChannelSize, inputSize]
-&gt; Tensor device dtype '[batchSize, outputChannelSize, outputSize]
</span><a href="Torch.Typed.Functional.html#conv1d"><span class="hs-identifier hs-var hs-var">conv1d</span></a></span></span><span> </span><span id="local-6989586621679709256"><span class="annot"><span class="annottext">Tensor
  device dtype '[outputChannelSize, inputChannelSize, kernelSize]
</span><a href="#local-6989586621679709256"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679709255"><span class="annot"><span class="annottext">Tensor device dtype '[outputChannelSize]
</span><a href="#local-6989586621679709255"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679709254"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputChannelSize, inputSize]
</span><a href="#local-6989586621679709254"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2410"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype '[batchSize, outputChannelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, outputChannelSize, outputSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype '[batchSize, outputChannelSize, outputSize])
 -&gt; Tensor device dtype '[batchSize, outputChannelSize, outputSize])
-&gt; IO
     (Tensor device dtype '[batchSize, outputChannelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, outputChannelSize, outputSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2411"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, inputChannelSize, inputSize]
-&gt; Tensor
     device dtype '[outputChannelSize, inputChannelSize, kernelSize]
-&gt; Tensor device dtype '[outputChannelSize]
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; IO
     (Tensor device dtype '[batchSize, outputChannelSize, outputSize])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast7</span></a></span><span>
</span><span id="line-2412"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.conv1d_tttllll</span></a></span><span>
</span><span id="line-2413"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputChannelSize, inputSize]
</span><a href="#local-6989586621679709254"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2414"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[outputChannelSize, inputChannelSize, kernelSize]
</span><a href="#local-6989586621679709256"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-2415"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype '[outputChannelSize]
</span><a href="#local-6989586621679709255"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-2416"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat stride =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709266"><span class="hs-identifier hs-type">stride</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2417"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat padding =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709265"><span class="hs-identifier hs-type">padding</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2418"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2419"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2420"></span><span>
</span><span id="line-2421"></span><span class="hs-comment">-- | conv2d</span><span>
</span><span id="line-2422"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2423"></span><span class="hs-comment">--</span><span>
</span><span id="line-2424"></span><span class="hs-comment">-- &gt;&gt;&gt; t = conv2d @'(1, 1) @'(0, 0) (ones :: CPUTensor 'D.Float '[10, 3, 1, 1]) (ones :: CPUTensor 'D.Float '[10]) (ones :: CPUTensor 'D.Float '[1, 3, 4, 5])</span><span>
</span><span id="line-2425"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-2426"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 10, 4, 5]</span><span>
</span><span id="line-2427"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[[[Float]]]]) $ t</span><span>
</span><span id="line-2428"></span><span class="hs-comment">-- (Float,([1,10,4,5],[[[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0]]]]))</span><span>
</span><span id="line-2429"></span><span class="annot"><a href="Torch.Typed.Functional.html#conv2d"><span class="hs-identifier hs-type">conv2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2430"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-2431"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709250"><span class="annot"><a href="#local-6989586621679709250"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2432"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709249"><span class="annot"><a href="#local-6989586621679709249"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2433"></span><span>    </span><span id="local-6989586621679709248"><span class="annot"><a href="#local-6989586621679709248"><span class="hs-identifier hs-type">inputChannelSize</span></a></span></span><span>
</span><span id="line-2434"></span><span>    </span><span id="local-6989586621679709247"><span class="annot"><a href="#local-6989586621679709247"><span class="hs-identifier hs-type">outputChannelSize</span></a></span></span><span>
</span><span id="line-2435"></span><span>    </span><span id="local-6989586621679709246"><span class="annot"><a href="#local-6989586621679709246"><span class="hs-identifier hs-type">kernelSize0</span></a></span></span><span>
</span><span id="line-2436"></span><span>    </span><span id="local-6989586621679709245"><span class="annot"><a href="#local-6989586621679709245"><span class="hs-identifier hs-type">kernelSize1</span></a></span></span><span>
</span><span id="line-2437"></span><span>    </span><span id="local-6989586621679709244"><span class="annot"><a href="#local-6989586621679709244"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span>
</span><span id="line-2438"></span><span>    </span><span id="local-6989586621679709243"><span class="annot"><a href="#local-6989586621679709243"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span>
</span><span id="line-2439"></span><span>    </span><span id="local-6989586621679709242"><span class="annot"><a href="#local-6989586621679709242"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-2440"></span><span>    </span><span id="local-6989586621679709241"><span class="annot"><a href="#local-6989586621679709241"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span>
</span><span id="line-2441"></span><span>    </span><span id="local-6989586621679709240"><span class="annot"><a href="#local-6989586621679709240"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span>
</span><span id="line-2442"></span><span>    </span><span id="local-6989586621679709239"><span class="annot"><a href="#local-6989586621679709239"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-2443"></span><span>    </span><span id="local-6989586621679709238"><span class="annot"><a href="#local-6989586621679709238"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2444"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-2445"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-2446"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709250"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2447"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709250"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2448"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709249"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2449"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709249"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2450"></span><span>         </span><span class="annot"><a href="#local-6989586621679709248"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2451"></span><span>         </span><span class="annot"><a href="#local-6989586621679709247"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2452"></span><span>         </span><span class="annot"><a href="#local-6989586621679709246"><span class="hs-identifier hs-type">kernelSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2453"></span><span>         </span><span class="annot"><a href="#local-6989586621679709245"><span class="hs-identifier hs-type">kernelSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2454"></span><span>         </span><span class="annot"><a href="#local-6989586621679709244"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2455"></span><span>         </span><span class="annot"><a href="#local-6989586621679709243"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2456"></span><span>         </span><span class="annot"><a href="#local-6989586621679709242"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2457"></span><span>         </span><span class="annot"><a href="#local-6989586621679709241"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2458"></span><span>         </span><span class="annot"><a href="#local-6989586621679709240"><span class="hs-identifier hs-type">outputSize1</span></a></span><span>
</span><span id="line-2459"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-2460"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709244"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709246"><span class="hs-identifier hs-type">kernelSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709250"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709249"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709241"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2461"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709243"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709245"><span class="hs-identifier hs-type">kernelSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709250"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709249"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709240"><span class="hs-identifier hs-type">outputSize1</span></a></span><span>
</span><span id="line-2462"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2463"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-2464"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709238"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709239"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709247"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709248"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709246"><span class="hs-identifier hs-type">kernelSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709245"><span class="hs-identifier hs-type">kernelSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2465"></span><span>  </span><span class="hs-comment">-- | bias</span><span>
</span><span id="line-2466"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709238"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709239"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709247"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2467"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2468"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709238"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709239"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709242"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709248"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709244"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709243"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2469"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2470"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709238"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709239"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709242"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709247"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709241"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709240"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2471"></span><span id="conv2d"><span class="annot"><span class="annottext">conv2d :: Tensor
  device
  dtype
  '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1]
-&gt; Tensor device dtype '[outputChannelSize]
-&gt; Tensor
     device dtype '[batchSize, inputChannelSize, inputSize0, inputSize1]
-&gt; Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1]
</span><a href="Torch.Typed.Functional.html#conv2d"><span class="hs-identifier hs-var hs-var">conv2d</span></a></span></span><span> </span><span id="local-6989586621679709237"><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1]
</span><a href="#local-6989586621679709237"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679709236"><span class="annot"><span class="annottext">Tensor device dtype '[outputChannelSize]
</span><a href="#local-6989586621679709236"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679709235"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, inputChannelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679709235"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2472"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1])
-&gt; Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, outputChannelSize, outputSize0, outputSize1])
 -&gt; Tensor
      device
      dtype
      '[batchSize, outputChannelSize, outputSize0, outputSize1])
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, outputChannelSize, outputSize0, outputSize1])
-&gt; Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2473"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device dtype '[batchSize, inputChannelSize, inputSize0, inputSize1]
-&gt; Tensor
     device
     dtype
     '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1]
-&gt; Tensor device dtype '[outputChannelSize]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Int
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, outputChannelSize, outputSize0, outputSize1])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast7</span></a></span><span>
</span><span id="line-2474"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.conv2d_tttllll</span></a></span><span>
</span><span id="line-2475"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, inputChannelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679709235"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2476"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1]
</span><a href="#local-6989586621679709237"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-2477"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype '[outputChannelSize]
</span><a href="#local-6989586621679709236"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-2478"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709250"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709250"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-2479"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709249"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709249"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-2480"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-2481"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2482"></span><span>
</span><span id="line-2483"></span><span class="hs-comment">-- | conv3d</span><span>
</span><span id="line-2484"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2485"></span><span class="hs-comment">--</span><span>
</span><span id="line-2486"></span><span class="hs-comment">-- &gt;&gt;&gt; t = conv3d @'(1, 1, 1) @'(0, 0, 0) (ones :: CPUTensor 'D.Float '[10, 3, 1, 1, 1]) (ones :: CPUTensor 'D.Float '[10]) (ones :: CPUTensor 'D.Float '[1, 3, 4, 5, 6])</span><span>
</span><span id="line-2487"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-2488"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 10, 4, 5, 6]</span><span>
</span><span id="line-2489"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[[[[Float]]]]]) $ t</span><span>
</span><span id="line-2490"></span><span class="hs-comment">-- (Float,([1,10,4,5,6],[[[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]],[[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]],[[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0],[4.0,4.0,4.0,4.0,4.0,4.0]]]]]))</span><span>
</span><span id="line-2491"></span><span class="annot"><a href="Torch.Typed.Functional.html#conv3d"><span class="hs-identifier hs-type">conv3d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2492"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-2493"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709232"><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2494"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679709231"><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2495"></span><span>    </span><span id="local-6989586621679709230"><span class="annot"><a href="#local-6989586621679709230"><span class="hs-identifier hs-type">inputChannelSize</span></a></span></span><span>
</span><span id="line-2496"></span><span>    </span><span id="local-6989586621679709229"><span class="annot"><a href="#local-6989586621679709229"><span class="hs-identifier hs-type">outputChannelSize</span></a></span></span><span>
</span><span id="line-2497"></span><span>    </span><span id="local-6989586621679709228"><span class="annot"><a href="#local-6989586621679709228"><span class="hs-identifier hs-type">kernelSize0</span></a></span></span><span>
</span><span id="line-2498"></span><span>    </span><span id="local-6989586621679709227"><span class="annot"><a href="#local-6989586621679709227"><span class="hs-identifier hs-type">kernelSize1</span></a></span></span><span>
</span><span id="line-2499"></span><span>    </span><span id="local-6989586621679709226"><span class="annot"><a href="#local-6989586621679709226"><span class="hs-identifier hs-type">kernelSize2</span></a></span></span><span>
</span><span id="line-2500"></span><span>    </span><span id="local-6989586621679709225"><span class="annot"><a href="#local-6989586621679709225"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span>
</span><span id="line-2501"></span><span>    </span><span id="local-6989586621679709224"><span class="annot"><a href="#local-6989586621679709224"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span>
</span><span id="line-2502"></span><span>    </span><span id="local-6989586621679709223"><span class="annot"><a href="#local-6989586621679709223"><span class="hs-identifier hs-type">inputSize2</span></a></span></span><span>
</span><span id="line-2503"></span><span>    </span><span id="local-6989586621679709222"><span class="annot"><a href="#local-6989586621679709222"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-2504"></span><span>    </span><span id="local-6989586621679709221"><span class="annot"><a href="#local-6989586621679709221"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span>
</span><span id="line-2505"></span><span>    </span><span id="local-6989586621679709220"><span class="annot"><a href="#local-6989586621679709220"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span>
</span><span id="line-2506"></span><span>    </span><span id="local-6989586621679709219"><span class="annot"><a href="#local-6989586621679709219"><span class="hs-identifier hs-type">outputSize2</span></a></span></span><span>
</span><span id="line-2507"></span><span>    </span><span id="local-6989586621679709218"><span class="annot"><a href="#local-6989586621679709218"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-2508"></span><span>    </span><span id="local-6989586621679709217"><span class="annot"><a href="#local-6989586621679709217"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2509"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-2510"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-2511"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2512"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2513"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2514"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2515"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2516"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2517"></span><span>         </span><span class="annot"><a href="#local-6989586621679709230"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2518"></span><span>         </span><span class="annot"><a href="#local-6989586621679709229"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2519"></span><span>         </span><span class="annot"><a href="#local-6989586621679709228"><span class="hs-identifier hs-type">kernelSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2520"></span><span>         </span><span class="annot"><a href="#local-6989586621679709227"><span class="hs-identifier hs-type">kernelSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2521"></span><span>         </span><span class="annot"><a href="#local-6989586621679709226"><span class="hs-identifier hs-type">kernelSize2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2522"></span><span>         </span><span class="annot"><a href="#local-6989586621679709225"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2523"></span><span>         </span><span class="annot"><a href="#local-6989586621679709224"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2524"></span><span>         </span><span class="annot"><a href="#local-6989586621679709223"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2525"></span><span>         </span><span class="annot"><a href="#local-6989586621679709222"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-2526"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-2527"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709225"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709228"><span class="hs-identifier hs-type">kernelSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709221"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2528"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709224"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709227"><span class="hs-identifier hs-type">kernelSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709220"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2529"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709223"><span class="hs-identifier hs-type">inputSize2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709226"><span class="hs-identifier hs-type">kernelSize2</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709219"><span class="hs-identifier hs-type">outputSize2</span></a></span><span>
</span><span id="line-2530"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2531"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-2532"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709218"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709229"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709230"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709228"><span class="hs-identifier hs-type">kernelSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709227"><span class="hs-identifier hs-type">kernelSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709226"><span class="hs-identifier hs-type">kernelSize2</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2533"></span><span>  </span><span class="hs-comment">-- | bias</span><span>
</span><span id="line-2534"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709218"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709229"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2535"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2536"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709218"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709222"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709230"><span class="hs-identifier hs-type">inputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709225"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709224"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709223"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2537"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2538"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709218"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709222"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709229"><span class="hs-identifier hs-type">outputChannelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709221"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709220"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709219"><span class="hs-identifier hs-type">outputSize2</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2539"></span><span id="conv3d"><span class="annot"><span class="annottext">conv3d :: Tensor
  device
  dtype
  '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1,
    kernelSize2]
-&gt; Tensor device dtype '[outputChannelSize]
-&gt; Tensor
     device
     dtype
     '[batchSize, inputChannelSize, inputSize0, inputSize1, inputSize2]
-&gt; Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1,
       outputSize2]
</span><a href="Torch.Typed.Functional.html#conv3d"><span class="hs-identifier hs-var hs-var">conv3d</span></a></span></span><span> </span><span id="local-6989586621679709216"><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1,
    kernelSize2]
</span><a href="#local-6989586621679709216"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679709215"><span class="annot"><span class="annottext">Tensor device dtype '[outputChannelSize]
</span><a href="#local-6989586621679709215"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679709214"><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, inputChannelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679709214"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2540"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1,
       outputSize2])
-&gt; Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1,
       outputSize2]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, outputChannelSize, outputSize0, outputSize1,
        outputSize2])
 -&gt; Tensor
      device
      dtype
      '[batchSize, outputChannelSize, outputSize0, outputSize1,
        outputSize2])
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, outputChannelSize, outputSize0, outputSize1,
          outputSize2])
-&gt; Tensor
     device
     dtype
     '[batchSize, outputChannelSize, outputSize0, outputSize1,
       outputSize2]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2541"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device
     dtype
     '[batchSize, inputChannelSize, inputSize0, inputSize1, inputSize2]
-&gt; Tensor
     device
     dtype
     '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1,
       kernelSize2]
-&gt; Tensor device dtype '[outputChannelSize]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Int
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, outputChannelSize, outputSize0, outputSize1,
          outputSize2])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast7</span></a></span><span>
</span><span id="line-2542"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.conv3d_tttllll</span></a></span><span>
</span><span id="line-2543"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, inputChannelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679709214"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2544"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[outputChannelSize, inputChannelSize, kernelSize0, kernelSize1,
    kernelSize2]
</span><a href="#local-6989586621679709216"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-2545"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype '[outputChannelSize]
</span><a href="#local-6989586621679709215"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-2546"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Trd3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709232"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-2547"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Trd3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709231"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-2548"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-2549"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2550"></span><span>
</span><span id="line-2551"></span><span class="hs-comment">-- | convTBC</span><span>
</span><span id="line-2552"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2553"></span><span class="hs-comment">-- 1D convolution over an input of shape `[timeSize, batchSize, inputChannels]`.</span><span>
</span><span id="line-2554"></span><span>
</span><span id="line-2555"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ convTBC @1 (ones :: CPUTensor 'D.Float '[1,4,5]) (ones :: CPUTensor 'D.Float '[5]) (ones :: CPUTensor 'D.Float '[3,3,4])</span><span>
</span><span id="line-2556"></span><span class="hs-comment">-- (Float,[5,3,5])</span><span>
</span><span id="line-2557"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ convTBC @0 (ones :: CPUTensor 'D.Float '[1,4,5]) (ones :: CPUTensor 'D.Float '[5]) (ones :: CPUTensor 'D.Float '[2,3,4])</span><span>
</span><span id="line-2558"></span><span class="hs-comment">-- (Float,[3,3,5])</span><span>
</span><span id="line-2559"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ convTBC @0 (ones :: CPUTensor 'D.Float '[2,4,5]) (ones :: CPUTensor 'D.Float '[5]) (ones :: CPUTensor 'D.Float '[2,3,4])</span><span>
</span><span id="line-2560"></span><span class="hs-comment">-- (Float,[2,3,5])</span><span>
</span><span id="line-2561"></span><span class="annot"><a href="Torch.Typed.Functional.html#convTBC"><span class="hs-identifier hs-type">convTBC</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2562"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709211"><span class="annot"><a href="#local-6989586621679709211"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span id="local-6989586621679709210"><span class="annot"><a href="#local-6989586621679709210"><span class="hs-identifier hs-type">timeSize</span></a></span></span><span> </span><span id="local-6989586621679709209"><span class="annot"><a href="#local-6989586621679709209"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679709208"><span class="annot"><a href="#local-6989586621679709208"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679709207"><span class="annot"><a href="#local-6989586621679709207"><span class="hs-identifier hs-type">inputChannels</span></a></span></span><span> </span><span id="local-6989586621679709206"><span class="annot"><a href="#local-6989586621679709206"><span class="hs-identifier hs-type">outputChannels</span></a></span></span><span> </span><span id="local-6989586621679709205"><span class="annot"><a href="#local-6989586621679709205"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709204"><span class="annot"><a href="#local-6989586621679709204"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2563"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709211"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2564"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709204"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709205"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709208"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709207"><span class="hs-identifier hs-type">inputChannels</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709206"><span class="hs-identifier hs-type">outputChannels</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2565"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709204"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709205"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709206"><span class="hs-identifier hs-type">outputChannels</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2566"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709204"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709205"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709210"><span class="hs-identifier hs-type">timeSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709209"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709207"><span class="hs-identifier hs-type">inputChannels</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2567"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709204"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709205"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709210"><span class="hs-identifier hs-type">timeSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709211"><span class="hs-identifier hs-type">padding</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679709208"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709209"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709206"><span class="hs-identifier hs-type">outputChannels</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2568"></span><span id="convTBC"><span class="annot"><span class="annottext">convTBC :: Tensor device dtype '[kernelSize, inputChannels, outputChannels]
-&gt; Tensor device dtype '[outputChannels]
-&gt; Tensor device dtype '[timeSize, batchSize, inputChannels]
-&gt; Tensor
     device
     dtype
     '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
       outputChannels]
</span><a href="Torch.Typed.Functional.html#convTBC"><span class="hs-identifier hs-var hs-var">convTBC</span></a></span></span><span> </span><span id="local-6989586621679709203"><span class="annot"><span class="annottext">Tensor device dtype '[kernelSize, inputChannels, outputChannels]
</span><a href="#local-6989586621679709203"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679709202"><span class="annot"><span class="annottext">Tensor device dtype '[outputChannels]
</span><a href="#local-6989586621679709202"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679709201"><span class="annot"><span class="annottext">Tensor device dtype '[timeSize, batchSize, inputChannels]
</span><a href="#local-6989586621679709201"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2569"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
       outputChannels])
-&gt; Tensor
     device
     dtype
     '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
       outputChannels]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
        outputChannels])
 -&gt; Tensor
      device
      dtype
      '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
        outputChannels])
-&gt; IO
     (Tensor
        device
        dtype
        '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
          outputChannels])
-&gt; Tensor
     device
     dtype
     '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
       outputChannels]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[timeSize, batchSize, inputChannels]
-&gt; Tensor device dtype '[kernelSize, inputChannels, outputChannels]
-&gt; Tensor device dtype '[outputChannels]
-&gt; Int
-&gt; IO
     (Tensor
        device
        dtype
        '[((timeSize + (padding * 2)) + 1) - kernelSize, batchSize,
          outputChannels])
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.conv_tbc_tttl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[timeSize, batchSize, inputChannels]
</span><a href="#local-6989586621679709201"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[kernelSize, inputChannels, outputChannels]
</span><a href="#local-6989586621679709203"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[outputChannels]
</span><a href="#local-6989586621679709202"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat padding =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709211"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2570"></span><span>
</span><span id="line-2571"></span><span class="hs-comment">-- conv_transpose1d :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2572"></span><span class="hs-comment">-- conv_transpose1d _input _weight _bias _stride _padding _output_padding _groups _dilation = unsafePerformIO $ (ATen.cast8 ATen.Managed.conv_transpose1d_tttlllll) _input _weight _bias _stride _padding _output_padding _groups _dilation</span><span>
</span><span id="line-2573"></span><span>
</span><span id="line-2574"></span><span class="hs-comment">-- | cosh</span><span>
</span><span id="line-2575"></span><span class="hs-comment">--</span><span>
</span><span id="line-2576"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ cosh (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2577"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2578"></span><span class="annot"><a href="Torch.Typed.Functional.html#cosh"><span class="hs-identifier hs-type">cosh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2579"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709198"><span class="annot"><a href="#local-6989586621679709198"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709197"><span class="annot"><a href="#local-6989586621679709197"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709196"><span class="annot"><a href="#local-6989586621679709196"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2580"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709196"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709197"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2581"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2582"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709196"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709197"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709198"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2583"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2584"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709196"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709197"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709198"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2585"></span><span id="cosh"><span class="annot"><span class="annottext">cosh :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#cosh"><span class="hs-identifier hs-var hs-var">cosh</span></a></span></span><span> </span><span id="local-6989586621679709195"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709195"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.cosh_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709195"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2586"></span><span>
</span><span id="line-2587"></span><span class="hs-comment">-- cosine_embedding_loss :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2588"></span><span class="hs-comment">-- cosine_embedding_loss _input1 _input2 _target _margin _reduction = unsafePerformIO $ (ATen.cast5 ATen.Managed.cosine_embedding_loss_tttdl) _input1 _input2 _target _margin _reduction</span><span>
</span><span id="line-2589"></span><span>
</span><span id="line-2590"></span><span class="hs-comment">-- cudnn_affine_grid_generator :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2591"></span><span class="hs-comment">-- cudnn_affine_grid_generator _theta _N _C _H _W = unsafePerformIO $ (ATen.cast5 ATen.Managed.cudnn_affine_grid_generator_tllll) _theta _N _C _H _W</span><span>
</span><span id="line-2592"></span><span>
</span><span id="line-2593"></span><span class="hs-comment">-- cudnn_batch_norm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Double -&gt; Double -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-2594"></span><span class="hs-comment">-- cudnn_batch_norm _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon = unsafePerformIO $ (ATen.cast8 ATen.Managed.cudnn_batch_norm_tttttbdd) _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon</span><span>
</span><span id="line-2595"></span><span>
</span><span id="line-2596"></span><span class="hs-comment">-- cudnn_convolution :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; Int -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2597"></span><span class="hs-comment">-- cudnn_convolution _input _weight _bias _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (ATen.cast9 ATen.Managed.cudnn_convolution_tttllllbb) _input _weight _bias _padding _stride _dilation _groups _benchmark _deterministic</span><span>
</span><span id="line-2598"></span><span>
</span><span id="line-2599"></span><span class="hs-comment">-- cudnn_convolution_transpose :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; Int -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2600"></span><span class="hs-comment">-- cudnn_convolution_transpose _input _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (ATen.ATen.cast10 ATen.Managed.cudnn_convolution_transpose_tttlllllbb) _input _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic</span><span>
</span><span id="line-2601"></span><span>
</span><span id="line-2602"></span><span class="hs-comment">-- cudnn_grid_sampler :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2603"></span><span class="hs-comment">-- cudnn_grid_sampler _input _grid = unsafePerformIO $ (ATen.cast2 ATen.Managed.cudnn_grid_sampler_tt) _input _grid</span><span>
</span><span id="line-2604"></span><span>
</span><span id="line-2605"></span><span class="hs-comment">-- | Det</span><span>
</span><span id="line-2606"></span><span class="hs-comment">--</span><span>
</span><span id="line-2607"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Det '[2,2]</span><span>
</span><span id="line-2608"></span><span class="hs-comment">-- Det '[2,2] :: [Nat]</span><span>
</span><span id="line-2609"></span><span class="hs-comment">-- = '[]</span><span>
</span><span id="line-2610"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Det '[3,2,2]</span><span>
</span><span id="line-2611"></span><span class="hs-comment">-- Det '[3,2,2] :: [Nat]</span><span>
</span><span id="line-2612"></span><span class="hs-comment">-- = '[3]</span><span>
</span><span id="line-2613"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="Det"><span class="annot"><a href="Torch.Typed.Functional.html#Det"><span class="hs-identifier hs-var">Det</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709193"><span class="annot"><a href="#local-6989586621679709193"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2614"></span><span>  </span><span id="Det"><span class="annot"><a href="Torch.Typed.Functional.html#Det"><span class="hs-identifier hs-var">Det</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709192"><span class="annot"><a href="#local-6989586621679709192"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679709192"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-2615"></span><span>  </span><span id="Det"><span class="annot"><a href="Torch.Typed.Functional.html#Det"><span class="hs-identifier hs-var">Det</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709191"><span class="annot"><a href="#local-6989586621679709191"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679709190"><span class="annot"><a href="#local-6989586621679709190"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679709190"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709191"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2616"></span><span>  </span><span id="Det"><span class="annot"><a href="Torch.Typed.Functional.html#Det"><span class="hs-identifier hs-var">Det</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;This shape must be square matrix or batch + squre matrix.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-2617"></span><span>
</span><span id="line-2618"></span><span class="hs-comment">-- | det</span><span>
</span><span id="line-2619"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2620"></span><span class="hs-comment">--</span><span>
</span><span id="line-2621"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ det (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-2622"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-2623"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ det (ones :: CPUTensor 'D.Float '[3,2,2])</span><span>
</span><span id="line-2624"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-2625"></span><span class="annot"><a href="Torch.Typed.Functional.html#det"><span class="hs-identifier hs-type">det</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2626"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709188"><span class="annot"><a href="#local-6989586621679709188"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709187"><span class="annot"><a href="#local-6989586621679709187"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709186"><span class="annot"><a href="#local-6989586621679709186"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2627"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2628"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709186"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709187"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709188"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2629"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2630"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709186"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709187"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#Det"><span class="hs-identifier hs-type">Det</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709188"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2631"></span><span id="det"><span class="annot"><span class="annottext">det :: Tensor device dtype shape -&gt; Tensor device dtype (Det shape)
</span><a href="Torch.Typed.Functional.html#det"><span class="hs-identifier hs-var hs-var">det</span></a></span></span><span> </span><span id="local-6989586621679709185"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709185"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (Det shape))
-&gt; Tensor device dtype (Det shape)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (Det shape))
 -&gt; Tensor device dtype (Det shape))
-&gt; IO (Tensor device dtype (Det shape))
-&gt; Tensor device dtype (Det shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype (Det shape))
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.det_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709185"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2632"></span><span>
</span><span id="line-2633"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DimsDistinctAscendingCheck"><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscendingCheck"><span class="hs-identifier hs-var">DimsDistinctAscendingCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709182"><span class="annot"><a href="#local-6989586621679709182"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709181"><span class="annot"><a href="#local-6989586621679709181"><span class="hs-identifier hs-type">dim2</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709180"><span class="annot"><a href="#local-6989586621679709180"><span class="hs-identifier hs-type">cmp</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Ordering</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2634"></span><span>  </span><span id="DimsDistinctAscendingCheck"><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscendingCheck"><span class="hs-identifier hs-var">DimsDistinctAscendingCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">LT</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-2635"></span><span>  </span><span id="DimsDistinctAscendingCheck"><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscendingCheck"><span class="hs-identifier hs-var">DimsDistinctAscendingCheck</span></a></span></span><span> </span><span id="local-6989586621679709179"><span class="annot"><a href="#local-6989586621679709179"><span class="hs-identifier hs-type hs-type">dim1</span></a></span></span><span> </span><span id="local-6989586621679709178"><span class="annot"><a href="#local-6989586621679709178"><span class="hs-identifier hs-type hs-type">dim2</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2636"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-2637"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Dimensions must be distinct and in ascending order, but got &quot;</span></span><span>
</span><span id="line-2638"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709179"><span class="hs-identifier hs-type">dim1</span></a></span><span>
</span><span id="line-2639"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;, &quot;</span></span><span>
</span><span id="line-2640"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709178"><span class="hs-identifier hs-type">dim2</span></a></span><span>
</span><span id="line-2641"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-2642"></span><span>
</span><span id="line-2643"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DimsDistinctAscending"><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscending"><span class="hs-identifier hs-var">DimsDistinctAscending</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709176"><span class="annot"><a href="#local-6989586621679709176"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709175"><span class="annot"><a href="#local-6989586621679709175"><span class="hs-identifier hs-type">dim2</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2644"></span><span>  </span><span id="DimsDistinctAscending"><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscending"><span class="hs-identifier hs-var">DimsDistinctAscending</span></a></span></span><span> </span><span id="local-6989586621679709174"><span class="annot"><a href="#local-6989586621679709174"><span class="hs-identifier hs-type hs-type">dim1</span></a></span></span><span> </span><span id="local-6989586621679709173"><span class="annot"><a href="#local-6989586621679709173"><span class="hs-identifier hs-type hs-type">dim2</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscendingCheck"><span class="hs-identifier hs-type">DimsDistinctAscendingCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709174"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709173"><span class="hs-identifier hs-type">dim2</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709174"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709173"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2645"></span><span>
</span><span id="line-2646"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DiagEmbedShapeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#DiagEmbedShapeImpl"><span class="hs-identifier hs-var">DiagEmbedShapeImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709171"><span class="annot"><a href="#local-6989586621679709171"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709170"><span class="annot"><a href="#local-6989586621679709170"><span class="hs-identifier hs-type">dim2</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709169"><span class="annot"><a href="#local-6989586621679709169"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709168"><span class="annot"><a href="#local-6989586621679709168"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2647"></span><span>  </span><span id="DiagEmbedShapeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#DiagEmbedShapeImpl"><span class="hs-identifier hs-var">DiagEmbedShapeImpl</span></a></span></span><span> </span><span id="local-6989586621679709167"><span class="annot"><a href="#local-6989586621679709167"><span class="hs-identifier hs-type hs-type">dim1</span></a></span></span><span> </span><span id="local-6989586621679709166"><span class="annot"><a href="#local-6989586621679709166"><span class="hs-identifier hs-type hs-type">dim2</span></a></span></span><span> </span><span id="local-6989586621679709165"><span class="annot"><a href="#local-6989586621679709165"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709164"><span class="annot"><a href="#local-6989586621679709164"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Insert"><span class="hs-identifier hs-type">Insert</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709167"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709164"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Insert"><span class="hs-identifier hs-type">Insert</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709166"><span class="hs-identifier hs-type">dim2</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709164"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Init"><span class="hs-identifier hs-type">Init</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709165"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2648"></span><span>
</span><span id="line-2649"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DiagEmbedShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagEmbedShape"><span class="hs-identifier hs-var">DiagEmbedShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709160"><span class="annot"><a href="#local-6989586621679709160"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709159"><span class="annot"><a href="#local-6989586621679709159"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709158"><span class="annot"><a href="#local-6989586621679709158"><span class="hs-identifier hs-type">dim2</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709157"><span class="annot"><a href="#local-6989586621679709157"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2650"></span><span>  </span><span id="DiagEmbedShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagEmbedShape"><span class="hs-identifier hs-var">DiagEmbedShape</span></a></span></span><span> </span><span id="local-6989586621679709156"><span class="annot"><a href="#local-6989586621679709156"><span class="hs-identifier hs-type hs-type">index</span></a></span></span><span> </span><span id="local-6989586621679709155"><span class="annot"><a href="#local-6989586621679709155"><span class="hs-identifier hs-type hs-type">dim1</span></a></span></span><span> </span><span id="local-6989586621679709154"><span class="annot"><a href="#local-6989586621679709154"><span class="hs-identifier hs-type hs-type">dim2</span></a></span></span><span> </span><span id="local-6989586621679709153"><span class="annot"><a href="#local-6989586621679709153"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DiagEmbedShapeImpl"><span class="hs-identifier hs-type">DiagEmbedShapeImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709155"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709154"><span class="hs-identifier hs-type">dim2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709153"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Last"><span class="hs-identifier hs-type">Last</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709153"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709156"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2651"></span><span>
</span><span id="line-2652"></span><span class="hs-comment">-- | diagEmbed</span><span>
</span><span id="line-2653"></span><span class="hs-comment">--</span><span>
</span><span id="line-2654"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagEmbed @0 @1 @2 Upper (ones :: CPUTensor 'D.Float '[2,3])</span><span>
</span><span id="line-2655"></span><span class="hs-comment">-- (Float,[2,3,3])</span><span>
</span><span id="line-2656"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagEmbed @1 @0 @2 Upper (ones :: CPUTensor 'D.Float '[2,3])</span><span>
</span><span id="line-2657"></span><span class="hs-comment">-- (Float,[4,2,4])</span><span>
</span><span id="line-2658"></span><span class="annot"><a href="Torch.Typed.Functional.html#diagEmbed"><span class="hs-identifier hs-type">diagEmbed</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2659"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709150"><span class="annot"><a href="#local-6989586621679709150"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span id="local-6989586621679709149"><span class="annot"><a href="#local-6989586621679709149"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span id="local-6989586621679709148"><span class="annot"><a href="#local-6989586621679709148"><span class="hs-identifier hs-type">dim2</span></a></span></span><span> </span><span id="local-6989586621679709147"><span class="annot"><a href="#local-6989586621679709147"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709146"><span class="annot"><a href="#local-6989586621679709146"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709145"><span class="annot"><a href="#local-6989586621679709145"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709144"><span class="annot"><a href="#local-6989586621679709144"><span class="hs-identifier hs-type">dtype</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2660"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709150"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2661"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709149"><span class="hs-identifier hs-type">dim1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2662"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709148"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2663"></span><span>    </span><span class="annot"><a href="#local-6989586621679709146"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DiagEmbedShape"><span class="hs-identifier hs-type">DiagEmbedShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709150"><span class="hs-identifier hs-type">index</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709149"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709148"><span class="hs-identifier hs-type">dim2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709147"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2664"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscending"><span class="hs-identifier hs-type">DimsDistinctAscending</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709149"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709148"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2665"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709145"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709144"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2666"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2667"></span><span>  </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2668"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2669"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709145"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709144"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709147"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2670"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2671"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709145"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709144"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709146"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-2672"></span><span id="diagEmbed"><span class="annot"><span class="annottext">diagEmbed :: Tri -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#diagEmbed"><span class="hs-identifier hs-var hs-var">diagEmbed</span></a></span></span><span> </span><span id="local-6989586621679709143"><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709143"><span class="hs-identifier hs-var">tri</span></a></span></span><span> </span><span id="local-6989586621679709142"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709142"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2673"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2674"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span>
</span><span id="line-2675"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.diag_embed_tlll</span></a></span><span>
</span><span id="line-2676"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709142"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-2677"></span><span>      </span><span class="hs-special">(</span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709143"><span class="hs-identifier hs-var">tri</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709150"><span class="hs-identifier hs-type">index</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="hs-glyph">-</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709150"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2678"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim1 =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709149"><span class="hs-identifier hs-type">dim1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2679"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim2 =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709148"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2680"></span><span>
</span><span id="line-2681"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DiagflatShapeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#DiagflatShapeImpl"><span class="hs-identifier hs-var">DiagflatShapeImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709139"><span class="annot"><a href="#local-6989586621679709139"><span class="hs-identifier hs-type">d</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2682"></span><span>  </span><span id="DiagflatShapeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#DiagflatShapeImpl"><span class="hs-identifier hs-var">DiagflatShapeImpl</span></a></span></span><span> </span><span id="local-6989586621679709138"><span class="annot"><a href="#local-6989586621679709138"><span class="hs-identifier hs-type hs-type">d</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709138"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709138"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2683"></span><span>
</span><span id="line-2684"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DiagflatShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagflatShape"><span class="hs-identifier hs-var">DiagflatShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709136"><span class="annot"><a href="#local-6989586621679709136"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709135"><span class="annot"><a href="#local-6989586621679709135"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2685"></span><span>  </span><span id="DiagflatShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagflatShape"><span class="hs-identifier hs-var">DiagflatShape</span></a></span></span><span> </span><span id="local-6989586621679709134"><span class="annot"><a href="#local-6989586621679709134"><span class="hs-identifier hs-type hs-type">index</span></a></span></span><span> </span><span id="local-6989586621679709133"><span class="annot"><a href="#local-6989586621679709133"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DiagflatShapeImpl"><span class="hs-identifier hs-type">DiagflatShapeImpl</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Numel"><span class="hs-identifier hs-type">Numel</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709133"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679709134"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2686"></span><span>
</span><span id="line-2687"></span><span class="hs-comment">-- | diagflat</span><span>
</span><span id="line-2688"></span><span class="hs-comment">--</span><span>
</span><span id="line-2689"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagflat @0 Upper (ones :: CPUTensor 'D.Float '[3])</span><span>
</span><span id="line-2690"></span><span class="hs-comment">-- (Float,[3,3])</span><span>
</span><span id="line-2691"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagflat @1 Upper (ones :: CPUTensor 'D.Float '[3])</span><span>
</span><span id="line-2692"></span><span class="hs-comment">-- (Float,[4,4])</span><span>
</span><span id="line-2693"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagflat @0 Upper (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-2694"></span><span class="hs-comment">-- (Float,[4,4])</span><span>
</span><span id="line-2695"></span><span class="annot"><a href="Torch.Typed.Functional.html#diagflat"><span class="hs-identifier hs-type">diagflat</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2696"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709130"><span class="annot"><a href="#local-6989586621679709130"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span id="local-6989586621679709129"><span class="annot"><a href="#local-6989586621679709129"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709128"><span class="annot"><a href="#local-6989586621679709128"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709127"><span class="annot"><a href="#local-6989586621679709127"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709126"><span class="annot"><a href="#local-6989586621679709126"><span class="hs-identifier hs-type">dtype</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2697"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709130"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2698"></span><span>    </span><span class="annot"><a href="#local-6989586621679709128"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DiagflatShape"><span class="hs-identifier hs-type">DiagflatShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709130"><span class="hs-identifier hs-type">index</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709129"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2699"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709127"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709126"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2700"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2701"></span><span>  </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2702"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2703"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709127"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709126"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709129"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2704"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2705"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709127"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709126"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709128"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-2706"></span><span id="diagflat"><span class="annot"><span class="annottext">diagflat :: Tri -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#diagflat"><span class="hs-identifier hs-var hs-var">diagflat</span></a></span></span><span> </span><span id="local-6989586621679709125"><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709125"><span class="hs-identifier hs-var">tri</span></a></span></span><span> </span><span id="local-6989586621679709124"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709124"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2707"></span><span>  </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.diagflat_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709124"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; IO (Tensor device dtype shape'))
-&gt; Int -&gt; IO (Tensor device dtype shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2708"></span><span>    </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Tri
</span><a href="#local-6989586621679709125"><span class="hs-identifier hs-var">tri</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-2709"></span><span>      </span><span class="annot"><span class="annottext">Tri
</span><a href="Torch.Functional.html#Upper"><span class="hs-identifier hs-var">Upper</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709130"><span class="hs-identifier hs-type">index</span></a></span><span>
</span><span id="line-2710"></span><span>      </span><span class="annot"><span class="annottext">Tri
</span><a href="Torch.Functional.html#Lower"><span class="hs-identifier hs-var">Lower</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-glyph">-</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709130"><span class="hs-identifier hs-type">index</span></a></span><span>
</span><span id="line-2711"></span><span>
</span><span id="line-2712"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="NDimAtLeastCheck"><span class="annot"><a href="Torch.Typed.Functional.html#NDimAtLeastCheck"><span class="hs-identifier hs-var">NDimAtLeastCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709121"><span class="annot"><a href="#local-6989586621679709121"><span class="hs-identifier hs-type">ndim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709120"><span class="annot"><a href="#local-6989586621679709120"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709119"><span class="annot"><a href="#local-6989586621679709119"><span class="hs-identifier hs-type">cmp</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Ordering</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2713"></span><span>  </span><span id="NDimAtLeastCheck"><span class="annot"><a href="Torch.Typed.Functional.html#NDimAtLeastCheck"><span class="hs-identifier hs-var">NDimAtLeastCheck</span></a></span></span><span> </span><span id="local-6989586621679709118"><span class="annot"><a href="#local-6989586621679709118"><span class="hs-identifier hs-type hs-type">ndim</span></a></span></span><span> </span><span id="local-6989586621679709117"><span class="annot"><a href="#local-6989586621679709117"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">GT</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2714"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-2715"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Input must have at least &quot;</span></span><span>
</span><span id="line-2716"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679709118"><span class="hs-identifier hs-type">ndim</span></a></span><span>
</span><span id="line-2717"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot; dimensions, but got &quot;</span></span><span>
</span><span id="line-2718"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#ListLength"><span class="hs-identifier hs-type">ListLength</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709117"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2719"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-2720"></span><span>  </span><span id="NDimAtLeastCheck"><span class="annot"><a href="Torch.Typed.Functional.html#NDimAtLeastCheck"><span class="hs-identifier hs-var">NDimAtLeastCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-2721"></span><span>
</span><span id="line-2722"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="NDimAtLeast"><span class="annot"><a href="Torch.Typed.Functional.html#NDimAtLeast"><span class="hs-identifier hs-var">NDimAtLeast</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709115"><span class="annot"><a href="#local-6989586621679709115"><span class="hs-identifier hs-type">ndim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709114"><span class="annot"><a href="#local-6989586621679709114"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2723"></span><span>  </span><span id="NDimAtLeast"><span class="annot"><a href="Torch.Typed.Functional.html#NDimAtLeast"><span class="hs-identifier hs-var">NDimAtLeast</span></a></span></span><span> </span><span id="local-6989586621679709113"><span class="annot"><a href="#local-6989586621679709113"><span class="hs-identifier hs-type hs-type">ndim</span></a></span></span><span> </span><span id="local-6989586621679709112"><span class="annot"><a href="#local-6989586621679709112"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NDimAtLeastCheck"><span class="hs-identifier hs-type">NDimAtLeastCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709113"><span class="hs-identifier hs-type">ndim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709112"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">CmpNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709113"><span class="hs-identifier hs-type">ndim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#ListLength"><span class="hs-identifier hs-type">ListLength</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709112"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2724"></span><span>
</span><span id="line-2725"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DiagonalShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagonalShape"><span class="hs-identifier hs-var">DiagonalShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709110"><span class="annot"><a href="#local-6989586621679709110"><span class="hs-identifier hs-type">tri</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Functional.html#Tri"><span class="hs-identifier hs-type">Tri</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709109"><span class="annot"><a href="#local-6989586621679709109"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709108"><span class="annot"><a href="#local-6989586621679709108"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709107"><span class="annot"><a href="#local-6989586621679709107"><span class="hs-identifier hs-type">dim2</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709106"><span class="annot"><a href="#local-6989586621679709106"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2726"></span><span>  </span><span id="DiagonalShape"><span class="annot"><a href="Torch.Typed.Functional.html#DiagonalShape"><span class="hs-identifier hs-var">DiagonalShape</span></a></span></span><span> </span><span id="local-6989586621679709105"><span class="annot"><a href="#local-6989586621679709105"><span class="hs-identifier hs-type hs-type">tri</span></a></span></span><span> </span><span id="local-6989586621679709104"><span class="annot"><a href="#local-6989586621679709104"><span class="hs-identifier hs-type hs-type">index</span></a></span></span><span> </span><span id="local-6989586621679709103"><span class="annot"><a href="#local-6989586621679709103"><span class="hs-identifier hs-type hs-type">dim1</span></a></span></span><span> </span><span id="local-6989586621679709102"><span class="annot"><a href="#local-6989586621679709102"><span class="hs-identifier hs-type hs-type">dim2</span></a></span></span><span> </span><span id="local-6989586621679709101"><span class="annot"><a href="#local-6989586621679709101"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2727"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#Remove"><span class="hs-identifier hs-type">Remove</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Remove"><span class="hs-identifier hs-type">Remove</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709101"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709102"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709103"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="Torch.Typed.Functional.html#DiagSize"><span class="hs-identifier hs-type">DiagSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709105"><span class="hs-identifier hs-type">tri</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709104"><span class="hs-identifier hs-type">index</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Index"><span class="hs-identifier hs-type">Index</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709101"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709103"><span class="hs-identifier hs-type">dim1</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Index"><span class="hs-identifier hs-type">Index</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709101"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709102"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-2728"></span><span>
</span><span id="line-2729"></span><span class="hs-comment">-- | diagonal</span><span>
</span><span id="line-2730"></span><span class="hs-comment">--</span><span>
</span><span id="line-2731"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagonal @'Upper @0 @0 @1 (ones :: CPUTensor 'D.Float '[3,3])</span><span>
</span><span id="line-2732"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-2733"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagonal @'Upper @1 @0 @1 (ones :: CPUTensor 'D.Float '[3,3])</span><span>
</span><span id="line-2734"></span><span class="hs-comment">-- (Float,[2])</span><span>
</span><span id="line-2735"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ diagonal @'Lower @1 @1 @2 (ones :: CPUTensor 'D.Float '[2,5,4,2])</span><span>
</span><span id="line-2736"></span><span class="hs-comment">-- (Float,[2,2,4])</span><span>
</span><span id="line-2737"></span><span class="annot"><a href="Torch.Typed.Functional.html#diagonal"><span class="hs-identifier hs-type">diagonal</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2738"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709096"><span class="annot"><a href="#local-6989586621679709096"><span class="hs-identifier hs-type">tri</span></a></span></span><span> </span><span id="local-6989586621679709095"><span class="annot"><a href="#local-6989586621679709095"><span class="hs-identifier hs-type">index</span></a></span></span><span> </span><span id="local-6989586621679709094"><span class="annot"><a href="#local-6989586621679709094"><span class="hs-identifier hs-type">dim1</span></a></span></span><span> </span><span id="local-6989586621679709093"><span class="annot"><a href="#local-6989586621679709093"><span class="hs-identifier hs-type">dim2</span></a></span></span><span> </span><span id="local-6989586621679709092"><span class="annot"><a href="#local-6989586621679709092"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709091"><span class="annot"><a href="#local-6989586621679709091"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709090"><span class="annot"><a href="#local-6989586621679709090"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679709089"><span class="annot"><a href="#local-6989586621679709089"><span class="hs-identifier hs-type">dtype</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2739"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownTri"><span class="hs-identifier hs-type">KnownTri</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709096"><span class="hs-identifier hs-type">tri</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2740"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709095"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2741"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709094"><span class="hs-identifier hs-type">dim1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2742"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709093"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2743"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#NDimAtLeast"><span class="hs-identifier hs-type">NDimAtLeast</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><a href="#local-6989586621679709092"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2744"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#DimsDistinctAscending"><span class="hs-identifier hs-type">DimsDistinctAscending</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709094"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709093"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2745"></span><span>    </span><span class="annot"><a href="#local-6989586621679709091"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DiagonalShape"><span class="hs-identifier hs-type">DiagonalShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709096"><span class="hs-identifier hs-type">tri</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709095"><span class="hs-identifier hs-type">index</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709094"><span class="hs-identifier hs-type">dim1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709093"><span class="hs-identifier hs-type">dim2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709092"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2746"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardDTypeValidation"><span class="hs-identifier hs-type">StandardDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709090"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709089"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2747"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2748"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2749"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709090"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709089"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709092"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2750"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2751"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709090"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709089"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709091"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-2752"></span><span id="diagonal"><span class="annot"><span class="annottext">diagonal :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#diagonal"><span class="hs-identifier hs-var hs-var">diagonal</span></a></span></span><span> </span><span id="local-6989586621679709088"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709088"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2753"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-2754"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span>
</span><span id="line-2755"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.diagonal_tlll</span></a></span><span>
</span><span id="line-2756"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709088"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-2757"></span><span>      </span><span class="hs-special">(</span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Tri -&gt; Bool
</span><a href="Torch.Functional.html#isUpper"><span class="hs-identifier hs-var">isUpper</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownTri tri =&gt; Tri
forall (tri :: Tri). KnownTri tri =&gt; Tri
</span><a href="Torch.Typed.Functional.html#triVal"><span class="hs-identifier hs-var">triVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709096"><span class="hs-identifier hs-type">tri</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709095"><span class="hs-identifier hs-type">index</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="hs-glyph">-</span><span> </span><span class="annot"><span class="annottext">KnownNat index =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709095"><span class="hs-identifier hs-type">index</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2758"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim1 =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709094"><span class="hs-identifier hs-type">dim1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2759"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim2 =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709093"><span class="hs-identifier hs-type">dim2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2760"></span><span>
</span><span id="line-2761"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DotDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#DotDTypeIsValid"><span class="hs-identifier hs-var">DotDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709085"><span class="annot"><a href="#local-6989586621679709085"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709084"><span class="annot"><a href="#local-6989586621679709084"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2762"></span><span>  </span><span id="DotDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#DotDTypeIsValid"><span class="hs-identifier hs-var">DotDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709083"><span class="annot"><a href="#local-6989586621679709083"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2763"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotBool"><span class="hs-identifier hs-type">DTypeIsNotBool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709083"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2764"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709083"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2765"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-2766"></span><span>  </span><span id="DotDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#DotDTypeIsValid"><span class="hs-identifier hs-var">DotDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679709081"><span class="annot"><a href="#local-6989586621679709081"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709080"><span class="annot"><a href="#local-6989586621679709080"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709081"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679709080"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2767"></span><span>  </span><span id="DotDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#DotDTypeIsValid"><span class="hs-identifier hs-var">DotDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679709079"><span class="annot"><a href="#local-6989586621679709079"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709078"><span class="annot"><a href="#local-6989586621679709078"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709079"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709078"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-2768"></span><span>
</span><span id="line-2769"></span><span class="hs-comment">-- | dot product</span><span>
</span><span id="line-2770"></span><span class="hs-comment">-- Note that this function does not broadcast.</span><span>
</span><span id="line-2771"></span><span class="annot"><a href="Torch.Typed.Functional.html#dot"><span class="hs-identifier hs-type">dot</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2772"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709076"><span class="annot"><a href="#local-6989586621679709076"><span class="hs-identifier hs-type">size</span></a></span></span><span> </span><span id="local-6989586621679709075"><span class="annot"><a href="#local-6989586621679709075"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709074"><span class="annot"><a href="#local-6989586621679709074"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2773"></span><span>  </span><span class="annot"><a href="Torch.Typed.Functional.html#DotDTypeIsValid"><span class="hs-identifier hs-type">DotDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709075"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2774"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2775"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709075"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709076"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2776"></span><span>  </span><span class="hs-comment">-- | other input</span><span>
</span><span id="line-2777"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709075"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709076"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2778"></span><span>  </span><span class="hs-comment">-- | dot product</span><span>
</span><span id="line-2779"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709075"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-2780"></span><span id="dot"><span class="annot"><span class="annottext">dot :: Tensor device dtype '[size]
-&gt; Tensor device dtype '[size] -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#dot"><span class="hs-identifier hs-var hs-var">dot</span></a></span></span><span> </span><span id="local-6989586621679709073"><span class="annot"><span class="annottext">Tensor device dtype '[size]
</span><a href="#local-6989586621679709073"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679709072"><span class="annot"><span class="annottext">Tensor device dtype '[size]
</span><a href="#local-6989586621679709072"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[size]
-&gt; Tensor device dtype '[size]
-&gt; IO (Tensor device dtype '[])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.dot_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[size]
</span><a href="#local-6989586621679709073"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[size]
</span><a href="#local-6989586621679709072"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-2781"></span><span>
</span><span id="line-2782"></span><span class="hs-comment">-- einsum :: String -&gt; [Tensor device dtype shape] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2783"></span><span class="hs-comment">-- einsum _equation _tensors = unsafePerformIO $ (ATen.cast2 ATen.Managed.einsum_sl) _equation _tensors</span><span>
</span><span id="line-2784"></span><span>
</span><span id="line-2785"></span><span class="hs-keyword">class</span><span> </span><span id="KnownMaybeNat"><span class="annot"><a href="Torch.Typed.Functional.html#KnownMaybeNat"><span class="hs-identifier hs-var">KnownMaybeNat</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710875"><span class="annot"><a href="#local-6989586621679710875"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2786"></span><span>  </span><span id="maybeNatVal"><span class="annot"><a href="Torch.Typed.Functional.html#maybeNatVal"><span class="hs-identifier hs-type">maybeNatVal</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span>
</span><span id="line-2787"></span><span>
</span><span id="line-2788"></span><span id="local-6989586621679709069"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679709069"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownMaybeNat"><span class="hs-identifier hs-type">KnownMaybeNat</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679709069"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2789"></span><span>  </span><span id="local-6989586621679709066"><span class="annot"><span class="annottext">maybeNatVal :: Maybe Integer
</span><a href="#local-6989586621679709066"><span class="hs-identifier hs-var hs-var hs-var hs-var">maybeNatVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Maybe Integer
forall a. a -&gt; Maybe a
</span><span class="hs-identifier hs-var">Just</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Maybe Integer)
-&gt; (Proxy n -&gt; Integer) -&gt; Proxy n -&gt; Maybe Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Proxy n -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; Type).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy n -&gt; Maybe Integer) -&gt; Proxy n -&gt; Maybe Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy n
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709069"><span class="hs-identifier hs-type">n</span></a></span></span><span>
</span><span id="line-2790"></span><span>
</span><span id="line-2791"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownMaybeNat"><span class="hs-identifier hs-type">KnownMaybeNat</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2792"></span><span>  </span><span id="local-6989586621679709062"><span class="annot"><span class="annottext">maybeNatVal :: Maybe Integer
</span><a href="#local-6989586621679709062"><span class="hs-identifier hs-var hs-var hs-var hs-var">maybeNatVal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Integer
forall a. Maybe a
</span><span class="hs-identifier hs-var">Nothing</span></span><span>
</span><span id="line-2793"></span><span>
</span><span id="line-2794"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="PaddingIdxCheck"><span class="annot"><a href="Torch.Typed.Functional.html#PaddingIdxCheck"><span class="hs-identifier hs-var">PaddingIdxCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709060"><span class="annot"><a href="#local-6989586621679709060"><span class="hs-identifier hs-type">idx</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709059"><span class="annot"><a href="#local-6989586621679709059"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-2795"></span><span>  </span><span id="PaddingIdxCheck"><span class="annot"><a href="Torch.Typed.Functional.html#PaddingIdxCheck"><span class="hs-identifier hs-var">PaddingIdxCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679709058"><span class="annot"><a href="#local-6989586621679709058"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709057"><span class="annot"><a href="#local-6989586621679709057"><span class="hs-identifier hs-type hs-type">numEmbeds</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679709058"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679709057"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span>
</span><span id="line-2796"></span><span>  </span><span id="PaddingIdxCheck"><span class="annot"><a href="Torch.Typed.Functional.html#PaddingIdxCheck"><span class="hs-identifier hs-var">PaddingIdxCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-2797"></span><span>
</span><span id="line-2798"></span><span class="hs-comment">-- | embedding</span><span>
</span><span id="line-2799"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2800"></span><span class="hs-comment">-- TODO: what about sparsity here?</span><span>
</span><span id="line-2801"></span><span class="hs-comment">-- TODO: what output dtypes are supported?</span><span>
</span><span id="line-2802"></span><span class="hs-comment">--</span><span>
</span><span id="line-2803"></span><span class="hs-comment">-- &gt;&gt;&gt; weights = fromJust [[1, 1], [2, 2], [3, 3], [4, 4]] :: CPUTensor 'D.Float '[4, 2]</span><span>
</span><span id="line-2804"></span><span class="hs-comment">-- &gt;&gt;&gt; indices = fromJust [[0], [2], [0], [1]] :: CPUTensor 'D.Int64 '[4, 1]</span><span>
</span><span id="line-2805"></span><span class="hs-comment">-- &gt;&gt;&gt; t = embedding @('Just 0) False False weights indices</span><span>
</span><span id="line-2806"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-2807"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[4, 1, 2]</span><span>
</span><span id="line-2808"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[[Float]]]) $ t</span><span>
</span><span id="line-2809"></span><span class="hs-comment">-- (Float,([4,1,2],[[[1.0,1.0]],[[3.0,3.0]],[[1.0,1.0]],[[2.0,2.0]]]))</span><span>
</span><span id="line-2810"></span><span class="hs-comment">-- &gt;&gt;&gt; t = embedding @'Nothing False False weights indices</span><span>
</span><span id="line-2811"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-2812"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[4, 1, 2]</span><span>
</span><span id="line-2813"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[[Float]]]) $ t</span><span>
</span><span id="line-2814"></span><span class="hs-comment">-- (Float,([4,1,2],[[[1.0,1.0]],[[3.0,3.0]],[[1.0,1.0]],[[2.0,2.0]]]))</span><span>
</span><span id="line-2815"></span><span class="annot"><a href="Torch.Typed.Functional.html#embedding"><span class="hs-identifier hs-type">embedding</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2816"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679709055"><span class="annot"><a href="#local-6989586621679709055"><span class="hs-identifier hs-type">paddingIdx</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679709054"><span class="annot"><a href="#local-6989586621679709054"><span class="hs-identifier hs-type">numEmbeds</span></a></span></span><span> </span><span id="local-6989586621679709053"><span class="annot"><a href="#local-6989586621679709053"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679709052"><span class="annot"><a href="#local-6989586621679709052"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709051"><span class="annot"><a href="#local-6989586621679709051"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709050"><span class="annot"><a href="#local-6989586621679709050"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2817"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownMaybeNat"><span class="hs-identifier hs-type">KnownMaybeNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709055"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2818"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#PaddingIdxCheck"><span class="hs-identifier hs-type">PaddingIdxCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709055"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709054"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span>
</span><span id="line-2819"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2820"></span><span>  </span><span class="hs-comment">-- | whether or not to scale the gradient by the frequencies</span><span>
</span><span id="line-2821"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2822"></span><span>  </span><span class="hs-comment">-- | whether or not the embedding is sparse</span><span>
</span><span id="line-2823"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2824"></span><span>  </span><span class="hs-comment">-- | weights</span><span>
</span><span id="line-2825"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709050"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709051"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679709054"><span class="hs-identifier hs-type">numEmbeds</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679709053"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2826"></span><span>  </span><span class="hs-comment">-- | indices</span><span>
</span><span id="line-2827"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709050"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709052"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2828"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2829"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709050"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709051"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679709053"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709052"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-2830"></span><span id="embedding"><span class="annot"><span class="annottext">embedding :: Bool
-&gt; Bool
-&gt; Tensor device dtype '[numEmbeds, embedDim]
-&gt; Tensor device 'Int64 shape
-&gt; Tensor device dtype (Reverse (embedDim : Reverse shape))
</span><a href="Torch.Typed.Functional.html#embedding"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span id="local-6989586621679709049"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709049"><span class="hs-identifier hs-var">scaleGradByFreq</span></a></span></span><span> </span><span id="local-6989586621679709048"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709048"><span class="hs-identifier hs-var">sparse</span></a></span></span><span> </span><span id="local-6989586621679709047"><span class="annot"><span class="annottext">Tensor device dtype '[numEmbeds, embedDim]
</span><a href="#local-6989586621679709047"><span class="hs-identifier hs-var">weights</span></a></span></span><span> </span><span id="local-6989586621679709046"><span class="annot"><span class="annottext">Tensor device 'Int64 shape
</span><a href="#local-6989586621679709046"><span class="hs-identifier hs-var">indices</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2831"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype (ReverseImpl (Reverse shape) '[embedDim]))
-&gt; Tensor device dtype (ReverseImpl (Reverse shape) '[embedDim])
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (ReverseImpl (Reverse shape) '[embedDim]))
 -&gt; Tensor device dtype (ReverseImpl (Reverse shape) '[embedDim]))
-&gt; IO
     (Tensor device dtype (ReverseImpl (Reverse shape) '[embedDim]))
-&gt; Tensor device dtype (ReverseImpl (Reverse shape) '[embedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[numEmbeds, embedDim]
-&gt; Tensor device 'Int64 shape
-&gt; Int
-&gt; Bool
-&gt; Bool
-&gt; IO
     (Tensor device dtype (ReverseImpl (Reverse shape) '[embedDim]))
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.embedding_ttlbb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[numEmbeds, embedDim]
</span><a href="#local-6989586621679709047"><span class="hs-identifier hs-var">weights</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 shape
</span><a href="#local-6989586621679709046"><span class="hs-identifier hs-var">indices</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679709044"><span class="hs-identifier hs-var">paddingIdx</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709049"><span class="hs-identifier hs-var">scaleGradByFreq</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709048"><span class="hs-identifier hs-var">sparse</span></a></span><span>
</span><span id="line-2832"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-2833"></span><span>    </span><span class="annot"><a href="#local-6989586621679709044"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-2834"></span><span>    </span><span id="local-6989586621679709044"><span class="annot"><span class="annottext">paddingIdx :: Int
</span><a href="#local-6989586621679709044"><span class="hs-identifier hs-var hs-var">paddingIdx</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">KnownMaybeNat paddingIdx =&gt; Maybe Integer
forall (n :: Maybe Nat). KnownMaybeNat n =&gt; Maybe Integer
</span><a href="Torch.Typed.Functional.html#maybeNatVal"><span class="hs-identifier hs-var">maybeNatVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709055"><span class="hs-identifier hs-type">paddingIdx</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-2835"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679709043"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679709043"><span class="hs-identifier hs-var">idx</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679709043"><span class="hs-identifier hs-var">idx</span></a></span><span>
</span><span id="line-2836"></span><span>      </span><span class="annot"><span class="annottext">Maybe Integer
</span><span class="hs-identifier hs-var">Nothing</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-glyph">-</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span>
</span><span id="line-2837"></span><span>
</span><span id="line-2838"></span><span class="hs-comment">-- embedding_bag :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Int -&gt; Bool -&gt; Tensor device dtype shape -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-2839"></span><span class="hs-comment">-- embedding_bag _weight _indices _offsets _scale_grad_by_freq _mode _sparse _per_sample_weights = unsafePerformIO $ (ATen.cast7 ATen.Managed.embedding_bag_tttblbt) _weight _indices _offsets _scale_grad_by_freq _mode _sparse _per_sample_weights</span><span>
</span><span id="line-2840"></span><span>
</span><span id="line-2841"></span><span class="hs-comment">-- | emptyLike</span><span>
</span><span id="line-2842"></span><span class="hs-comment">-- TODO: this seems quite unsafe, the values of this tensor will be random</span><span>
</span><span id="line-2843"></span><span class="hs-comment">--</span><span>
</span><span id="line-2844"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- emptyLike (ones :: CPUTensor 'D.Float '[3,4,5])</span><span>
</span><span id="line-2845"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-2846"></span><span class="hs-comment">-- (Float,[3,4,5])</span><span>
</span><span id="line-2847"></span><span class="annot"><a href="Torch.Typed.Functional.html#emptyLike"><span class="hs-identifier hs-type">emptyLike</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2848"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709041"><span class="annot"><a href="#local-6989586621679709041"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709040"><span class="annot"><a href="#local-6989586621679709040"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709039"><span class="annot"><a href="#local-6989586621679709039"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2849"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2850"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709039"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709040"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709041"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2851"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2852"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709039"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709040"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709041"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-2853"></span><span id="emptyLike"><span class="annot"><span class="annottext">emptyLike :: Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.Functional.html#emptyLike"><span class="hs-identifier hs-var hs-var">emptyLike</span></a></span></span><span> </span><span id="local-6989586621679709038"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709038"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.empty_like_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709038"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2854"></span><span>
</span><span id="line-2855"></span><span class="hs-comment">-- | erfc</span><span>
</span><span id="line-2856"></span><span class="hs-comment">--</span><span>
</span><span id="line-2857"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ erfc (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2858"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2859"></span><span class="annot"><a href="Torch.Typed.Functional.html#erfc"><span class="hs-identifier hs-type">erfc</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2860"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709035"><span class="annot"><a href="#local-6989586621679709035"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709034"><span class="annot"><a href="#local-6989586621679709034"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709033"><span class="annot"><a href="#local-6989586621679709033"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2861"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709033"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709034"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2862"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2863"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709033"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709034"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709035"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2864"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2865"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709033"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709034"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709035"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2866"></span><span id="erfc"><span class="annot"><span class="annottext">erfc :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#erfc"><span class="hs-identifier hs-var hs-var">erfc</span></a></span></span><span> </span><span id="local-6989586621679709032"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709032"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.erfc_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709032"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2867"></span><span>
</span><span id="line-2868"></span><span class="hs-comment">-- | expm1</span><span>
</span><span id="line-2869"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2870"></span><span class="hs-comment">--</span><span>
</span><span id="line-2871"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ expm1 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2872"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2873"></span><span class="annot"><a href="Torch.Typed.Functional.html#expm1"><span class="hs-identifier hs-type">expm1</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2874"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709029"><span class="annot"><a href="#local-6989586621679709029"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709028"><span class="annot"><a href="#local-6989586621679709028"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709027"><span class="annot"><a href="#local-6989586621679709027"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2875"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709027"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709028"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2876"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2877"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709027"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709028"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709029"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2878"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2879"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709027"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709028"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709029"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2880"></span><span id="expm1"><span class="annot"><span class="annottext">expm1 :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#expm1"><span class="hs-identifier hs-var hs-var">expm1</span></a></span></span><span> </span><span id="local-6989586621679709026"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709026"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.expm1_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709026"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2881"></span><span>
</span><span id="line-2882"></span><span class="hs-comment">-- | expand</span><span>
</span><span id="line-2883"></span><span class="hs-comment">-- TODO: figure out what the `implicit` boolean value does</span><span>
</span><span id="line-2884"></span><span class="hs-comment">--</span><span>
</span><span id="line-2885"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2]</span><span>
</span><span id="line-2886"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = expand @'[3, 1, 2] False t</span><span>
</span><span id="line-2887"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t'</span><span>
</span><span id="line-2888"></span><span class="hs-comment">-- (Float,[3,1,2])</span><span>
</span><span id="line-2889"></span><span class="hs-comment">-- &gt;&gt;&gt; t'' = expand @'[3, 1, 2] True t</span><span>
</span><span id="line-2890"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t''</span><span>
</span><span id="line-2891"></span><span class="hs-comment">-- (Float,[3,1,2])</span><span>
</span><span id="line-2892"></span><span class="hs-comment">-- &gt;&gt;&gt; toInt (all (t' ==. t'')) == 1</span><span>
</span><span id="line-2893"></span><span class="hs-comment">-- True</span><span>
</span><span id="line-2894"></span><span class="annot"><a href="Torch.Typed.Functional.html#expand"><span class="hs-identifier hs-type">expand</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2895"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709023"><span class="annot"><a href="#local-6989586621679709023"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679709022"><span class="annot"><a href="#local-6989586621679709022"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709021"><span class="annot"><a href="#local-6989586621679709021"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709020"><span class="annot"><a href="#local-6989586621679709020"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2896"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownShape"><span class="hs-identifier hs-type">KnownShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709023"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-2897"></span><span>    </span><span class="annot"><a href="#local-6989586621679709023"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709022"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709023"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-2898"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2899"></span><span>  </span><span class="hs-comment">-- | some boolean value with unknown function</span><span>
</span><span id="line-2900"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2901"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2902"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709020"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709021"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709022"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2903"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2904"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709020"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709021"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709023"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-2905"></span><span id="expand"><span class="annot"><span class="annottext">expand :: Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#expand"><span class="hs-identifier hs-var hs-var">expand</span></a></span></span><span> </span><span id="local-6989586621679709019"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709019"><span class="hs-identifier hs-var">someBool</span></a></span></span><span> </span><span id="local-6989586621679709018"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709018"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; [Int]
-&gt; Bool
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.tensor_expand_lb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709018"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownShape shape' =&gt; [Int]
forall (shape :: [Nat]). KnownShape shape =&gt; [Int]
</span><a href="Torch.Typed.Tensor.html#shapeVal"><span class="hs-identifier hs-var">shapeVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679709023"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679709019"><span class="hs-identifier hs-var">someBool</span></a></span><span>
</span><span id="line-2906"></span><span>
</span><span id="line-2907"></span><span class="hs-comment">-- flatten :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2908"></span><span class="hs-comment">-- flatten _input _start_dim _end_dim = unsafePerformIO $ (ATen.cast3 ATen.Managed.flatten_tll) _input _start_dim _end_dim</span><span>
</span><span id="line-2909"></span><span>
</span><span id="line-2910"></span><span class="hs-comment">-- | flattenAll</span><span>
</span><span id="line-2911"></span><span class="hs-comment">--</span><span>
</span><span id="line-2912"></span><span class="hs-comment">-- &gt;&gt;&gt; t = flattenAll (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2913"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-2914"></span><span class="hs-comment">-- (Float,[6])</span><span>
</span><span id="line-2915"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-2916"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[6]</span><span>
</span><span id="line-2917"></span><span class="annot"><a href="Torch.Typed.Functional.html#flattenAll"><span class="hs-identifier hs-type">flattenAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2918"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709014"><span class="annot"><a href="#local-6989586621679709014"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709013"><span class="annot"><a href="#local-6989586621679709013"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709012"><span class="annot"><a href="#local-6989586621679709012"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2919"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownShape"><span class="hs-identifier hs-type">KnownShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709014"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2920"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2921"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709012"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709013"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709014"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2922"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2923"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709012"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709013"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="../file:///nix/store/1mdaip8k8g5d1ha6705l1v4i4d6l2c03-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">Product</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709014"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-2924"></span><span id="flattenAll"><span class="annot"><span class="annottext">flattenAll :: Tensor device dtype shape -&gt; Tensor device dtype '[Product shape]
</span><a href="Torch.Typed.Functional.html#flattenAll"><span class="hs-identifier hs-var hs-var">flattenAll</span></a></span></span><span> </span><span id="local-6989586621679709011"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709011"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2925"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype '[Let6989586621680387342Prod shape shape 1])
-&gt; Tensor device dtype '[Let6989586621680387342Prod shape shape 1]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype '[Let6989586621680387342Prod shape shape 1])
 -&gt; Tensor device dtype '[Let6989586621680387342Prod shape shape 1])
-&gt; IO
     (Tensor device dtype '[Let6989586621680387342Prod shape shape 1])
-&gt; Tensor device dtype '[Let6989586621680387342Prod shape shape 1]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Int
-&gt; IO
     (Tensor device dtype '[Let6989586621680387342Prod shape shape 1])
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.flatten_tll</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709011"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-2926"></span><span>
</span><span id="line-2927"></span><span class="hs-comment">-- | frac</span><span>
</span><span id="line-2928"></span><span class="hs-comment">--</span><span>
</span><span id="line-2929"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ frac (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2930"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2931"></span><span class="annot"><a href="Torch.Typed.Functional.html#frac"><span class="hs-identifier hs-type">frac</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2932"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709008"><span class="annot"><a href="#local-6989586621679709008"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709007"><span class="annot"><a href="#local-6989586621679709007"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709006"><span class="annot"><a href="#local-6989586621679709006"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2933"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709006"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709007"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-2934"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2935"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709006"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709007"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709008"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2936"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2937"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709006"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709007"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709008"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2938"></span><span id="frac"><span class="annot"><span class="annottext">frac :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#frac"><span class="hs-identifier hs-var hs-var">frac</span></a></span></span><span> </span><span id="local-6989586621679709005"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709005"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.frac_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679709005"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-2939"></span><span>
</span><span id="line-2940"></span><span class="hs-comment">-- | full like</span><span>
</span><span id="line-2941"></span><span class="hs-comment">--</span><span>
</span><span id="line-2942"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fullLike 3.0 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-2943"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-2944"></span><span class="annot"><a href="Torch.Typed.Functional.html#fullLike"><span class="hs-identifier hs-type">fullLike</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-2945"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679709002"><span class="annot"><a href="#local-6989586621679709002"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679709001"><span class="annot"><a href="#local-6989586621679709001"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679709000"><span class="annot"><a href="#local-6989586621679709000"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-2946"></span><span>  </span><span class="hs-comment">-- | fill value</span><span>
</span><span id="line-2947"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2948"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-2949"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709000"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709001"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709002"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-2950"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-2951"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709000"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709001"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679709002"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-2952"></span><span id="fullLike"><span class="annot"><span class="annottext">fullLike :: Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#fullLike"><span class="hs-identifier hs-var hs-var">fullLike</span></a></span></span><span> </span><span id="local-6989586621679708999"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708999"><span class="hs-identifier hs-var">fillValue</span></a></span></span><span> </span><span id="local-6989586621679708998"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708998"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-2953"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Float
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.full_like_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708998"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708999"><span class="hs-identifier hs-var">fillValue</span></a></span><span>
</span><span id="line-2954"></span><span>
</span><span id="line-2955"></span><span class="hs-comment">-- grid_sampler :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2956"></span><span class="hs-comment">-- grid_sampler _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (ATen.cast4 ATen.Managed.grid_sampler_ttll) _input _grid _interpolation_mode _padding_mode</span><span>
</span><span id="line-2957"></span><span>
</span><span id="line-2958"></span><span class="hs-comment">-- grid_sampler_2d :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2959"></span><span class="hs-comment">-- grid_sampler_2d _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (ATen.cast4 ATen.Managed.grid_sampler_2d_ttll) _input _grid _interpolation_mode _padding_mode</span><span>
</span><span id="line-2960"></span><span>
</span><span id="line-2961"></span><span class="hs-comment">-- grid_sampler_3d :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2962"></span><span class="hs-comment">-- grid_sampler_3d _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (ATen.cast4 ATen.Managed.grid_sampler_3d_ttll) _input _grid _interpolation_mode _padding_mode</span><span>
</span><span id="line-2963"></span><span>
</span><span id="line-2964"></span><span class="hs-comment">-- hinge_embedding_loss :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2965"></span><span class="hs-comment">-- hinge_embedding_loss _input _target _margin _reduction = unsafePerformIO $ (ATen.cast4 ATen.Managed.hinge_embedding_loss_ttdl) _input _target _margin _reduction</span><span>
</span><span id="line-2966"></span><span>
</span><span id="line-2967"></span><span class="hs-comment">-- ger :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2968"></span><span class="hs-comment">-- ger _input _vec2 = unsafePerformIO $ (ATen.cast2 ATen.Managed.ger_tt) _input _vec2</span><span>
</span><span id="line-2969"></span><span>
</span><span id="line-2970"></span><span class="hs-comment">-- group_norm :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2971"></span><span class="hs-comment">-- group_norm _input _num_groups _weight _bias _eps _cudnn_enabled = unsafePerformIO $ (ATen.cast6 ATen.Managed.group_norm_tlttdb) _input _num_groups _weight _bias _eps _cudnn_enabled</span><span>
</span><span id="line-2972"></span><span>
</span><span id="line-2973"></span><span class="hs-comment">-- fft :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2974"></span><span class="hs-comment">-- fft _input _signal_ndim _normalized = unsafePerformIO $ (ATen.cast3 ATen.Managed.fft_tlb) _input _signal_ndim _normalized</span><span>
</span><span id="line-2975"></span><span>
</span><span id="line-2976"></span><span class="hs-comment">-- ifft :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2977"></span><span class="hs-comment">-- ifft _input _signal_ndim _normalized = unsafePerformIO $ (ATen.cast3 ATen.Managed.ifft_tlb) _input _signal_ndim _normalized</span><span>
</span><span id="line-2978"></span><span>
</span><span id="line-2979"></span><span class="hs-comment">-- rfft :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2980"></span><span class="hs-comment">-- rfft _input _signal_ndim _normalized _onesided = unsafePerformIO $ (ATen.cast4 ATen.Managed.rfft_tlbb) _input _signal_ndim _normalized _onesided</span><span>
</span><span id="line-2981"></span><span>
</span><span id="line-2982"></span><span class="hs-comment">-- irfft :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Bool -&gt; [Int] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2983"></span><span class="hs-comment">-- irfft _input _signal_ndim _normalized _onesided _signal_sizes = unsafePerformIO $ (ATen.cast5 ATen.Managed.irfft_tlbbl) _input _signal_ndim _normalized _onesided _signal_sizes</span><span>
</span><span id="line-2984"></span><span>
</span><span id="line-2985"></span><span class="hs-comment">-- index :: Tensor device dtype shape -&gt; [Tensor device dtype shape] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2986"></span><span class="hs-comment">-- index _input _indices = unsafePerformIO $ (ATen.cast2 ATen.Managed.index_tl) _input _indices</span><span>
</span><span id="line-2987"></span><span>
</span><span id="line-2988"></span><span class="hs-comment">-- index_copy :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2989"></span><span class="hs-comment">-- index_copy _input _dim _index _source = unsafePerformIO $ (ATen.cast4 ATen.Managed.index_copy_tltt) _input _dim _index _source</span><span>
</span><span id="line-2990"></span><span>
</span><span id="line-2991"></span><span class="hs-comment">-- index_put :: Tensor device dtype shape -&gt; [Tensor device dtype shape] -&gt; Tensor device dtype shape -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2992"></span><span class="hs-comment">-- index_put _input _indices _values _accumulate = unsafePerformIO $ (ATen.cast4 ATen.Managed.index_put_tltb) _input _indices _values _accumulate</span><span>
</span><span id="line-2993"></span><span>
</span><span id="line-2994"></span><span class="hs-comment">-- instance_norm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Double -&gt; Double -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-2995"></span><span class="hs-comment">-- instance_norm _input _weight _bias _running_mean _running_var _use_input_stats _momentum _eps _cudnn_enabled = unsafePerformIO $ (ATen.cast9 ATen.Managed.instance_norm_tttttbddb) _input _weight _bias _running_mean _running_var _use_input_stats _momentum _eps _cudnn_enabled</span><span>
</span><span id="line-2996"></span><span>
</span><span id="line-2997"></span><span class="hs-comment">-- | isclose</span><span>
</span><span id="line-2998"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-2999"></span><span class="hs-comment">--</span><span>
</span><span id="line-3000"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ isclose 0.1 0.1 False (ones :: CPUTensor 'D.Float '[3,2]) (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3001"></span><span class="hs-comment">-- (Bool,[3,2])</span><span>
</span><span id="line-3002"></span><span class="annot"><a href="Torch.Typed.Functional.html#isclose"><span class="hs-identifier hs-type">isclose</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3003"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708995"><span class="annot"><a href="#local-6989586621679708995"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708994"><span class="annot"><a href="#local-6989586621679708994"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708993"><span class="annot"><a href="#local-6989586621679708993"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3004"></span><span>  </span><span class="hs-comment">-- | relative tolerance</span><span>
</span><span id="line-3005"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3006"></span><span>  </span><span class="hs-comment">-- | absolute tolerance</span><span>
</span><span id="line-3007"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3008"></span><span>  </span><span class="hs-comment">-- | whether or not NaN equals NaN</span><span>
</span><span id="line-3009"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3010"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-3011"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708993"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708994"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708995"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3012"></span><span>  </span><span class="hs-comment">-- | other input tensor</span><span>
</span><span id="line-3013"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708993"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708994"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708995"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3014"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3015"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708993"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708995"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3016"></span><span id="isclose"><span class="annot"><span class="annottext">isclose :: Double
-&gt; Double
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Tensor device 'Bool shape
</span><a href="Torch.Typed.Functional.html#isclose"><span class="hs-identifier hs-var hs-var">isclose</span></a></span></span><span> </span><span id="local-6989586621679708992"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708992"><span class="hs-identifier hs-var">rtol</span></a></span></span><span> </span><span id="local-6989586621679708991"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708991"><span class="hs-identifier hs-var">atol</span></a></span></span><span> </span><span id="local-6989586621679708990"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708990"><span class="hs-identifier hs-var">equalNaN</span></a></span></span><span> </span><span id="local-6989586621679708989"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708989"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679708988"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708988"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3017"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape)
-&gt; IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; CDouble
 -&gt; CDouble
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Double
-&gt; Double
-&gt; Bool
-&gt; IO (Tensor device 'Bool shape)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; CDouble
-&gt; CDouble
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.isclose_ttddb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708989"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708988"><span class="hs-identifier hs-var">other</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708992"><span class="hs-identifier hs-var">rtol</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708991"><span class="hs-identifier hs-var">atol</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708990"><span class="hs-identifier hs-var">equalNaN</span></a></span><span>
</span><span id="line-3018"></span><span>
</span><span id="line-3019"></span><span class="hs-comment">-- | is NaN</span><span>
</span><span id="line-3020"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3021"></span><span class="hs-comment">--</span><span>
</span><span id="line-3022"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ isNaN (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3023"></span><span class="hs-comment">-- (Bool,[3,2])</span><span>
</span><span id="line-3024"></span><span class="annot"><a href="Torch.Typed.Functional.html#isNaN"><span class="hs-identifier hs-type">isNaN</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3025"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708985"><span class="annot"><a href="#local-6989586621679708985"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708984"><span class="annot"><a href="#local-6989586621679708984"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708983"><span class="annot"><a href="#local-6989586621679708983"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3026"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3027"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708983"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708984"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708985"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3028"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3029"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708983"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708985"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3030"></span><span id="isNaN"><span class="annot"><span class="annottext">isNaN :: Tensor device dtype shape -&gt; Tensor device 'Bool shape
</span><a href="Torch.Typed.Functional.html#isNaN"><span class="hs-identifier hs-var hs-var">isNaN</span></a></span></span><span> </span><span id="local-6989586621679708982"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708982"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape)
-&gt; IO (Tensor device 'Bool shape) -&gt; Tensor device 'Bool shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device 'Bool shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.isnan_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708982"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3031"></span><span>
</span><span id="line-3032"></span><span class="hs-comment">-- | is distributed</span><span>
</span><span id="line-3033"></span><span class="annot"><a href="Torch.Typed.Functional.html#isDistributed"><span class="hs-identifier hs-type">isDistributed</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3034"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708979"><span class="annot"><a href="#local-6989586621679708979"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708978"><span class="annot"><a href="#local-6989586621679708978"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708977"><span class="annot"><a href="#local-6989586621679708977"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3035"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3036"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708977"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708978"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708979"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3037"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3038"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-3039"></span><span id="isDistributed"><span class="annot"><span class="annottext">isDistributed :: Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#isDistributed"><span class="hs-identifier hs-var hs-var">isDistributed</span></a></span></span><span> </span><span id="local-6989586621679708976"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708976"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor device dtype shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.is_distributed_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708976"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3040"></span><span>
</span><span id="line-3041"></span><span class="hs-comment">-- | is floating point</span><span>
</span><span id="line-3042"></span><span class="hs-comment">-- TODO: this can be decided statically</span><span>
</span><span id="line-3043"></span><span class="annot"><a href="Torch.Typed.Functional.html#isFloatingPoint"><span class="hs-identifier hs-type">isFloatingPoint</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3044"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708973"><span class="annot"><a href="#local-6989586621679708973"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708972"><span class="annot"><a href="#local-6989586621679708972"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708971"><span class="annot"><a href="#local-6989586621679708971"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3045"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3046"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708971"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708972"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708973"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3047"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3048"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-3049"></span><span id="isFloatingPoint"><span class="annot"><span class="annottext">isFloatingPoint :: Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#isFloatingPoint"><span class="hs-identifier hs-var hs-var">isFloatingPoint</span></a></span></span><span> </span><span id="local-6989586621679708970"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708970"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor device dtype shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.is_floating_point_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708970"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3050"></span><span>
</span><span id="line-3051"></span><span class="hs-comment">-- | is complex</span><span>
</span><span id="line-3052"></span><span class="annot"><a href="Torch.Typed.Functional.html#isComplex"><span class="hs-identifier hs-type">isComplex</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3053"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708967"><span class="annot"><a href="#local-6989586621679708967"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708966"><span class="annot"><a href="#local-6989586621679708966"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708965"><span class="annot"><a href="#local-6989586621679708965"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3054"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3055"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708965"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708966"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708967"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3056"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3057"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-3058"></span><span id="isComplex"><span class="annot"><span class="annottext">isComplex :: Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#isComplex"><span class="hs-identifier hs-var hs-var">isComplex</span></a></span></span><span> </span><span id="local-6989586621679708964"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708964"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor device dtype shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.is_complex_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708964"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3059"></span><span>
</span><span id="line-3060"></span><span class="hs-comment">-- | is non-zero</span><span>
</span><span id="line-3061"></span><span class="hs-comment">-- this operation is only defined for tensors with shape '[] or '[1]</span><span>
</span><span id="line-3062"></span><span class="annot"><a href="Torch.Typed.Functional.html#isNonZero"><span class="hs-identifier hs-type">isNonZero</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3063"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708961"><span class="annot"><a href="#local-6989586621679708961"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708960"><span class="annot"><a href="#local-6989586621679708960"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708959"><span class="annot"><a href="#local-6989586621679708959"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3064"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Numel"><span class="hs-identifier hs-type">Numel</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708961"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3065"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3066"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708960"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708961"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3067"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3068"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-3069"></span><span id="isNonZero"><span class="annot"><span class="annottext">isNonZero :: Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#isNonZero"><span class="hs-identifier hs-var hs-var">isNonZero</span></a></span></span><span> </span><span id="local-6989586621679708958"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708958"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor device dtype shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.is_nonzero_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708958"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3070"></span><span>
</span><span id="line-3071"></span><span class="hs-comment">-- | is same size</span><span>
</span><span id="line-3072"></span><span class="hs-comment">-- TODO: this can be decided statically</span><span>
</span><span id="line-3073"></span><span class="annot"><a href="Torch.Typed.Functional.html#isSameSize"><span class="hs-identifier hs-type">isSameSize</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3074"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708955"><span class="annot"><a href="#local-6989586621679708955"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708954"><span class="annot"><a href="#local-6989586621679708954"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708953"><span class="annot"><a href="#local-6989586621679708953"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708952"><span class="annot"><a href="#local-6989586621679708952"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3075"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-3076"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708952"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708953"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708955"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3077"></span><span>  </span><span class="hs-comment">-- | other input tensor</span><span>
</span><span id="line-3078"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708952"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708953"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708954"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3079"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3080"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-3081"></span><span id="isSameSize"><span class="annot"><span class="annottext">isSameSize :: Tensor device dtype shape -&gt; Tensor device dtype shape' -&gt; Bool
</span><a href="Torch.Typed.Functional.html#isSameSize"><span class="hs-identifier hs-var hs-var">isSameSize</span></a></span></span><span> </span><span id="local-6989586621679708951"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708951"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679708950"><span class="annot"><span class="annottext">Tensor device dtype shape'
</span><a href="#local-6989586621679708950"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3082"></span><span>  </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape'
-&gt; IO Bool
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.is_same_size_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708951"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape'
</span><a href="#local-6989586621679708950"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-3083"></span><span>
</span><span id="line-3084"></span><span class="annot"><a href="Torch.Typed.Functional.html#isSigned"><span class="hs-identifier hs-type">isSigned</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3085"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708947"><span class="annot"><a href="#local-6989586621679708947"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708946"><span class="annot"><a href="#local-6989586621679708946"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708945"><span class="annot"><a href="#local-6989586621679708945"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3086"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3087"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708945"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708946"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708947"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3088"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3089"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-3090"></span><span id="isSigned"><span class="annot"><span class="annottext">isSigned :: Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#isSigned"><span class="hs-identifier hs-var hs-var">isSigned</span></a></span></span><span> </span><span id="local-6989586621679708944"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708944"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor device dtype shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.is_signed_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708944"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3091"></span><span>
</span><span id="line-3092"></span><span class="hs-comment">-- kl_div :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3093"></span><span class="hs-comment">-- kl_div _input _target _reduction = unsafePerformIO $ (ATen.cast3 ATen.Managed.kl_div_ttl) _input _target _reduction</span><span>
</span><span id="line-3094"></span><span>
</span><span id="line-3095"></span><span class="hs-comment">-- kthvalue :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3096"></span><span class="hs-comment">-- kthvalue _input _k _dim _keepdim = unsafePerformIO $ (ATen.cast4 ATen.Managed.kthvalue_tllb) _input _k _dim _keepdim</span><span>
</span><span id="line-3097"></span><span>
</span><span id="line-3098"></span><span class="hs-comment">-- | layerNorm</span><span>
</span><span id="line-3099"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3100"></span><span class="hs-comment">-- TODO: figure out if and when CUDNN works here, tie it also to the `device`</span><span>
</span><span id="line-3101"></span><span class="hs-comment">--</span><span>
</span><span id="line-3102"></span><span class="hs-comment">-- &gt;&gt;&gt; t = layerNorm @'[1, 2] @'[2, 1, 2] @'D.Float @'( 'D.CPU, 0) ones ones 0.01 ones</span><span>
</span><span id="line-3103"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-3104"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 1, 2]</span><span>
</span><span id="line-3105"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-3106"></span><span class="hs-comment">-- (Float,[2,1,2])</span><span>
</span><span id="line-3107"></span><span class="annot"><a href="Torch.Typed.Functional.html#layerNorm"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3108"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708941"><span class="annot"><a href="#local-6989586621679708941"><span class="hs-identifier hs-type">normalizedShape</span></a></span></span><span> </span><span id="local-6989586621679708940"><span class="annot"><a href="#local-6989586621679708940"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708939"><span class="annot"><a href="#local-6989586621679708939"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708938"><span class="annot"><a href="#local-6989586621679708938"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3109"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownShape"><span class="hs-identifier hs-type">KnownShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708941"><span class="hs-identifier hs-type">normalizedShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3110"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#IsSuffixOf"><span class="hs-identifier hs-type">IsSuffixOf</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708941"><span class="hs-identifier hs-type">normalizedShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708940"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3111"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3112"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-3113"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708938"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708939"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708941"><span class="hs-identifier hs-type">normalizedShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3114"></span><span>  </span><span class="hs-comment">-- | bias</span><span>
</span><span id="line-3115"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708938"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708939"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708941"><span class="hs-identifier hs-type">normalizedShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3116"></span><span>  </span><span class="hs-comment">-- | eps</span><span>
</span><span id="line-3117"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3118"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-3119"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708938"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708939"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708940"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3120"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-3121"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708938"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708939"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708940"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3122"></span><span id="layerNorm"><span class="annot"><span class="annottext">layerNorm :: Tensor device dtype normalizedShape
-&gt; Tensor device dtype normalizedShape
-&gt; Double
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#layerNorm"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679708936"><span class="annot"><span class="annottext">Tensor device dtype normalizedShape
</span><a href="#local-6989586621679708936"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679708935"><span class="annot"><span class="annottext">Tensor device dtype normalizedShape
</span><a href="#local-6989586621679708935"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679708934"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708934"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span id="local-6989586621679708933"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708933"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3123"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3124"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; CDouble
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; [Int]
-&gt; Tensor device dtype normalizedShape
-&gt; Tensor device dtype normalizedShape
-&gt; Double
-&gt; Bool
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span>
</span><span id="line-3125"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; CDouble
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.layer_norm_tlttdb</span></a></span><span>
</span><span id="line-3126"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708933"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3127"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownShape normalizedShape =&gt; [Int]
forall (shape :: [Nat]). KnownShape shape =&gt; [Int]
</span><a href="Torch.Typed.Tensor.html#shapeVal"><span class="hs-identifier hs-var">shapeVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708941"><span class="hs-identifier hs-type">normalizedShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3128"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype normalizedShape
</span><a href="#local-6989586621679708936"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-3129"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype normalizedShape
</span><a href="#local-6989586621679708935"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-3130"></span><span>      </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708934"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-3131"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype normalizedShape -&gt; Bool
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#cudnnIsAcceptable"><span class="hs-identifier hs-var">cudnnIsAcceptable</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype normalizedShape
</span><a href="#local-6989586621679708936"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-3132"></span><span>          </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype normalizedShape -&gt; Bool
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#cudnnIsAcceptable"><span class="hs-identifier hs-var">cudnnIsAcceptable</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype normalizedShape
</span><a href="#local-6989586621679708935"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-3133"></span><span>          </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape -&gt; Bool
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; Bool
</span><a href="Torch.Typed.Functional.html#cudnnIsAcceptable"><span class="hs-identifier hs-var">cudnnIsAcceptable</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708933"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3134"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-3135"></span><span>
</span><span id="line-3136"></span><span class="hs-comment">-- native_layer_norm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Double -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3137"></span><span class="hs-comment">-- native_layer_norm _input _weight _bias _M _N _eps = unsafePerformIO $ (ATen.cast6 ATen.Managed.native_layer_norm_tttlld) _input _weight _bias _M _N _eps</span><span>
</span><span id="line-3138"></span><span>
</span><span id="line-3139"></span><span class="hs-comment">-- | linear</span><span>
</span><span id="line-3140"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3141"></span><span class="hs-comment">-- https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#linear</span><span>
</span><span id="line-3142"></span><span class="hs-comment">--</span><span>
</span><span id="line-3143"></span><span class="hs-comment">-- &gt;&gt;&gt; w = fromJust [[-0.5, -2,  0.5], [1.5, -0.5, 0.5]] :: CPUTensor 'D.Float '[2, 3]</span><span>
</span><span id="line-3144"></span><span class="hs-comment">-- &gt;&gt;&gt; b = fromJust [0, 0.5] :: CPUTensor 'D.Float '[2]</span><span>
</span><span id="line-3145"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[-2, 0.5, 1], [0.5, 0, 0], [0, 1, 0], [0, 0, 0], [1, -1, 0]] :: CPUTensor 'D.Float '[5, 3]</span><span>
</span><span id="line-3146"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = linear w b t</span><span>
</span><span id="line-3147"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-3148"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[5, 2]</span><span>
</span><span id="line-3149"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[Float]]) $ t'</span><span>
</span><span id="line-3150"></span><span class="hs-comment">-- (Float,([5,2],[[0.5,-2.25],[-0.25,1.25],[-2.0,0.0],[0.0,0.5],[1.5,2.5]]))</span><span>
</span><span id="line-3151"></span><span class="annot"><a href="Torch.Typed.Functional.html#linear"><span class="hs-identifier hs-type">linear</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3152"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708929"><span class="annot"><a href="#local-6989586621679708929"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708928"><span class="annot"><a href="#local-6989586621679708928"><span class="hs-identifier hs-type">inputFeatures</span></a></span></span><span> </span><span id="local-6989586621679708927"><span class="annot"><a href="#local-6989586621679708927"><span class="hs-identifier hs-type">outputFeatures</span></a></span></span><span> </span><span id="local-6989586621679708926"><span class="annot"><a href="#local-6989586621679708926"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708925"><span class="annot"><a href="#local-6989586621679708925"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3153"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708925"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708926"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708927"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708928"><span class="hs-identifier hs-type">inputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3154"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708925"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708926"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708927"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3155"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708925"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708926"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708929"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708928"><span class="hs-identifier hs-type">inputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3156"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708925"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708926"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708929"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708927"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3157"></span><span id="linear"><span class="annot"><span class="annottext">linear :: Tensor device dtype '[outputFeatures, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures]
-&gt; Tensor device dtype '[batchSize, inputFeatures]
-&gt; Tensor device dtype '[batchSize, outputFeatures]
</span><a href="Torch.Typed.Functional.html#linear"><span class="hs-identifier hs-var hs-var">linear</span></a></span></span><span> </span><span id="local-6989586621679708924"><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures, inputFeatures]
</span><a href="#local-6989586621679708924"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679708923"><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures]
</span><a href="#local-6989586621679708923"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679708922"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputFeatures]
</span><a href="#local-6989586621679708922"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, outputFeatures])
-&gt; Tensor device dtype '[batchSize, outputFeatures]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, outputFeatures])
 -&gt; Tensor device dtype '[batchSize, outputFeatures])
-&gt; IO (Tensor device dtype '[batchSize, outputFeatures])
-&gt; Tensor device dtype '[batchSize, outputFeatures]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures]
-&gt; IO (Tensor device dtype '[batchSize, outputFeatures])
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.linear_ttt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputFeatures]
</span><a href="#local-6989586621679708922"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures, inputFeatures]
</span><a href="#local-6989586621679708924"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures]
</span><a href="#local-6989586621679708923"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-3158"></span><span>
</span><span id="line-3159"></span><span class="hs-comment">-- | linear'</span><span>
</span><span id="line-3160"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3161"></span><span class="hs-comment">-- TODO: can we use the ATen linear function or not here?</span><span>
</span><span id="line-3162"></span><span class="hs-comment">-- https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#linear</span><span>
</span><span id="line-3163"></span><span class="hs-comment">--</span><span>
</span><span id="line-3164"></span><span class="hs-comment">-- &gt;&gt;&gt; w = fromJust [[-0.5, -2,  0.5], [1.5, -0.5, 0.5]] :: CPUTensor 'D.Float '[2, 3]</span><span>
</span><span id="line-3165"></span><span class="hs-comment">-- &gt;&gt;&gt; b = fromJust [0, 0.5] :: CPUTensor 'D.Float '[2]</span><span>
</span><span id="line-3166"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[-2, 0.5, 1], [0.5, 0, 0], [0, 1, 0], [0, 0, 0], [1, -1, 0]] :: CPUTensor 'D.Float '[5, 3]</span><span>
</span><span id="line-3167"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = linear' w b t</span><span>
</span><span id="line-3168"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-3169"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[5, 2]</span><span>
</span><span id="line-3170"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[Float]]) $ t'</span><span>
</span><span id="line-3171"></span><span class="hs-comment">-- (Float,([5,2],[[0.5,-2.25],[-0.25,1.25],[-2.0,0.0],[0.0,0.5],[1.5,2.5]]))</span><span>
</span><span id="line-3172"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[[[-2, 0.5, 1], [0.5, 0, 0], [0, 1, 0], [0, 0, 0], [1, -1, 0]], [[-2, 0.5, 1], [0.5, 0, 0], [0, 1, 0], [0, 0, 0], [1, -1, 0]]]] :: CPUTensor 'D.Float '[1, 2, 5, 3]</span><span>
</span><span id="line-3173"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = linear' w b t</span><span>
</span><span id="line-3174"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-3175"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 2, 5, 2]</span><span>
</span><span id="line-3176"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[[[Float]]]]) $ t'</span><span>
</span><span id="line-3177"></span><span class="hs-comment">-- (Float,([1,2,5,2],[[[[0.5,-2.25],[-0.25,1.25],[-2.0,0.0],[0.0,0.5],[1.5,2.5]],[[0.5,-2.25],[-0.25,1.25],[-2.0,0.0],[0.0,0.5],[1.5,2.5]]]]))</span><span>
</span><span id="line-3178"></span><span class="annot"><a href="Torch.Typed.Functional.html#linear%27"><span class="hs-identifier hs-type">linear'</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3179"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708919"><span class="annot"><a href="#local-6989586621679708919"><span class="hs-identifier hs-type">inputFeatures</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708918"><span class="annot"><a href="#local-6989586621679708918"><span class="hs-identifier hs-type">outputFeatures</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708917"><span class="annot"><a href="#local-6989586621679708917"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708916"><span class="annot"><a href="#local-6989586621679708916"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708915"><span class="annot"><a href="#local-6989586621679708915"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708914"><span class="annot"><a href="#local-6989586621679708914"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708913"><span class="annot"><a href="#local-6989586621679708913"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-operator">.</span><span>
</span><span id="line-3180"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679708913"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#MatMul"><span class="hs-identifier hs-type">MatMul</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708917"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708919"><span class="hs-identifier hs-type">inputFeatures</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708918"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-3181"></span><span>    </span><span class="annot"><a href="#local-6989586621679708916"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708913"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708913"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-3182"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3183"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-3184"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708914"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708915"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708918"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708919"><span class="hs-identifier hs-type">inputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3185"></span><span>  </span><span class="hs-comment">-- | bias</span><span>
</span><span id="line-3186"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708914"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708915"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708918"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3187"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3188"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708914"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708915"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708917"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3189"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3190"></span><span>  </span><span class="hs-comment">-- linear' weight bias input = Torch.Static.add (matmul input $ transpose @0 @1 weight) bias</span><span>
</span><span id="line-3191"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708914"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708915"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708916"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-3192"></span><span id="linear%27"><span class="annot"><span class="annottext">linear' :: Tensor device dtype '[outputFeatures, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures]
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#linear%27"><span class="hs-identifier hs-var hs-var">linear'</span></a></span></span><span> </span><span id="local-6989586621679708911"><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures, inputFeatures]
</span><a href="#local-6989586621679708911"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679708910"><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures]
</span><a href="#local-6989586621679708910"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679708909"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708909"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype '[outputFeatures, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures]
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.linear_ttt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708909"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures, inputFeatures]
</span><a href="#local-6989586621679708911"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures]
</span><a href="#local-6989586621679708910"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-3193"></span><span>
</span><span id="line-3194"></span><span class="hs-comment">-- | mkldnnLinear</span><span>
</span><span id="line-3195"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3196"></span><span class="hs-comment">-- TODO: mkldnnLinear does not return a usuable tensor value and is hence broken</span><span>
</span><span id="line-3197"></span><span class="hs-comment">-- TODO: figure out `device` for this</span><span>
</span><span id="line-3198"></span><span class="hs-comment">--</span><span>
</span><span id="line-3199"></span><span class="hs-comment">-- &gt;&gt;&gt; w = fromJust [[-0.5, -2,  0.5], [1.5, -0.5, 0.5]] :: CPUTensor 'D.Float '[2, 3]</span><span>
</span><span id="line-3200"></span><span class="hs-comment">-- &gt;&gt;&gt; b = fromJust [0, 0.5] :: CPUTensor 'D.Float '[2]</span><span>
</span><span id="line-3201"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[-2, 0.5, 1], [0.5, 0, 0], [0, 1, 0], [0, 0, 0], [1, -1, 0]] :: CPUTensor 'D.Float '[5, 3]</span><span>
</span><span id="line-3202"></span><span class="hs-comment">--</span><span>
</span><span id="line-3203"></span><span class="hs-comment">-- -- &gt;&gt;&gt; t' = mkldnnLinear (toMKLDNN w) (toMKLDNN b) (toMKLDNN t)</span><span>
</span><span id="line-3204"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-3205"></span><span class="hs-comment">-- -- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[5, 2]</span><span>
</span><span id="line-3206"></span><span class="hs-comment">-- -- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[Float]]) $ t'</span><span>
</span><span id="line-3207"></span><span class="hs-comment">-- -- (Float,([5,2],[[0.5,-2.25],[-0.25,1.25],[-2.0,0.0],[0.0,0.5],[1.5,2.5]]))</span><span>
</span><span id="line-3208"></span><span class="annot"><a href="Torch.Typed.Functional.html#mkldnnLinear"><span class="hs-identifier hs-type">mkldnnLinear</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3209"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708907"><span class="annot"><a href="#local-6989586621679708907"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708906"><span class="annot"><a href="#local-6989586621679708906"><span class="hs-identifier hs-type">inputFeatures</span></a></span></span><span> </span><span id="local-6989586621679708905"><span class="annot"><a href="#local-6989586621679708905"><span class="hs-identifier hs-type">outputFeatures</span></a></span></span><span> </span><span id="local-6989586621679708904"><span class="annot"><a href="#local-6989586621679708904"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708903"><span class="annot"><a href="#local-6989586621679708903"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3210"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-3211"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708903"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708904"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708905"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708906"><span class="hs-identifier hs-type">inputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3212"></span><span>  </span><span class="hs-comment">-- | bias</span><span>
</span><span id="line-3213"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708903"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708904"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708905"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3214"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3215"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708903"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708904"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708907"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708906"><span class="hs-identifier hs-type">inputFeatures</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3216"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3217"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708903"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708904"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708907"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708905"><span class="hs-identifier hs-type">outputFeatures</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3218"></span><span id="mkldnnLinear"><span class="annot"><span class="annottext">mkldnnLinear :: Tensor device dtype '[outputFeatures, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures]
-&gt; Tensor device dtype '[batchSize, inputFeatures]
-&gt; Tensor device dtype '[batchSize, outputFeatures]
</span><a href="Torch.Typed.Functional.html#mkldnnLinear"><span class="hs-identifier hs-var hs-var">mkldnnLinear</span></a></span></span><span> </span><span id="local-6989586621679708902"><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures, inputFeatures]
</span><a href="#local-6989586621679708902"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679708901"><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures]
</span><a href="#local-6989586621679708901"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679708900"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputFeatures]
</span><a href="#local-6989586621679708900"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, outputFeatures])
-&gt; Tensor device dtype '[batchSize, outputFeatures]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, outputFeatures])
 -&gt; Tensor device dtype '[batchSize, outputFeatures])
-&gt; IO (Tensor device dtype '[batchSize, outputFeatures])
-&gt; Tensor device dtype '[batchSize, outputFeatures]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures, inputFeatures]
-&gt; Tensor device dtype '[outputFeatures]
-&gt; IO (Tensor device dtype '[batchSize, outputFeatures])
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mkldnn_linear_ttt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputFeatures]
</span><a href="#local-6989586621679708900"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures, inputFeatures]
</span><a href="#local-6989586621679708902"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[outputFeatures]
</span><a href="#local-6989586621679708901"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-3219"></span><span>
</span><span id="line-3220"></span><span class="hs-comment">-- fbgemm_linear_int8_weight :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3221"></span><span class="hs-comment">-- fbgemm_linear_int8_weight _input _weight _packed _col_offsets _weight_scale _weight_zero_point _bias = unsafePerformIO $ (ATen.cast7 ATen.Managed.fbgemm_linear_int8_weight_ttttsst) _input _weight _packed _col_offsets _weight_scale _weight_zero_point _bias</span><span>
</span><span id="line-3222"></span><span>
</span><span id="line-3223"></span><span class="hs-comment">-- fbgemm_linear_quantize_weight :: Tensor device dtype shape -&gt; (Tensor device dtype shape,Tensor device dtype shape,Double,Int)</span><span>
</span><span id="line-3224"></span><span class="hs-comment">-- fbgemm_linear_quantize_weight _input = unsafePerformIO $ (ATen.cast1 ATen.Managed.fbgemm_linear_quantize_weight_t) _input</span><span>
</span><span id="line-3225"></span><span>
</span><span id="line-3226"></span><span class="hs-comment">-- fbgemm_pack_gemm_matrix_fp16 :: Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3227"></span><span class="hs-comment">-- fbgemm_pack_gemm_matrix_fp16 _input = unsafePerformIO $ (ATen.cast1 ATen.Managed.fbgemm_pack_gemm_matrix_fp16_t) _input</span><span>
</span><span id="line-3228"></span><span>
</span><span id="line-3229"></span><span class="hs-comment">-- fbgemm_linear_fp16_weight :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3230"></span><span class="hs-comment">-- fbgemm_linear_fp16_weight _input _packed_weight _bias = unsafePerformIO $ (ATen.cast3 ATen.Managed.fbgemm_linear_fp16_weight_ttt) _input _packed_weight _bias</span><span>
</span><span id="line-3231"></span><span>
</span><span id="line-3232"></span><span class="hs-comment">-- fbgemm_pack_quantized_matrix :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3233"></span><span class="hs-comment">-- fbgemm_pack_quantized_matrix _input _K _N = unsafePerformIO $ (ATen.cast3 ATen.Managed.fbgemm_pack_quantized_matrix_tll) _input _K _N</span><span>
</span><span id="line-3234"></span><span>
</span><span id="line-3235"></span><span class="hs-comment">-- fbgemm_is_cpu_supported :: Bool</span><span>
</span><span id="line-3236"></span><span class="hs-comment">-- fbgemm_is_cpu_supported  = unsafePerformIO $ (cast0 ATen.Managed.fbgemm_is_cpu_supported)</span><span>
</span><span id="line-3237"></span><span>
</span><span id="line-3238"></span><span class="hs-comment">-- | log</span><span>
</span><span id="line-3239"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3240"></span><span class="hs-comment">-- TODO: will log throw for negative numbers or just generate NaNs? should we return a Maybe?</span><span>
</span><span id="line-3241"></span><span class="hs-comment">--</span><span>
</span><span id="line-3242"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ log (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3243"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3244"></span><span class="annot"><a href="Torch.Typed.Functional.html#log"><span class="hs-identifier hs-type">log</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3245"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708897"><span class="annot"><a href="#local-6989586621679708897"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708896"><span class="annot"><a href="#local-6989586621679708896"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708895"><span class="annot"><a href="#local-6989586621679708895"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3246"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3247"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708895"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708896"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708897"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3248"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3249"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708895"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708896"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708897"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3250"></span><span id="log"><span class="annot"><span class="annottext">log :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#log"><span class="hs-identifier hs-var hs-var">log</span></a></span></span><span> </span><span id="local-6989586621679708894"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708894"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.log_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708894"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3251"></span><span>
</span><span id="line-3252"></span><span class="hs-comment">-- | logDet</span><span>
</span><span id="line-3253"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3254"></span><span class="hs-comment">-- TODO: will logDet throw? and if so, should we return a Maybe?</span><span>
</span><span id="line-3255"></span><span class="hs-comment">--</span><span>
</span><span id="line-3256"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ logDet (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-3257"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-3258"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ logDet (ones :: CPUTensor 'D.Float '[3,2,2])</span><span>
</span><span id="line-3259"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-3260"></span><span class="annot"><a href="Torch.Typed.Functional.html#logDet"><span class="hs-identifier hs-type">logDet</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3261"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708891"><span class="annot"><a href="#local-6989586621679708891"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708890"><span class="annot"><a href="#local-6989586621679708890"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708889"><span class="annot"><a href="#local-6989586621679708889"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708888"><span class="annot"><a href="#local-6989586621679708888"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3262"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708891"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Det"><span class="hs-identifier hs-type">Det</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708890"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3263"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3264"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708888"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708889"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708890"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3265"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3266"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708888"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708889"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708891"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-3267"></span><span id="logDet"><span class="annot"><span class="annottext">logDet :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#logDet"><span class="hs-identifier hs-var hs-var">logDet</span></a></span></span><span> </span><span id="local-6989586621679708887"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708887"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape')
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.logdet_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708887"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3268"></span><span>
</span><span id="line-3269"></span><span class="hs-comment">-- | logarithm of the sum of the exponentials</span><span>
</span><span id="line-3270"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3271"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/torch.html#torch.logsumexp.</span><span>
</span><span id="line-3272"></span><span class="hs-comment">--</span><span>
</span><span id="line-3273"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [[5, 1], [3, 2], [4, 1], [2, 7]] :: CPUTensor 'D.Float '[4, 2]</span><span>
</span><span id="line-3274"></span><span class="hs-comment">--</span><span>
</span><span id="line-3275"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Float]) $ logSumExp @1 @DropDim t</span><span>
</span><span id="line-3276"></span><span class="hs-comment">-- (Float,([4],[5.01815,3.3132617,4.0485873,7.0067153]))</span><span>
</span><span id="line-3277"></span><span class="hs-comment">--</span><span>
</span><span id="line-3278"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ logSumExp @1 @KeepDim t</span><span>
</span><span id="line-3279"></span><span class="hs-comment">-- (Float,([4,1],[[5.01815],[3.3132617],[4.0485873],[7.0067153]]))</span><span>
</span><span id="line-3280"></span><span class="hs-comment">--</span><span>
</span><span id="line-3281"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [Float]) $ logSumExp @0 @DropDim t</span><span>
</span><span id="line-3282"></span><span class="hs-comment">-- (Float,([2],[5.44019,7.0116277]))</span><span>
</span><span id="line-3283"></span><span class="hs-comment">--</span><span>
</span><span id="line-3284"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ logSumExp @0 @KeepDim t</span><span>
</span><span id="line-3285"></span><span class="hs-comment">-- (Float,([1,2],[[5.44019,7.0116277]]))</span><span>
</span><span id="line-3286"></span><span class="annot"><a href="Torch.Typed.Functional.html#logSumExp"><span class="hs-identifier hs-type">logSumExp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3287"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708884"><span class="annot"><a href="#local-6989586621679708884"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708883"><span class="annot"><a href="#local-6989586621679708883"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679708882"><span class="annot"><a href="#local-6989586621679708882"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708881"><span class="annot"><a href="#local-6989586621679708881"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708880"><span class="annot"><a href="#local-6989586621679708880"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708879"><span class="annot"><a href="#local-6989586621679708879"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3288"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708884"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3289"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708883"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3290"></span><span>    </span><span class="annot"><a href="../file:///nix/store/zrl3kdrpbhxqs3qd1g1mhjdnhnvkji84-reflection-lib-reflection-2.1.6-haddock-doc/share/doc/reflection/html/src"><span class="hs-identifier hs-type">Reifies</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708880"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3291"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708879"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708880"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3292"></span><span>    </span><span class="annot"><a href="#local-6989586621679708882"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708881"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708884"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708883"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span>
</span><span id="line-3293"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3294"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3295"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708879"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708880"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708881"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3296"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3297"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708879"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708880"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708882"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-3298"></span><span id="logSumExp"><span class="annot"><span class="annottext">logSumExp :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#logSumExp"><span class="hs-identifier hs-var hs-var">logSumExp</span></a></span></span><span> </span><span id="local-6989586621679708877"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708877"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3299"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3300"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-3301"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.logsumexp_tlb</span></a></span><span>
</span><span id="line-3302"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708877"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3303"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708884"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3304"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708883"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3305"></span><span>
</span><span id="line-3306"></span><span class="hs-comment">-- margin_ranking_loss :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3307"></span><span class="hs-comment">-- margin_ranking_loss _input1 _input2 _target _margin _reduction = unsafePerformIO $ (ATen.cast5 ATen.Managed.margin_ranking_loss_tttdl) _input1 _input2 _target _margin _reduction</span><span>
</span><span id="line-3308"></span><span>
</span><span id="line-3309"></span><span class="hs-comment">-- | matrixPower</span><span>
</span><span id="line-3310"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3311"></span><span class="hs-comment">-- TODO: figure out input shape restrictions, should be matrix or a batched matrix</span><span>
</span><span id="line-3312"></span><span class="hs-comment">-- TODO: figure out restrictions on the power, can it be zero or negative?</span><span>
</span><span id="line-3313"></span><span class="hs-comment">--</span><span>
</span><span id="line-3314"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ matrixPower 2 (ones :: CPUTensor 'D.Float '[3,4,4])</span><span>
</span><span id="line-3315"></span><span class="hs-comment">-- (Float,[3,4,4])</span><span>
</span><span id="line-3316"></span><span class="annot"><a href="Torch.Typed.Functional.html#matrixPower"><span class="hs-identifier hs-type">matrixPower</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3317"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708874"><span class="annot"><a href="#local-6989586621679708874"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708873"><span class="annot"><a href="#local-6989586621679708873"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708872"><span class="annot"><a href="#local-6989586621679708872"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708871"><span class="annot"><a href="#local-6989586621679708871"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3318"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708874"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Square"><span class="hs-identifier hs-type">Square</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708873"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3319"></span><span>  </span><span class="hs-comment">-- | power</span><span>
</span><span id="line-3320"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3321"></span><span>  </span><span class="hs-comment">-- | input matrix</span><span>
</span><span id="line-3322"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708871"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708872"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708873"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3323"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3324"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708871"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708872"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708874"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-3325"></span><span id="matrixPower"><span class="annot"><span class="annottext">matrixPower :: Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#matrixPower"><span class="hs-identifier hs-var hs-var">matrixPower</span></a></span></span><span> </span><span id="local-6989586621679708870"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708870"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679708869"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708869"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.matrix_power_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708869"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708870"><span class="hs-identifier hs-var">n</span></a></span><span>
</span><span id="line-3326"></span><span>
</span><span id="line-3327"></span><span class="hs-comment">-- | maxValues</span><span>
</span><span id="line-3328"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3329"></span><span class="hs-comment">--</span><span>
</span><span id="line-3330"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3,4,5]</span><span>
</span><span id="line-3331"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ maxValues @0 @KeepDim t</span><span>
</span><span id="line-3332"></span><span class="hs-comment">-- (Float,[1,4,5])</span><span>
</span><span id="line-3333"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ maxValues @0 @DropDim t</span><span>
</span><span id="line-3334"></span><span class="hs-comment">-- (Float,[4,5])</span><span>
</span><span id="line-3335"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ maxValues @1 @KeepDim t</span><span>
</span><span id="line-3336"></span><span class="hs-comment">-- (Float,[3,1,5])</span><span>
</span><span id="line-3337"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ maxValues @1 @DropDim t</span><span>
</span><span id="line-3338"></span><span class="hs-comment">-- (Float,[3,5])</span><span>
</span><span id="line-3339"></span><span class="annot"><a href="Torch.Typed.Functional.html#maxValues"><span class="hs-identifier hs-type">maxValues</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3340"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708866"><span class="annot"><a href="#local-6989586621679708866"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708865"><span class="annot"><a href="#local-6989586621679708865"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679708864"><span class="annot"><a href="#local-6989586621679708864"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708863"><span class="annot"><a href="#local-6989586621679708863"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708862"><span class="annot"><a href="#local-6989586621679708862"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708861"><span class="annot"><a href="#local-6989586621679708861"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3341"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708866"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3342"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708865"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3343"></span><span>    </span><span class="annot"><a href="#local-6989586621679708864"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708863"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708866"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708865"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span>
</span><span id="line-3344"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3345"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3346"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708861"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708862"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708863"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3347"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3348"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708861"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708862"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708864"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-3349"></span><span id="maxValues"><span class="annot"><span class="annottext">maxValues :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#maxValues"><span class="hs-identifier hs-var hs-var">maxValues</span></a></span></span><span> </span><span id="local-6989586621679708860"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708860"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3350"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3351"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-3352"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.max_values_tlb</span></a></span><span>
</span><span id="line-3353"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708860"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3354"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708866"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3355"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708865"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3356"></span><span>
</span><span id="line-3357"></span><span class="hs-comment">-- | minValues</span><span>
</span><span id="line-3358"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3359"></span><span class="hs-comment">--</span><span>
</span><span id="line-3360"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3,4,5]</span><span>
</span><span id="line-3361"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ minValues @0 @KeepDim t</span><span>
</span><span id="line-3362"></span><span class="hs-comment">-- (Float,[1,4,5])</span><span>
</span><span id="line-3363"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ minValues @0 @DropDim t</span><span>
</span><span id="line-3364"></span><span class="hs-comment">-- (Float,[4,5])</span><span>
</span><span id="line-3365"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ minValues @1 @KeepDim t</span><span>
</span><span id="line-3366"></span><span class="hs-comment">-- (Float,[3,1,5])</span><span>
</span><span id="line-3367"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ minValues @1 @DropDim t</span><span>
</span><span id="line-3368"></span><span class="hs-comment">-- (Float,[3,5])</span><span>
</span><span id="line-3369"></span><span class="annot"><a href="Torch.Typed.Functional.html#minValues"><span class="hs-identifier hs-type">minValues</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3370"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708857"><span class="annot"><a href="#local-6989586621679708857"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708856"><span class="annot"><a href="#local-6989586621679708856"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span></span><span> </span><span id="local-6989586621679708855"><span class="annot"><a href="#local-6989586621679708855"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708854"><span class="annot"><a href="#local-6989586621679708854"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708853"><span class="annot"><a href="#local-6989586621679708853"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708852"><span class="annot"><a href="#local-6989586621679708852"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3371"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708857"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3372"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownKeepOrDropDim"><span class="hs-identifier hs-type">KnownKeepOrDropDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708856"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3373"></span><span>    </span><span class="annot"><a href="#local-6989586621679708855"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalDropDimension"><span class="hs-identifier hs-type">ConditionalDropDimension</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708854"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708857"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708856"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span>
</span><span id="line-3374"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3375"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3376"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708852"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708853"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708854"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3377"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3378"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708852"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708853"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708855"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-3379"></span><span id="minValues"><span class="annot"><span class="annottext">minValues :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#minValues"><span class="hs-identifier hs-var hs-var">minValues</span></a></span></span><span> </span><span id="local-6989586621679708851"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708851"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3380"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3381"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-3382"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.min_values_tlb</span></a></span><span>
</span><span id="line-3383"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708851"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3384"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708857"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3385"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownKeepOrDropDim keepOrDropDim =&gt; Bool
forall k (keepOrDropDim :: k).
KnownKeepOrDropDim keepOrDropDim =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#keepOrDropDimVal"><span class="hs-identifier hs-var">keepOrDropDimVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708856"><span class="hs-identifier hs-type">keepOrDropDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3386"></span><span>
</span><span id="line-3387"></span><span class="hs-comment">-- | maxPool1d</span><span>
</span><span id="line-3388"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3389"></span><span class="hs-comment">--</span><span>
</span><span id="line-3390"></span><span class="hs-comment">-- &gt;&gt;&gt; t = maxPool1d @1 @1 @0 (ones :: CPUTensor 'D.Float '[1,3,4])</span><span>
</span><span id="line-3391"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-3392"></span><span class="hs-comment">-- [1,3,4]</span><span>
</span><span id="line-3393"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-3394"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 4]</span><span>
</span><span id="line-3395"></span><span class="annot"><a href="Torch.Typed.Functional.html#maxPool1d"><span class="hs-identifier hs-type">maxPool1d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3396"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708848"><span class="annot"><a href="#local-6989586621679708848"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679708847"><span class="annot"><a href="#local-6989586621679708847"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span id="local-6989586621679708846"><span class="annot"><a href="#local-6989586621679708846"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span id="local-6989586621679708845"><span class="annot"><a href="#local-6989586621679708845"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679708844"><span class="annot"><a href="#local-6989586621679708844"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708843"><span class="annot"><a href="#local-6989586621679708843"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708842"><span class="annot"><a href="#local-6989586621679708842"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span> </span><span id="local-6989586621679708841"><span class="annot"><a href="#local-6989586621679708841"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708840"><span class="annot"><a href="#local-6989586621679708840"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3397"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-3398"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-3399"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="#local-6989586621679708848"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3400"></span><span>         </span><span class="annot"><a href="#local-6989586621679708847"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3401"></span><span>         </span><span class="annot"><a href="#local-6989586621679708846"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3402"></span><span>         </span><span class="annot"><a href="#local-6989586621679708845"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3403"></span><span>         </span><span class="annot"><a href="#local-6989586621679708844"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3404"></span><span>         </span><span class="annot"><a href="#local-6989586621679708843"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-3405"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-3406"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708844"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708848"><span class="hs-identifier hs-type">kernelSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708847"><span class="hs-identifier hs-type">stride</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708846"><span class="hs-identifier hs-type">padding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708842"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-3407"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3408"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3409"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708840"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708841"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708843"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708845"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708844"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3410"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3411"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708840"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708841"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708843"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708845"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708842"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3412"></span><span id="maxPool1d"><span class="annot"><span class="annottext">maxPool1d :: Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
</span><a href="Torch.Typed.Functional.html#maxPool1d"><span class="hs-identifier hs-var hs-var">maxPool1d</span></a></span></span><span> </span><span id="local-6989586621679708839"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679708839"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3413"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, channelSize, outputSize])
 -&gt; Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; IO (Tensor device dtype '[batchSize, channelSize, outputSize])
-&gt; Tensor device dtype '[batchSize, channelSize, outputSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3414"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, channelSize, inputSize]
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; Bool
-&gt; IO (Tensor device dtype '[batchSize, channelSize, outputSize])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span>
</span><span id="line-3415"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.max_pool1d_tllllb</span></a></span><span>
</span><span id="line-3416"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, channelSize, inputSize]
</span><a href="#local-6989586621679708839"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3417"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat kernelSize =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708848"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3418"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat stride =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708847"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3419"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat padding =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708846"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3420"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-3421"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-3422"></span><span>
</span><span id="line-3423"></span><span class="hs-comment">-- max_pool1d_with_indices :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3424"></span><span class="hs-comment">-- max_pool1d_with_indices _input _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (ATen.cast6 ATen.Managed.max_pool1d_with_indices_tllllb) _input _kernel_size _stride _padding _dilation _ceil_mode</span><span>
</span><span id="line-3425"></span><span>
</span><span id="line-3426"></span><span class="hs-comment">-- | maxPool2d</span><span>
</span><span id="line-3427"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3428"></span><span class="hs-comment">--</span><span>
</span><span id="line-3429"></span><span class="hs-comment">-- &gt;&gt;&gt; t = maxPool2d @'(1,1) @'(1,1) @'(0,0) (ones :: CPUTensor 'D.Float '[1,3,4,5])</span><span>
</span><span id="line-3430"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-3431"></span><span class="hs-comment">-- [1,3,4,5]</span><span>
</span><span id="line-3432"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-3433"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 4, 5]</span><span>
</span><span id="line-3434"></span><span class="annot"><a href="Torch.Typed.Functional.html#maxPool2d"><span class="hs-identifier hs-type">maxPool2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3435"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708836"><span class="annot"><a href="#local-6989586621679708836"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679708835"><span class="annot"><a href="#local-6989586621679708835"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span id="local-6989586621679708834"><span class="annot"><a href="#local-6989586621679708834"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span id="local-6989586621679708833"><span class="annot"><a href="#local-6989586621679708833"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679708832"><span class="annot"><a href="#local-6989586621679708832"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span> </span><span id="local-6989586621679708831"><span class="annot"><a href="#local-6989586621679708831"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span> </span><span id="local-6989586621679708830"><span class="annot"><a href="#local-6989586621679708830"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708829"><span class="annot"><a href="#local-6989586621679708829"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span> </span><span id="local-6989586621679708828"><span class="annot"><a href="#local-6989586621679708828"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span> </span><span id="local-6989586621679708827"><span class="annot"><a href="#local-6989586621679708827"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708826"><span class="annot"><a href="#local-6989586621679708826"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3436"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-3437"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-3438"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708836"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3439"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708836"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3440"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708835"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3441"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708835"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3442"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708834"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3443"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708834"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3444"></span><span>         </span><span class="annot"><a href="#local-6989586621679708833"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3445"></span><span>         </span><span class="annot"><a href="#local-6989586621679708832"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3446"></span><span>         </span><span class="annot"><a href="#local-6989586621679708831"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3447"></span><span>         </span><span class="annot"><a href="#local-6989586621679708830"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-3448"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-3449"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708832"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708836"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708835"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708834"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708829"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3450"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708831"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708836"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708835"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708834"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708828"><span class="hs-identifier hs-type">outputSize1</span></a></span><span>
</span><span id="line-3451"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3452"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3453"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708826"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708827"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708830"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708833"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708832"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708831"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3454"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3455"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708826"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708827"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708830"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708833"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708829"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708828"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3456"></span><span id="maxPool2d"><span class="annot"><span class="annottext">maxPool2d :: Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
</span><a href="Torch.Typed.Functional.html#maxPool2d"><span class="hs-identifier hs-var hs-var">maxPool2d</span></a></span></span><span> </span><span id="local-6989586621679708825"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679708825"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3457"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
 -&gt; Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3458"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Bool
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span>
</span><span id="line-3459"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.max_pool2d_tllllb</span></a></span><span>
</span><span id="line-3460"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679708825"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3461"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708836"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708836"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3462"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708835"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708835"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3463"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708834"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708834"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3464"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3465"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-3466"></span><span>
</span><span id="line-3467"></span><span class="hs-comment">-- | mkldnnMaxPool2d</span><span>
</span><span id="line-3468"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3469"></span><span class="hs-comment">-- TODO: does this function work, that is, does it return values without throwing? when does it work?</span><span>
</span><span id="line-3470"></span><span class="hs-comment">-- TODO: this should probably be only callable if the device is MKLDNN?</span><span>
</span><span id="line-3471"></span><span class="hs-comment">-- -- &gt;&gt;&gt; t = mkldnnMaxPool2d @'(1,1) @'(1,1) @'(0,0) (toMKLDNN (ones :: CPUTensor 'D.Float '[1,3,4,5]))</span><span>
</span><span id="line-3472"></span><span class="hs-comment">-- -- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-3473"></span><span class="hs-comment">-- -- [1,3,4,5]</span><span>
</span><span id="line-3474"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-3475"></span><span class="hs-comment">-- -- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 4, 5]</span><span>
</span><span id="line-3476"></span><span class="annot"><a href="Torch.Typed.Functional.html#mkldnnMaxPool2d"><span class="hs-identifier hs-type">mkldnnMaxPool2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3477"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708822"><span class="annot"><a href="#local-6989586621679708822"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679708821"><span class="annot"><a href="#local-6989586621679708821"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span id="local-6989586621679708820"><span class="annot"><a href="#local-6989586621679708820"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span id="local-6989586621679708819"><span class="annot"><a href="#local-6989586621679708819"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679708818"><span class="annot"><a href="#local-6989586621679708818"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span> </span><span id="local-6989586621679708817"><span class="annot"><a href="#local-6989586621679708817"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span> </span><span id="local-6989586621679708816"><span class="annot"><a href="#local-6989586621679708816"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708815"><span class="annot"><a href="#local-6989586621679708815"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span> </span><span id="local-6989586621679708814"><span class="annot"><a href="#local-6989586621679708814"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span> </span><span id="local-6989586621679708813"><span class="annot"><a href="#local-6989586621679708813"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708812"><span class="annot"><a href="#local-6989586621679708812"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3478"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-3479"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-3480"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708822"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3481"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708822"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3482"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708821"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3483"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708821"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3484"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708820"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3485"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708820"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3486"></span><span>         </span><span class="annot"><a href="#local-6989586621679708819"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3487"></span><span>         </span><span class="annot"><a href="#local-6989586621679708818"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3488"></span><span>         </span><span class="annot"><a href="#local-6989586621679708817"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3489"></span><span>         </span><span class="annot"><a href="#local-6989586621679708816"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-3490"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-3491"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708818"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708822"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708821"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708820"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708815"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3492"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708817"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708822"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708821"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708820"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708814"><span class="hs-identifier hs-type">outputSize1</span></a></span><span>
</span><span id="line-3493"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3494"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3495"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708812"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708813"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708816"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708819"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708818"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708817"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3496"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3497"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708812"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708813"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708816"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708819"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708815"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708814"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3498"></span><span id="mkldnnMaxPool2d"><span class="annot"><span class="annottext">mkldnnMaxPool2d :: Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
</span><a href="Torch.Typed.Functional.html#mkldnnMaxPool2d"><span class="hs-identifier hs-var hs-var">mkldnnMaxPool2d</span></a></span></span><span> </span><span id="local-6989586621679708811"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679708811"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3499"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
 -&gt; Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3500"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Bool
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span>
</span><span id="line-3501"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mkldnn_max_pool2d_tllllb</span></a></span><span>
</span><span id="line-3502"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679708811"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3503"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708822"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708822"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3504"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708821"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708821"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3505"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708820"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708820"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3506"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3507"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-3508"></span><span>
</span><span id="line-3509"></span><span class="hs-comment">-- | quantizedMaxPool2d</span><span>
</span><span id="line-3510"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3511"></span><span class="hs-comment">-- TODO: what are quantized functions and when are they available?</span><span>
</span><span id="line-3512"></span><span class="hs-comment">-- -- &gt;&gt;&gt; t = quantizedMaxPool2d @'(1,1) @'(1,1) @'(0,0) (ones :: CPUTensor 'D.Float '[1,3,4,5])</span><span>
</span><span id="line-3513"></span><span class="hs-comment">-- -- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-3514"></span><span class="hs-comment">-- -- [1,3,4,5]</span><span>
</span><span id="line-3515"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-3516"></span><span class="hs-comment">-- -- t :: Tensor 'D.Float '[1, 3, 4, 5]</span><span>
</span><span id="line-3517"></span><span class="annot"><a href="Torch.Typed.Functional.html#quantizedMaxPool2d"><span class="hs-identifier hs-type">quantizedMaxPool2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3518"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708808"><span class="annot"><a href="#local-6989586621679708808"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span> </span><span id="local-6989586621679708807"><span class="annot"><a href="#local-6989586621679708807"><span class="hs-identifier hs-type">stride</span></a></span></span><span> </span><span id="local-6989586621679708806"><span class="annot"><a href="#local-6989586621679708806"><span class="hs-identifier hs-type">padding</span></a></span></span><span> </span><span id="local-6989586621679708805"><span class="annot"><a href="#local-6989586621679708805"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679708804"><span class="annot"><a href="#local-6989586621679708804"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span> </span><span id="local-6989586621679708803"><span class="annot"><a href="#local-6989586621679708803"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span> </span><span id="local-6989586621679708802"><span class="annot"><a href="#local-6989586621679708802"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708801"><span class="annot"><a href="#local-6989586621679708801"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span> </span><span id="local-6989586621679708800"><span class="annot"><a href="#local-6989586621679708800"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span> </span><span id="local-6989586621679708799"><span class="annot"><a href="#local-6989586621679708799"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708798"><span class="annot"><a href="#local-6989586621679708798"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3519"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-3520"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-3521"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708808"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3522"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708808"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3523"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708807"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3524"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708807"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3525"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708806"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3526"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708806"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3527"></span><span>         </span><span class="annot"><a href="#local-6989586621679708805"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3528"></span><span>         </span><span class="annot"><a href="#local-6989586621679708804"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3529"></span><span>         </span><span class="annot"><a href="#local-6989586621679708803"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3530"></span><span>         </span><span class="annot"><a href="#local-6989586621679708802"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-3531"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-3532"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708804"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708808"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708807"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708806"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708801"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3533"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708803"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708808"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708807"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708806"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708800"><span class="hs-identifier hs-type">outputSize1</span></a></span><span>
</span><span id="line-3534"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3535"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3536"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708799"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708802"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708805"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708804"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708803"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3537"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3538"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708799"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708802"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708805"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708801"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708800"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3539"></span><span id="quantizedMaxPool2d"><span class="annot"><span class="annottext">quantizedMaxPool2d :: Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
</span><a href="Torch.Typed.Functional.html#quantizedMaxPool2d"><span class="hs-identifier hs-var hs-var">quantizedMaxPool2d</span></a></span></span><span> </span><span id="local-6989586621679708797"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679708797"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3540"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
 -&gt; Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3541"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span>
</span><span id="line-3542"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.quantized_max_pool2d_tllll</span></a></span><span>
</span><span id="line-3543"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679708797"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3544"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708808"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708808"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3545"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708807"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708807"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3546"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708806"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708806"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3547"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3548"></span><span>
</span><span id="line-3549"></span><span class="hs-comment">-- | maxPool3d</span><span>
</span><span id="line-3550"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3551"></span><span class="hs-comment">--</span><span>
</span><span id="line-3552"></span><span class="hs-comment">-- &gt;&gt;&gt; t = maxPool3d @'(1,1,1) @'(1,1,1) @'(0,0,0) (ones :: CPUTensor 'D.Float '[1,3,4,5,6])</span><span>
</span><span id="line-3553"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-3554"></span><span class="hs-comment">-- [1,3,4,5,6]</span><span>
</span><span id="line-3555"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-3556"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 4, 5, 6]</span><span>
</span><span id="line-3557"></span><span class="annot"><a href="Torch.Typed.Functional.html#maxPool3d"><span class="hs-identifier hs-type">maxPool3d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3558"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-3559"></span><span>    </span><span id="local-6989586621679708794"><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span>
</span><span id="line-3560"></span><span>    </span><span id="local-6989586621679708793"><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span></span><span>
</span><span id="line-3561"></span><span>    </span><span id="local-6989586621679708792"><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span></span><span>
</span><span id="line-3562"></span><span>    </span><span id="local-6989586621679708791"><span class="annot"><a href="#local-6989586621679708791"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span>
</span><span id="line-3563"></span><span>    </span><span id="local-6989586621679708790"><span class="annot"><a href="#local-6989586621679708790"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span>
</span><span id="line-3564"></span><span>    </span><span id="local-6989586621679708789"><span class="annot"><a href="#local-6989586621679708789"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span>
</span><span id="line-3565"></span><span>    </span><span id="local-6989586621679708788"><span class="annot"><a href="#local-6989586621679708788"><span class="hs-identifier hs-type">inputSize2</span></a></span></span><span>
</span><span id="line-3566"></span><span>    </span><span id="local-6989586621679708787"><span class="annot"><a href="#local-6989586621679708787"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-3567"></span><span>    </span><span id="local-6989586621679708786"><span class="annot"><a href="#local-6989586621679708786"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span>
</span><span id="line-3568"></span><span>    </span><span id="local-6989586621679708785"><span class="annot"><a href="#local-6989586621679708785"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span>
</span><span id="line-3569"></span><span>    </span><span id="local-6989586621679708784"><span class="annot"><a href="#local-6989586621679708784"><span class="hs-identifier hs-type">outputSize2</span></a></span></span><span>
</span><span id="line-3570"></span><span>    </span><span id="local-6989586621679708783"><span class="annot"><a href="#local-6989586621679708783"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-3571"></span><span>    </span><span id="local-6989586621679708782"><span class="annot"><a href="#local-6989586621679708782"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3572"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-3573"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-3574"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3575"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3576"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3577"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3578"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3579"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3580"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3581"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3582"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3583"></span><span>         </span><span class="annot"><a href="#local-6989586621679708791"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3584"></span><span>         </span><span class="annot"><a href="#local-6989586621679708790"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3585"></span><span>         </span><span class="annot"><a href="#local-6989586621679708789"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3586"></span><span>         </span><span class="annot"><a href="#local-6989586621679708788"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3587"></span><span>         </span><span class="annot"><a href="#local-6989586621679708787"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-3588"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-3589"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708790"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708786"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3590"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708789"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708785"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3591"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708788"><span class="hs-identifier hs-type">inputSize2</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708784"><span class="hs-identifier hs-type">outputSize2</span></a></span><span>
</span><span id="line-3592"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3593"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3594"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708782"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708783"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708787"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708791"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708790"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708789"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708788"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3595"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3596"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708782"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708783"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708787"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708791"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708786"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708785"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708784"><span class="hs-identifier hs-type">outputSize2</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3597"></span><span id="maxPool3d"><span class="annot"><span class="annottext">maxPool3d :: Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2]
</span><a href="Torch.Typed.Functional.html#maxPool3d"><span class="hs-identifier hs-var hs-var">maxPool3d</span></a></span></span><span> </span><span id="local-6989586621679708781"><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679708781"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3598"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
 -&gt; Tensor
      device
      dtype
      '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-3599"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Bool
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span>
</span><span id="line-3600"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.max_pool3d_tllllb</span></a></span><span>
</span><span id="line-3601"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679708781"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3602"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-special">[</span><span> </span><span class="annot"><span class="annottext">KnownNat (Fst3 kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-3603"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Snd3 kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-3604"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Trd3 kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708794"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3605"></span><span>        </span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3606"></span><span>          </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-3607"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-3608"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Trd3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708793"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3609"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Trd3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708792"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3610"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3611"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-3612"></span><span>
</span><span id="line-3613"></span><span class="hs-comment">-- | maskedFill</span><span>
</span><span id="line-3614"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3615"></span><span class="hs-comment">--</span><span>
</span><span id="line-3616"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2, 1, 3]</span><span>
</span><span id="line-3617"></span><span class="hs-comment">-- &gt;&gt;&gt; m = fromJust [[False], [True], [False]] :: CPUTensor 'D.Bool '[3, 1]</span><span>
</span><span id="line-3618"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = maskedFill @Float m 0.5 t</span><span>
</span><span id="line-3619"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-3620"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 3, 3]</span><span>
</span><span id="line-3621"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\u -&gt; D.asValue (toDynamic u) :: [[[Float]]]) $ t'</span><span>
</span><span id="line-3622"></span><span class="hs-comment">-- (Float,([2,3,3],[[[1.0,1.0,1.0],[0.5,0.5,0.5],[1.0,1.0,1.0]],[[1.0,1.0,1.0],[0.5,0.5,0.5],[1.0,1.0,1.0]]]))</span><span>
</span><span id="line-3623"></span><span class="annot"><a href="Torch.Typed.Functional.html#maskedFill"><span class="hs-identifier hs-type">maskedFill</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3624"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708778"><span class="annot"><a href="#local-6989586621679708778"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679708777"><span class="annot"><a href="#local-6989586621679708777"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708776"><span class="annot"><a href="#local-6989586621679708776"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708775"><span class="annot"><a href="#local-6989586621679708775"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679708774"><span class="annot"><a href="#local-6989586621679708774"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708773"><span class="annot"><a href="#local-6989586621679708773"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3625"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708778"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708775"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708777"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708776"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3626"></span><span>  </span><span class="hs-comment">-- | mask</span><span>
</span><span id="line-3627"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708773"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708776"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3628"></span><span>  </span><span class="hs-comment">-- | fill value</span><span>
</span><span id="line-3629"></span><span>  </span><span class="annot"><a href="#local-6989586621679708778"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3630"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3631"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708773"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708774"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708777"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3632"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3633"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708773"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708774"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708775"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-3634"></span><span id="maskedFill"><span class="annot"><span class="annottext">maskedFill :: Tensor device 'Bool shape'
-&gt; a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape''
</span><a href="Torch.Typed.Functional.html#maskedFill"><span class="hs-identifier hs-var hs-var">maskedFill</span></a></span></span><span> </span><span id="local-6989586621679708772"><span class="annot"><span class="annottext">Tensor device 'Bool shape'
</span><a href="#local-6989586621679708772"><span class="hs-identifier hs-var">mask</span></a></span></span><span> </span><span id="local-6989586621679708771"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679708771"><span class="hs-identifier hs-var">value</span></a></span></span><span> </span><span id="local-6989586621679708770"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708770"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3635"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape'') -&gt; Tensor device dtype shape''
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape'') -&gt; Tensor device dtype shape'')
-&gt; IO (Tensor device dtype shape'') -&gt; Tensor device dtype shape''
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device 'Bool shape'
-&gt; a
-&gt; IO (Tensor device dtype shape'')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.masked_fill_tts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708770"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape'
</span><a href="#local-6989586621679708772"><span class="hs-identifier hs-var">mask</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679708771"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-3636"></span><span>
</span><span id="line-3637"></span><span class="hs-comment">-- mkldnn_convolution :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3638"></span><span class="hs-comment">-- mkldnn_convolution _input _weight _bias _padding _stride _dilation _groups = unsafePerformIO $ (ATen.cast7 ATen.Managed.mkldnn_convolution_tttllll) _input _weight _bias _padding _stride _dilation _groups</span><span>
</span><span id="line-3639"></span><span>
</span><span id="line-3640"></span><span class="hs-comment">-- miopen_batch_norm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Double -&gt; Double -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3641"></span><span class="hs-comment">-- miopen_batch_norm _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon = unsafePerformIO $ (ATen.cast8 ATen.Managed.miopen_batch_norm_tttttbdd) _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon</span><span>
</span><span id="line-3642"></span><span>
</span><span id="line-3643"></span><span class="hs-comment">-- miopen_convolution :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; Int -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3644"></span><span class="hs-comment">-- miopen_convolution _input _weight _bias _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (ATen.cast9 ATen.Managed.miopen_convolution_tttllllbb) _input _weight _bias _padding _stride _dilation _groups _benchmark _deterministic</span><span>
</span><span id="line-3645"></span><span>
</span><span id="line-3646"></span><span class="hs-comment">-- miopen_convolution_transpose :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; Int -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3647"></span><span class="hs-comment">-- miopen_convolution_transpose _input _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (ATen.ATen.cast10 ATen.Managed.miopen_convolution_transpose_tttlllllbb) _input _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic</span><span>
</span><span id="line-3648"></span><span>
</span><span id="line-3649"></span><span class="hs-comment">-- miopen_depthwise_convolution :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; [Int] -&gt; Int -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3650"></span><span class="hs-comment">-- miopen_depthwise_convolution _input _weight _bias _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (ATen.cast9 ATen.Managed.miopen_depthwise_convolution_tttllllbb) _input _weight _bias _padding _stride _dilation _groups _benchmark _deterministic</span><span>
</span><span id="line-3651"></span><span>
</span><span id="line-3652"></span><span class="hs-comment">-- miopen_rnn :: Tensor device dtype shape -&gt; [Tensor device dtype shape] -&gt; Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Int -&gt; Bool -&gt; Double -&gt; Bool -&gt; Bool -&gt; [Int] -&gt; Tensor device dtype shape -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3653"></span><span class="hs-comment">-- miopen_rnn _input _weight _weight_stride0 _hx _cx _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state = unsafePerformIO $ (ATen.ATen.cast14 ATen.Managed.miopen_rnn_tllttlllbdbblt) _input _weight _weight_stride0 _hx _cx _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state</span><span>
</span><span id="line-3654"></span><span>
</span><span id="line-3655"></span><span class="hs-comment">-- | matrix-matrix multiplication</span><span>
</span><span id="line-3656"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3657"></span><span class="hs-comment">--</span><span>
</span><span id="line-3658"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ mm (ones :: CPUTensor 'D.Float '[3,2]) (zeros :: CPUTensor 'D.Float '[2,4])</span><span>
</span><span id="line-3659"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-3660"></span><span class="annot"><a href="Torch.Typed.Functional.html#mm"><span class="hs-identifier hs-type">mm</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3661"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708767"><span class="annot"><a href="#local-6989586621679708767"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679708766"><span class="annot"><a href="#local-6989586621679708766"><span class="hs-identifier hs-type">k</span></a></span></span><span> </span><span id="local-6989586621679708765"><span class="annot"><a href="#local-6989586621679708765"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679708764"><span class="annot"><a href="#local-6989586621679708764"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708763"><span class="annot"><a href="#local-6989586621679708763"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3662"></span><span>  </span><span class="hs-comment">-- | first input matrix</span><span>
</span><span id="line-3663"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708763"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708764"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708767"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708766"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3664"></span><span>  </span><span class="hs-comment">-- | second input matrix</span><span>
</span><span id="line-3665"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708763"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708764"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708766"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708765"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3666"></span><span>  </span><span class="hs-comment">-- | output matrix</span><span>
</span><span id="line-3667"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708763"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708764"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708767"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708765"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3668"></span><span id="mm"><span class="annot"><span class="annottext">mm :: Tensor device dtype '[n, k]
-&gt; Tensor device dtype '[k, m] -&gt; Tensor device dtype '[n, m]
</span><a href="Torch.Typed.Functional.html#mm"><span class="hs-identifier hs-var hs-var">mm</span></a></span></span><span> </span><span id="local-6989586621679708762"><span class="annot"><span class="annottext">Tensor device dtype '[n, k]
</span><a href="#local-6989586621679708762"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679708761"><span class="annot"><span class="annottext">Tensor device dtype '[k, m]
</span><a href="#local-6989586621679708761"><span class="hs-identifier hs-var">b</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[n, m]) -&gt; Tensor device dtype '[n, m]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[n, m]) -&gt; Tensor device dtype '[n, m])
-&gt; IO (Tensor device dtype '[n, m]) -&gt; Tensor device dtype '[n, m]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[n, k]
-&gt; Tensor device dtype '[k, m]
-&gt; IO (Tensor device dtype '[n, m])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mm_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[n, k]
</span><a href="#local-6989586621679708762"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[k, m]
</span><a href="#local-6989586621679708761"><span class="hs-identifier hs-var">b</span></a></span><span>
</span><span id="line-3669"></span><span>
</span><span id="line-3670"></span><span class="hs-comment">-- | matrix-vector multiplication</span><span>
</span><span id="line-3671"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3672"></span><span class="hs-comment">--</span><span>
</span><span id="line-3673"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ mv (ones :: CPUTensor 'D.Float '[3,2]) (zeros :: CPUTensor 'D.Float '[2])</span><span>
</span><span id="line-3674"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-3675"></span><span class="annot"><a href="Torch.Typed.Functional.html#mv"><span class="hs-identifier hs-type">mv</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3676"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708758"><span class="annot"><a href="#local-6989586621679708758"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679708757"><span class="annot"><a href="#local-6989586621679708757"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679708756"><span class="annot"><a href="#local-6989586621679708756"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708755"><span class="annot"><a href="#local-6989586621679708755"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3677"></span><span>  </span><span class="hs-comment">-- | input matrix</span><span>
</span><span id="line-3678"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708755"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708756"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708758"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708757"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3679"></span><span>  </span><span class="hs-comment">-- | input vector</span><span>
</span><span id="line-3680"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708755"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708756"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708757"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3681"></span><span>  </span><span class="hs-comment">-- | output vector</span><span>
</span><span id="line-3682"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708755"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708756"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708758"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-3683"></span><span id="mv"><span class="annot"><span class="annottext">mv :: Tensor device dtype '[n, m]
-&gt; Tensor device dtype '[m] -&gt; Tensor device dtype '[n]
</span><a href="Torch.Typed.Functional.html#mv"><span class="hs-identifier hs-var hs-var">mv</span></a></span></span><span> </span><span id="local-6989586621679708754"><span class="annot"><span class="annottext">Tensor device dtype '[n, m]
</span><a href="#local-6989586621679708754"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679708753"><span class="annot"><span class="annottext">Tensor device dtype '[m]
</span><a href="#local-6989586621679708753"><span class="hs-identifier hs-var">vec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[n]) -&gt; Tensor device dtype '[n]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[n]) -&gt; Tensor device dtype '[n])
-&gt; IO (Tensor device dtype '[n]) -&gt; Tensor device dtype '[n]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[n, m]
-&gt; Tensor device dtype '[m]
-&gt; IO (Tensor device dtype '[n])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.mv_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[n, m]
</span><a href="#local-6989586621679708754"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[m]
</span><a href="#local-6989586621679708753"><span class="hs-identifier hs-var">vec</span></a></span><span>
</span><span id="line-3684"></span><span>
</span><span id="line-3685"></span><span class="hs-comment">-- mvlgamma :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3686"></span><span class="hs-comment">-- mvlgamma _input _p = unsafePerformIO $ (ATen.cast2 ATen.Managed.mvlgamma_tl) _input _p</span><span>
</span><span id="line-3687"></span><span>
</span><span id="line-3688"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-3689"></span><span>  </span><span id="NarrowCheck"><span class="annot"><a href="Torch.Typed.Functional.html#NarrowCheck"><span class="hs-identifier hs-var">NarrowCheck</span></a></span></span><span>
</span><span id="line-3690"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679708751"><span class="annot"><a href="#local-6989586621679708751"><span class="hs-identifier hs-type">mbCurrent</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-3691"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679708750"><span class="annot"><a href="#local-6989586621679708750"><span class="hs-identifier hs-type">mbUpdated</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3692"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679708749"><span class="annot"><a href="#local-6989586621679708749"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-3693"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679708748"><span class="annot"><a href="#local-6989586621679708748"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-3694"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679708747"><span class="annot"><a href="#local-6989586621679708747"><span class="hs-identifier hs-type">start</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-3695"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679708746"><span class="annot"><a href="#local-6989586621679708746"><span class="hs-identifier hs-type">length</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3696"></span><span>    </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span>
</span><span id="line-3697"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-3698"></span><span>  </span><span id="NarrowCheck"><span class="annot"><a href="Torch.Typed.Functional.html#NarrowCheck"><span class="hs-identifier hs-var">NarrowCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679708745"><span class="annot"><a href="#local-6989586621679708745"><span class="hs-identifier hs-type hs-type">sh</span></a></span></span><span> </span><span id="local-6989586621679708744"><span class="annot"><a href="#local-6989586621679708744"><span class="hs-identifier hs-type hs-type">d</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DimOutOfBound"><span class="hs-identifier hs-type">DimOutOfBound</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708745"><span class="hs-identifier hs-type">sh</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708744"><span class="hs-identifier hs-type">d</span></a></span><span>
</span><span id="line-3699"></span><span>  </span><span id="NarrowCheck"><span class="annot"><a href="Torch.Typed.Functional.html#NarrowCheck"><span class="hs-identifier hs-var">NarrowCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708743"><span class="annot"><a href="#local-6989586621679708743"><span class="hs-identifier hs-type hs-type">c</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span id="local-6989586621679708742"><span class="annot"><a href="#local-6989586621679708742"><span class="hs-identifier hs-type hs-type">sh</span></a></span></span><span> </span><span id="local-6989586621679708741"><span class="annot"><a href="#local-6989586621679708741"><span class="hs-identifier hs-type hs-type">d</span></a></span></span><span> </span><span id="local-6989586621679708740"><span class="annot"><a href="#local-6989586621679708740"><span class="hs-identifier hs-type hs-type">s</span></a></span></span><span> </span><span id="local-6989586621679708739"><span class="annot"><a href="#local-6989586621679708739"><span class="hs-identifier hs-type hs-type">l</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DimOutOfBound"><span class="hs-identifier hs-type">DimOutOfBound</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708742"><span class="hs-identifier hs-type">sh</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708741"><span class="hs-identifier hs-type">d</span></a></span><span>
</span><span id="line-3700"></span><span>  </span><span id="NarrowCheck"><span class="annot"><a href="Torch.Typed.Functional.html#NarrowCheck"><span class="hs-identifier hs-var">NarrowCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708738"><span class="annot"><a href="#local-6989586621679708738"><span class="hs-identifier hs-type hs-type">r</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679708738"><span class="hs-identifier hs-type">r</span></a></span><span>
</span><span id="line-3701"></span><span>
</span><span id="line-3702"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="Narrow%27"><span class="annot"><a href="Torch.Typed.Functional.html#Narrow%27"><span class="hs-identifier hs-var">Narrow'</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708737"><span class="annot"><a href="#local-6989586621679708737"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708736"><span class="annot"><a href="#local-6989586621679708736"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708735"><span class="annot"><a href="#local-6989586621679708735"><span class="hs-identifier hs-type">current</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708734"><span class="annot"><a href="#local-6989586621679708734"><span class="hs-identifier hs-type">start</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708733"><span class="annot"><a href="#local-6989586621679708733"><span class="hs-identifier hs-type">length</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3703"></span><span>  </span><span id="Narrow%27"><span class="annot"><a href="Torch.Typed.Functional.html#Narrow%27"><span class="hs-identifier hs-var">Narrow'</span></a></span></span><span> </span><span id="local-6989586621679708732"><span class="annot"><a href="#local-6989586621679708732"><span class="hs-identifier hs-type hs-type">d</span></a></span></span><span> </span><span id="local-6989586621679708731"><span class="annot"><a href="#local-6989586621679708731"><span class="hs-identifier hs-type hs-type">sh</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708730"><span class="annot"><a href="#local-6989586621679708730"><span class="hs-identifier hs-type hs-type">c</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708729"><span class="annot"><a href="#local-6989586621679708729"><span class="hs-identifier hs-type hs-type">s</span></a></span></span><span> </span><span id="local-6989586621679708728"><span class="annot"><a href="#local-6989586621679708728"><span class="hs-identifier hs-type hs-type">l</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3704"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#If"><span class="hs-identifier hs-type">If</span></a></span><span>
</span><span id="line-3705"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708729"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679708728"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=?</span></span><span> </span><span class="annot"><a href="#local-6989586621679708730"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3706"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#ReplaceDim"><span class="hs-identifier hs-type">ReplaceDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708732"><span class="hs-identifier hs-type">d</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708731"><span class="hs-identifier hs-type">sh</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708728"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3707"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-3708"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;The end of the requested narrow segment &quot;</span></span><span>
</span><span id="line-3709"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708729"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><a href="#local-6989586621679708728"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3710"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot; would be larger than current size &quot;</span></span><span>
</span><span id="line-3711"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708730"><span class="hs-identifier hs-type">c</span></a></span><span>
</span><span id="line-3712"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot; at dimension &quot;</span></span><span>
</span><span id="line-3713"></span><span>              </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708732"><span class="hs-identifier hs-type">d</span></a></span><span>
</span><span id="line-3714"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-3715"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-3716"></span><span>  </span><span id="Narrow%27"><span class="annot"><a href="Torch.Typed.Functional.html#Narrow%27"><span class="hs-identifier hs-var">Narrow'</span></a></span></span><span> </span><span id="local-6989586621679708727"><span class="annot"><a href="#local-6989586621679708727"><span class="hs-identifier hs-type hs-type">d</span></a></span></span><span> </span><span id="local-6989586621679708726"><span class="annot"><a href="#local-6989586621679708726"><span class="hs-identifier hs-type hs-type">sh</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span id="local-6989586621679708725"><span class="annot"><a href="#local-6989586621679708725"><span class="hs-identifier hs-type hs-type">s</span></a></span></span><span> </span><span id="local-6989586621679708724"><span class="annot"><a href="#local-6989586621679708724"><span class="hs-identifier hs-type hs-type">l</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3717"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-3718"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Requested narrow dimension &quot;</span></span><span>
</span><span id="line-3719"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708727"><span class="hs-identifier hs-type">d</span></a></span><span>
</span><span id="line-3720"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot; doesnt exist in &quot;</span></span><span>
</span><span id="line-3721"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708726"><span class="hs-identifier hs-type">sh</span></a></span><span>
</span><span id="line-3722"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-3723"></span><span>
</span><span id="line-3724"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="Narrow"><span class="annot"><a href="Torch.Typed.Functional.html#Narrow"><span class="hs-identifier hs-var">Narrow</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708723"><span class="annot"><a href="#local-6989586621679708723"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708722"><span class="annot"><a href="#local-6989586621679708722"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708721"><span class="annot"><a href="#local-6989586621679708721"><span class="hs-identifier hs-type">start</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708720"><span class="annot"><a href="#local-6989586621679708720"><span class="hs-identifier hs-type">length</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3725"></span><span>  </span><span id="Narrow"><span class="annot"><a href="Torch.Typed.Functional.html#Narrow"><span class="hs-identifier hs-var">Narrow</span></a></span></span><span> </span><span id="local-6989586621679708719"><span class="annot"><a href="#local-6989586621679708719"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708718"><span class="annot"><a href="#local-6989586621679708718"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708717"><span class="annot"><a href="#local-6989586621679708717"><span class="hs-identifier hs-type hs-type">start</span></a></span></span><span> </span><span id="local-6989586621679708716"><span class="annot"><a href="#local-6989586621679708716"><span class="hs-identifier hs-type hs-type">length</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3726"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#NarrowCheck"><span class="hs-identifier hs-type">NarrowCheck</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#ExtractDim"><span class="hs-identifier hs-type">ExtractDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708718"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708719"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#Narrow%27"><span class="hs-identifier hs-type">Narrow'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708718"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708719"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#ExtractDim"><span class="hs-identifier hs-type">ExtractDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708718"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708719"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708717"><span class="hs-identifier hs-type">start</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708716"><span class="hs-identifier hs-type">length</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708719"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708718"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708717"><span class="hs-identifier hs-type">start</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708716"><span class="hs-identifier hs-type">length</span></a></span><span>
</span><span id="line-3727"></span><span>
</span><span id="line-3728"></span><span class="hs-comment">-- | &quot;Narrow&quot; a tensor by returning a tensor that is a slice from 'start' of length 'length' along 'dim'</span><span>
</span><span id="line-3729"></span><span class="hs-comment">--</span><span>
</span><span id="line-3730"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ narrow @0 @0 @2 (ones :: CPUTensor 'D.Float '[3,3,3])</span><span>
</span><span id="line-3731"></span><span class="hs-comment">-- (Float,[2,3,3])</span><span>
</span><span id="line-3732"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ narrow @1 @1 @2 (ones :: CPUTensor 'D.Half '[3,3,3])</span><span>
</span><span id="line-3733"></span><span class="hs-comment">-- (Half,[3,2,3])</span><span>
</span><span id="line-3734"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ narrow @1 @1 @2 (ones :: CPUTensor 'D.Bool '[3,3,3])</span><span>
</span><span id="line-3735"></span><span class="hs-comment">-- (Bool,[3,2,3])</span><span>
</span><span id="line-3736"></span><span class="annot"><a href="Torch.Typed.Functional.html#narrow"><span class="hs-identifier hs-type">narrow</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3737"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708714"><span class="annot"><a href="#local-6989586621679708714"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708713"><span class="annot"><a href="#local-6989586621679708713"><span class="hs-identifier hs-type">start</span></a></span></span><span> </span><span id="local-6989586621679708712"><span class="annot"><a href="#local-6989586621679708712"><span class="hs-identifier hs-type">length</span></a></span></span><span> </span><span id="local-6989586621679708711"><span class="annot"><a href="#local-6989586621679708711"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708710"><span class="annot"><a href="#local-6989586621679708710"><span class="hs-identifier hs-type">mbSize</span></a></span></span><span> </span><span id="local-6989586621679708709"><span class="annot"><a href="#local-6989586621679708709"><span class="hs-identifier hs-type">mbNewShape</span></a></span></span><span> </span><span id="local-6989586621679708708"><span class="annot"><a href="#local-6989586621679708708"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708707"><span class="annot"><a href="#local-6989586621679708707"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3738"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708714"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708713"><span class="hs-identifier hs-type">start</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708712"><span class="hs-identifier hs-type">length</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-3739"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708711"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3740"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3741"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708707"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708708"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708711"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3742"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708707"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708708"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#Narrow"><span class="hs-identifier hs-type">Narrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708711"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708714"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708713"><span class="hs-identifier hs-type">start</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708712"><span class="hs-identifier hs-type">length</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3743"></span><span id="narrow"><span class="annot"><span class="annottext">narrow :: Tensor device dtype shape
-&gt; Tensor device dtype (Narrow shape dim start length)
</span><a href="Torch.Typed.Functional.html#narrow"><span class="hs-identifier hs-var hs-var">narrow</span></a></span></span><span> </span><span id="local-6989586621679708706"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708706"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     (NarrowCheck
        (ExtractDim dim shape)
        (Narrow' dim shape (ExtractDim dim shape) start length)
        shape
        dim
        start
        length))
-&gt; Tensor
     device
     dtype
     (NarrowCheck
        (ExtractDim dim shape)
        (Narrow' dim shape (ExtractDim dim shape) start length)
        shape
        dim
        start
        length)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      (NarrowCheck
         (ExtractDim dim shape)
         (Narrow' dim shape (ExtractDim dim shape) start length)
         shape
         dim
         start
         length))
 -&gt; Tensor
      device
      dtype
      (NarrowCheck
         (ExtractDim dim shape)
         (Narrow' dim shape (ExtractDim dim shape) start length)
         shape
         dim
         start
         length))
-&gt; IO
     (Tensor
        device
        dtype
        (NarrowCheck
           (ExtractDim dim shape)
           (Narrow' dim shape (ExtractDim dim shape) start length)
           shape
           dim
           start
           length))
-&gt; Tensor
     device
     dtype
     (NarrowCheck
        (ExtractDim dim shape)
        (Narrow' dim shape (ExtractDim dim shape) start length)
        shape
        dim
        start
        length)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Int
-&gt; Int
-&gt; IO
     (Tensor
        device
        dtype
        (NarrowCheck
           (ExtractDim dim shape)
           (Narrow' dim shape (ExtractDim dim shape) start length)
           shape
           dim
           start
           length))
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; Int64 -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.narrow_tlll</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708706"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708704"><span class="hs-identifier hs-var">_dim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708703"><span class="hs-identifier hs-var">_start</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708702"><span class="hs-identifier hs-var">_length</span></a></span><span>
</span><span id="line-3744"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-3745"></span><span>    </span><span id="local-6989586621679708704"><span class="annot"><span class="annottext">_dim :: Int
</span><a href="#local-6989586621679708704"><span class="hs-identifier hs-var hs-var">_dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708714"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-3746"></span><span>    </span><span id="local-6989586621679708703"><span class="annot"><span class="annottext">_start :: Int
</span><a href="#local-6989586621679708703"><span class="hs-identifier hs-var hs-var">_start</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat start =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708713"><span class="hs-identifier hs-type">start</span></a></span><span>
</span><span id="line-3747"></span><span>    </span><span id="local-6989586621679708702"><span class="annot"><span class="annottext">_length :: Int
</span><a href="#local-6989586621679708702"><span class="hs-identifier hs-var hs-var">_length</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat length =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708712"><span class="hs-identifier hs-type">length</span></a></span><span>
</span><span id="line-3748"></span><span>
</span><span id="line-3749"></span><span class="hs-comment">-- native_batch_norm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Double -&gt; Double -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3750"></span><span class="hs-comment">-- native_batch_norm _input _weight _bias _running_mean _running_var _training _momentum _eps = unsafePerformIO $ (ATen.cast8 ATen.Managed.native_batch_norm_tttttbdd) _input _weight _bias _running_mean _running_var _training _momentum _eps</span><span>
</span><span id="line-3751"></span><span>
</span><span id="line-3752"></span><span class="hs-comment">-- batch_norm_stats :: Tensor device dtype shape -&gt; Double -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3753"></span><span class="hs-comment">-- batch_norm_stats _input _eps = unsafePerformIO $ (ATen.cast2 ATen.Managed.batch_norm_stats_td) _input _eps</span><span>
</span><span id="line-3754"></span><span>
</span><span id="line-3755"></span><span class="hs-comment">-- batch_norm_elemt :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3756"></span><span class="hs-comment">-- batch_norm_elemt _input _weight _bias _mean _invstd _eps = unsafePerformIO $ (ATen.cast6 ATen.Managed.batch_norm_elemt_tttttd) _input _weight _bias _mean _invstd _eps</span><span>
</span><span id="line-3757"></span><span>
</span><span id="line-3758"></span><span class="hs-comment">-- batch_norm_gather_stats :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Double -&gt; Int -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3759"></span><span class="hs-comment">-- batch_norm_gather_stats _input _mean _invstd _running_mean _running_var _momentum _eps _count = unsafePerformIO $ (ATen.cast8 ATen.Managed.batch_norm_gather_stats_tttttddl) _input _mean _invstd _running_mean _running_var _momentum _eps _count</span><span>
</span><span id="line-3760"></span><span>
</span><span id="line-3761"></span><span class="hs-comment">-- batch_norm_gather_stats_with_counts :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Double -&gt; [Int] -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3762"></span><span class="hs-comment">-- batch_norm_gather_stats_with_counts _input _mean _invstd _running_mean _running_var _momentum _eps _counts = unsafePerformIO $ (ATen.cast8 ATen.Managed.batch_norm_gather_stats_with_counts_tttttddl) _input _mean _invstd _running_mean _running_var _momentum _eps _counts</span><span>
</span><span id="line-3763"></span><span>
</span><span id="line-3764"></span><span class="hs-comment">-- batch_norm_update_stats :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3765"></span><span class="hs-comment">-- batch_norm_update_stats _input _running_mean _running_var _momentum = unsafePerformIO $ (ATen.cast4 ATen.Managed.batch_norm_update_stats_tttd) _input _running_mean _running_var _momentum</span><span>
</span><span id="line-3766"></span><span>
</span><span id="line-3767"></span><span class="hs-comment">-- | onesLike</span><span>
</span><span id="line-3768"></span><span class="hs-comment">--</span><span>
</span><span id="line-3769"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ onesLike (ones :: CPUTensor 'D.Float '[3,4,5])</span><span>
</span><span id="line-3770"></span><span class="hs-comment">-- (Float,[3,4,5])</span><span>
</span><span id="line-3771"></span><span class="annot"><a href="Torch.Typed.Functional.html#onesLike"><span class="hs-identifier hs-type">onesLike</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3772"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708700"><span class="annot"><a href="#local-6989586621679708700"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708699"><span class="annot"><a href="#local-6989586621679708699"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708698"><span class="annot"><a href="#local-6989586621679708698"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3773"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3774"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708698"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708699"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708700"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3775"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3776"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708698"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708699"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708700"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3777"></span><span id="onesLike"><span class="annot"><span class="annottext">onesLike :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#onesLike"><span class="hs-identifier hs-var hs-var">onesLike</span></a></span></span><span> </span><span id="local-6989586621679708697"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708697"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.ones_like_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708697"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3778"></span><span>
</span><span id="line-3779"></span><span class="hs-comment">-- pairwise_distance :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Double -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3780"></span><span class="hs-comment">-- pairwise_distance _x1 _x2 _p _eps _keepdim = unsafePerformIO $ (ATen.cast5 ATen.Managed.pairwise_distance_ttddb) _x1 _x2 _p _eps _keepdim</span><span>
</span><span id="line-3781"></span><span>
</span><span id="line-3782"></span><span class="hs-comment">-- cdist :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3783"></span><span class="hs-comment">-- cdist _x1 _x2 _p = unsafePerformIO $ (ATen.cast3 ATen.Managed.cdist_ttd) _x1 _x2 _p</span><span>
</span><span id="line-3784"></span><span>
</span><span id="line-3785"></span><span class="hs-comment">-- pdist :: Tensor device dtype shape -&gt; Double -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3786"></span><span class="hs-comment">-- pdist _input _p = unsafePerformIO $ (ATen.cast2 ATen.Managed.pdist_td) _input _p</span><span>
</span><span id="line-3787"></span><span>
</span><span id="line-3788"></span><span class="hs-comment">-- cosine_similarity :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Double -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3789"></span><span class="hs-comment">-- cosine_similarity _x1 _x2 _dim _eps = unsafePerformIO $ (ATen.cast4 ATen.Managed.cosine_similarity_ttld) _x1 _x2 _dim _eps</span><span>
</span><span id="line-3790"></span><span>
</span><span id="line-3791"></span><span class="hs-comment">-- pixel_shuffle :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3792"></span><span class="hs-comment">-- pixel_shuffle _input _upscale_factor = unsafePerformIO $ (ATen.cast2 ATen.Managed.pixel_shuffle_tl) _input _upscale_factor</span><span>
</span><span id="line-3793"></span><span>
</span><span id="line-3794"></span><span class="hs-comment">-- pin_memory :: Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3795"></span><span class="hs-comment">-- pin_memory _input = unsafePerformIO $ (ATen.cast1 ATen.Managed.pin_memory_t) _input</span><span>
</span><span id="line-3796"></span><span>
</span><span id="line-3797"></span><span class="hs-comment">-- pinverse :: Tensor device dtype shape -&gt; Double -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3798"></span><span class="hs-comment">-- pinverse _input _rcond = unsafePerformIO $ (ATen.cast2 ATen.Managed.pinverse_td) _input _rcond</span><span>
</span><span id="line-3799"></span><span>
</span><span id="line-3800"></span><span class="hs-comment">-- poisson_nll_loss :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Bool -&gt; Double -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3801"></span><span class="hs-comment">-- poisson_nll_loss _input _target _log_input _full _eps _reduction = unsafePerformIO $ (ATen.cast6 ATen.Managed.poisson_nll_loss_ttbbdl) _input _target _log_input _full _eps _reduction</span><span>
</span><span id="line-3802"></span><span>
</span><span id="line-3803"></span><span class="hs-comment">-- | randLike</span><span>
</span><span id="line-3804"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3805"></span><span class="hs-comment">--</span><span>
</span><span id="line-3806"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- randLike (ones :: CPUTensor 'D.Float '[3,4,5])</span><span>
</span><span id="line-3807"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-3808"></span><span class="hs-comment">-- (Float,[3,4,5])</span><span>
</span><span id="line-3809"></span><span class="annot"><a href="Torch.Typed.Functional.html#randLike"><span class="hs-identifier hs-type">randLike</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3810"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708694"><span class="annot"><a href="#local-6989586621679708694"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708693"><span class="annot"><a href="#local-6989586621679708693"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708692"><span class="annot"><a href="#local-6989586621679708692"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3811"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3812"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708692"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708693"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708694"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3813"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3814"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708692"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708693"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708694"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3815"></span><span id="randLike"><span class="annot"><span class="annottext">randLike :: Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.Functional.html#randLike"><span class="hs-identifier hs-var hs-var">randLike</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.rand_like_t</span></a></span><span>
</span><span id="line-3816"></span><span>
</span><span id="line-3817"></span><span class="hs-comment">-- | randnLike</span><span>
</span><span id="line-3818"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3819"></span><span class="hs-comment">--</span><span>
</span><span id="line-3820"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- randnLike (ones :: CPUTensor 'D.Float '[3,4,5])</span><span>
</span><span id="line-3821"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-3822"></span><span class="hs-comment">-- (Float,[3,4,5])</span><span>
</span><span id="line-3823"></span><span class="annot"><a href="Torch.Typed.Functional.html#randnLike"><span class="hs-identifier hs-type">randnLike</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3824"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708689"><span class="annot"><a href="#local-6989586621679708689"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708688"><span class="annot"><a href="#local-6989586621679708688"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708687"><span class="annot"><a href="#local-6989586621679708687"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3825"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3826"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708687"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708688"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708689"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3827"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3828"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708687"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708688"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708689"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3829"></span><span id="randnLike"><span class="annot"><span class="annottext">randnLike :: Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.Functional.html#randnLike"><span class="hs-identifier hs-var hs-var">randnLike</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.randn_like_t</span></a></span><span>
</span><span id="line-3830"></span><span>
</span><span id="line-3831"></span><span class="hs-comment">-- | reciprocal</span><span>
</span><span id="line-3832"></span><span class="hs-comment">--</span><span>
</span><span id="line-3833"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ reciprocal (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3834"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3835"></span><span class="annot"><a href="Torch.Typed.Functional.html#reciprocal"><span class="hs-identifier hs-type">reciprocal</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3836"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708684"><span class="annot"><a href="#local-6989586621679708684"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708683"><span class="annot"><a href="#local-6989586621679708683"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708682"><span class="annot"><a href="#local-6989586621679708682"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3837"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3838"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708683"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708684"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3839"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3840"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708683"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708684"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3841"></span><span id="reciprocal"><span class="annot"><span class="annottext">reciprocal :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#reciprocal"><span class="hs-identifier hs-var hs-var">reciprocal</span></a></span></span><span> </span><span id="local-6989586621679708681"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708681"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.reciprocal_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708681"><span class="hs-identifier hs-var">_input</span></a></span><span>
</span><span id="line-3842"></span><span>
</span><span id="line-3843"></span><span class="hs-comment">-- | negate</span><span>
</span><span id="line-3844"></span><span class="hs-comment">-- TODO: probably not defined for `D.Bool` tensors</span><span>
</span><span id="line-3845"></span><span class="hs-comment">--</span><span>
</span><span id="line-3846"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ neg (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3847"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3848"></span><span class="annot"><a href="Torch.Typed.Functional.html#neg"><span class="hs-identifier hs-type">neg</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3849"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708678"><span class="annot"><a href="#local-6989586621679708678"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708677"><span class="annot"><a href="#local-6989586621679708677"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708676"><span class="annot"><a href="#local-6989586621679708676"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3850"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3851"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708676"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708677"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708678"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3852"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3853"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708676"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708677"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708678"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3854"></span><span id="neg"><span class="annot"><span class="annottext">neg :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#neg"><span class="hs-identifier hs-var hs-var">neg</span></a></span></span><span> </span><span id="local-6989586621679708675"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708675"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.neg_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708675"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3855"></span><span>
</span><span id="line-3856"></span><span class="hs-comment">-- | round</span><span>
</span><span id="line-3857"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors</span><span>
</span><span id="line-3858"></span><span class="hs-comment">--</span><span>
</span><span id="line-3859"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ round (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3860"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3861"></span><span class="annot"><a href="Torch.Typed.Functional.html#round"><span class="hs-identifier hs-type">round</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3862"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708672"><span class="annot"><a href="#local-6989586621679708672"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708671"><span class="annot"><a href="#local-6989586621679708671"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708670"><span class="annot"><a href="#local-6989586621679708670"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3863"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3864"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708670"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708671"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708672"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3865"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3866"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708670"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708671"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708672"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3867"></span><span id="round"><span class="annot"><span class="annottext">round :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#round"><span class="hs-identifier hs-var hs-var">round</span></a></span></span><span> </span><span id="local-6989586621679708669"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708669"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.round_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708669"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3868"></span><span>
</span><span id="line-3869"></span><span class="hs-comment">-- | prelu activation function</span><span>
</span><span id="line-3870"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3871"></span><span class="hs-comment">--</span><span>
</span><span id="line-3872"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ prelu (ones :: CPUTensor 'D.Float '[]) (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3873"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3874"></span><span class="annot"><a href="Torch.Typed.Functional.html#prelu"><span class="hs-identifier hs-type">prelu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3875"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708666"><span class="annot"><a href="#local-6989586621679708666"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708665"><span class="annot"><a href="#local-6989586621679708665"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708664"><span class="annot"><a href="#local-6989586621679708664"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3876"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-3877"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708665"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3878"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3879"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708665"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708666"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3880"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3881"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708665"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708666"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3882"></span><span id="prelu"><span class="annot"><span class="annottext">prelu :: Tensor device dtype '[]
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#prelu"><span class="hs-identifier hs-var hs-var">prelu</span></a></span></span><span> </span><span id="local-6989586621679708663"><span class="annot"><span class="annottext">Tensor device dtype '[]
</span><a href="#local-6989586621679708663"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679708662"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708662"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype '[]
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.prelu_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708662"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[]
</span><a href="#local-6989586621679708663"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-3883"></span><span>
</span><span id="line-3884"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="GeluDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#GeluDTypeIsValid"><span class="hs-identifier hs-var">GeluDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708659"><span class="annot"><a href="#local-6989586621679708659"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708658"><span class="annot"><a href="#local-6989586621679708658"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3885"></span><span>  </span><span id="GeluDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#GeluDTypeIsValid"><span class="hs-identifier hs-var">GeluDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708657"><span class="annot"><a href="#local-6989586621679708657"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3886"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708657"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3887"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708657"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-3888"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-3889"></span><span>  </span><span id="GeluDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#GeluDTypeIsValid"><span class="hs-identifier hs-var">GeluDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679708656"><span class="annot"><a href="#local-6989586621679708656"><span class="hs-identifier hs-type hs-type">deviceIndex</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708655"><span class="annot"><a href="#local-6989586621679708655"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-3890"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsFloatingPoint"><span class="hs-identifier hs-type">DTypeIsFloatingPoint</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708656"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708655"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-3891"></span><span>      </span><span class="annot"><a href="Torch.Typed.Aux.html#DTypeIsNotHalf"><span class="hs-identifier hs-type">DTypeIsNotHalf</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Device.html#CUDA"><span class="hs-identifier hs-type">D.CUDA</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708656"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708655"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-3892"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-3893"></span><span>  </span><span id="GeluDTypeIsValid"><span class="annot"><a href="Torch.Typed.Functional.html#GeluDTypeIsValid"><span class="hs-identifier hs-var">GeluDTypeIsValid</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679708654"><span class="annot"><a href="#local-6989586621679708654"><span class="hs-identifier hs-type hs-type">deviceType</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708653"><span class="annot"><a href="#local-6989586621679708653"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#UnsupportedDTypeForDevice"><span class="hs-identifier hs-type">UnsupportedDTypeForDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708654"><span class="hs-identifier hs-type">deviceType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708653"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-3894"></span><span>
</span><span id="line-3895"></span><span class="hs-comment">-- | gelu activation function</span><span>
</span><span id="line-3896"></span><span class="hs-comment">--</span><span>
</span><span id="line-3897"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ round (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3898"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3899"></span><span class="annot"><a href="Torch.Typed.Functional.html#gelu"><span class="hs-identifier hs-type">gelu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3900"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708651"><span class="annot"><a href="#local-6989586621679708651"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708650"><span class="annot"><a href="#local-6989586621679708650"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708649"><span class="annot"><a href="#local-6989586621679708649"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3901"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#GeluDTypeIsValid"><span class="hs-identifier hs-type">GeluDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708649"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708650"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3902"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3903"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708649"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708650"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708651"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3904"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3905"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708649"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708650"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708651"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3906"></span><span id="gelu"><span class="annot"><span class="annottext">gelu :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#gelu"><span class="hs-identifier hs-var hs-var">gelu</span></a></span></span><span> </span><span id="local-6989586621679708648"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708648"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.gelu_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708648"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3907"></span><span>
</span><span id="line-3908"></span><span class="hs-comment">-- hardshrink :: Tensor device dtype shape -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3909"></span><span class="hs-comment">-- hardshrink _input _lambd = unsafePerformIO $ (ATen.cast2 ATen.Managed.hardshrink_ts) _input _lambd</span><span>
</span><span id="line-3910"></span><span>
</span><span id="line-3911"></span><span class="hs-comment">-- | rsqrt</span><span>
</span><span id="line-3912"></span><span class="hs-comment">--</span><span>
</span><span id="line-3913"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ rsqrt (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3914"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3915"></span><span class="annot"><a href="Torch.Typed.Functional.html#rsqrt"><span class="hs-identifier hs-type">rsqrt</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3916"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708645"><span class="annot"><a href="#local-6989586621679708645"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708644"><span class="annot"><a href="#local-6989586621679708644"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708643"><span class="annot"><a href="#local-6989586621679708643"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3917"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708643"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708644"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-3918"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3919"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708643"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708644"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708645"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3920"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3921"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708643"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708644"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708645"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3922"></span><span id="rsqrt"><span class="annot"><span class="annottext">rsqrt :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#rsqrt"><span class="hs-identifier hs-var hs-var">rsqrt</span></a></span></span><span> </span><span id="local-6989586621679708642"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708642"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.rsqrt_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708642"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-3923"></span><span>
</span><span id="line-3924"></span><span class="hs-comment">-- | celu activation function</span><span>
</span><span id="line-3925"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-3926"></span><span class="hs-comment">--</span><span>
</span><span id="line-3927"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ celu 3.0 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-3928"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-3929"></span><span class="annot"><a href="Torch.Typed.Functional.html#celu"><span class="hs-identifier hs-type">celu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-3930"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708639"><span class="annot"><a href="#local-6989586621679708639"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708638"><span class="annot"><a href="#local-6989586621679708638"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708637"><span class="annot"><a href="#local-6989586621679708637"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-3931"></span><span>  </span><span class="hs-comment">-- | alpha</span><span>
</span><span id="line-3932"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3933"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-3934"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708637"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708638"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708639"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-3935"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-3936"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708637"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708638"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708639"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-3937"></span><span id="celu"><span class="annot"><span class="annottext">celu :: Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#celu"><span class="hs-identifier hs-var hs-var">celu</span></a></span></span><span> </span><span id="local-6989586621679708636"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708636"><span class="hs-identifier hs-var">alpha</span></a></span></span><span> </span><span id="local-6989586621679708635"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708635"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Float
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.celu_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708635"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708636"><span class="hs-identifier hs-var">alpha</span></a></span><span>
</span><span id="line-3938"></span><span>
</span><span id="line-3939"></span><span class="hs-comment">-- slice :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3940"></span><span class="hs-comment">-- slice _input _dim _start _end _step = unsafePerformIO $ (ATen.cast5 ATen.Managed.slice_tllll) _input _dim _start _end _step</span><span>
</span><span id="line-3941"></span><span>
</span><span id="line-3942"></span><span class="hs-comment">-- slogdet :: Tensor device dtype shape -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-3943"></span><span class="hs-comment">-- slogdet _input = unsafePerformIO $ (ATen.cast1 ATen.Managed.slogdet_t) _input</span><span>
</span><span id="line-3944"></span><span>
</span><span id="line-3945"></span><span class="hs-comment">-- smm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3946"></span><span class="hs-comment">-- smm _input _mat2 = unsafePerformIO $ (ATen.cast2 ATen.Managed.smm_tt) _input _mat2</span><span>
</span><span id="line-3947"></span><span>
</span><span id="line-3948"></span><span class="hs-comment">-- split :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; [Tensor device dtype shape]</span><span>
</span><span id="line-3949"></span><span class="hs-comment">-- split _input _split_size _dim = unsafePerformIO $ (ATen.cast3 ATen.Managed.split_tll) _input _split_size _dim</span><span>
</span><span id="line-3950"></span><span>
</span><span id="line-3951"></span><span class="hs-comment">-- split_with_sizes :: Tensor device dtype shape -&gt; [Int] -&gt; Int -&gt; [Tensor device dtype shape]</span><span>
</span><span id="line-3952"></span><span class="hs-comment">-- split_with_sizes _input _split_sizes _dim = unsafePerformIO $ (ATen.cast3 ATen.Managed.split_with_sizes_tll) _input _split_sizes _dim</span><span>
</span><span id="line-3953"></span><span>
</span><span id="line-3954"></span><span class="hs-comment">-- sspaddmm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-3955"></span><span class="hs-comment">-- sspaddmm _input _mat1 _mat2 _beta _alpha = unsafePerformIO $ (ATen.cast5 ATen.Managed.sspaddmm_tttss) _input _mat1 _mat2 _beta _alpha</span><span>
</span><span id="line-3956"></span><span>
</span><span id="line-3957"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="StackImpl"><span class="annot"><a href="Torch.Typed.Functional.html#StackImpl"><span class="hs-identifier hs-var">StackImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708632"><span class="annot"><a href="#local-6989586621679708632"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708631"><span class="annot"><a href="#local-6989586621679708631"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708630"><span class="annot"><a href="#local-6989586621679708630"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708629"><span class="annot"><a href="#local-6989586621679708629"><span class="hs-identifier hs-type">count</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3958"></span><span>  </span><span id="StackImpl"><span class="annot"><a href="Torch.Typed.Functional.html#StackImpl"><span class="hs-identifier hs-var">StackImpl</span></a></span></span><span> </span><span id="local-6989586621679708628"><span class="annot"><a href="#local-6989586621679708628"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679708627"><span class="annot"><a href="#local-6989586621679708627"><span class="hs-identifier hs-type hs-type">count</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3959"></span><span>  </span><span id="StackImpl"><span class="annot"><a href="Torch.Typed.Functional.html#StackImpl"><span class="hs-identifier hs-var">StackImpl</span></a></span></span><span> </span><span id="local-6989586621679708626"><span class="annot"><a href="#local-6989586621679708626"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679708625"><span class="annot"><a href="#local-6989586621679708625"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679708624"><span class="annot"><a href="#local-6989586621679708624"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708623"><span class="annot"><a href="#local-6989586621679708623"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708622"><span class="annot"><a href="#local-6989586621679708622"><span class="hs-identifier hs-type hs-type">count</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-type">MaybeTriple</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeStackShape"><span class="hs-identifier hs-type">ComputeStackShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708623"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708626"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708622"><span class="hs-identifier hs-type">count</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679708624"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679708625"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3960"></span><span>  </span><span id="StackImpl"><span class="annot"><a href="Torch.Typed.Functional.html#StackImpl"><span class="hs-identifier hs-var">StackImpl</span></a></span></span><span> </span><span id="local-6989586621679708620"><span class="annot"><a href="#local-6989586621679708620"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679708619"><span class="annot"><a href="#local-6989586621679708619"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679708618"><span class="annot"><a href="#local-6989586621679708618"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708617"><span class="annot"><a href="#local-6989586621679708617"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708619"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708618"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708617"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708616"><span class="annot"><a href="#local-6989586621679708616"><span class="hs-identifier hs-type hs-type">tensors</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708615"><span class="annot"><a href="#local-6989586621679708615"><span class="hs-identifier hs-type hs-type">count</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#StackImpl"><span class="hs-identifier hs-type">StackImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708620"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708619"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708618"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708617"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708616"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708615"><span class="hs-identifier hs-type">count</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-3961"></span><span>  </span><span id="StackImpl"><span class="annot"><a href="Torch.Typed.Functional.html#StackImpl"><span class="hs-identifier hs-var">StackImpl</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3962"></span><span>
</span><span id="line-3963"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MaybePair"><span class="annot"><a href="Torch.Typed.Functional.html#MaybePair"><span class="hs-identifier hs-var">MaybePair</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708613"><span class="annot"><a href="#local-6989586621679708613"><span class="hs-identifier hs-type">a'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679708612"><span class="annot"><a href="#local-6989586621679708612"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708611"><span class="annot"><a href="#local-6989586621679708611"><span class="hs-identifier hs-type">b'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679708610"><span class="annot"><a href="#local-6989586621679708610"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708612"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708610"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3964"></span><span>  </span><span id="MaybePair"><span class="annot"><a href="Torch.Typed.Functional.html#MaybePair"><span class="hs-identifier hs-var">MaybePair</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3965"></span><span>  </span><span id="MaybePair"><span class="annot"><a href="Torch.Typed.Functional.html#MaybePair"><span class="hs-identifier hs-var">MaybePair</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3966"></span><span>  </span><span id="MaybePair"><span class="annot"><a href="Torch.Typed.Functional.html#MaybePair"><span class="hs-identifier hs-var">MaybePair</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708609"><span class="annot"><a href="#local-6989586621679708609"><span class="hs-identifier hs-type hs-type">a'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708608"><span class="annot"><a href="#local-6989586621679708608"><span class="hs-identifier hs-type hs-type">b'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708609"><span class="hs-identifier hs-type">a'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708608"><span class="hs-identifier hs-type">b'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3967"></span><span>
</span><span id="line-3968"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MaybeTriple"><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-var">MaybeTriple</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708607"><span class="annot"><a href="#local-6989586621679708607"><span class="hs-identifier hs-type">a'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679708606"><span class="annot"><a href="#local-6989586621679708606"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708605"><span class="annot"><a href="#local-6989586621679708605"><span class="hs-identifier hs-type">b'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679708604"><span class="annot"><a href="#local-6989586621679708604"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708603"><span class="annot"><a href="#local-6989586621679708603"><span class="hs-identifier hs-type">c'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679708602"><span class="annot"><a href="#local-6989586621679708602"><span class="hs-identifier hs-type hs-type">c</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708606"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708604"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708602"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3969"></span><span>  </span><span id="MaybeTriple"><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-var">MaybeTriple</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3970"></span><span>  </span><span id="MaybeTriple"><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-var">MaybeTriple</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3971"></span><span>  </span><span id="MaybeTriple"><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-var">MaybeTriple</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3972"></span><span>  </span><span id="MaybeTriple"><span class="annot"><a href="Torch.Typed.Functional.html#MaybeTriple"><span class="hs-identifier hs-var">MaybeTriple</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708601"><span class="annot"><a href="#local-6989586621679708601"><span class="hs-identifier hs-type hs-type">a'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708600"><span class="annot"><a href="#local-6989586621679708600"><span class="hs-identifier hs-type hs-type">b'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708599"><span class="annot"><a href="#local-6989586621679708599"><span class="hs-identifier hs-type hs-type">c'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708601"><span class="hs-identifier hs-type">a'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708600"><span class="hs-identifier hs-type">b'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708599"><span class="hs-identifier hs-type">c'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3973"></span><span>
</span><span id="line-3974"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="ComputeStackShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeStackShape"><span class="hs-identifier hs-var">ComputeStackShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708598"><span class="annot"><a href="#local-6989586621679708598"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708597"><span class="annot"><a href="#local-6989586621679708597"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708596"><span class="annot"><a href="#local-6989586621679708596"><span class="hs-identifier hs-type">count</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3975"></span><span>  </span><span id="ComputeStackShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeStackShape"><span class="hs-identifier hs-var">ComputeStackShape</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3976"></span><span>  </span><span id="ComputeStackShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeStackShape"><span class="hs-identifier hs-var">ComputeStackShape</span></a></span></span><span> </span><span id="local-6989586621679708595"><span class="annot"><a href="#local-6989586621679708595"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span id="local-6989586621679708594"><span class="annot"><a href="#local-6989586621679708594"><span class="hs-identifier hs-type hs-type">count</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708594"><span class="hs-identifier hs-type">count</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708595"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3977"></span><span>  </span><span id="ComputeStackShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeStackShape"><span class="hs-identifier hs-var">ComputeStackShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708593"><span class="annot"><a href="#local-6989586621679708593"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708592"><span class="annot"><a href="#local-6989586621679708592"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708591"><span class="annot"><a href="#local-6989586621679708591"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708590"><span class="annot"><a href="#local-6989586621679708590"><span class="hs-identifier hs-type hs-type">count</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe"><span class="hs-identifier hs-type">AppendToMaybe</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708593"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ComputeStackShape"><span class="hs-identifier hs-type">ComputeStackShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708592"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708591"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708590"><span class="hs-identifier hs-type">count</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3978"></span><span>  </span><span id="ComputeStackShape"><span class="annot"><a href="Torch.Typed.Functional.html#ComputeStackShape"><span class="hs-identifier hs-var">ComputeStackShape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-3979"></span><span>
</span><span id="line-3980"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="StackCheck"><span class="annot"><a href="Torch.Typed.Functional.html#StackCheck"><span class="hs-identifier hs-var">StackCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708588"><span class="annot"><a href="#local-6989586621679708588"><span class="hs-identifier hs-type">res</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-3981"></span><span>  </span><span id="StackCheck"><span class="annot"><a href="Torch.Typed.Functional.html#StackCheck"><span class="hs-identifier hs-var">StackCheck</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Stacking impossible.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-3982"></span><span>  </span><span id="StackCheck"><span class="annot"><a href="Torch.Typed.Functional.html#StackCheck"><span class="hs-identifier hs-var">StackCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span id="local-6989586621679708587"><span class="annot"><a href="#local-6989586621679708587"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679708586"><span class="annot"><a href="#local-6989586621679708586"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679708585"><span class="annot"><a href="#local-6989586621679708585"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708587"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708586"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708585"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-3983"></span><span>
</span><span id="line-3984"></span><span class="hs-comment">-- | Stack</span><span>
</span><span id="line-3985"></span><span class="hs-comment">--</span><span>
</span><span id="line-3986"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Stack 0 '[Tensor '( 'D.CPU, 0) 'D.Float '[]]</span><span>
</span><span id="line-3987"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-3988"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-3989"></span><span class="hs-comment">-- = '( '[1], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-3990"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Stack 0 '[Tensor '( 'D.CPU, 0) 'D.Float '[2,2]]</span><span>
</span><span id="line-3991"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-3992"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-3993"></span><span class="hs-comment">-- = '( '[1, 2, 2], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-3994"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Stack 1 '[Tensor '( 'D.CPU, 0) 'D.Float '[2,2]]</span><span>
</span><span id="line-3995"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-3996"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-3997"></span><span class="hs-comment">-- = '( '[2, 1, 2], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-3998"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Stack 2 '[Tensor '( 'D.CPU, 0) 'D.Float '[2,2]]</span><span>
</span><span id="line-3999"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-4000"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-4001"></span><span class="hs-comment">-- = '( '[2, 2, 1], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-4002"></span><span class="hs-comment">-- &gt;&gt;&gt; type Ty = Stack 2 '[Tensor '( 'D.CPU, 0) 'D.Float '[2,2], Tensor '( 'D.CPU, 0) 'D.Float '[2,2], Tensor '( 'D.CPU, 0) 'D.Float '[2,2]]</span><span>
</span><span id="line-4003"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! Ty</span><span>
</span><span id="line-4004"></span><span class="hs-comment">-- Ty :: ([Nat], D.DType, (D.DeviceType, Nat))</span><span>
</span><span id="line-4005"></span><span class="hs-comment">-- = '( '[2, 2, 3], 'D.Float, '( 'D.CPU, 0))</span><span>
</span><span id="line-4006"></span><span class="hs-keyword">type</span><span> </span><span id="Stack"><span class="annot"><a href="Torch.Typed.Functional.html#Stack"><span class="hs-identifier hs-var">Stack</span></a></span></span><span> </span><span id="local-6989586621679708583"><span class="annot"><a href="#local-6989586621679708583"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708582"><span class="annot"><a href="#local-6989586621679708582"><span class="hs-identifier hs-type">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#StackCheck"><span class="hs-identifier hs-type">StackCheck</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#StackImpl"><span class="hs-identifier hs-type">StackImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708583"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708582"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-4007"></span><span>
</span><span id="line-4008"></span><span class="hs-comment">-- | stack</span><span>
</span><span id="line-4009"></span><span class="hs-comment">--</span><span>
</span><span id="line-4010"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[]</span><span>
</span><span id="line-4011"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = stack @0 (t :. HNil)</span><span>
</span><span id="line-4012"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-4013"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[1]</span><span>
</span><span id="line-4014"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [Float]) $ t'</span><span>
</span><span id="line-4015"></span><span class="hs-comment">-- (Float,([1],[1.0]))</span><span>
</span><span id="line-4016"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[2,2]</span><span>
</span><span id="line-4017"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = stack @0 (t :. HNil)</span><span>
</span><span id="line-4018"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-4019"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 2, 2]</span><span>
</span><span id="line-4020"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[[Float]]]) $ t'</span><span>
</span><span id="line-4021"></span><span class="hs-comment">-- (Float,([1,2,2],[[[1.0,1.0],[1.0,1.0]]]))</span><span>
</span><span id="line-4022"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = stack @1 (t :. HNil)</span><span>
</span><span id="line-4023"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-4024"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 1, 2]</span><span>
</span><span id="line-4025"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[[Float]]]) $ t'</span><span>
</span><span id="line-4026"></span><span class="hs-comment">-- (Float,([2,1,2],[[[1.0,1.0]],[[1.0,1.0]]]))</span><span>
</span><span id="line-4027"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = stack @2 (t :. HNil)</span><span>
</span><span id="line-4028"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-4029"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 2, 1]</span><span>
</span><span id="line-4030"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[[Float]]]) $ t'</span><span>
</span><span id="line-4031"></span><span class="hs-comment">-- (Float,([2,2,1],[[[1.0],[1.0]],[[1.0],[1.0]]]))</span><span>
</span><span id="line-4032"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = stack @2 (t :. t :. t :. HNil)</span><span>
</span><span id="line-4033"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-4034"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Float '[2, 2, 3]</span><span>
</span><span id="line-4035"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t'' -&gt; D.asValue (toDynamic t'') :: [[[Float]]]) $ t'</span><span>
</span><span id="line-4036"></span><span class="hs-comment">-- (Float,([2,2,3],[[[1.0,1.0,1.0],[1.0,1.0,1.0]],[[1.0,1.0,1.0],[1.0,1.0,1.0]]]))</span><span>
</span><span id="line-4037"></span><span class="annot"><a href="Torch.Typed.Functional.html#stack"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4038"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708580"><span class="annot"><a href="#local-6989586621679708580"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708579"><span class="annot"><a href="#local-6989586621679708579"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708578"><span class="annot"><a href="#local-6989586621679708578"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708577"><span class="annot"><a href="#local-6989586621679708577"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679708576"><span class="annot"><a href="#local-6989586621679708576"><span class="hs-identifier hs-type">tensors</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4039"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708580"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4040"></span><span>    </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708579"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708578"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708577"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Stack"><span class="hs-identifier hs-type">Stack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708580"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708576"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4041"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708576"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4042"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4043"></span><span>  </span><span class="hs-comment">-- | input list of tensors</span><span>
</span><span id="line-4044"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708576"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4045"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4046"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708577"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708578"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708579"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4047"></span><span id="stack"><span class="annot"><span class="annottext">stack :: HList tensors -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#stack"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span id="local-6989586621679708575"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679708575"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; HList tensors -&gt; Int -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.stack_ll</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679708575"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708580"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-4048"></span><span>
</span><span id="line-4049"></span><span class="hs-comment">-- stft :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Int -&gt; Tensor device dtype shape -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4050"></span><span class="hs-comment">-- stft _input _n_fft _hop_length _win_length _window _normalized _onesided = unsafePerformIO $ (ATen.cast7 ATen.Managed.stft_tllltbb) _input _n_fft _hop_length _win_length _window _normalized _onesided</span><span>
</span><span id="line-4051"></span><span>
</span><span id="line-4052"></span><span class="hs-comment">-- stride :: Tensor device dtype shape -&gt; Int -&gt; Int</span><span>
</span><span id="line-4053"></span><span class="hs-comment">-- stride _input _dim = unsafePerformIO $ (ATen.cast2 ATen.Managed.stride_tl) _input _dim</span><span>
</span><span id="line-4054"></span><span>
</span><span id="line-4055"></span><span class="hs-comment">-- | t</span><span>
</span><span id="line-4056"></span><span class="hs-comment">--</span><span>
</span><span id="line-4057"></span><span class="hs-comment">-- dtype &amp;&amp;&amp; shape $ t ones :: CPUTensor 'D.Float '[3,2]</span><span>
</span><span id="line-4058"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4059"></span><span class="annot"><a href="Torch.Typed.Functional.html#t"><span class="hs-identifier hs-type">t</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4060"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708572"><span class="annot"><a href="#local-6989586621679708572"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708571"><span class="annot"><a href="#local-6989586621679708571"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708570"><span class="annot"><a href="#local-6989586621679708570"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4061"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4062"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708570"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708571"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708572"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4063"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4064"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708570"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708571"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708572"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4065"></span><span id="t"><span class="annot"><span class="annottext">t :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#t"><span class="hs-identifier hs-var hs-var">t</span></a></span></span><span> </span><span id="local-6989586621679708569"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708569"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.t_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708569"><span class="hs-identifier hs-var">_input</span></a></span><span>
</span><span id="line-4066"></span><span>
</span><span id="line-4067"></span><span class="hs-comment">-- | tan</span><span>
</span><span id="line-4068"></span><span class="hs-comment">--</span><span>
</span><span id="line-4069"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ tan (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4070"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4071"></span><span class="annot"><a href="Torch.Typed.Functional.html#tan"><span class="hs-identifier hs-type">tan</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4072"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708566"><span class="annot"><a href="#local-6989586621679708566"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708565"><span class="annot"><a href="#local-6989586621679708565"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708564"><span class="annot"><a href="#local-6989586621679708564"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4073"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708564"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708565"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4074"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4075"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708564"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708565"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708566"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4076"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4077"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708564"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708565"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708566"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4078"></span><span id="tan"><span class="annot"><span class="annottext">tan :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#tan"><span class="hs-identifier hs-var hs-var">tan</span></a></span></span><span> </span><span id="local-6989586621679708563"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708563"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.tan_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708563"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4079"></span><span>
</span><span id="line-4080"></span><span class="hs-comment">-- tensordot :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; [Int] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4081"></span><span class="hs-comment">-- tensordot _input _other _dims_input _dims_other = unsafePerformIO $ (ATen.cast4 ATen.Managed.tensordot_ttll) _input _other _dims_input _dims_other</span><span>
</span><span id="line-4082"></span><span>
</span><span id="line-4083"></span><span class="hs-comment">-- threshold :: Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4084"></span><span class="hs-comment">-- threshold _input _threshold _value = unsafePerformIO $ (ATen.cast3 ATen.Managed.threshold_tss) _input _threshold _value</span><span>
</span><span id="line-4085"></span><span>
</span><span id="line-4086"></span><span class="hs-comment">-- one_hot :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4087"></span><span class="hs-comment">-- one_hot _input _num_classes = unsafePerformIO $ (ATen.cast2 ATen.Managed.one_hot_tl) _input _num_classes</span><span>
</span><span id="line-4088"></span><span>
</span><span id="line-4089"></span><span class="hs-comment">-- flip :: Tensor device dtype shape -&gt; [Int] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4090"></span><span class="hs-comment">-- flip _input _dims = unsafePerformIO $ (ATen.cast2 ATen.Managed.flip_tl) _input _dims</span><span>
</span><span id="line-4091"></span><span>
</span><span id="line-4092"></span><span class="hs-comment">-- roll :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4093"></span><span class="hs-comment">-- roll _input _shifts _dims = unsafePerformIO $ (ATen.cast3 ATen.Managed.roll_tll) _input _shifts _dims</span><span>
</span><span id="line-4094"></span><span>
</span><span id="line-4095"></span><span class="hs-comment">-- rot90 :: Tensor device dtype shape -&gt; Int -&gt; [Int] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4096"></span><span class="hs-comment">-- rot90 _input _k _dims = unsafePerformIO $ (ATen.cast3 ATen.Managed.rot90_tll) _input _k _dims</span><span>
</span><span id="line-4097"></span><span>
</span><span id="line-4098"></span><span class="hs-comment">-- triplet_margin_loss :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Double -&gt; Double -&gt; Double -&gt; Bool -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4099"></span><span class="hs-comment">-- triplet_margin_loss _anchor _positive _negative _margin _p _eps _swap _reduction = unsafePerformIO $ (ATen.cast8 ATen.Managed.triplet_margin_loss_tttdddbl) _anchor _positive _negative _margin _p _eps _swap _reduction</span><span>
</span><span id="line-4100"></span><span>
</span><span id="line-4101"></span><span class="hs-comment">-- | trunc</span><span>
</span><span id="line-4102"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-4103"></span><span class="hs-comment">--</span><span>
</span><span id="line-4104"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ trunc (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4105"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4106"></span><span class="annot"><a href="Torch.Typed.Functional.html#trunc"><span class="hs-identifier hs-type">trunc</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4107"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708560"><span class="annot"><a href="#local-6989586621679708560"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708559"><span class="annot"><a href="#local-6989586621679708559"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708558"><span class="annot"><a href="#local-6989586621679708558"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4108"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708558"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708559"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4109"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4110"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708558"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708559"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708560"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4111"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4112"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708558"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708559"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708560"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4113"></span><span id="trunc"><span class="annot"><span class="annottext">trunc :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#trunc"><span class="hs-identifier hs-var hs-var">trunc</span></a></span></span><span> </span><span id="local-6989586621679708557"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708557"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.trunc_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708557"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4114"></span><span>
</span><span id="line-4115"></span><span class="hs-comment">-- unique_dim :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Bool -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4116"></span><span class="hs-comment">-- unique_dim _input _dim _sorted _return_inverse _return_counts = unsafePerformIO $ (ATen.cast5 ATen.Managed.unique_dim_tlbbb) _input _dim _sorted _return_inverse _return_counts</span><span>
</span><span id="line-4117"></span><span>
</span><span id="line-4118"></span><span class="hs-comment">-- unique_consecutive :: Tensor device dtype shape -&gt; Bool -&gt; Bool -&gt; Int -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4119"></span><span class="hs-comment">-- unique_consecutive _input _return_inverse _return_counts _dim = unsafePerformIO $ (ATen.cast4 ATen.Managed.unique_consecutive_tbbl) _input _return_inverse _return_counts _dim</span><span>
</span><span id="line-4120"></span><span>
</span><span id="line-4121"></span><span class="hs-comment">-- unique_dim_consecutive :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4122"></span><span class="hs-comment">-- unique_dim_consecutive _input _dim _return_inverse _return_counts = unsafePerformIO $ (ATen.cast4 ATen.Managed.unique_dim_consecutive_tlbb) _input _dim _return_inverse _return_counts</span><span>
</span><span id="line-4123"></span><span>
</span><span id="line-4124"></span><span class="hs-comment">-- | UnsqueezeImpl</span><span>
</span><span id="line-4125"></span><span class="hs-comment">--</span><span>
</span><span id="line-4126"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! UnsqueezeImpl '[4] 0</span><span>
</span><span id="line-4127"></span><span class="hs-comment">-- UnsqueezeImpl '[4] 0 :: Maybe [Nat]</span><span>
</span><span id="line-4128"></span><span class="hs-comment">-- = 'Just '[1, 4]</span><span>
</span><span id="line-4129"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! UnsqueezeImpl '[4] 1</span><span>
</span><span id="line-4130"></span><span class="hs-comment">-- UnsqueezeImpl '[4] 1 :: Maybe [Nat]</span><span>
</span><span id="line-4131"></span><span class="hs-comment">-- = 'Just '[4, 1]</span><span>
</span><span id="line-4132"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! UnsqueezeImpl '[4] 2</span><span>
</span><span id="line-4133"></span><span class="hs-comment">-- UnsqueezeImpl '[4] 2 :: Maybe [Nat]</span><span>
</span><span id="line-4134"></span><span class="hs-comment">-- = 'Nothing</span><span>
</span><span id="line-4135"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="UnsqueezeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeImpl"><span class="hs-identifier hs-var">UnsqueezeImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708554"><span class="annot"><a href="#local-6989586621679708554"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708553"><span class="annot"><a href="#local-6989586621679708553"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708552"><span class="annot"><a href="#local-6989586621679708552"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708553"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4136"></span><span>  </span><span id="UnsqueezeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeImpl"><span class="hs-identifier hs-var">UnsqueezeImpl</span></a></span></span><span> </span><span id="local-6989586621679708551"><span class="annot"><a href="#local-6989586621679708551"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708551"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4137"></span><span>  </span><span id="UnsqueezeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeImpl"><span class="hs-identifier hs-var">UnsqueezeImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708550"><span class="annot"><a href="#local-6989586621679708550"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708549"><span class="annot"><a href="#local-6989586621679708549"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708548"><span class="annot"><a href="#local-6989586621679708548"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe"><span class="hs-identifier hs-type">AppendToMaybe</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708550"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeImpl"><span class="hs-identifier hs-type">UnsqueezeImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708549"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708548"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-4138"></span><span>  </span><span id="UnsqueezeImpl"><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeImpl"><span class="hs-identifier hs-var">UnsqueezeImpl</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-4139"></span><span>
</span><span id="line-4140"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="UnsqueezeCheck"><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeCheck"><span class="hs-identifier hs-var">UnsqueezeCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708546"><span class="annot"><a href="#local-6989586621679708546"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708545"><span class="annot"><a href="#local-6989586621679708545"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708544"><span class="annot"><a href="#local-6989586621679708544"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708543"><span class="annot"><a href="#local-6989586621679708543"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708545"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708545"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4141"></span><span>  </span><span id="UnsqueezeCheck"><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeCheck"><span class="hs-identifier hs-var">UnsqueezeCheck</span></a></span></span><span> </span><span id="local-6989586621679708542"><span class="annot"><a href="#local-6989586621679708542"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708541"><span class="annot"><a href="#local-6989586621679708541"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4142"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-4143"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Cannot unsqueeze the tensor since the specified dimension &quot;</span></span><span>
</span><span id="line-4144"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708541"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-4145"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot; is too large (the tensor is only &quot;</span></span><span>
</span><span id="line-4146"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#ListLength"><span class="hs-identifier hs-type">ListLength</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708542"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4147"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;D)&quot;</span></span><span>
</span><span id="line-4148"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-4149"></span><span>  </span><span id="UnsqueezeCheck"><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeCheck"><span class="hs-identifier hs-var">UnsqueezeCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708540"><span class="annot"><a href="#local-6989586621679708540"><span class="hs-identifier hs-type hs-type">shape'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679708540"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4150"></span><span>
</span><span id="line-4151"></span><span class="hs-keyword">type</span><span> </span><span id="Unsqueeze"><span class="annot"><a href="Torch.Typed.Functional.html#Unsqueeze"><span class="hs-identifier hs-var">Unsqueeze</span></a></span></span><span> </span><span id="local-6989586621679708538"><span class="annot"><a href="#local-6989586621679708538"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708537"><span class="annot"><a href="#local-6989586621679708537"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeCheck"><span class="hs-identifier hs-type">UnsqueezeCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708538"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708537"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#UnsqueezeImpl"><span class="hs-identifier hs-type">UnsqueezeImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708538"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708537"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4152"></span><span>
</span><span id="line-4153"></span><span class="hs-comment">-- | unsqueeze</span><span>
</span><span id="line-4154"></span><span class="hs-comment">--</span><span>
</span><span id="line-4155"></span><span class="hs-comment">-- &gt;&gt;&gt; t = fromJust [1, 2, 3, 4] :: CPUTensor 'D.Int64 '[4]</span><span>
</span><span id="line-4156"></span><span class="hs-comment">-- &gt;&gt;&gt; t' = unsqueeze @0 t</span><span>
</span><span id="line-4157"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-4158"></span><span class="hs-comment">-- t' :: Tensor '( 'D.CPU, 0) 'D.Int64 '[1, 4]</span><span>
</span><span id="line-4159"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\u -&gt; D.asValue (toDynamic u) :: [[Int]]) $ t'</span><span>
</span><span id="line-4160"></span><span class="hs-comment">-- (Int64,([1,4],[[1,2,3,4]]))</span><span>
</span><span id="line-4161"></span><span class="hs-comment">-- &gt;&gt;&gt; t'' = unsqueeze @1 t</span><span>
</span><span id="line-4162"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t''</span><span>
</span><span id="line-4163"></span><span class="hs-comment">-- t'' :: Tensor '( 'D.CPU, 0) 'D.Int64 '[4, 1]</span><span>
</span><span id="line-4164"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\u -&gt; D.asValue (toDynamic u) :: [[Int]]) $ t''</span><span>
</span><span id="line-4165"></span><span class="hs-comment">-- (Int64,([4,1],[[1],[2],[3],[4]]))</span><span>
</span><span id="line-4166"></span><span class="annot"><a href="Torch.Typed.Functional.html#unsqueeze"><span class="hs-identifier hs-type">unsqueeze</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4167"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708535"><span class="annot"><a href="#local-6989586621679708535"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708534"><span class="annot"><a href="#local-6989586621679708534"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708533"><span class="annot"><a href="#local-6989586621679708533"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708532"><span class="annot"><a href="#local-6989586621679708532"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708531"><span class="annot"><a href="#local-6989586621679708531"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4168"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708535"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708533"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Unsqueeze"><span class="hs-identifier hs-type">Unsqueeze</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708534"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708535"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4169"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4170"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708531"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708532"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708534"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4171"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4172"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708531"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708532"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708533"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4173"></span><span id="unsqueeze"><span class="annot"><span class="annottext">unsqueeze :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#unsqueeze"><span class="hs-identifier hs-var hs-var">unsqueeze</span></a></span></span><span> </span><span id="local-6989586621679708530"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708530"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.unsqueeze_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708530"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708535"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4174"></span><span>
</span><span id="line-4175"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SqueezeAll"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeAll"><span class="hs-identifier hs-var">SqueezeAll</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708527"><span class="annot"><a href="#local-6989586621679708527"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4176"></span><span>  </span><span id="SqueezeAll"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeAll"><span class="hs-identifier hs-var">SqueezeAll</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-4177"></span><span>  </span><span id="SqueezeAll"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeAll"><span class="hs-identifier hs-var">SqueezeAll</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708526"><span class="annot"><a href="#local-6989586621679708526"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeAll"><span class="hs-identifier hs-type">SqueezeAll</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708526"><span class="hs-identifier hs-type">xs</span></a></span><span>
</span><span id="line-4178"></span><span>  </span><span id="SqueezeAll"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeAll"><span class="hs-identifier hs-var">SqueezeAll</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708525"><span class="annot"><a href="#local-6989586621679708525"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708524"><span class="annot"><a href="#local-6989586621679708524"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679708525"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeAll"><span class="hs-identifier hs-type">SqueezeAll</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708524"><span class="hs-identifier hs-type">xs</span></a></span><span>
</span><span id="line-4179"></span><span>
</span><span id="line-4180"></span><span class="hs-comment">-- | squeeze all dimensions</span><span>
</span><span id="line-4181"></span><span class="hs-comment">--</span><span>
</span><span id="line-4182"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ squeezeAll (ones :: CPUTensor 'D.Float '[2,1,2,1,2])</span><span>
</span><span id="line-4183"></span><span class="hs-comment">-- (Float,[2,2,2])</span><span>
</span><span id="line-4184"></span><span class="hs-comment">-- &gt;&gt;&gt; squeezeAll (ones :: CPUTensor 'D.Float '[2,1,2,1,2])</span><span>
</span><span id="line-4185"></span><span class="hs-comment">-- Tensor Float [2,2,2] [[[ 1.0000   ,  1.0000   ],</span><span>
</span><span id="line-4186"></span><span class="hs-comment">--                        [ 1.0000   ,  1.0000   ]],</span><span>
</span><span id="line-4187"></span><span class="hs-comment">--                       [[ 1.0000   ,  1.0000   ],</span><span>
</span><span id="line-4188"></span><span class="hs-comment">--                        [ 1.0000   ,  1.0000   ]]]</span><span>
</span><span id="line-4189"></span><span class="annot"><a href="Torch.Typed.Functional.html#squeezeAll"><span class="hs-identifier hs-type">squeezeAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4190"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708522"><span class="annot"><a href="#local-6989586621679708522"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708521"><span class="annot"><a href="#local-6989586621679708521"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708520"><span class="annot"><a href="#local-6989586621679708520"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708519"><span class="annot"><a href="#local-6989586621679708519"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4191"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708521"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeAll"><span class="hs-identifier hs-type">SqueezeAll</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708522"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4192"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4193"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708519"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708520"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708522"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4194"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4195"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708519"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708520"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708521"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4196"></span><span id="squeezeAll"><span class="annot"><span class="annottext">squeezeAll :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#squeezeAll"><span class="hs-identifier hs-var hs-var">squeezeAll</span></a></span></span><span> </span><span id="local-6989586621679708518"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708518"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape')
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.squeeze_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708518"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4197"></span><span>
</span><span id="line-4198"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SqueezeDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimImpl"><span class="hs-identifier hs-var">SqueezeDimImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708515"><span class="annot"><a href="#local-6989586621679708515"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708514"><span class="annot"><a href="#local-6989586621679708514"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708513"><span class="annot"><a href="#local-6989586621679708513"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708514"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4199"></span><span>  </span><span id="SqueezeDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimImpl"><span class="hs-identifier hs-var">SqueezeDimImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708512"><span class="annot"><a href="#local-6989586621679708512"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679708512"><span class="hs-identifier hs-type">xs</span></a></span><span>
</span><span id="line-4200"></span><span>  </span><span id="SqueezeDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimImpl"><span class="hs-identifier hs-var">SqueezeDimImpl</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-4201"></span><span>  </span><span id="SqueezeDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimImpl"><span class="hs-identifier hs-var">SqueezeDimImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708511"><span class="annot"><a href="#local-6989586621679708511"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708510"><span class="annot"><a href="#local-6989586621679708510"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708509"><span class="annot"><a href="#local-6989586621679708509"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe"><span class="hs-identifier hs-type">AppendToMaybe</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708511"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimImpl"><span class="hs-identifier hs-type">SqueezeDimImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708510"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708509"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-4202"></span><span>  </span><span id="SqueezeDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimImpl"><span class="hs-identifier hs-var">SqueezeDimImpl</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-4203"></span><span>
</span><span id="line-4204"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="SqueezeDimCheck"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimCheck"><span class="hs-identifier hs-var">SqueezeDimCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708507"><span class="annot"><a href="#local-6989586621679708507"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708506"><span class="annot"><a href="#local-6989586621679708506"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708505"><span class="annot"><a href="#local-6989586621679708505"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708504"><span class="annot"><a href="#local-6989586621679708504"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708506"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708506"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4205"></span><span>  </span><span id="SqueezeDimCheck"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimCheck"><span class="hs-identifier hs-var">SqueezeDimCheck</span></a></span></span><span> </span><span id="local-6989586621679708503"><span class="annot"><a href="#local-6989586621679708503"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708502"><span class="annot"><a href="#local-6989586621679708502"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;The tensor cannot be squeezed at the specified dimension &quot;</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708502"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4206"></span><span>  </span><span id="SqueezeDimCheck"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimCheck"><span class="hs-identifier hs-var">SqueezeDimCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708501"><span class="annot"><a href="#local-6989586621679708501"><span class="hs-identifier hs-type hs-type">shape'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679708501"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4207"></span><span>
</span><span id="line-4208"></span><span class="hs-comment">-- | Calculate the output shape of a squeeze along a given dimension</span><span>
</span><span id="line-4209"></span><span class="hs-comment">--</span><span>
</span><span id="line-4210"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! SqueezeDim '[2,1,2] 1</span><span>
</span><span id="line-4211"></span><span class="hs-comment">-- SqueezeDim '[2,1,2] 1 :: [Nat]</span><span>
</span><span id="line-4212"></span><span class="hs-comment">-- = '[2, 2]</span><span>
</span><span id="line-4213"></span><span class="hs-keyword">type</span><span> </span><span id="SqueezeDim"><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDim"><span class="hs-identifier hs-var">SqueezeDim</span></a></span></span><span> </span><span id="local-6989586621679708499"><span class="annot"><a href="#local-6989586621679708499"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708498"><span class="annot"><a href="#local-6989586621679708498"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimCheck"><span class="hs-identifier hs-type">SqueezeDimCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708499"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708498"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDimImpl"><span class="hs-identifier hs-type">SqueezeDimImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708499"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708498"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4214"></span><span>
</span><span id="line-4215"></span><span class="hs-comment">-- | squeeze a particular dimension</span><span>
</span><span id="line-4216"></span><span class="hs-comment">--</span><span>
</span><span id="line-4217"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ squeezeDim @1 (ones :: CPUTensor 'D.Float '[2,1,2,1,2])</span><span>
</span><span id="line-4218"></span><span class="hs-comment">-- (Float,[2,2,1,2])</span><span>
</span><span id="line-4219"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ squeezeDim @3 (ones :: CPUTensor 'D.Float '[2,1,2,1,2])</span><span>
</span><span id="line-4220"></span><span class="hs-comment">-- (Float,[2,1,2,2])</span><span>
</span><span id="line-4221"></span><span class="annot"><a href="Torch.Typed.Functional.html#squeezeDim"><span class="hs-identifier hs-type">squeezeDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4222"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708496"><span class="annot"><a href="#local-6989586621679708496"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708495"><span class="annot"><a href="#local-6989586621679708495"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708494"><span class="annot"><a href="#local-6989586621679708494"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708493"><span class="annot"><a href="#local-6989586621679708493"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708492"><span class="annot"><a href="#local-6989586621679708492"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4223"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708496"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708494"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SqueezeDim"><span class="hs-identifier hs-type">SqueezeDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708495"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708496"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4224"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4225"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708492"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708493"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708495"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4226"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4227"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708492"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708493"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708494"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4228"></span><span id="squeezeDim"><span class="annot"><span class="annottext">squeezeDim :: Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#squeezeDim"><span class="hs-identifier hs-var hs-var">squeezeDim</span></a></span></span><span> </span><span id="local-6989586621679708491"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708491"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.squeeze_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708491"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708496"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4229"></span><span>
</span><span id="line-4230"></span><span class="hs-comment">-- where' :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4231"></span><span class="hs-comment">-- where' _condition _input _other = unsafePerformIO $ (ATen.cast3 ATen.Managed.where_ttt) _condition _input _other</span><span>
</span><span id="line-4232"></span><span>
</span><span id="line-4233"></span><span class="hs-comment">-- where_ :: Tensor device dtype shape -&gt; [Tensor device dtype shape]</span><span>
</span><span id="line-4234"></span><span class="hs-comment">-- where_ _condition = unsafePerformIO $ (ATen.cast1 ATen.Managed.where_t) _condition</span><span>
</span><span id="line-4235"></span><span>
</span><span id="line-4236"></span><span class="hs-comment">-- norm_except_dim :: Tensor device dtype shape -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4237"></span><span class="hs-comment">-- norm_except_dim _v _pow _dim = unsafePerformIO $ (ATen.cast3 ATen.Managed.norm_except_dim_tll) _v _pow _dim</span><span>
</span><span id="line-4238"></span><span>
</span><span id="line-4239"></span><span class="hs-comment">-- | zerosLike</span><span>
</span><span id="line-4240"></span><span class="hs-comment">--</span><span>
</span><span id="line-4241"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ zerosLike (ones :: CPUTensor 'D.Float '[3,4,5])</span><span>
</span><span id="line-4242"></span><span class="hs-comment">-- (Float,[3,4,5])</span><span>
</span><span id="line-4243"></span><span class="annot"><a href="Torch.Typed.Functional.html#zerosLike"><span class="hs-identifier hs-type">zerosLike</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4244"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708488"><span class="annot"><a href="#local-6989586621679708488"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708487"><span class="annot"><a href="#local-6989586621679708487"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708486"><span class="annot"><a href="#local-6989586621679708486"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4245"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4246"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708486"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708487"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708488"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4247"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4248"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708486"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708487"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708488"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4249"></span><span id="zerosLike"><span class="annot"><span class="annottext">zerosLike :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#zerosLike"><span class="hs-identifier hs-var hs-var">zerosLike</span></a></span></span><span> </span><span id="local-6989586621679708485"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708485"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.zeros_like_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708485"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4250"></span><span>
</span><span id="line-4251"></span><span class="hs-comment">-- native_norm :: Tensor device dtype shape -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4252"></span><span class="hs-comment">-- native_norm _input _p = unsafePerformIO $ (ATen.cast2 ATen.Managed.native_norm_ts) _input _p</span><span>
</span><span id="line-4253"></span><span>
</span><span id="line-4254"></span><span class="hs-comment">-- | clone</span><span>
</span><span id="line-4255"></span><span class="hs-comment">--</span><span>
</span><span id="line-4256"></span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- clone (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4257"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-4258"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4259"></span><span class="annot"><a href="Torch.Typed.Functional.html#clone"><span class="hs-identifier hs-type">clone</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4260"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708482"><span class="annot"><a href="#local-6989586621679708482"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708481"><span class="annot"><a href="#local-6989586621679708481"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708480"><span class="annot"><a href="#local-6989586621679708480"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4261"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708480"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708481"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708482"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4262"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708480"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708481"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708482"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4263"></span><span id="clone"><span class="annot"><span class="annottext">clone :: Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
</span><a href="Torch.Typed.Functional.html#clone"><span class="hs-identifier hs-var hs-var">clone</span></a></span></span><span> </span><span id="local-6989586621679708479"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708479"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.clone_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708479"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4264"></span><span>
</span><span id="line-4265"></span><span class="hs-comment">-- s_native_addmm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4266"></span><span class="hs-comment">-- s_native_addmm _input _mat1 _mat2 _beta _alpha = unsafePerformIO $ (ATen.cast5 ATen.Managed.s_native_addmm_tttss) _input _mat1 _mat2 _beta _alpha</span><span>
</span><span id="line-4267"></span><span>
</span><span id="line-4268"></span><span class="hs-comment">-- | addmm</span><span>
</span><span id="line-4269"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-4270"></span><span class="hs-comment">-- TODO: can we use D.Scalar here for beta and alpha?</span><span>
</span><span id="line-4271"></span><span class="hs-comment">--</span><span>
</span><span id="line-4272"></span><span class="hs-comment">-- &gt;&gt;&gt; t = addmm 1 1 (ones :: CPUTensor 'D.Float '[3,2]) (zeros :: CPUTensor 'D.Float '[2,4]) (ones :: CPUTensor 'D.Float '[])</span><span>
</span><span id="line-4273"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ t</span><span>
</span><span id="line-4274"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-4275"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-4276"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[3, 4]</span><span>
</span><span id="line-4277"></span><span class="annot"><a href="Torch.Typed.Functional.html#addmm"><span class="hs-identifier hs-type">addmm</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4278"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708476"><span class="annot"><a href="#local-6989586621679708476"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708475"><span class="annot"><a href="#local-6989586621679708475"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708474"><span class="annot"><a href="#local-6989586621679708474"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679708473"><span class="annot"><a href="#local-6989586621679708473"><span class="hs-identifier hs-type">k</span></a></span></span><span> </span><span id="local-6989586621679708472"><span class="annot"><a href="#local-6989586621679708472"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679708471"><span class="annot"><a href="#local-6989586621679708471"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708470"><span class="annot"><a href="#local-6989586621679708470"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4279"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708474"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708473"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708472"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-4280"></span><span>    </span><span class="annot"><a href="#local-6989586621679708476"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708475"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708474"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708472"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4281"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4282"></span><span>  </span><span class="hs-comment">-- | beta</span><span>
</span><span id="line-4283"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4284"></span><span>  </span><span class="hs-comment">-- | alpha</span><span>
</span><span id="line-4285"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4286"></span><span>  </span><span class="hs-comment">-- | first input matrix</span><span>
</span><span id="line-4287"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708470"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708471"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708474"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708473"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4288"></span><span>  </span><span class="hs-comment">-- | second input matrix</span><span>
</span><span id="line-4289"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708470"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708471"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708473"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708472"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4290"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-4291"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708470"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708471"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708475"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4292"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-4293"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708470"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708471"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708476"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4294"></span><span id="addmm"><span class="annot"><span class="annottext">addmm :: Float
-&gt; Float
-&gt; Tensor device dtype '[n, k]
-&gt; Tensor device dtype '[k, m]
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#addmm"><span class="hs-identifier hs-var hs-var">addmm</span></a></span></span><span> </span><span id="local-6989586621679708469"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708469"><span class="hs-identifier hs-var">beta</span></a></span></span><span> </span><span id="local-6989586621679708468"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708468"><span class="hs-identifier hs-var">alpha</span></a></span></span><span> </span><span id="local-6989586621679708467"><span class="annot"><span class="annottext">Tensor device dtype '[n, k]
</span><a href="#local-6989586621679708467"><span class="hs-identifier hs-var">mat1</span></a></span></span><span> </span><span id="local-6989586621679708466"><span class="annot"><span class="annottext">Tensor device dtype '[k, m]
</span><a href="#local-6989586621679708466"><span class="hs-identifier hs-var">mat2</span></a></span></span><span> </span><span id="local-6989586621679708465"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708465"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype '[n, k]
-&gt; Tensor device dtype '[k, m]
-&gt; Float
-&gt; Float
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.addmm_tttss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708465"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[n, k]
</span><a href="#local-6989586621679708467"><span class="hs-identifier hs-var">mat1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[k, m]
</span><a href="#local-6989586621679708466"><span class="hs-identifier hs-var">mat2</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708469"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679708468"><span class="hs-identifier hs-var">alpha</span></a></span><span>
</span><span id="line-4295"></span><span>
</span><span id="line-4296"></span><span class="hs-comment">-- hspmm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4297"></span><span class="hs-comment">-- hspmm _mat1 _mat2 = unsafePerformIO $ (ATen.cast2 ATen.Managed.hspmm_tt) _mat1 _mat2</span><span>
</span><span id="line-4298"></span><span>
</span><span id="line-4299"></span><span class="hs-comment">-- | numel</span><span>
</span><span id="line-4300"></span><span class="hs-comment">-- TODO: since this is decidable at compile time, this should probably be calculated from the tensor type instead</span><span>
</span><span id="line-4301"></span><span class="annot"><a href="Torch.Typed.Functional.html#numel"><span class="hs-identifier hs-type">numel</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4302"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708462"><span class="annot"><a href="#local-6989586621679708462"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708461"><span class="annot"><a href="#local-6989586621679708461"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708460"><span class="annot"><a href="#local-6989586621679708460"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4303"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4304"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708460"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708461"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708462"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4305"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4306"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-4307"></span><span id="numel"><span class="annot"><span class="annottext">numel :: Tensor device dtype shape -&gt; Int
</span><a href="Torch.Typed.Functional.html#numel"><span class="hs-identifier hs-var hs-var">numel</span></a></span></span><span> </span><span id="local-6989586621679708459"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708459"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Int -&gt; Int
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Int -&gt; Int) -&gt; IO Int -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor device dtype shape -&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.tensor_numel</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708459"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4308"></span><span>
</span><span id="line-4309"></span><span class="hs-comment">-- unbind :: Tensor device dtype shape -&gt; Int -&gt; [Tensor device dtype shape]</span><span>
</span><span id="line-4310"></span><span class="hs-comment">-- unbind _input _dim = unsafePerformIO $ (ATen.cast2 ATen.Managed.unbind_tl) _input _dim</span><span>
</span><span id="line-4311"></span><span>
</span><span id="line-4312"></span><span class="hs-comment">-- mkldnn_reorder_conv2d_weight :: Tensor device dtype shape -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4313"></span><span class="hs-comment">-- mkldnn_reorder_conv2d_weight _input _padding _stride _dilation _groups = unsafePerformIO $ (ATen.cast5 ATen.Managed.mkldnn_reorder_conv2d_weight_tllll) _input _padding _stride _dilation _groups</span><span>
</span><span id="line-4314"></span><span>
</span><span id="line-4315"></span><span class="hs-comment">--quantize_linear :: Tensor device dtype shape -&gt; Double -&gt; Int -&gt; DType -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4316"></span><span class="hs-comment">--quantize_linear _input _scale _zero_point _dtype = unsafePerformIO $ (ATen.cast4 ATen.Managed.quantize_linear_tdls) _input _scale _zero_point _dtype</span><span>
</span><span id="line-4317"></span><span>
</span><span id="line-4318"></span><span class="hs-comment">--quantize_linear_per_channel :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; [Int] -&gt; DType -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4319"></span><span class="hs-comment">--quantize_linear_per_channel _input _scales _zero_points _axis _dtype = unsafePerformIO $ (ATen.cast5 ATen.Managed.quantize_linear_per_channel_tttls) _input _scales _zero_points _axis _dtype</span><span>
</span><span id="line-4320"></span><span>
</span><span id="line-4321"></span><span class="hs-comment">-- dequantize :: Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4322"></span><span class="hs-comment">-- dequantize _input = unsafePerformIO $ (ATen.cast1 ATen.Managed.dequantize_t) _input</span><span>
</span><span id="line-4323"></span><span>
</span><span id="line-4324"></span><span class="hs-comment">-- | qScale</span><span>
</span><span id="line-4325"></span><span class="hs-comment">-- TODO: are there any restrictions on the dtype?</span><span>
</span><span id="line-4326"></span><span class="annot"><a href="Torch.Typed.Functional.html#qScale"><span class="hs-identifier hs-type">qScale</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4327"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708456"><span class="annot"><a href="#local-6989586621679708456"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708455"><span class="annot"><a href="#local-6989586621679708455"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708454"><span class="annot"><a href="#local-6989586621679708454"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4328"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4329"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708454"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708455"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708456"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4330"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4331"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-4332"></span><span id="qScale"><span class="annot"><span class="annottext">qScale :: Tensor device dtype shape -&gt; Double
</span><a href="Torch.Typed.Functional.html#qScale"><span class="hs-identifier hs-var hs-var">qScale</span></a></span></span><span> </span><span id="local-6989586621679708453"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708453"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Double -&gt; Double
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Double -&gt; Double) -&gt; IO Double -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CDouble)
-&gt; Tensor device dtype shape -&gt; IO Double
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CDouble
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.q_scale_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708453"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4333"></span><span>
</span><span id="line-4334"></span><span class="hs-comment">-- | qZeroPoint</span><span>
</span><span id="line-4335"></span><span class="hs-comment">-- TODO: are there any restrictions on the dtype?</span><span>
</span><span id="line-4336"></span><span class="annot"><a href="Torch.Typed.Functional.html#qZeroPoint"><span class="hs-identifier hs-type">qZeroPoint</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4337"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708450"><span class="annot"><a href="#local-6989586621679708450"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708449"><span class="annot"><a href="#local-6989586621679708449"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708448"><span class="annot"><a href="#local-6989586621679708448"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4338"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4339"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708448"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708449"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708450"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4340"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4341"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-4342"></span><span id="qZeroPoint"><span class="annot"><span class="annottext">qZeroPoint :: Tensor device dtype shape -&gt; Int
</span><a href="Torch.Typed.Functional.html#qZeroPoint"><span class="hs-identifier hs-var hs-var">qZeroPoint</span></a></span></span><span> </span><span id="local-6989586621679708447"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708447"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Int -&gt; Int
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Int -&gt; Int) -&gt; IO Int -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor device dtype shape -&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.q_zero_point_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708447"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4343"></span><span>
</span><span id="line-4344"></span><span class="hs-comment">-- int_repr :: Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4345"></span><span class="hs-comment">-- int_repr _input = unsafePerformIO $ (ATen.cast1 ATen.Managed.int_repr_t) _input</span><span>
</span><span id="line-4346"></span><span>
</span><span id="line-4347"></span><span class="hs-comment">-- fake_quantize_per_tensor_affine :: Tensor device dtype shape -&gt; Double -&gt; Int -&gt; Int -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4348"></span><span class="hs-comment">-- fake_quantize_per_tensor_affine _input _scale _zero_point _quant_min _quant_max = unsafePerformIO $ (ATen.cast5 ATen.Managed.fake_quantize_per_tensor_affine_tdlll) _input _scale _zero_point _quant_min _quant_max</span><span>
</span><span id="line-4349"></span><span>
</span><span id="line-4350"></span><span class="hs-comment">-- meshgrid :: [Tensor device dtype shape] -&gt; [Tensor device dtype shape]</span><span>
</span><span id="line-4351"></span><span class="hs-comment">-- meshgrid _tensors = unsafePerformIO $ (ATen.cast1 ATen.Managed.meshgrid_l) _tensors</span><span>
</span><span id="line-4352"></span><span>
</span><span id="line-4353"></span><span class="hs-comment">-- cartesian_prod :: [Tensor device dtype shape] -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4354"></span><span class="hs-comment">-- cartesian_prod _tensors = unsafePerformIO $ (ATen.cast1 ATen.Managed.cartesian_prod_l) _tensors</span><span>
</span><span id="line-4355"></span><span>
</span><span id="line-4356"></span><span class="hs-comment">-- combinations :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4357"></span><span class="hs-comment">-- combinations _input _r _with_replacement = unsafePerformIO $ (ATen.cast3 ATen.Managed.combinations_tlb) _input _r _with_replacement</span><span>
</span><span id="line-4358"></span><span>
</span><span id="line-4359"></span><span class="hs-comment">-- | The directional specification of a recurrent function</span><span>
</span><span id="line-4360"></span><span id="local-6989586621679708444"><span id="local-6989586621679708445"></span></span><span class="hs-keyword">data</span><span> </span><span id="RNNDirectionality"><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-var">RNNDirectionality</span></a></span></span><span>
</span><span id="line-4361"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="hs-comment">-- | Forward and backward along the sequential axis using independant parameters for each.</span><span>
</span><span id="line-4362"></span><span>    </span><span id="Bidirectional"><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-var">Bidirectional</span></a></span></span><span>
</span><span id="line-4363"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | Forward along the sequential axis.</span><span>
</span><span id="line-4364"></span><span>    </span><span id="Unidirectional"><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-var">Unidirectional</span></a></span></span><span>
</span><span id="line-4365"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708438"><span id="local-6989586621679708440"><span id="local-6989586621679708442"><span class="annot"><span class="annottext">Int -&gt; RNNDirectionality -&gt; ShowS
[RNNDirectionality] -&gt; ShowS
RNNDirectionality -&gt; String
(Int -&gt; RNNDirectionality -&gt; ShowS)
-&gt; (RNNDirectionality -&gt; String)
-&gt; ([RNNDirectionality] -&gt; ShowS)
-&gt; Show RNNDirectionality
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [RNNDirectionality] -&gt; ShowS
$cshowList :: [RNNDirectionality] -&gt; ShowS
show :: RNNDirectionality -&gt; String
$cshow :: RNNDirectionality -&gt; String
showsPrec :: Int -&gt; RNNDirectionality -&gt; ShowS
$cshowsPrec :: Int -&gt; RNNDirectionality -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. RNNDirectionality -&gt; Rep RNNDirectionality x)
-&gt; (forall x. Rep RNNDirectionality x -&gt; RNNDirectionality)
-&gt; Generic RNNDirectionality
forall x. Rep RNNDirectionality x -&gt; RNNDirectionality
forall x. RNNDirectionality -&gt; Rep RNNDirectionality x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep RNNDirectionality x -&gt; RNNDirectionality
$cfrom :: forall x. RNNDirectionality -&gt; Rep RNNDirectionality x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- TODO:  We could also have BidirectionalTied weights.</span><span>
</span><span id="line-4366"></span><span>
</span><span id="line-4367"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="NumberOfDirections"><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-var">NumberOfDirections</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708432"><span class="annot"><a href="#local-6989586621679708432"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4368"></span><span>  </span><span id="NumberOfDirections"><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-var">NumberOfDirections</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-number">2</span></span><span>
</span><span id="line-4369"></span><span>  </span><span id="NumberOfDirections"><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-var">NumberOfDirections</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-4370"></span><span>
</span><span id="line-4371"></span><span class="hs-keyword">class</span><span> </span><span id="KnownRNNDirectionality"><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNDirectionality"><span class="hs-identifier hs-var">KnownRNNDirectionality</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710583"><span class="annot"><a href="#local-6989586621679710583"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4372"></span><span>  </span><span id="rnnBidirectional"><span class="annot"><a href="Torch.Typed.Functional.html#rnnBidirectional"><span class="hs-identifier hs-type">rnnBidirectional</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-4373"></span><span>
</span><span id="line-4374"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNDirectionality"><span class="hs-identifier hs-type">KnownRNNDirectionality</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4375"></span><span>  </span><span id="local-6989586621679708428"><span class="annot"><span class="annottext">rnnBidirectional :: Bool
</span><a href="#local-6989586621679708428"><span class="hs-identifier hs-var hs-var hs-var hs-var">rnnBidirectional</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-4376"></span><span>
</span><span id="line-4377"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNDirectionality"><span class="hs-identifier hs-type">KnownRNNDirectionality</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4378"></span><span>  </span><span id="local-6989586621679708426"><span class="annot"><span class="annottext">rnnBidirectional :: Bool
</span><a href="#local-6989586621679708426"><span class="hs-identifier hs-var hs-var hs-var hs-var">rnnBidirectional</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-4379"></span><span>
</span><span id="line-4380"></span><span class="hs-comment">-- | Specification for the sequential axis of a recurrent function.</span><span>
</span><span id="line-4381"></span><span id="local-6989586621679708424"><span id="local-6989586621679708425"></span></span><span class="hs-keyword">data</span><span> </span><span id="RNNShapeOrder"><span class="annot"><a href="Torch.Typed.Functional.html#RNNShapeOrder"><span class="hs-identifier hs-var">RNNShapeOrder</span></a></span></span><span>
</span><span id="line-4382"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="hs-comment">-- | Input is of shape (Batch, Sequence, Features)</span><span>
</span><span id="line-4383"></span><span>    </span><span id="BatchFirst"><span class="annot"><a href="Torch.Typed.Functional.html#BatchFirst"><span class="hs-identifier hs-var">BatchFirst</span></a></span></span><span>
</span><span id="line-4384"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | Input is of shape (Sequence, Batch, Features)</span><span>
</span><span id="line-4385"></span><span>    </span><span id="SequenceFirst"><span class="annot"><a href="Torch.Typed.Functional.html#SequenceFirst"><span class="hs-identifier hs-var">SequenceFirst</span></a></span></span><span>
</span><span id="line-4386"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708418"><span id="local-6989586621679708420"><span id="local-6989586621679708422"><span class="annot"><span class="annottext">Int -&gt; RNNShapeOrder -&gt; ShowS
[RNNShapeOrder] -&gt; ShowS
RNNShapeOrder -&gt; String
(Int -&gt; RNNShapeOrder -&gt; ShowS)
-&gt; (RNNShapeOrder -&gt; String)
-&gt; ([RNNShapeOrder] -&gt; ShowS)
-&gt; Show RNNShapeOrder
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [RNNShapeOrder] -&gt; ShowS
$cshowList :: [RNNShapeOrder] -&gt; ShowS
show :: RNNShapeOrder -&gt; String
$cshow :: RNNShapeOrder -&gt; String
showsPrec :: Int -&gt; RNNShapeOrder -&gt; ShowS
$cshowsPrec :: Int -&gt; RNNShapeOrder -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. RNNShapeOrder -&gt; Rep RNNShapeOrder x)
-&gt; (forall x. Rep RNNShapeOrder x -&gt; RNNShapeOrder)
-&gt; Generic RNNShapeOrder
forall x. Rep RNNShapeOrder x -&gt; RNNShapeOrder
forall x. RNNShapeOrder -&gt; Rep RNNShapeOrder x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep RNNShapeOrder x -&gt; RNNShapeOrder
$cfrom :: forall x. RNNShapeOrder -&gt; Rep RNNShapeOrder x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-4387"></span><span>
</span><span id="line-4388"></span><span class="hs-keyword">class</span><span> </span><span id="KnownRNNShapeOrder"><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNShapeOrder"><span class="hs-identifier hs-var">KnownRNNShapeOrder</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679710576"><span class="annot"><a href="#local-6989586621679710576"><span class="hs-identifier hs-type">shapeOrder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShapeOrder"><span class="hs-identifier hs-type">RNNShapeOrder</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4389"></span><span>  </span><span id="rnnBatchFirst"><span class="annot"><a href="Torch.Typed.Functional.html#rnnBatchFirst"><span class="hs-identifier hs-type">rnnBatchFirst</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-4390"></span><span>
</span><span id="line-4391"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNShapeOrder"><span class="hs-identifier hs-type">KnownRNNShapeOrder</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#BatchFirst"><span class="hs-identifier hs-type">BatchFirst</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4392"></span><span>  </span><span id="local-6989586621679708412"><span class="annot"><span class="annottext">rnnBatchFirst :: Bool
</span><a href="#local-6989586621679708412"><span class="hs-identifier hs-var hs-var hs-var hs-var">rnnBatchFirst</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-4393"></span><span>
</span><span id="line-4394"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNShapeOrder"><span class="hs-identifier hs-type">KnownRNNShapeOrder</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SequenceFirst"><span class="hs-identifier hs-type">SequenceFirst</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4395"></span><span>  </span><span id="local-6989586621679708410"><span class="annot"><span class="annottext">rnnBatchFirst :: Bool
</span><a href="#local-6989586621679708410"><span class="hs-identifier hs-var hs-var hs-var hs-var">rnnBatchFirst</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-4396"></span><span>
</span><span id="line-4397"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="RNNShape"><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-var">RNNShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708408"><span class="annot"><a href="#local-6989586621679708408"><span class="hs-identifier hs-type">shapeOrder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShapeOrder"><span class="hs-identifier hs-type">RNNShapeOrder</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708407"><span class="annot"><a href="#local-6989586621679708407"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708406"><span class="annot"><a href="#local-6989586621679708406"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708405"><span class="annot"><a href="#local-6989586621679708405"><span class="hs-identifier hs-type">featureSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4398"></span><span>  </span><span id="RNNShape"><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-var">RNNShape</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#BatchFirst"><span class="hs-identifier hs-type">BatchFirst</span></a></span><span> </span><span id="local-6989586621679708404"><span class="annot"><a href="#local-6989586621679708404"><span class="hs-identifier hs-type hs-type">seqLen</span></a></span></span><span> </span><span id="local-6989586621679708403"><span class="annot"><a href="#local-6989586621679708403"><span class="hs-identifier hs-type hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708402"><span class="annot"><a href="#local-6989586621679708402"><span class="hs-identifier hs-type hs-type">featureSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708403"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708404"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708402"><span class="hs-identifier hs-type">featureSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4399"></span><span>  </span><span id="RNNShape"><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-var">RNNShape</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#SequenceFirst"><span class="hs-identifier hs-type">SequenceFirst</span></a></span><span> </span><span id="local-6989586621679708401"><span class="annot"><a href="#local-6989586621679708401"><span class="hs-identifier hs-type hs-type">seqLen</span></a></span></span><span> </span><span id="local-6989586621679708400"><span class="annot"><a href="#local-6989586621679708400"><span class="hs-identifier hs-type hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708399"><span class="annot"><a href="#local-6989586621679708399"><span class="hs-identifier hs-type hs-type">featureSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708401"><span class="hs-identifier hs-type">seqLen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708400"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708399"><span class="hs-identifier hs-type">featureSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4400"></span><span>
</span><span id="line-4401"></span><span class="hs-keyword">type</span><span> </span><span id="LSTMWIShape"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-var">LSTMWIShape</span></a></span></span><span> </span><span id="local-6989586621679708397"><span class="annot"><a href="#local-6989586621679708397"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708396"><span class="annot"><a href="#local-6989586621679708396"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708397"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708396"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4402"></span><span>
</span><span id="line-4403"></span><span class="hs-keyword">type</span><span> </span><span id="LSTMWHShape"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-var">LSTMWHShape</span></a></span></span><span> </span><span id="local-6989586621679708394"><span class="annot"><a href="#local-6989586621679708394"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708393"><span class="annot"><a href="#local-6989586621679708393"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708394"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708394"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4404"></span><span>
</span><span id="line-4405"></span><span class="hs-keyword">type</span><span> </span><span id="LSTMBIShape"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-var">LSTMBIShape</span></a></span></span><span> </span><span id="local-6989586621679708391"><span class="annot"><a href="#local-6989586621679708391"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708390"><span class="annot"><a href="#local-6989586621679708390"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708391"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4406"></span><span>
</span><span id="line-4407"></span><span class="hs-keyword">type</span><span> </span><span id="LSTMBHShape"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-var">LSTMBHShape</span></a></span></span><span> </span><span id="local-6989586621679708388"><span class="annot"><a href="#local-6989586621679708388"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708387"><span class="annot"><a href="#local-6989586621679708387"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708388"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4408"></span><span>
</span><span id="line-4409"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="LSTMRImpl"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-var">LSTMRImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708385"><span class="annot"><a href="#local-6989586621679708385"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708384"><span class="annot"><a href="#local-6989586621679708384"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708383"><span class="annot"><a href="#local-6989586621679708383"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708382"><span class="annot"><a href="#local-6989586621679708382"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4410"></span><span>  </span><span id="LSTMRImpl"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-var">LSTMRImpl</span></a></span></span><span> </span><span id="local-6989586621679708381"><span class="annot"><a href="#local-6989586621679708381"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708380"><span class="annot"><a href="#local-6989586621679708380"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4411"></span><span>    </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708380"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708381"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4412"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708380"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708381"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4413"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708380"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708381"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4414"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708380"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708381"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-4415"></span><span>     </span><span class="hs-special">]</span><span>
</span><span id="line-4416"></span><span>  </span><span id="LSTMRImpl"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-var">LSTMRImpl</span></a></span></span><span> </span><span id="local-6989586621679708379"><span class="annot"><a href="#local-6989586621679708379"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708378"><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708377"><span class="annot"><a href="#local-6989586621679708377"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4417"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-type">LSTMRImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708379"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708377"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span>
</span><span id="line-4418"></span><span>      </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4419"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4420"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4421"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708378"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4422"></span><span>          </span><span class="hs-special">]</span><span>
</span><span id="line-4423"></span><span>  </span><span id="LSTMRImpl"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-var">LSTMRImpl</span></a></span></span><span> </span><span id="local-6989586621679708376"><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708375"><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4424"></span><span>    </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4425"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4426"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4427"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4428"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4429"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4430"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4431"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708375"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708376"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-4432"></span><span>     </span><span class="hs-special">]</span><span>
</span><span id="line-4433"></span><span>  </span><span id="LSTMRImpl"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-var">LSTMRImpl</span></a></span></span><span> </span><span id="local-6989586621679708374"><span class="annot"><a href="#local-6989586621679708374"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708373"><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708372"><span class="annot"><a href="#local-6989586621679708372"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4434"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-type">LSTMRImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708374"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708372"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span>
</span><span id="line-4435"></span><span>      </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4436"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4437"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4438"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4439"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4440"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4441"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4442"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708373"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4443"></span><span>          </span><span class="hs-special">]</span><span>
</span><span id="line-4444"></span><span>
</span><span id="line-4445"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="LSTMR%27"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR%27"><span class="hs-identifier hs-var">LSTMR'</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708370"><span class="annot"><a href="#local-6989586621679708370"><span class="hs-identifier hs-type">shapes</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708369"><span class="annot"><a href="#local-6989586621679708369"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708368"><span class="annot"><a href="#local-6989586621679708368"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708367"><span class="annot"><a href="#local-6989586621679708367"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4446"></span><span>  </span><span id="LSTMR%27"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR%27"><span class="hs-identifier hs-var">LSTMR'</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679708366"><span class="annot"><a href="#local-6989586621679708366"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708365"><span class="annot"><a href="#local-6989586621679708365"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-4447"></span><span>  </span><span id="LSTMR%27"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR%27"><span class="hs-identifier hs-var">LSTMR'</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708364"><span class="annot"><a href="#local-6989586621679708364"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708363"><span class="annot"><a href="#local-6989586621679708363"><span class="hs-identifier hs-type hs-type">shapes</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708362"><span class="annot"><a href="#local-6989586621679708362"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708361"><span class="annot"><a href="#local-6989586621679708361"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708362"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708364"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR%27"><span class="hs-identifier hs-type">LSTMR'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708363"><span class="hs-identifier hs-type">shapes</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708362"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708361"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-4448"></span><span>
</span><span id="line-4449"></span><span class="hs-keyword">type</span><span> </span><span id="LSTMR"><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR"><span class="hs-identifier hs-var">LSTMR</span></a></span></span><span> </span><span id="local-6989586621679708359"><span class="annot"><a href="#local-6989586621679708359"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708358"><span class="annot"><a href="#local-6989586621679708358"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708357"><span class="annot"><a href="#local-6989586621679708357"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679708356"><span class="annot"><a href="#local-6989586621679708356"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span id="local-6989586621679708355"><span class="annot"><a href="#local-6989586621679708355"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708354"><span class="annot"><a href="#local-6989586621679708354"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR%27"><span class="hs-identifier hs-type">LSTMR'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMRImpl"><span class="hs-identifier hs-type">LSTMRImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708359"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708358"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708357"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708356"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708355"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708354"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-4450"></span><span>
</span><span id="line-4451"></span><span class="hs-comment">-- | lstm</span><span>
</span><span id="line-4452"></span><span class="hs-comment">-- Parameters for this ATen function are non-trivially provided.  See the</span><span>
</span><span id="line-4453"></span><span class="hs-comment">-- `Typed.NN.LSTM` module for doctests.</span><span>
</span><span id="line-4454"></span><span class="annot"><a href="Torch.Typed.Functional.html#lstm"><span class="hs-identifier hs-type">lstm</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4455"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-4456"></span><span>    </span><span id="local-6989586621679708352"><span class="annot"><a href="#local-6989586621679708352"><span class="hs-identifier hs-type">shapeOrder</span></a></span></span><span>
</span><span id="line-4457"></span><span>    </span><span id="local-6989586621679708351"><span class="annot"><a href="#local-6989586621679708351"><span class="hs-identifier hs-type">directionality</span></a></span></span><span>
</span><span id="line-4458"></span><span>    </span><span id="local-6989586621679708350"><span class="annot"><a href="#local-6989586621679708350"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span>
</span><span id="line-4459"></span><span>    </span><span id="local-6989586621679708349"><span class="annot"><a href="#local-6989586621679708349"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span>
</span><span id="line-4460"></span><span>    </span><span id="local-6989586621679708348"><span class="annot"><a href="#local-6989586621679708348"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-4461"></span><span>    </span><span id="local-6989586621679708347"><span class="annot"><a href="#local-6989586621679708347"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span>
</span><span id="line-4462"></span><span>    </span><span id="local-6989586621679708346"><span class="annot"><a href="#local-6989586621679708346"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-4463"></span><span>    </span><span id="local-6989586621679708345"><span class="annot"><a href="#local-6989586621679708345"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span>
</span><span id="line-4464"></span><span>    </span><span id="local-6989586621679708344"><span class="annot"><a href="#local-6989586621679708344"><span class="hs-identifier hs-type">inputShape</span></a></span></span><span>
</span><span id="line-4465"></span><span>    </span><span id="local-6989586621679708343"><span class="annot"><a href="#local-6989586621679708343"><span class="hs-identifier hs-type">outputShape</span></a></span></span><span>
</span><span id="line-4466"></span><span>    </span><span id="local-6989586621679708342"><span class="annot"><a href="#local-6989586621679708342"><span class="hs-identifier hs-type">hxShape</span></a></span></span><span>
</span><span id="line-4467"></span><span>    </span><span id="local-6989586621679708341"><span class="annot"><a href="#local-6989586621679708341"><span class="hs-identifier hs-type">tensorParameters</span></a></span></span><span>
</span><span id="line-4468"></span><span>    </span><span id="local-6989586621679708340"><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-4469"></span><span>    </span><span id="local-6989586621679708339"><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4470"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708350"><span class="hs-identifier hs-type">numLayers</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4471"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNShapeOrder"><span class="hs-identifier hs-type">KnownRNNShapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708352"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4472"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNDirectionality"><span class="hs-identifier hs-type">KnownRNNDirectionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708351"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4473"></span><span>    </span><span class="annot"><a href="#local-6989586621679708346"><span class="hs-identifier hs-type">outputSize</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708345"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708351"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4474"></span><span>    </span><span class="annot"><a href="#local-6989586621679708344"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708352"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708349"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708348"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708347"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4475"></span><span>    </span><span class="annot"><a href="#local-6989586621679708343"><span class="hs-identifier hs-type">outputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708352"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708349"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708348"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708346"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4476"></span><span>    </span><span class="annot"><a href="#local-6989586621679708342"><span class="hs-identifier hs-type">hxShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708350"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708351"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708348"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708345"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-4477"></span><span>    </span><span class="annot"><a href="#local-6989586621679708341"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR"><span class="hs-identifier hs-type">LSTMR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708347"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708345"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708350"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708351"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4478"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708341"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4479"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4480"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708341"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4481"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4482"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4483"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708342"><span class="hs-identifier hs-type">hxShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708342"><span class="hs-identifier hs-type">hxShape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4484"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708344"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4485"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708343"><span class="hs-identifier hs-type">outputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4486"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708342"><span class="hs-identifier hs-type">hxShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4487"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708342"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-4488"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-4489"></span><span id="lstm"><span class="annot"><span class="annottext">lstm :: HList tensorParameters
-&gt; Double
-&gt; Bool
-&gt; (Tensor device dtype hxShape, Tensor device dtype hxShape)
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.Functional.html#lstm"><span class="hs-identifier hs-var hs-var">lstm</span></a></span></span><span> </span><span id="local-6989586621679708338"><span class="annot"><span class="annottext">HList tensorParameters
</span><a href="#local-6989586621679708338"><span class="hs-identifier hs-var">tensorParameters</span></a></span></span><span> </span><span id="local-6989586621679708337"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708337"><span class="hs-identifier hs-var">dropoutProb</span></a></span></span><span> </span><span id="local-6989586621679708336"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708336"><span class="hs-identifier hs-var">dropoutOn</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708335"><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679708335"><span class="hs-identifier hs-var">cc</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679708334"><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679708334"><span class="hs-identifier hs-var">hc</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708333"><span class="annot"><span class="annottext">Tensor device dtype inputShape
</span><a href="#local-6989586621679708333"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4490"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype outputShape, Tensor device dtype hxShape,
   Tensor device dtype hxShape)
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
 -&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
     Tensor device dtype hxShape))
-&gt; IO
     (Tensor device dtype outputShape, Tensor device dtype hxShape,
      Tensor device dtype hxShape)
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-4491"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorList
 -&gt; ForeignPtr TensorList
 -&gt; CBool
 -&gt; Int64
 -&gt; CDouble
 -&gt; CBool
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor, Tensor))))
-&gt; Tensor device dtype inputShape
-&gt; [Tensor device dtype hxShape]
-&gt; HList tensorParameters
-&gt; Bool
-&gt; Int64
-&gt; Double
-&gt; Bool
-&gt; Bool
-&gt; Bool
-&gt; IO
     (Tensor device dtype outputShape, Tensor device dtype hxShape,
      Tensor device dtype hxShape)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 x7 cx7 x8 cx8
       y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6, Castable x7 cx7,
 Castable x8 cx8, Castable y cy) =&gt;
(ca
 -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; cx7 -&gt; cx8 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; x7 -&gt; x8 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast9</span></a></span><span>
</span><span id="line-4492"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorList
-&gt; ForeignPtr TensorList
-&gt; CBool
-&gt; Int64
-&gt; CDouble
-&gt; CBool
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.lstm_tllbldbbb</span></a></span><span>
</span><span id="line-4493"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype inputShape
</span><a href="#local-6989586621679708333"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4494"></span><span>      </span><span class="annot"><span class="annottext">[Tensor device dtype hxShape]
</span><a href="#local-6989586621679708330"><span class="hs-identifier hs-var">hx</span></a></span><span>
</span><span id="line-4495"></span><span>      </span><span class="annot"><span class="annottext">HList tensorParameters
</span><a href="#local-6989586621679708338"><span class="hs-identifier hs-var">tensorParameters</span></a></span><span>
</span><span id="line-4496"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708329"><span class="hs-identifier hs-var">hasBiases</span></a></span><span>
</span><span id="line-4497"></span><span>      </span><span class="annot"><span class="annottext">Int64
</span><a href="#local-6989586621679708328"><span class="hs-identifier hs-var">numLayers</span></a></span><span>
</span><span id="line-4498"></span><span>      </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708337"><span class="hs-identifier hs-var">dropoutProb</span></a></span><span>
</span><span id="line-4499"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708336"><span class="hs-identifier hs-var">dropoutOn</span></a></span><span>
</span><span id="line-4500"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownRNNDirectionality directionality =&gt; Bool
forall (directionality :: RNNDirectionality).
KnownRNNDirectionality directionality =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#rnnBidirectional"><span class="hs-identifier hs-var">rnnBidirectional</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708351"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4501"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownRNNShapeOrder shapeOrder =&gt; Bool
forall (shapeOrder :: RNNShapeOrder).
KnownRNNShapeOrder shapeOrder =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#rnnBatchFirst"><span class="hs-identifier hs-var">rnnBatchFirst</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708352"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4502"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-4503"></span><span>    </span><span id="local-6989586621679708329"><span class="annot"><span class="annottext">hasBiases :: Bool
</span><a href="#local-6989586621679708329"><span class="hs-identifier hs-var hs-var">hasBiases</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-4504"></span><span>    </span><span class="annot"><a href="#local-6989586621679708330"><span class="hs-identifier hs-type">hx</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708339"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708340"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708342"><span class="hs-identifier hs-type">hxShape</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4505"></span><span>    </span><span id="local-6989586621679708330"><span class="annot"><span class="annottext">hx :: [Tensor device dtype hxShape]
</span><a href="#local-6989586621679708330"><span class="hs-identifier hs-var hs-var">hx</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679708335"><span class="hs-identifier hs-var">cc</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679708334"><span class="hs-identifier hs-var">hc</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4506"></span><span>    </span><span class="annot"><a href="#local-6989586621679708328"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">I.Int64</span></span><span>
</span><span id="line-4507"></span><span>    </span><span id="local-6989586621679708328"><span class="annot"><span class="annottext">numLayers :: Int64
</span><a href="#local-6989586621679708328"><span class="hs-identifier hs-var hs-var">numLayers</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int64
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int64) -&gt; Int -&gt; Int64
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat numLayers =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708350"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-4508"></span><span>
</span><span id="line-4509"></span><span class="hs-comment">-- | lstmCell</span><span>
</span><span id="line-4510"></span><span class="hs-comment">--</span><span>
</span><span id="line-4511"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ lstmCell (ones :: CPUTensor 'D.Float '[12,2]) (ones :: CPUTensor 'D.Float '[12,3]) (ones :: CPUTensor 'D.Float '[12]) (ones :: CPUTensor 'D.Float '[12]) ((ones :: CPUTensor 'D.Float '[2,3]), (ones :: CPUTensor 'D.Float '[2,3])) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-4512"></span><span class="hs-comment">-- (Float,[2,3])</span><span>
</span><span id="line-4513"></span><span class="annot"><a href="Torch.Typed.Functional.html#lstmCell"><span class="hs-identifier hs-type">lstmCell</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4514"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708326"><span class="annot"><a href="#local-6989586621679708326"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708325"><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708324"><span class="annot"><a href="#local-6989586621679708324"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708323"><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708322"><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4515"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708326"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4516"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4517"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4518"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4519"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708324"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-4520"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708324"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4521"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4522"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708324"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708326"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4523"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708324"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-4524"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708324"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4525"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-4526"></span><span id="lstmCell"><span class="annot"><span class="annottext">lstmCell :: Tensor device dtype '[4 * hiddenSize, inputSize]
-&gt; Tensor device dtype '[4 * hiddenSize, hiddenSize]
-&gt; Tensor device dtype '[4 * hiddenSize]
-&gt; Tensor device dtype '[4 * hiddenSize]
-&gt; (Tensor device dtype '[batchSize, hiddenSize],
    Tensor device dtype '[batchSize, hiddenSize])
-&gt; Tensor device dtype '[batchSize, inputSize]
-&gt; (Tensor device dtype '[batchSize, hiddenSize],
    Tensor device dtype '[batchSize, hiddenSize])
</span><a href="Torch.Typed.Functional.html#lstmCell"><span class="hs-identifier hs-var hs-var">lstmCell</span></a></span></span><span> </span><span id="local-6989586621679708321"><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, inputSize]
</span><a href="#local-6989586621679708321"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span id="local-6989586621679708320"><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, hiddenSize]
</span><a href="#local-6989586621679708320"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span id="local-6989586621679708319"><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize]
</span><a href="#local-6989586621679708319"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span id="local-6989586621679708318"><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize]
</span><a href="#local-6989586621679708318"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708317"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, hiddenSize]
</span><a href="#local-6989586621679708317"><span class="hs-identifier hs-var">cc</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679708316"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, hiddenSize]
</span><a href="#local-6989586621679708316"><span class="hs-identifier hs-var">hc</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708315"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputSize]
</span><a href="#local-6989586621679708315"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4527"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype '[batchSize, hiddenSize],
   Tensor device dtype '[batchSize, hiddenSize])
-&gt; (Tensor device dtype '[batchSize, hiddenSize],
    Tensor device dtype '[batchSize, hiddenSize])
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype '[batchSize, hiddenSize],
    Tensor device dtype '[batchSize, hiddenSize])
 -&gt; (Tensor device dtype '[batchSize, hiddenSize],
     Tensor device dtype '[batchSize, hiddenSize]))
-&gt; IO
     (Tensor device dtype '[batchSize, hiddenSize],
      Tensor device dtype '[batchSize, hiddenSize])
-&gt; (Tensor device dtype '[batchSize, hiddenSize],
    Tensor device dtype '[batchSize, hiddenSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-4528"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorList
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype '[batchSize, inputSize]
-&gt; [Tensor device dtype '[batchSize, hiddenSize]]
-&gt; Tensor device dtype '[4 * hiddenSize, inputSize]
-&gt; Tensor device dtype '[4 * hiddenSize, hiddenSize]
-&gt; Tensor device dtype '[4 * hiddenSize]
-&gt; Tensor device dtype '[4 * hiddenSize]
-&gt; IO
     (Tensor device dtype '[batchSize, hiddenSize],
      Tensor device dtype '[batchSize, hiddenSize])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorList
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.lstm_cell_tltttt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputSize]
</span><a href="#local-6989586621679708315"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor device dtype '[batchSize, hiddenSize]]
</span><a href="#local-6989586621679708313"><span class="hs-identifier hs-var">hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, inputSize]
</span><a href="#local-6989586621679708321"><span class="hs-identifier hs-var">wi</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, hiddenSize]
</span><a href="#local-6989586621679708320"><span class="hs-identifier hs-var">wh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize]
</span><a href="#local-6989586621679708319"><span class="hs-identifier hs-var">bi</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize]
</span><a href="#local-6989586621679708318"><span class="hs-identifier hs-var">bh</span></a></span><span>
</span><span id="line-4529"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-4530"></span><span>    </span><span id="local-6989586621679708313"><span class="annot"><span class="annottext">hx :: [Tensor device dtype '[batchSize, hiddenSize]]
</span><a href="#local-6989586621679708313"><span class="hs-identifier hs-var hs-var">hx</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, hiddenSize]
</span><a href="#local-6989586621679708317"><span class="hs-identifier hs-var">cc</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, hiddenSize]
</span><a href="#local-6989586621679708316"><span class="hs-identifier hs-var">hc</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708323"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708324"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708325"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">]</span><span>
</span><span id="line-4531"></span><span>
</span><span id="line-4532"></span><span class="hs-keyword">type</span><span> </span><span id="GRUWIShape"><span class="annot"><a href="Torch.Typed.Functional.html#GRUWIShape"><span class="hs-identifier hs-var">GRUWIShape</span></a></span></span><span> </span><span id="local-6989586621679708311"><span class="annot"><a href="#local-6989586621679708311"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708310"><span class="annot"><a href="#local-6989586621679708310"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708311"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708310"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4533"></span><span>
</span><span id="line-4534"></span><span class="hs-keyword">type</span><span> </span><span id="GRUWHShape"><span class="annot"><a href="Torch.Typed.Functional.html#GRUWHShape"><span class="hs-identifier hs-var">GRUWHShape</span></a></span></span><span> </span><span id="local-6989586621679708308"><span class="annot"><a href="#local-6989586621679708308"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708307"><span class="annot"><a href="#local-6989586621679708307"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708308"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708308"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4535"></span><span>
</span><span id="line-4536"></span><span class="hs-keyword">type</span><span> </span><span id="GRUBIShape"><span class="annot"><a href="Torch.Typed.Functional.html#GRUBIShape"><span class="hs-identifier hs-var">GRUBIShape</span></a></span></span><span> </span><span id="local-6989586621679708305"><span class="annot"><a href="#local-6989586621679708305"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708304"><span class="annot"><a href="#local-6989586621679708304"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708305"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4537"></span><span>
</span><span id="line-4538"></span><span class="hs-keyword">type</span><span> </span><span id="GRUBHShape"><span class="annot"><a href="Torch.Typed.Functional.html#GRUBHShape"><span class="hs-identifier hs-var">GRUBHShape</span></a></span></span><span> </span><span id="local-6989586621679708302"><span class="annot"><a href="#local-6989586621679708302"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708301"><span class="annot"><a href="#local-6989586621679708301"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708302"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4539"></span><span>
</span><span id="line-4540"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="GRURImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-var">GRURImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708299"><span class="annot"><a href="#local-6989586621679708299"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708298"><span class="annot"><a href="#local-6989586621679708298"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708297"><span class="annot"><a href="#local-6989586621679708297"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708296"><span class="annot"><a href="#local-6989586621679708296"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4541"></span><span>  </span><span id="GRURImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-var">GRURImpl</span></a></span></span><span> </span><span id="local-6989586621679708295"><span class="annot"><a href="#local-6989586621679708295"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708294"><span class="annot"><a href="#local-6989586621679708294"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4542"></span><span>    </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWIShape"><span class="hs-identifier hs-type">GRUWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708294"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708295"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4543"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWHShape"><span class="hs-identifier hs-type">GRUWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708294"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708295"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4544"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBIShape"><span class="hs-identifier hs-type">GRUBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708294"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708295"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4545"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBHShape"><span class="hs-identifier hs-type">GRUBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708294"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708295"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-4546"></span><span>     </span><span class="hs-special">]</span><span>
</span><span id="line-4547"></span><span>  </span><span id="GRURImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-var">GRURImpl</span></a></span></span><span> </span><span id="local-6989586621679708293"><span class="annot"><a href="#local-6989586621679708293"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708292"><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708291"><span class="annot"><a href="#local-6989586621679708291"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4548"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-type">GRURImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708293"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708291"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span>
</span><span id="line-4549"></span><span>      </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWIShape"><span class="hs-identifier hs-type">GRUWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4550"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWHShape"><span class="hs-identifier hs-type">GRUWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4551"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBIShape"><span class="hs-identifier hs-type">GRUBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4552"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBHShape"><span class="hs-identifier hs-type">GRUBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708292"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4553"></span><span>          </span><span class="hs-special">]</span><span>
</span><span id="line-4554"></span><span>  </span><span id="GRURImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-var">GRURImpl</span></a></span></span><span> </span><span id="local-6989586621679708290"><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708289"><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4555"></span><span>    </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWIShape"><span class="hs-identifier hs-type">GRUWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4556"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWHShape"><span class="hs-identifier hs-type">GRUWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4557"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBIShape"><span class="hs-identifier hs-type">GRUBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4558"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBHShape"><span class="hs-identifier hs-type">GRUBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4559"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWIShape"><span class="hs-identifier hs-type">GRUWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4560"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWHShape"><span class="hs-identifier hs-type">GRUWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4561"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBIShape"><span class="hs-identifier hs-type">GRUBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4562"></span><span>       </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBHShape"><span class="hs-identifier hs-type">GRUBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708289"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708290"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-4563"></span><span>     </span><span class="hs-special">]</span><span>
</span><span id="line-4564"></span><span>  </span><span id="GRURImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-var">GRURImpl</span></a></span></span><span> </span><span id="local-6989586621679708288"><span class="annot"><a href="#local-6989586621679708288"><span class="hs-identifier hs-type hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708287"><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708286"><span class="annot"><a href="#local-6989586621679708286"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4565"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-type">GRURImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708288"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708286"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span>
</span><span id="line-4566"></span><span>      </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWIShape"><span class="hs-identifier hs-type">GRUWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4567"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWHShape"><span class="hs-identifier hs-type">GRUWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4568"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBIShape"><span class="hs-identifier hs-type">GRUBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4569"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBHShape"><span class="hs-identifier hs-type">GRUBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4570"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWIShape"><span class="hs-identifier hs-type">GRUWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4571"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUWHShape"><span class="hs-identifier hs-type">GRUWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4572"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBIShape"><span class="hs-identifier hs-type">GRUBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4573"></span><span>            </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUBHShape"><span class="hs-identifier hs-type">GRUBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708287"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4574"></span><span>          </span><span class="hs-special">]</span><span>
</span><span id="line-4575"></span><span>
</span><span id="line-4576"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="GRUR%27"><span class="annot"><a href="Torch.Typed.Functional.html#GRUR%27"><span class="hs-identifier hs-var">GRUR'</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708284"><span class="annot"><a href="#local-6989586621679708284"><span class="hs-identifier hs-type">shapes</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708283"><span class="annot"><a href="#local-6989586621679708283"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708282"><span class="annot"><a href="#local-6989586621679708282"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708281"><span class="annot"><a href="#local-6989586621679708281"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4577"></span><span>  </span><span id="GRUR%27"><span class="annot"><a href="Torch.Typed.Functional.html#GRUR%27"><span class="hs-identifier hs-var">GRUR'</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679708280"><span class="annot"><a href="#local-6989586621679708280"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708279"><span class="annot"><a href="#local-6989586621679708279"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-4578"></span><span>  </span><span id="GRUR%27"><span class="annot"><a href="Torch.Typed.Functional.html#GRUR%27"><span class="hs-identifier hs-var">GRUR'</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708278"><span class="annot"><a href="#local-6989586621679708278"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708277"><span class="annot"><a href="#local-6989586621679708277"><span class="hs-identifier hs-type hs-type">shapes</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708276"><span class="annot"><a href="#local-6989586621679708276"><span class="hs-identifier hs-type hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708275"><span class="annot"><a href="#local-6989586621679708275"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708275"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708276"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708278"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUR%27"><span class="hs-identifier hs-type">GRUR'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708277"><span class="hs-identifier hs-type">shapes</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708276"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708275"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-4579"></span><span>
</span><span id="line-4580"></span><span class="hs-keyword">type</span><span> </span><span id="GRUR"><span class="annot"><a href="Torch.Typed.Functional.html#GRUR"><span class="hs-identifier hs-var">GRUR</span></a></span></span><span> </span><span id="local-6989586621679708273"><span class="annot"><a href="#local-6989586621679708273"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708272"><span class="annot"><a href="#local-6989586621679708272"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708271"><span class="annot"><a href="#local-6989586621679708271"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679708270"><span class="annot"><a href="#local-6989586621679708270"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span id="local-6989586621679708269"><span class="annot"><a href="#local-6989586621679708269"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708268"><span class="annot"><a href="#local-6989586621679708268"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUR%27"><span class="hs-identifier hs-type">GRUR'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#GRURImpl"><span class="hs-identifier hs-type">GRURImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708273"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708272"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708271"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708270"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708269"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708268"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-4581"></span><span>
</span><span id="line-4582"></span><span class="hs-comment">-- | gru</span><span>
</span><span id="line-4583"></span><span class="hs-comment">-- Parameters for this ATen function are non-trivially provided.  See the</span><span>
</span><span id="line-4584"></span><span class="hs-comment">-- `Typed.NN.GRU` module for doctests.</span><span>
</span><span id="line-4585"></span><span class="annot"><a href="Torch.Typed.Functional.html#gru"><span class="hs-identifier hs-type">gru</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4586"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-4587"></span><span>    </span><span id="local-6989586621679708266"><span class="annot"><a href="#local-6989586621679708266"><span class="hs-identifier hs-type">shapeOrder</span></a></span></span><span>
</span><span id="line-4588"></span><span>    </span><span id="local-6989586621679708265"><span class="annot"><a href="#local-6989586621679708265"><span class="hs-identifier hs-type">directionality</span></a></span></span><span>
</span><span id="line-4589"></span><span>    </span><span id="local-6989586621679708264"><span class="annot"><a href="#local-6989586621679708264"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span>
</span><span id="line-4590"></span><span>    </span><span id="local-6989586621679708263"><span class="annot"><a href="#local-6989586621679708263"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span>
</span><span id="line-4591"></span><span>    </span><span id="local-6989586621679708262"><span class="annot"><a href="#local-6989586621679708262"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-4592"></span><span>    </span><span id="local-6989586621679708261"><span class="annot"><a href="#local-6989586621679708261"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span>
</span><span id="line-4593"></span><span>    </span><span id="local-6989586621679708260"><span class="annot"><a href="#local-6989586621679708260"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-4594"></span><span>    </span><span id="local-6989586621679708259"><span class="annot"><a href="#local-6989586621679708259"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span>
</span><span id="line-4595"></span><span>    </span><span id="local-6989586621679708258"><span class="annot"><a href="#local-6989586621679708258"><span class="hs-identifier hs-type">inputShape</span></a></span></span><span>
</span><span id="line-4596"></span><span>    </span><span id="local-6989586621679708257"><span class="annot"><a href="#local-6989586621679708257"><span class="hs-identifier hs-type">outputShape</span></a></span></span><span>
</span><span id="line-4597"></span><span>    </span><span id="local-6989586621679708256"><span class="annot"><a href="#local-6989586621679708256"><span class="hs-identifier hs-type">hcShape</span></a></span></span><span>
</span><span id="line-4598"></span><span>    </span><span id="local-6989586621679708255"><span class="annot"><a href="#local-6989586621679708255"><span class="hs-identifier hs-type">tensorParameters</span></a></span></span><span>
</span><span id="line-4599"></span><span>    </span><span id="local-6989586621679708254"><span class="annot"><a href="#local-6989586621679708254"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-4600"></span><span>    </span><span id="local-6989586621679708253"><span class="annot"><a href="#local-6989586621679708253"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4601"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708264"><span class="hs-identifier hs-type">numLayers</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4602"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNShapeOrder"><span class="hs-identifier hs-type">KnownRNNShapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708266"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4603"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNDirectionality"><span class="hs-identifier hs-type">KnownRNNDirectionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708265"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4604"></span><span>    </span><span class="annot"><a href="#local-6989586621679708260"><span class="hs-identifier hs-type">outputSize</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708259"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708265"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4605"></span><span>    </span><span class="annot"><a href="#local-6989586621679708258"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708266"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708263"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708262"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708261"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4606"></span><span>    </span><span class="annot"><a href="#local-6989586621679708257"><span class="hs-identifier hs-type">outputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708266"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708263"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708262"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708260"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4607"></span><span>    </span><span class="annot"><a href="#local-6989586621679708256"><span class="hs-identifier hs-type">hcShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708264"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708265"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708262"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708259"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-4608"></span><span>    </span><span class="annot"><a href="#local-6989586621679708255"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GRUR"><span class="hs-identifier hs-type">GRUR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708261"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708259"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708264"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708265"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708254"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708253"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4609"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708255"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4610"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4611"></span><span>  </span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708255"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4612"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4613"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4614"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708253"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708254"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708256"><span class="hs-identifier hs-type">hcShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4615"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708253"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708254"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708258"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4616"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708253"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708254"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708257"><span class="hs-identifier hs-type">outputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-4617"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708253"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708254"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708256"><span class="hs-identifier hs-type">hcShape</span></a></span><span>
</span><span id="line-4618"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-4619"></span><span id="gru"><span class="annot"><span class="annottext">gru :: HList tensorParameters
-&gt; Double
-&gt; Bool
-&gt; Tensor device dtype hcShape
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hcShape)
</span><a href="Torch.Typed.Functional.html#gru"><span class="hs-identifier hs-var hs-var">gru</span></a></span></span><span> </span><span id="local-6989586621679708252"><span class="annot"><span class="annottext">HList tensorParameters
</span><a href="#local-6989586621679708252"><span class="hs-identifier hs-var">tensorParameters</span></a></span></span><span> </span><span id="local-6989586621679708251"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708251"><span class="hs-identifier hs-var">dropoutProb</span></a></span></span><span> </span><span id="local-6989586621679708250"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708250"><span class="hs-identifier hs-var">dropoutOn</span></a></span></span><span> </span><span id="local-6989586621679708249"><span class="annot"><span class="annottext">Tensor device dtype hcShape
</span><a href="#local-6989586621679708249"><span class="hs-identifier hs-var">hc</span></a></span></span><span> </span><span id="local-6989586621679708248"><span class="annot"><span class="annottext">Tensor device dtype inputShape
</span><a href="#local-6989586621679708248"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4620"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype outputShape, Tensor device dtype hcShape)
-&gt; (Tensor device dtype outputShape, Tensor device dtype hcShape)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype outputShape, Tensor device dtype hcShape)
 -&gt; (Tensor device dtype outputShape, Tensor device dtype hcShape))
-&gt; IO
     (Tensor device dtype outputShape, Tensor device dtype hcShape)
-&gt; (Tensor device dtype outputShape, Tensor device dtype hcShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-4621"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr TensorList
 -&gt; CBool
 -&gt; Int64
 -&gt; CDouble
 -&gt; CBool
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype inputShape
-&gt; Tensor device dtype hcShape
-&gt; HList tensorParameters
-&gt; Bool
-&gt; Int64
-&gt; Double
-&gt; Bool
-&gt; Bool
-&gt; Bool
-&gt; IO
     (Tensor device dtype outputShape, Tensor device dtype hcShape)
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 x7 cx7 x8 cx8
       y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6, Castable x7 cx7,
 Castable x8 cx8, Castable y cy) =&gt;
(ca
 -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; cx7 -&gt; cx8 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; x7 -&gt; x8 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast9</span></a></span><span>
</span><span id="line-4622"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr TensorList
-&gt; CBool
-&gt; Int64
-&gt; CDouble
-&gt; CBool
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.gru_ttlbldbbb</span></a></span><span>
</span><span id="line-4623"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype inputShape
</span><a href="#local-6989586621679708248"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4624"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype hcShape
</span><a href="#local-6989586621679708249"><span class="hs-identifier hs-var">hc</span></a></span><span>
</span><span id="line-4625"></span><span>      </span><span class="annot"><span class="annottext">HList tensorParameters
</span><a href="#local-6989586621679708252"><span class="hs-identifier hs-var">tensorParameters</span></a></span><span>
</span><span id="line-4626"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708246"><span class="hs-identifier hs-var">hasBiases</span></a></span><span>
</span><span id="line-4627"></span><span>      </span><span class="annot"><span class="annottext">Int64
</span><a href="#local-6989586621679708245"><span class="hs-identifier hs-var">numLayers</span></a></span><span>
</span><span id="line-4628"></span><span>      </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679708251"><span class="hs-identifier hs-var">dropoutProb</span></a></span><span>
</span><span id="line-4629"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708250"><span class="hs-identifier hs-var">dropoutOn</span></a></span><span>
</span><span id="line-4630"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownRNNDirectionality directionality =&gt; Bool
forall (directionality :: RNNDirectionality).
KnownRNNDirectionality directionality =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#rnnBidirectional"><span class="hs-identifier hs-var">rnnBidirectional</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708265"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4631"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownRNNShapeOrder shapeOrder =&gt; Bool
forall (shapeOrder :: RNNShapeOrder).
KnownRNNShapeOrder shapeOrder =&gt;
Bool
</span><a href="Torch.Typed.Functional.html#rnnBatchFirst"><span class="hs-identifier hs-var">rnnBatchFirst</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708266"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4632"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-4633"></span><span>    </span><span id="local-6989586621679708246"><span class="annot"><span class="annottext">hasBiases :: Bool
</span><a href="#local-6989586621679708246"><span class="hs-identifier hs-var hs-var">hasBiases</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-4634"></span><span>    </span><span class="annot"><a href="#local-6989586621679708245"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">I.Int64</span></span><span>
</span><span id="line-4635"></span><span>    </span><span id="local-6989586621679708245"><span class="annot"><span class="annottext">numLayers :: Int64
</span><a href="#local-6989586621679708245"><span class="hs-identifier hs-var hs-var">numLayers</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int64
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int64) -&gt; Int -&gt; Int64
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat numLayers =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708264"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-4636"></span><span>
</span><span id="line-4637"></span><span class="hs-comment">-- | gruCell</span><span>
</span><span id="line-4638"></span><span class="hs-comment">--</span><span>
</span><span id="line-4639"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ gruCell (ones :: CPUTensor 'D.Float '[9,2]) (ones :: CPUTensor 'D.Float '[9,3]) (ones :: CPUTensor 'D.Float '[9]) (ones :: CPUTensor 'D.Float '[9]) (ones :: CPUTensor 'D.Float '[2,3]) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-4640"></span><span class="hs-comment">-- (Float,[2,3])</span><span>
</span><span id="line-4641"></span><span class="annot"><a href="Torch.Typed.Functional.html#gruCell"><span class="hs-identifier hs-type">gruCell</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4642"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708243"><span class="annot"><a href="#local-6989586621679708243"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679708242"><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679708241"><span class="annot"><a href="#local-6989586621679708241"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679708240"><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708239"><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4643"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708243"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4644"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4645"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4646"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4647"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708241"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4648"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708241"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708243"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4649"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708240"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708241"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708242"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4650"></span><span id="gruCell"><span class="annot"><span class="annottext">gruCell :: Tensor device dtype '[3 * hiddenSize, inputSize]
-&gt; Tensor device dtype '[3 * hiddenSize, hiddenSize]
-&gt; Tensor device dtype '[3 * hiddenSize]
-&gt; Tensor device dtype '[3 * hiddenSize]
-&gt; Tensor device dtype '[batchSize, hiddenSize]
-&gt; Tensor device dtype '[batchSize, inputSize]
-&gt; Tensor device dtype '[batchSize, hiddenSize]
</span><a href="Torch.Typed.Functional.html#gruCell"><span class="hs-identifier hs-var hs-var">gruCell</span></a></span></span><span> </span><span id="local-6989586621679708238"><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize, inputSize]
</span><a href="#local-6989586621679708238"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span id="local-6989586621679708237"><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize, hiddenSize]
</span><a href="#local-6989586621679708237"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span id="local-6989586621679708236"><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize]
</span><a href="#local-6989586621679708236"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span id="local-6989586621679708235"><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize]
</span><a href="#local-6989586621679708235"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span id="local-6989586621679708234"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, hiddenSize]
</span><a href="#local-6989586621679708234"><span class="hs-identifier hs-var">hx</span></a></span></span><span> </span><span id="local-6989586621679708233"><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputSize]
</span><a href="#local-6989586621679708233"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4651"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[batchSize, hiddenSize])
-&gt; Tensor device dtype '[batchSize, hiddenSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[batchSize, hiddenSize])
 -&gt; Tensor device dtype '[batchSize, hiddenSize])
-&gt; IO (Tensor device dtype '[batchSize, hiddenSize])
-&gt; Tensor device dtype '[batchSize, hiddenSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-4652"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype '[batchSize, inputSize]
-&gt; Tensor device dtype '[batchSize, hiddenSize]
-&gt; Tensor device dtype '[3 * hiddenSize, inputSize]
-&gt; Tensor device dtype '[3 * hiddenSize, hiddenSize]
-&gt; Tensor device dtype '[3 * hiddenSize]
-&gt; Tensor device dtype '[3 * hiddenSize]
-&gt; IO (Tensor device dtype '[batchSize, hiddenSize])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast6</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.gru_cell_tttttt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, inputSize]
</span><a href="#local-6989586621679708233"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[batchSize, hiddenSize]
</span><a href="#local-6989586621679708234"><span class="hs-identifier hs-var">hx</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize, inputSize]
</span><a href="#local-6989586621679708238"><span class="hs-identifier hs-var">wi</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize, hiddenSize]
</span><a href="#local-6989586621679708237"><span class="hs-identifier hs-var">wh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize]
</span><a href="#local-6989586621679708236"><span class="hs-identifier hs-var">bi</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[3 * hiddenSize]
</span><a href="#local-6989586621679708235"><span class="hs-identifier hs-var">bh</span></a></span><span>
</span><span id="line-4653"></span><span>
</span><span id="line-4654"></span><span class="hs-comment">-- rnn_tanh_cell :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4655"></span><span class="hs-comment">-- rnn_tanh_cell _input _hx _w_ih _w_hh _b_ih _b_hh = unsafePerformIO $ (ATen.cast6 ATen.Managed.rnn_tanh_cell_tttttt) _input _hx _w_ih _w_hh _b_ih _b_hh</span><span>
</span><span id="line-4656"></span><span>
</span><span id="line-4657"></span><span class="hs-comment">-- rnn_relu_cell :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4658"></span><span class="hs-comment">-- rnn_relu_cell _input _hx _w_ih _w_hh _b_ih _b_hh = unsafePerformIO $ (ATen.cast6 ATen.Managed.rnn_relu_cell_tttttt) _input _hx _w_ih _w_hh _b_ih _b_hh</span><span>
</span><span id="line-4659"></span><span>
</span><span id="line-4660"></span><span class="hs-comment">-- quantized_lstm :: Tensor device dtype shape -&gt; [Tensor device dtype shape] -&gt; [Tensor device dtype shape] -&gt; Bool -&gt; Int -&gt; Double -&gt; Bool -&gt; Bool -&gt; Bool -&gt; DType -&gt; (Tensor device dtype shape,Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4661"></span><span class="hs-comment">-- quantized_lstm _input _hx _params _has_biases _num_layers _dropout _train _bidirectional _batch_first _dtype = unsafePerformIO $ (ATen.ATen.cast10 ATen.Managed.quantized_lstm_tllbldbbbs) _input _hx _params _has_biases _num_layers _dropout _train _bidirectional _batch_first _dtype</span><span>
</span><span id="line-4662"></span><span>
</span><span id="line-4663"></span><span class="hs-comment">-- quantized_lstm_cell :: Tensor device dtype shape -&gt; [Tensor device dtype shape] -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Float -&gt; Float -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4664"></span><span class="hs-comment">-- quantized_lstm_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (ATen.ATen.cast14 ATen.Managed.quantized_lstm_cell_tlttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh</span><span>
</span><span id="line-4665"></span><span>
</span><span id="line-4666"></span><span class="hs-comment">-- quantized_gru_cell :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4667"></span><span class="hs-comment">-- quantized_gru_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (ATen.ATen.cast14 ATen.Managed.quantized_gru_cell_ttttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh</span><span>
</span><span id="line-4668"></span><span>
</span><span id="line-4669"></span><span class="hs-comment">-- quantized_rnn_relu_cell :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4670"></span><span class="hs-comment">-- quantized_rnn_relu_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (ATen.ATen.cast14 ATen.Managed.quantized_rnn_relu_cell_ttttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh</span><span>
</span><span id="line-4671"></span><span>
</span><span id="line-4672"></span><span class="hs-comment">-- quantized_rnn_tanh_cell :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4673"></span><span class="hs-comment">-- quantized_rnn_tanh_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (ATen.ATen.cast14 ATen.Managed.quantized_rnn_tanh_cell_ttttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh</span><span>
</span><span id="line-4674"></span><span>
</span><span id="line-4675"></span><span class="hs-comment">-- masked_scatter :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4676"></span><span class="hs-comment">-- masked_scatter _input _mask _source = unsafePerformIO $ (ATen.cast3 ATen.Managed.masked_scatter_ttt) _input _mask _source</span><span>
</span><span id="line-4677"></span><span>
</span><span id="line-4678"></span><span class="hs-comment">-- index_add :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4679"></span><span class="hs-comment">-- index_add _input _dim _index _source = unsafePerformIO $ (ATen.cast4 ATen.Managed.index_add_tltt) _input _dim _index _source</span><span>
</span><span id="line-4680"></span><span>
</span><span id="line-4681"></span><span class="hs-comment">-- scatter_add :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4682"></span><span class="hs-comment">-- scatter_add _input _dim _index _src = unsafePerformIO $ (ATen.cast4 ATen.Managed.scatter_add_tltt) _input _dim _index _src</span><span>
</span><span id="line-4683"></span><span>
</span><span id="line-4684"></span><span class="hs-comment">-- addbmm :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4685"></span><span class="hs-comment">-- addbmm _input _batch1 _batch2 _beta _alpha = unsafePerformIO $ (ATen.cast5 ATen.Managed.addbmm_tttss) _input _batch1 _batch2 _beta _alpha</span><span>
</span><span id="line-4686"></span><span>
</span><span id="line-4687"></span><span class="hs-comment">-- cross :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4688"></span><span class="hs-comment">-- cross _input _other _dim = unsafePerformIO $ (ATen.cast3 ATen.Managed.cross_ttl) _input _other _dim</span><span>
</span><span id="line-4689"></span><span>
</span><span id="line-4690"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MatrixOrMatrixBatch"><span class="annot"><a href="Torch.Typed.Functional.html#MatrixOrMatrixBatch"><span class="hs-identifier hs-var">MatrixOrMatrixBatch</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708230"><span class="annot"><a href="#local-6989586621679708230"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4691"></span><span>  </span><span id="MatrixOrMatrixBatch"><span class="annot"><a href="Torch.Typed.Functional.html#MatrixOrMatrixBatch"><span class="hs-identifier hs-var">MatrixOrMatrixBatch</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708229"><span class="annot"><a href="#local-6989586621679708229"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679708228"><span class="annot"><a href="#local-6989586621679708228"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708229"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708228"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4692"></span><span>  </span><span id="MatrixOrMatrixBatch"><span class="annot"><a href="Torch.Typed.Functional.html#MatrixOrMatrixBatch"><span class="hs-identifier hs-var">MatrixOrMatrixBatch</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708227"><span class="annot"><a href="#local-6989586621679708227"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679708226"><span class="annot"><a href="#local-6989586621679708226"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679708225"><span class="annot"><a href="#local-6989586621679708225"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708227"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708226"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708225"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-4693"></span><span>  </span><span id="MatrixOrMatrixBatch"><span class="annot"><a href="Torch.Typed.Functional.html#MatrixOrMatrixBatch"><span class="hs-identifier hs-var">MatrixOrMatrixBatch</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;The input must be matrix or a batch of matrices.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-4694"></span><span>
</span><span id="line-4695"></span><span class="hs-comment">-- | triu</span><span>
</span><span id="line-4696"></span><span class="hs-comment">-- TODO: triu is not implemented for D.Bool, or maybe numeric type is lifted?</span><span>
</span><span id="line-4697"></span><span class="hs-comment">--</span><span>
</span><span id="line-4698"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3, 4]</span><span>
</span><span id="line-4699"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ triu 0 t</span><span>
</span><span id="line-4700"></span><span class="hs-comment">-- (Float,([3,4],[[1.0,1.0,1.0,1.0],[0.0,1.0,1.0,1.0],[0.0,0.0,1.0,1.0]]))</span><span>
</span><span id="line-4701"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ triu 1 t</span><span>
</span><span id="line-4702"></span><span class="hs-comment">-- (Float,([3,4],[[0.0,1.0,1.0,1.0],[0.0,0.0,1.0,1.0],[0.0,0.0,0.0,1.0]]))</span><span>
</span><span id="line-4703"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ triu (-1) t</span><span>
</span><span id="line-4704"></span><span class="hs-comment">-- (Float,([3,4],[[1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0],[0.0,1.0,1.0,1.0]]))</span><span>
</span><span id="line-4705"></span><span class="annot"><a href="Torch.Typed.Functional.html#triu"><span class="hs-identifier hs-type">triu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4706"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708223"><span class="annot"><a href="#local-6989586621679708223"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708222"><span class="annot"><a href="#local-6989586621679708222"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708221"><span class="annot"><a href="#local-6989586621679708221"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4707"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708223"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#MatrixOrMatrixBatch"><span class="hs-identifier hs-type">MatrixOrMatrixBatch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708223"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4708"></span><span>  </span><span class="hs-comment">-- | diagonal</span><span>
</span><span id="line-4709"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4710"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4711"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708221"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708222"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708223"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4712"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4713"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708221"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708222"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708223"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4714"></span><span id="triu"><span class="annot"><span class="annottext">triu :: Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#triu"><span class="hs-identifier hs-var hs-var">triu</span></a></span></span><span> </span><span id="local-6989586621679708220"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708220"><span class="hs-identifier hs-var">diagonal</span></a></span></span><span> </span><span id="local-6989586621679708219"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708219"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.triu_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708219"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708220"><span class="hs-identifier hs-var">diagonal</span></a></span><span>
</span><span id="line-4715"></span><span>
</span><span id="line-4716"></span><span class="hs-comment">-- | tril</span><span>
</span><span id="line-4717"></span><span class="hs-comment">-- TODO: tril is not implemented for D.Bool, or maybe numeric type is lifted?</span><span>
</span><span id="line-4718"></span><span class="hs-comment">--</span><span>
</span><span id="line-4719"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3, 4]</span><span>
</span><span id="line-4720"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ tril 0 t</span><span>
</span><span id="line-4721"></span><span class="hs-comment">-- (Float,([3,4],[[1.0,0.0,0.0,0.0],[1.0,1.0,0.0,0.0],[1.0,1.0,1.0,0.0]]))</span><span>
</span><span id="line-4722"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ tril 1 t</span><span>
</span><span id="line-4723"></span><span class="hs-comment">-- (Float,([3,4],[[1.0,1.0,0.0,0.0],[1.0,1.0,1.0,0.0],[1.0,1.0,1.0,1.0]]))</span><span>
</span><span id="line-4724"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t' -&gt; D.asValue (toDynamic t') :: [[Float]]) $ tril (-1) t</span><span>
</span><span id="line-4725"></span><span class="hs-comment">-- (Float,([3,4],[[0.0,0.0,0.0,0.0],[1.0,0.0,0.0,0.0],[1.0,1.0,0.0,0.0]]))</span><span>
</span><span id="line-4726"></span><span class="annot"><a href="Torch.Typed.Functional.html#tril"><span class="hs-identifier hs-type">tril</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4727"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708216"><span class="annot"><a href="#local-6989586621679708216"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708215"><span class="annot"><a href="#local-6989586621679708215"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708214"><span class="annot"><a href="#local-6989586621679708214"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4728"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708216"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#MatrixOrMatrixBatch"><span class="hs-identifier hs-type">MatrixOrMatrixBatch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708216"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4729"></span><span>  </span><span class="hs-comment">-- | diagonal</span><span>
</span><span id="line-4730"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4731"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4732"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708214"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708215"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708216"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4733"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4734"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708214"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708215"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708216"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4735"></span><span id="tril"><span class="annot"><span class="annottext">tril :: Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#tril"><span class="hs-identifier hs-var hs-var">tril</span></a></span></span><span> </span><span id="local-6989586621679708213"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708213"><span class="hs-identifier hs-var">diagonal</span></a></span></span><span> </span><span id="local-6989586621679708212"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708212"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.tril_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708212"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708213"><span class="hs-identifier hs-var">diagonal</span></a></span><span>
</span><span id="line-4736"></span><span>
</span><span id="line-4737"></span><span class="hs-comment">-- | trace</span><span>
</span><span id="line-4738"></span><span class="hs-comment">--</span><span>
</span><span id="line-4739"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ trace (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4740"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4741"></span><span class="annot"><a href="Torch.Typed.Functional.html#trace"><span class="hs-identifier hs-type">trace</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4742"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708209"><span class="annot"><a href="#local-6989586621679708209"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708208"><span class="annot"><a href="#local-6989586621679708208"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708207"><span class="annot"><a href="#local-6989586621679708207"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4743"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4744"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708207"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708208"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708209"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4745"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4746"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708207"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708208"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708209"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4747"></span><span id="trace"><span class="annot"><span class="annottext">trace :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#trace"><span class="hs-identifier hs-var hs-var">trace</span></a></span></span><span> </span><span id="local-6989586621679708206"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708206"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.trace_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708206"><span class="hs-identifier hs-var">_input</span></a></span><span>
</span><span id="line-4748"></span><span>
</span><span id="line-4749"></span><span class="hs-comment">-- take :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4750"></span><span class="hs-comment">-- take _input _index = unsafePerformIO $ (ATen.cast2 ATen.Managed.take_tt) _input _index</span><span>
</span><span id="line-4751"></span><span>
</span><span id="line-4752"></span><span class="hs-comment">-- index_select :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4753"></span><span class="hs-comment">-- index_select _input _dim _index = unsafePerformIO $ (ATen.cast3 ATen.Managed.index_select_tlt) _input _dim _index</span><span>
</span><span id="line-4754"></span><span>
</span><span id="line-4755"></span><span class="annot"><a href="Torch.Typed.Functional.html#maskedSelect"><span class="hs-identifier hs-type">maskedSelect</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4756"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708203"><span class="annot"><a href="#local-6989586621679708203"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708202"><span class="annot"><a href="#local-6989586621679708202"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708201"><span class="annot"><a href="#local-6989586621679708201"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679708200"><span class="annot"><a href="#local-6989586621679708200"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708199"><span class="annot"><a href="#local-6989586621679708199"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4757"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708201"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Broadcast"><span class="hs-identifier hs-type">Broadcast</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708203"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708202"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4758"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708199"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708203"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4759"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708199"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708200"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708202"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4760"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#UnknownShapeTensor"><span class="hs-identifier hs-type">UnknownShapeTensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708199"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708200"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-4761"></span><span id="maskedSelect"><span class="annot"><span class="annottext">maskedSelect :: Tensor device 'Bool shape
-&gt; Tensor device dtype shape' -&gt; UnknownShapeTensor device dtype
</span><a href="Torch.Typed.Functional.html#maskedSelect"><span class="hs-identifier hs-var hs-var">maskedSelect</span></a></span></span><span> </span><span id="local-6989586621679708198"><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679708198"><span class="hs-identifier hs-var">mask</span></a></span></span><span> </span><span id="local-6989586621679708197"><span class="annot"><span class="annottext">Tensor device dtype shape'
</span><a href="#local-6989586621679708197"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype Any -&gt; UnknownShapeTensor device dtype
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Tensor device dtype shape -&gt; UnknownShapeTensor device dtype
</span><a href="Torch.Typed.Tensor.html#UnknownShapeTensor"><span class="hs-identifier hs-var">UnknownShapeTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype Any -&gt; UnknownShapeTensor device dtype)
-&gt; Tensor device dtype Any -&gt; UnknownShapeTensor device dtype
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype Any) -&gt; Tensor device dtype Any
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype Any) -&gt; Tensor device dtype Any)
-&gt; IO (Tensor device dtype Any) -&gt; Tensor device dtype Any
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape'
-&gt; Tensor device 'Bool shape
-&gt; IO (Tensor device dtype Any)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.masked_select_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape'
</span><a href="#local-6989586621679708197"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Bool shape
</span><a href="#local-6989586621679708198"><span class="hs-identifier hs-var">mask</span></a></span><span>
</span><span id="line-4762"></span><span>
</span><span id="line-4763"></span><span class="hs-comment">-- | nonzero</span><span>
</span><span id="line-4764"></span><span class="hs-comment">--</span><span>
</span><span id="line-4765"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nonzero (zeros :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4766"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4767"></span><span class="annot"><a href="Torch.Typed.Functional.html#nonzero"><span class="hs-identifier hs-type">nonzero</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4768"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708193"><span class="annot"><a href="#local-6989586621679708193"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708192"><span class="annot"><a href="#local-6989586621679708192"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708191"><span class="annot"><a href="#local-6989586621679708191"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4769"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4770"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708191"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708192"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708193"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4771"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4772"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708191"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708192"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708193"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4773"></span><span id="nonzero"><span class="annot"><span class="annottext">nonzero :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#nonzero"><span class="hs-identifier hs-var hs-var">nonzero</span></a></span></span><span> </span><span id="local-6989586621679708190"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708190"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.nonzero_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708190"><span class="hs-identifier hs-var">_input</span></a></span><span>
</span><span id="line-4774"></span><span>
</span><span id="line-4775"></span><span class="hs-comment">-- nonzero_numpy :: Tensor device dtype shape -&gt; [Tensor device dtype shape]</span><span>
</span><span id="line-4776"></span><span class="hs-comment">-- nonzero_numpy _input = unsafePerformIO $ (ATen.cast1 ATen.Managed.nonzero_numpy_t) _input</span><span>
</span><span id="line-4777"></span><span>
</span><span id="line-4778"></span><span class="hs-comment">-- | GatherDimImpl</span><span>
</span><span id="line-4779"></span><span class="hs-comment">--</span><span>
</span><span id="line-4780"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! GatherDimImpl '[2, 1, 1] '[2, 4, 1] 1</span><span>
</span><span id="line-4781"></span><span class="hs-comment">-- GatherDimImpl '[2, 1, 1] '[2, 4, 1] 1 :: Maybe [Nat]</span><span>
</span><span id="line-4782"></span><span class="hs-comment">-- = 'Just '[2, 4, 1]</span><span>
</span><span id="line-4783"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! GatherDimImpl '[2, 1, 1] '[2, 4, 2] 1</span><span>
</span><span id="line-4784"></span><span class="hs-comment">-- GatherDimImpl '[2, 1, 1] '[2, 4, 2] 1 :: Maybe [Nat]</span><span>
</span><span id="line-4785"></span><span class="hs-comment">-- = 'Nothing</span><span>
</span><span id="line-4786"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! GatherDimImpl '[2, 1, 1] '[2, 0, 1] 1</span><span>
</span><span id="line-4787"></span><span class="hs-comment">-- GatherDimImpl '[2, 1, 1] '[2, 0, 1] 1 :: Maybe [Nat]</span><span>
</span><span id="line-4788"></span><span class="hs-comment">-- = 'Nothing</span><span>
</span><span id="line-4789"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! GatherDimImpl '[2, 1, 1] '[2, 1] 1</span><span>
</span><span id="line-4790"></span><span class="hs-comment">-- GatherDimImpl '[2, 1, 1] '[2, 1] 1 :: Maybe [Nat]</span><span>
</span><span id="line-4791"></span><span class="hs-comment">-- = 'Nothing</span><span>
</span><span id="line-4792"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! GatherDimImpl '[2, 1, 1] '[2, 1, 3] 2</span><span>
</span><span id="line-4793"></span><span class="hs-comment">-- GatherDimImpl '[2, 1, 1] '[2, 1, 3] 2 :: Maybe [Nat]</span><span>
</span><span id="line-4794"></span><span class="hs-comment">-- = 'Just '[2, 1, 3]</span><span>
</span><span id="line-4795"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="GatherDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimImpl"><span class="hs-identifier hs-var">GatherDimImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708187"><span class="annot"><a href="#local-6989586621679708187"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708186"><span class="annot"><a href="#local-6989586621679708186"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708185"><span class="annot"><a href="#local-6989586621679708185"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4796"></span><span>  </span><span id="GatherDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimImpl"><span class="hs-identifier hs-var">GatherDimImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708184"><span class="annot"><a href="#local-6989586621679708184"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708183"><span class="annot"><a href="#local-6989586621679708183"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708182"><span class="annot"><a href="#local-6989586621679708182"><span class="hs-identifier hs-type hs-type">y</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708183"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#If"><span class="hs-identifier hs-type">If</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=?</span></span><span> </span><span class="annot"><a href="#local-6989586621679708182"><span class="hs-identifier hs-type">y</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708182"><span class="hs-identifier hs-type">y</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708183"><span class="hs-identifier hs-type">xs</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-4797"></span><span>  </span><span id="GatherDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimImpl"><span class="hs-identifier hs-var">GatherDimImpl</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708181"><span class="annot"><a href="#local-6989586621679708181"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708180"><span class="annot"><a href="#local-6989586621679708180"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708181"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679708179"><span class="annot"><a href="#local-6989586621679708179"><span class="hs-identifier hs-type hs-type">ys</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708178"><span class="annot"><a href="#local-6989586621679708178"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#AppendToMaybe"><span class="hs-identifier hs-type">AppendToMaybe</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708181"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimImpl"><span class="hs-identifier hs-type">GatherDimImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708180"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708179"><span class="hs-identifier hs-type">ys</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708178"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-4798"></span><span>  </span><span id="GatherDimImpl"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimImpl"><span class="hs-identifier hs-var">GatherDimImpl</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-4799"></span><span>
</span><span id="line-4800"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="GatherDimCheck"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimCheck"><span class="hs-identifier hs-var">GatherDimCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708176"><span class="annot"><a href="#local-6989586621679708176"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span id="local-6989586621679708175"><span class="annot"><a href="#local-6989586621679708175"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708174"><span class="annot"><a href="#local-6989586621679708174"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708175"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708173"><span class="annot"><a href="#local-6989586621679708173"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708172"><span class="annot"><a href="#local-6989586621679708172"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708175"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708175"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4801"></span><span>  </span><span id="GatherDimCheck"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimCheck"><span class="hs-identifier hs-var">GatherDimCheck</span></a></span></span><span> </span><span id="local-6989586621679708171"><span class="annot"><a href="#local-6989586621679708171"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708170"><span class="annot"><a href="#local-6989586621679708170"><span class="hs-identifier hs-type hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708169"><span class="annot"><a href="#local-6989586621679708169"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-4802"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-4803"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Cannot gather the tensor at dimension &quot;</span></span><span>
</span><span id="line-4804"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708169"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-4805"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot; using index of shape &quot;</span></span><span>
</span><span id="line-4806"></span><span>          </span><span class="annot"><span class="hs-operator hs-type">:&lt;&gt;:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">ShowType</span></span><span> </span><span class="annot"><a href="#local-6989586621679708170"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4807"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-4808"></span><span>  </span><span id="GatherDimCheck"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimCheck"><span class="hs-identifier hs-var">GatherDimCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708168"><span class="annot"><a href="#local-6989586621679708168"><span class="hs-identifier hs-type hs-type">shape''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679708168"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-4809"></span><span>
</span><span id="line-4810"></span><span class="hs-comment">-- | Calculate the output shape of a gather operation for a given index shape along a given axis</span><span>
</span><span id="line-4811"></span><span class="hs-comment">--</span><span>
</span><span id="line-4812"></span><span class="hs-comment">-- &gt;&gt;&gt; :kind! GatherDim '[2, 1, 1] '[2, 1, 3] 2</span><span>
</span><span id="line-4813"></span><span class="hs-comment">-- GatherDim '[2, 1, 1] '[2, 1, 3] 2 :: [Nat]</span><span>
</span><span id="line-4814"></span><span class="hs-comment">-- = '[2, 1, 3]</span><span>
</span><span id="line-4815"></span><span class="hs-keyword">type</span><span> </span><span id="GatherDim"><span class="annot"><a href="Torch.Typed.Functional.html#GatherDim"><span class="hs-identifier hs-var">GatherDim</span></a></span></span><span> </span><span id="local-6989586621679708166"><span class="annot"><a href="#local-6989586621679708166"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708165"><span class="annot"><a href="#local-6989586621679708165"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708164"><span class="annot"><a href="#local-6989586621679708164"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimCheck"><span class="hs-identifier hs-type">GatherDimCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708166"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708165"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708164"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#GatherDimImpl"><span class="hs-identifier hs-type">GatherDimImpl</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708166"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708165"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708164"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4816"></span><span>
</span><span id="line-4817"></span><span class="hs-comment">-- | gather values along an axis for a specified dimension.</span><span>
</span><span id="line-4818"></span><span class="annot"><a href="Torch.Typed.Functional.html#gatherDim"><span class="hs-identifier hs-type">gatherDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4819"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708162"><span class="annot"><a href="#local-6989586621679708162"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708161"><span class="annot"><a href="#local-6989586621679708161"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708160"><span class="annot"><a href="#local-6989586621679708160"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708159"><span class="annot"><a href="#local-6989586621679708159"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708158"><span class="annot"><a href="#local-6989586621679708158"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4820"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708162"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679708160"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#GatherDim"><span class="hs-identifier hs-type">GatherDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708161"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708160"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708162"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4821"></span><span>  </span><span class="hs-comment">-- | the indices of elements to gather</span><span>
</span><span id="line-4822"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708158"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708160"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4823"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4824"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708158"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708159"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708161"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4825"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4826"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708158"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708159"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708160"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-4827"></span><span id="gatherDim"><span class="annot"><span class="annottext">gatherDim :: Tensor device 'Int64 shape'
-&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#gatherDim"><span class="hs-identifier hs-var hs-var">gatherDim</span></a></span></span><span> </span><span id="local-6989586621679708157"><span class="annot"><span class="annottext">Tensor device 'Int64 shape'
</span><a href="#local-6989586621679708157"><span class="hs-identifier hs-var">index</span></a></span></span><span> </span><span id="local-6989586621679708156"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708156"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape') -&gt; Tensor device dtype shape')
-&gt; IO (Tensor device dtype shape') -&gt; Tensor device dtype shape'
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Tensor device 'Int64 shape'
-&gt; Bool
-&gt; IO (Tensor device dtype shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.gather_tltb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708156"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708162"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 shape'
</span><a href="#local-6989586621679708157"><span class="hs-identifier hs-var">index</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-4828"></span><span>
</span><span id="line-4829"></span><span class="hs-comment">-- addcmul :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4830"></span><span class="hs-comment">-- addcmul _input _tensor1 _tensor2 _value = unsafePerformIO $ (ATen.cast4 ATen.Managed.addcmul_ttts) _input _tensor1 _tensor2 _value</span><span>
</span><span id="line-4831"></span><span>
</span><span id="line-4832"></span><span class="hs-comment">-- addcdiv :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4833"></span><span class="hs-comment">-- addcdiv _input _tensor1 _tensor2 _value = unsafePerformIO $ (ATen.cast4 ATen.Managed.addcdiv_ttts) _input _tensor1 _tensor2 _value</span><span>
</span><span id="line-4834"></span><span>
</span><span id="line-4835"></span><span class="hs-comment">-- lstsq :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4836"></span><span class="hs-comment">-- lstsq _input _A = unsafePerformIO $ (ATen.cast2 ATen.Managed.lstsq_tt) _input _A</span><span>
</span><span id="line-4837"></span><span>
</span><span id="line-4838"></span><span class="hs-comment">-- triangular_solve :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Bool -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4839"></span><span class="hs-comment">-- triangular_solve _input _A _upper _transpose _unitriangular = unsafePerformIO $ (ATen.cast5 ATen.Managed.triangular_solve_ttbbb) _input _A _upper _transpose _unitriangular</span><span>
</span><span id="line-4840"></span><span>
</span><span id="line-4841"></span><span class="hs-comment">-- qr :: Tensor device dtype shape -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4842"></span><span class="hs-comment">-- qr _input _some = unsafePerformIO $ (ATen.cast2 ATen.Managed.qr_tb) _input _some</span><span>
</span><span id="line-4843"></span><span>
</span><span id="line-4844"></span><span class="hs-comment">-- ormqr :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4845"></span><span class="hs-comment">-- ormqr _input _input2 _input3 _left _transpose = unsafePerformIO $ (ATen.cast5 ATen.Managed.ormqr_tttbb) _input _input2 _input3 _left _transpose</span><span>
</span><span id="line-4846"></span><span>
</span><span id="line-4847"></span><span class="hs-comment">-- lu_solve :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4848"></span><span class="hs-comment">-- lu_solve _input _LU_data _LU_pivots = unsafePerformIO $ (ATen.cast3 ATen.Managed.lu_solve_ttt) _input _LU_data _LU_pivots</span><span>
</span><span id="line-4849"></span><span>
</span><span id="line-4850"></span><span class="hs-comment">-- | lgamma function</span><span>
</span><span id="line-4851"></span><span class="hs-comment">--</span><span>
</span><span id="line-4852"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ lgamma (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4853"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4854"></span><span class="annot"><a href="Torch.Typed.Functional.html#lgamma"><span class="hs-identifier hs-type">lgamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4855"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708153"><span class="annot"><a href="#local-6989586621679708153"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708152"><span class="annot"><a href="#local-6989586621679708152"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708151"><span class="annot"><a href="#local-6989586621679708151"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4856"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708151"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708152"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4857"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4858"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708151"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708152"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708153"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4859"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4860"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708151"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708152"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708153"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4861"></span><span id="lgamma"><span class="annot"><span class="annottext">lgamma :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#lgamma"><span class="hs-identifier hs-var hs-var">lgamma</span></a></span></span><span> </span><span id="local-6989586621679708150"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708150"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.lgamma_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708150"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4862"></span><span>
</span><span id="line-4863"></span><span class="hs-comment">-- | digamma function</span><span>
</span><span id="line-4864"></span><span class="hs-comment">--</span><span>
</span><span id="line-4865"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ digamma (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4866"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4867"></span><span class="annot"><a href="Torch.Typed.Functional.html#digamma"><span class="hs-identifier hs-type">digamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4868"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708147"><span class="annot"><a href="#local-6989586621679708147"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708146"><span class="annot"><a href="#local-6989586621679708146"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708145"><span class="annot"><a href="#local-6989586621679708145"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4869"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708145"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708146"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4870"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4871"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708145"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708146"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708147"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4872"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4873"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708145"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708146"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708147"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4874"></span><span id="digamma"><span class="annot"><span class="annottext">digamma :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#digamma"><span class="hs-identifier hs-var hs-var">digamma</span></a></span></span><span> </span><span id="local-6989586621679708144"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708144"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.digamma_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708144"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4875"></span><span>
</span><span id="line-4876"></span><span class="hs-comment">-- | polygamma function</span><span>
</span><span id="line-4877"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-4878"></span><span class="annot"><a href="Torch.Typed.Functional.html#polygamma"><span class="hs-identifier hs-type">polygamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4879"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708141"><span class="annot"><a href="#local-6989586621679708141"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708140"><span class="annot"><a href="#local-6989586621679708140"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708139"><span class="annot"><a href="#local-6989586621679708139"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4880"></span><span>  </span><span class="hs-comment">-- | order</span><span>
</span><span id="line-4881"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4882"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4883"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708139"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708140"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708141"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4884"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4885"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708139"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708140"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708141"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4886"></span><span id="polygamma"><span class="annot"><span class="annottext">polygamma :: Int -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#polygamma"><span class="hs-identifier hs-var hs-var">polygamma</span></a></span></span><span> </span><span id="local-6989586621679708138"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708138"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679708137"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708137"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Int
-&gt; Tensor device dtype shape
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.polygamma_lt</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708138"><span class="hs-identifier hs-var">n</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708137"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4887"></span><span>
</span><span id="line-4888"></span><span class="hs-comment">-- | inverse of the error function</span><span>
</span><span id="line-4889"></span><span class="hs-comment">--</span><span>
</span><span id="line-4890"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ erfinv (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-4891"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-4892"></span><span class="annot"><a href="Torch.Typed.Functional.html#erfinv"><span class="hs-identifier hs-type">erfinv</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4893"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708134"><span class="annot"><a href="#local-6989586621679708134"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708133"><span class="annot"><a href="#local-6989586621679708133"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708132"><span class="annot"><a href="#local-6989586621679708132"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4894"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708132"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708133"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4895"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4896"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708132"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708133"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708134"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4897"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4898"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708132"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708133"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708134"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-4899"></span><span id="erfinv"><span class="annot"><span class="annottext">erfinv :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#erfinv"><span class="hs-identifier hs-var hs-var">erfinv</span></a></span></span><span> </span><span id="local-6989586621679708131"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708131"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.erfinv_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708131"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4900"></span><span>
</span><span id="line-4901"></span><span class="hs-comment">-- dist :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4902"></span><span class="hs-comment">-- dist _input _other _p = unsafePerformIO $ (ATen.cast3 ATen.Managed.dist_tts) _input _other _p</span><span>
</span><span id="line-4903"></span><span>
</span><span id="line-4904"></span><span class="hs-comment">-- atan2 :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4905"></span><span class="hs-comment">-- atan2 _input _other = unsafePerformIO $ (ATen.cast2 ATen.Managed.atan2_tt) _input _other</span><span>
</span><span id="line-4906"></span><span>
</span><span id="line-4907"></span><span class="hs-comment">-- histc :: Tensor device dtype shape -&gt; Int -&gt; Float -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4908"></span><span class="hs-comment">-- histc _input _bins _min _max = unsafePerformIO $ (ATen.cast4 ATen.Managed.histc_tlss) _input _bins _min _max</span><span>
</span><span id="line-4909"></span><span>
</span><span id="line-4910"></span><span class="hs-comment">-- | minAll</span><span>
</span><span id="line-4911"></span><span class="hs-comment">--</span><span>
</span><span id="line-4912"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ minAll (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-4913"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-4914"></span><span class="annot"><a href="Torch.Typed.Functional.html#minAll"><span class="hs-identifier hs-type">minAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4915"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708128"><span class="annot"><a href="#local-6989586621679708128"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708127"><span class="annot"><a href="#local-6989586621679708127"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708126"><span class="annot"><a href="#local-6989586621679708126"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4916"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4917"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708126"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708127"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708128"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4918"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4919"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708126"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708127"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-4920"></span><span id="minAll"><span class="annot"><span class="annottext">minAll :: Tensor device dtype shape -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#minAll"><span class="hs-identifier hs-var hs-var">minAll</span></a></span></span><span> </span><span id="local-6989586621679708125"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708125"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.min_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708125"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4921"></span><span>
</span><span id="line-4922"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="DropValue"><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-var">DropValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708124"><span class="annot"><a href="#local-6989586621679708124"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708123"><span class="annot"><a href="#local-6989586621679708123"><span class="hs-identifier hs-type">i</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4923"></span><span>  </span><span id="DropValue"><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-var">DropValue</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Can not find a element in the list.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-4924"></span><span>  </span><span id="DropValue"><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-var">DropValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708122"><span class="annot"><a href="#local-6989586621679708122"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679708121"><span class="annot"><a href="#local-6989586621679708121"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679708121"><span class="hs-identifier hs-type">xs</span></a></span><span>
</span><span id="line-4925"></span><span>  </span><span id="DropValue"><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-var">DropValue</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708120"><span class="annot"><a href="#local-6989586621679708120"><span class="hs-identifier hs-type hs-type">x</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679708119"><span class="annot"><a href="#local-6989586621679708119"><span class="hs-identifier hs-type hs-type">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679708118"><span class="annot"><a href="#local-6989586621679708118"><span class="hs-identifier hs-type hs-type">i</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679708120"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708119"><span class="hs-identifier hs-type">xs</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708118"><span class="hs-identifier hs-type">i</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-4926"></span><span>
</span><span id="line-4927"></span><span class="hs-comment">-- | minDim</span><span>
</span><span id="line-4928"></span><span class="hs-comment">--</span><span>
</span><span id="line-4929"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3,4,5]</span><span>
</span><span id="line-4930"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ minDim @0 t</span><span>
</span><span id="line-4931"></span><span class="hs-comment">-- (Float,[4,5])</span><span>
</span><span id="line-4932"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ minDim @1 t</span><span>
</span><span id="line-4933"></span><span class="hs-comment">-- (Float,[3,5])</span><span>
</span><span id="line-4934"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ minDim @2 t</span><span>
</span><span id="line-4935"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-4936"></span><span class="annot"><a href="Torch.Typed.Functional.html#minDim"><span class="hs-identifier hs-type">minDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4937"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708116"><span class="annot"><a href="#local-6989586621679708116"><span class="hs-identifier hs-type">d</span></a></span></span><span> </span><span id="local-6989586621679708115"><span class="annot"><a href="#local-6989586621679708115"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708114"><span class="annot"><a href="#local-6989586621679708114"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708113"><span class="annot"><a href="#local-6989586621679708113"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4938"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708116"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4939"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4940"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708113"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708114"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708115"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4941"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4942"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708113"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708114"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708115"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708116"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4943"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708113"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708115"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708116"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4944"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-4945"></span><span id="minDim"><span class="annot"><span class="annottext">minDim :: Tensor device dtype shape
-&gt; (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
</span><a href="Torch.Typed.Functional.html#minDim"><span class="hs-identifier hs-var hs-var">minDim</span></a></span></span><span> </span><span id="local-6989586621679708112"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708112"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype (DropValue shape d),
   Tensor device 'Int64 (DropValue shape d))
-&gt; (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
 -&gt; (Tensor device dtype (DropValue shape d),
     Tensor device 'Int64 (DropValue shape d)))
-&gt; IO
     (Tensor device dtype (DropValue shape d),
      Tensor device 'Int64 (DropValue shape d))
-&gt; (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO
     (Tensor device dtype (DropValue shape d),
      Tensor device 'Int64 (DropValue shape d))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.min_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708112"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat d =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708116"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4946"></span><span>
</span><span id="line-4947"></span><span class="hs-comment">-- | maxAll</span><span>
</span><span id="line-4948"></span><span class="hs-comment">--</span><span>
</span><span id="line-4949"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ maxAll (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-4950"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-4951"></span><span class="annot"><a href="Torch.Typed.Functional.html#maxAll"><span class="hs-identifier hs-type">maxAll</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4952"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708109"><span class="annot"><a href="#local-6989586621679708109"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708108"><span class="annot"><a href="#local-6989586621679708108"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708107"><span class="annot"><a href="#local-6989586621679708107"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4953"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4954"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708107"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708108"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708109"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4955"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4956"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708107"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708108"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-4957"></span><span id="maxAll"><span class="annot"><span class="annottext">maxAll :: Tensor device dtype shape -&gt; Tensor device dtype '[]
</span><a href="Torch.Typed.Functional.html#maxAll"><span class="hs-identifier hs-var hs-var">maxAll</span></a></span></span><span> </span><span id="local-6989586621679708106"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708106"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[])
-&gt; IO (Tensor device dtype '[]) -&gt; Tensor device dtype '[]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype '[])
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.max_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708106"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-4958"></span><span>
</span><span id="line-4959"></span><span class="hs-comment">-- | maxDim</span><span>
</span><span id="line-4960"></span><span class="hs-comment">--</span><span>
</span><span id="line-4961"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones :: CPUTensor 'D.Float '[3,4,5]</span><span>
</span><span id="line-4962"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ maxDim @0 t</span><span>
</span><span id="line-4963"></span><span class="hs-comment">-- (Float,[4,5])</span><span>
</span><span id="line-4964"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ maxDim @1 t</span><span>
</span><span id="line-4965"></span><span class="hs-comment">-- (Float,[3,5])</span><span>
</span><span id="line-4966"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ fst $ maxDim @2 t</span><span>
</span><span id="line-4967"></span><span class="hs-comment">-- (Float,[3,4])</span><span>
</span><span id="line-4968"></span><span class="annot"><a href="Torch.Typed.Functional.html#maxDim"><span class="hs-identifier hs-type">maxDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-4969"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708104"><span class="annot"><a href="#local-6989586621679708104"><span class="hs-identifier hs-type">d</span></a></span></span><span> </span><span id="local-6989586621679708103"><span class="annot"><a href="#local-6989586621679708103"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708102"><span class="annot"><a href="#local-6989586621679708102"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708101"><span class="annot"><a href="#local-6989586621679708101"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-4970"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708104"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-4971"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-4972"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708101"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708102"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708103"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-4973"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-4974"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708101"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708102"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708103"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708104"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-4975"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708101"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#DropValue"><span class="hs-identifier hs-type">DropValue</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708103"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708104"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4976"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-4977"></span><span id="maxDim"><span class="annot"><span class="annottext">maxDim :: Tensor device dtype shape
-&gt; (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
</span><a href="Torch.Typed.Functional.html#maxDim"><span class="hs-identifier hs-var hs-var">maxDim</span></a></span></span><span> </span><span id="local-6989586621679708100"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708100"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor device dtype (DropValue shape d),
   Tensor device 'Int64 (DropValue shape d))
-&gt; (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
 -&gt; (Tensor device dtype (DropValue shape d),
     Tensor device 'Int64 (DropValue shape d)))
-&gt; IO
     (Tensor device dtype (DropValue shape d),
      Tensor device 'Int64 (DropValue shape d))
-&gt; (Tensor device dtype (DropValue shape d),
    Tensor device 'Int64 (DropValue shape d))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO
     (Tensor device dtype (DropValue shape d),
      Tensor device 'Int64 (DropValue shape d))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.max_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708100"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat d =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708104"><span class="hs-identifier hs-type">d</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4978"></span><span>
</span><span id="line-4979"></span><span class="hs-comment">-- sort :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-4980"></span><span class="hs-comment">-- sort _input _dim _descending = unsafePerformIO $ (ATen.cast3 ATen.Managed.sort_tlb) _input _dim _descending</span><span>
</span><span id="line-4981"></span><span>
</span><span id="line-4982"></span><span class="hs-comment">-- argsort :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-4983"></span><span class="hs-comment">-- argsort _input _dim _descending = unsafePerformIO $ (ATen.cast3 ATen.Managed.argsort_tlb) _input _dim _descending</span><span>
</span><span id="line-4984"></span><span>
</span><span id="line-4985"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="TopKCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKCheck"><span class="hs-identifier hs-var">TopKCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708097"><span class="annot"><a href="#local-6989586621679708097"><span class="hs-identifier hs-type">k</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708096"><span class="annot"><a href="#local-6989586621679708096"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708095"><span class="annot"><a href="#local-6989586621679708095"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708094"><span class="annot"><a href="#local-6989586621679708094"><span class="hs-identifier hs-type">satd</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708093"><span class="annot"><a href="#local-6989586621679708093"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span id="local-6989586621679708092"><span class="annot"><a href="#local-6989586621679708092"><span class="hs-identifier hs-type hs-type">a</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679708092"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4986"></span><span>  </span><span id="TopKCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKCheck"><span class="hs-identifier hs-var">TopKCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679708091"><span class="annot"><a href="#local-6989586621679708091"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708090"><span class="annot"><a href="#local-6989586621679708090"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DimOutOfBound"><span class="hs-identifier hs-type">DimOutOfBound</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708091"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708090"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-4987"></span><span>  </span><span id="TopKCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKCheck"><span class="hs-identifier hs-var">TopKCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679708089"><span class="annot"><a href="#local-6989586621679708089"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708088"><span class="annot"><a href="#local-6989586621679708088"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#DimOutOfBound"><span class="hs-identifier hs-type">DimOutOfBound</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708089"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708088"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-4988"></span><span>  </span><span id="TopKCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKCheck"><span class="hs-identifier hs-var">TopKCheck</span></a></span></span><span> </span><span id="local-6989586621679708087"><span class="annot"><a href="#local-6989586621679708087"><span class="hs-identifier hs-type hs-type">k</span></a></span></span><span> </span><span id="local-6989586621679708086"><span class="annot"><a href="#local-6989586621679708086"><span class="hs-identifier hs-type hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708085"><span class="annot"><a href="#local-6989586621679708085"><span class="hs-identifier hs-type hs-type">dim</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708084"><span class="annot"><a href="#local-6989586621679708084"><span class="hs-identifier hs-type hs-type">v</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679708083"><span class="annot"><a href="#local-6989586621679708083"><span class="hs-identifier hs-type hs-type">result</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#If"><span class="hs-identifier hs-type">If</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708087"><span class="hs-identifier hs-type">k</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=?</span></span><span> </span><span class="annot"><a href="#local-6989586621679708084"><span class="hs-identifier hs-type">v</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708083"><span class="hs-identifier hs-type">result</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;k must be less than or equal to the number of elements in the requested dimension.&quot;</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-4989"></span><span>
</span><span id="line-4990"></span><span class="hs-keyword">type</span><span> </span><span id="TopK"><span class="annot"><a href="Torch.Typed.Functional.html#TopK"><span class="hs-identifier hs-var">TopK</span></a></span></span><span> </span><span id="local-6989586621679708081"><span class="annot"><a href="#local-6989586621679708081"><span class="hs-identifier hs-type">k</span></a></span></span><span> </span><span id="local-6989586621679708080"><span class="annot"><a href="#local-6989586621679708080"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708079"><span class="annot"><a href="#local-6989586621679708079"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#TopKCheck"><span class="hs-identifier hs-type">TopKCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708081"><span class="hs-identifier hs-type">k</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708080"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708079"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#ExtractDim"><span class="hs-identifier hs-type">ExtractDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708079"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708080"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#ReplaceDim"><span class="hs-identifier hs-type">ReplaceDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708079"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708080"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708081"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-4991"></span><span>
</span><span id="line-4992"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="TopKDeviceAndDTypeCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKDeviceAndDTypeCheck"><span class="hs-identifier hs-var">TopKDeviceAndDTypeCheck</span></a></span></span><span> </span><span id="local-6989586621679708077"><span class="annot"><a href="#local-6989586621679708077"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679708076"><span class="annot"><a href="#local-6989586621679708076"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Constraint</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-4993"></span><span>  </span><span id="TopKDeviceAndDTypeCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKDeviceAndDTypeCheck"><span class="hs-identifier hs-var">TopKDeviceAndDTypeCheck</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Bool"><span class="hs-identifier hs-type">D.Bool</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;topk is not defined for Bool tensors.&quot;</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-4994"></span><span>  </span><span id="TopKDeviceAndDTypeCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKDeviceAndDTypeCheck"><span class="hs-identifier hs-var">TopKDeviceAndDTypeCheck</span></a></span></span><span> </span><span class="annot"><a href="Torch.DType.html#Half"><span class="hs-identifier hs-type">D.Half</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#CPU"><span class="hs-identifier hs-type">D.CPU</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;topk is not defined for Half types on CPU.&quot;</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-4995"></span><span>  </span><span id="TopKDeviceAndDTypeCheck"><span class="annot"><a href="Torch.Typed.Functional.html#TopKDeviceAndDTypeCheck"><span class="hs-identifier hs-var">TopKDeviceAndDTypeCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-4996"></span><span>
</span><span id="line-4997"></span><span class="hs-comment">-- | Returns the k largest (if largest is `True`) elements of the given input tensor along a given dimension.</span><span>
</span><span id="line-4998"></span><span class="hs-comment">--</span><span>
</span><span id="line-4999"></span><span class="hs-comment">-- &gt;&gt;&gt; topk @3 @1 True True (ones :: CPUTensor 'D.Float '[2,3])</span><span>
</span><span id="line-5000"></span><span class="hs-comment">-- (Tensor Float [2,3] [[ 1.0000   ,  1.0000   ,  1.0000   ],</span><span>
</span><span id="line-5001"></span><span class="hs-comment">--                     [ 1.0000   ,  1.0000   ,  1.0000   ]],Tensor Int64 [2,3] [[ 0,  1,  2],</span><span>
</span><span id="line-5002"></span><span class="hs-comment">--                     [ 0,  1,  2]])</span><span>
</span><span id="line-5003"></span><span class="hs-comment">-- &gt;&gt;&gt; topk @0 @1 True True (ones :: CPUTensor 'D.Float '[2,3])</span><span>
</span><span id="line-5004"></span><span class="hs-comment">-- (Tensor Float [2,0] [[],</span><span>
</span><span id="line-5005"></span><span class="hs-comment">--                     []],Tensor Int64 [2,0] [[],</span><span>
</span><span id="line-5006"></span><span class="hs-comment">--                     []])</span><span>
</span><span id="line-5007"></span><span class="annot"><a href="Torch.Typed.Functional.html#topk"><span class="hs-identifier hs-type">topk</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5008"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708074"><span class="annot"><a href="#local-6989586621679708074"><span class="hs-identifier hs-type">k</span></a></span></span><span> </span><span id="local-6989586621679708073"><span class="annot"><a href="#local-6989586621679708073"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span id="local-6989586621679708072"><span class="annot"><a href="#local-6989586621679708072"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679708071"><span class="annot"><a href="#local-6989586621679708071"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708070"><span class="annot"><a href="#local-6989586621679708070"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708069"><span class="annot"><a href="#local-6989586621679708069"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5009"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708074"><span class="hs-identifier hs-type">k</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5010"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708073"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5011"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708071"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5012"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#TopKDeviceAndDTypeCheck"><span class="hs-identifier hs-type">TopKDeviceAndDTypeCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708070"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708069"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5013"></span><span>    </span><span class="annot"><a href="#local-6989586621679708072"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#TopK"><span class="hs-identifier hs-type">TopK</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708074"><span class="hs-identifier hs-type">k</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708071"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708073"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-5014"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5015"></span><span>  </span><span class="hs-comment">-- | if we're returning the top k largest (or, if False, the top k smallest)</span><span>
</span><span id="line-5016"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5017"></span><span>  </span><span class="hs-comment">-- | if the resulting k elements are themselves sorted</span><span>
</span><span id="line-5018"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5019"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5020"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708069"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708070"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708071"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5021"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5022"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708069"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708070"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708072"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708069"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708072"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5023"></span><span id="topk"><span class="annot"><span class="annottext">topk :: Bool
-&gt; Bool
-&gt; Tensor device dtype shape
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
</span><a href="Torch.Typed.Functional.html#topk"><span class="hs-identifier hs-var hs-var">topk</span></a></span></span><span> </span><span id="local-6989586621679708068"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708068"><span class="hs-identifier hs-var">_largest</span></a></span></span><span> </span><span id="local-6989586621679708067"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708067"><span class="hs-identifier hs-var">_sorted</span></a></span></span><span> </span><span id="local-6989586621679708066"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708066"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape', Tensor device 'Int64 shape')
 -&gt; (Tensor device dtype shape', Tensor device 'Int64 shape'))
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
-&gt; (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Int64
 -&gt; Int64
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; Int
-&gt; Bool
-&gt; Bool
-&gt; IO (Tensor device dtype shape', Tensor device 'Int64 shape')
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Int64
-&gt; Int64
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.topk_tllbb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708066"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708064"><span class="hs-identifier hs-var">_k</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708063"><span class="hs-identifier hs-var">_dim</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708068"><span class="hs-identifier hs-var">_largest</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679708067"><span class="hs-identifier hs-var">_sorted</span></a></span><span>
</span><span id="line-5024"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-5025"></span><span>    </span><span id="local-6989586621679708064"><span class="annot"><span class="annottext">_k :: Int
</span><a href="#local-6989586621679708064"><span class="hs-identifier hs-var hs-var">_k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat k =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708074"><span class="hs-identifier hs-type">k</span></a></span><span>
</span><span id="line-5026"></span><span>    </span><span id="local-6989586621679708063"><span class="annot"><span class="annottext">_dim :: Int
</span><a href="#local-6989586621679708063"><span class="hs-identifier hs-var hs-var">_dim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat dim =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708073"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-5027"></span><span>
</span><span id="line-5028"></span><span class="hs-comment">-- renorm :: Tensor device dtype shape -&gt; Float -&gt; Int -&gt; Float -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5029"></span><span class="hs-comment">-- renorm _input _p _dim _maxnorm = unsafePerformIO $ (ATen.cast4 ATen.Managed.renorm_tsls) _input _p _dim _maxnorm</span><span>
</span><span id="line-5030"></span><span>
</span><span id="line-5031"></span><span class="hs-comment">-- equal :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Bool</span><span>
</span><span id="line-5032"></span><span class="hs-comment">-- equal _input _other = unsafePerformIO $ (ATen.cast2 ATen.Managed.equal_tt) _input _other</span><span>
</span><span id="line-5033"></span><span>
</span><span id="line-5034"></span><span class="hs-comment">-- | alias</span><span>
</span><span id="line-5035"></span><span class="hs-comment">--</span><span>
</span><span id="line-5036"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ alias (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-5037"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-5038"></span><span class="annot"><a href="Torch.Typed.Functional.html#alias"><span class="hs-identifier hs-type">alias</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5039"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708061"><span class="annot"><a href="#local-6989586621679708061"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708060"><span class="annot"><a href="#local-6989586621679708060"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708059"><span class="annot"><a href="#local-6989586621679708059"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5040"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5041"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708059"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708060"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708061"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5042"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5043"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708059"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708060"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708061"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-5044"></span><span id="alias"><span class="annot"><span class="annottext">alias :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#alias"><span class="hs-identifier hs-var hs-var">alias</span></a></span></span><span> </span><span id="local-6989586621679708058"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708058"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.alias_t</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708058"><span class="hs-identifier hs-var">_input</span></a></span><span>
</span><span id="line-5045"></span><span>
</span><span id="line-5046"></span><span class="hs-comment">-- | L1 loss</span><span>
</span><span id="line-5047"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5048"></span><span class="hs-comment">--</span><span>
</span><span id="line-5049"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ l1Loss @ReduceNone (ones :: CPUTensor 'D.Float '[2,2]) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-5050"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-5051"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ l1Loss @ReduceSum (ones :: CPUTensor 'D.Float '[2,2]) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-5052"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-5053"></span><span class="annot"><a href="Torch.Typed.Functional.html#l1Loss"><span class="hs-identifier hs-type">l1Loss</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5054"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708055"><span class="annot"><a href="#local-6989586621679708055"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span id="local-6989586621679708054"><span class="annot"><a href="#local-6989586621679708054"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708053"><span class="annot"><a href="#local-6989586621679708053"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708052"><span class="annot"><a href="#local-6989586621679708052"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5055"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708055"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5056"></span><span>  </span><span class="hs-comment">-- | prediciton</span><span>
</span><span id="line-5057"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708052"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708053"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708054"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5058"></span><span>  </span><span class="hs-comment">-- | target</span><span>
</span><span id="line-5059"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708052"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708053"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708054"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5060"></span><span>  </span><span class="hs-comment">-- | loss</span><span>
</span><span id="line-5061"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708052"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708053"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-type">ConditionalReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708054"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708055"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5062"></span><span id="l1Loss"><span class="annot"><span class="annottext">l1Loss :: Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
</span><a href="Torch.Typed.Functional.html#l1Loss"><span class="hs-identifier hs-var hs-var">l1Loss</span></a></span></span><span> </span><span id="local-6989586621679708051"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708051"><span class="hs-identifier hs-var">prediction</span></a></span></span><span> </span><span id="local-6989586621679708050"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708050"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5063"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype (ConditionalReduction shape reduction))
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (ConditionalReduction shape reduction))
 -&gt; Tensor device dtype (ConditionalReduction shape reduction))
-&gt; IO (Tensor device dtype (ConditionalReduction shape reduction))
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5064"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype (ConditionalReduction shape reduction))
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.l1_loss_ttl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708051"><span class="hs-identifier hs-var">prediction</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708050"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708055"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5065"></span><span>
</span><span id="line-5066"></span><span class="hs-comment">-- multi_margin_loss :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Float -&gt; Float -&gt; Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5067"></span><span class="hs-comment">-- multi_margin_loss _input _target _p _margin _weight _reduction = unsafePerformIO $ (ATen.cast6 ATen.Managed.multi_margin_loss_ttsstl) _input _target _p _margin _weight _reduction</span><span>
</span><span id="line-5068"></span><span>
</span><span id="line-5069"></span><span class="hs-comment">-- multilabel_margin_loss :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5070"></span><span class="hs-comment">-- multilabel_margin_loss _input _target _reduction = unsafePerformIO $ (ATen.cast3 ATen.Managed.multilabel_margin_loss_ttl) _input _target _reduction</span><span>
</span><span id="line-5071"></span><span>
</span><span id="line-5072"></span><span class="hs-comment">-- | negative log likelihood loss</span><span>
</span><span id="line-5073"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5074"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/nn.functional.html?highlight=nll_loss#torch.nn.functional.nll_loss.</span><span>
</span><span id="line-5075"></span><span class="hs-comment">--</span><span>
</span><span id="line-5076"></span><span class="hs-comment">-- &gt;&gt;&gt; input &lt;- randn @'[3, 5] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5077"></span><span class="hs-comment">-- &gt;&gt;&gt; target = fromJust [1, 0, 4] :: CPUTensor 'D.Int64 '[3]</span><span>
</span><span id="line-5078"></span><span class="hs-comment">-- &gt;&gt;&gt; weight = ones @'[5] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5079"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceNone @3 @5 @'[] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5080"></span><span class="hs-comment">-- (Float,[3])</span><span>
</span><span id="line-5081"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceMean @3 @5 @'[] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5082"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-5083"></span><span class="hs-comment">-- &gt;&gt;&gt; input &lt;- randn @'[3, 5, 2] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5084"></span><span class="hs-comment">-- &gt;&gt;&gt; target = fromJust [[1, 1], [0, 1], [4, 0]] :: CPUTensor 'D.Int64 '[3, 2]</span><span>
</span><span id="line-5085"></span><span class="hs-comment">-- &gt;&gt;&gt; weight = ones @'[5] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5086"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceNone @3 @5 @'[2] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5087"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-5088"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceMean @3 @5 @'[2] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5089"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-5090"></span><span class="hs-comment">-- &gt;&gt;&gt; input &lt;- randn @'[3, 5, 1, 2] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5091"></span><span class="hs-comment">-- &gt;&gt;&gt; target = fromJust [[[1, 1]], [[0, 1]], [[4, 0]]] :: CPUTensor 'D.Int64 '[3, 1, 2]</span><span>
</span><span id="line-5092"></span><span class="hs-comment">-- &gt;&gt;&gt; weight = ones @'[5] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5093"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceNone @3 @5 @'[1, 2] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5094"></span><span class="hs-comment">-- (Float,[3,1,2])</span><span>
</span><span id="line-5095"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceMean @3 @5 @'[1, 2] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5096"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-5097"></span><span class="hs-comment">-- &gt;&gt;&gt; input &lt;- randn @'[3, 5, 2, 1, 2] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5098"></span><span class="hs-comment">-- &gt;&gt;&gt; target = fromJust [[[[1, 1]], [[0, 2]]], [[[0, 1]], [[1, 0]]], [[[4, 0]], [[1, 2]]]] :: CPUTensor 'D.Int64 '[3, 2, 1, 2]</span><span>
</span><span id="line-5099"></span><span class="hs-comment">-- &gt;&gt;&gt; weight = ones @'[5] @'D.Float @'( 'D.CPU, 0)</span><span>
</span><span id="line-5100"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceNone @3 @5 @'[2, 1, 2] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5101"></span><span class="hs-comment">-- (Float,[3,2,1,2])</span><span>
</span><span id="line-5102"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ nllLoss @ReduceMean @3 @5 @'[2, 1, 2] weight (-100) (logSoftmax @1 input) target</span><span>
</span><span id="line-5103"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-5104"></span><span class="annot"><a href="Torch.Typed.Functional.html#nllLoss"><span class="hs-identifier hs-type">nllLoss</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5105"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708047"><span class="annot"><a href="#local-6989586621679708047"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span id="local-6989586621679708046"><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span></span><span> </span><span id="local-6989586621679708045"><span class="annot"><a href="#local-6989586621679708045"><span class="hs-identifier hs-type">c</span></a></span></span><span> </span><span id="local-6989586621679708044"><span class="annot"><a href="#local-6989586621679708044"><span class="hs-identifier hs-type">ds</span></a></span></span><span> </span><span id="local-6989586621679708043"><span class="annot"><a href="#local-6989586621679708043"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708042"><span class="annot"><a href="#local-6989586621679708042"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5106"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708047"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679708045"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownShape"><span class="hs-identifier hs-type">KnownShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708044"><span class="hs-identifier hs-type">ds</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5107"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-5108"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708043"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679708045"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5109"></span><span>  </span><span class="hs-comment">-- | ignore which index</span><span>
</span><span id="line-5110"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5111"></span><span>  </span><span class="hs-comment">-- | prediction</span><span>
</span><span id="line-5112"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708043"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708045"><span class="hs-identifier hs-type">c</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708044"><span class="hs-identifier hs-type">ds</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5113"></span><span>  </span><span class="hs-comment">-- | target</span><span>
</span><span id="line-5114"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708044"><span class="hs-identifier hs-type">ds</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5115"></span><span>  </span><span class="hs-comment">-- | loss</span><span>
</span><span id="line-5116"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708043"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-type">ConditionalReduction</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679708044"><span class="hs-identifier hs-type">ds</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679708047"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5117"></span><span id="nllLoss"><span class="annot"><span class="annottext">nllLoss :: Tensor device dtype '[c]
-&gt; Int
-&gt; Tensor device dtype (n : c : ds)
-&gt; Tensor device 'Int64 (n : ds)
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
</span><a href="Torch.Typed.Functional.html#nllLoss"><span class="hs-identifier hs-var hs-var">nllLoss</span></a></span></span><span> </span><span id="local-6989586621679708041"><span class="annot"><span class="annottext">Tensor device dtype '[c]
</span><a href="#local-6989586621679708041"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679708040"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708040"><span class="hs-identifier hs-var">ignoreIndex</span></a></span></span><span> </span><span id="local-6989586621679708039"><span class="annot"><span class="annottext">Tensor device dtype (n : c : ds)
</span><a href="#local-6989586621679708039"><span class="hs-identifier hs-var">prediction</span></a></span></span><span> </span><span id="local-6989586621679708038"><span class="annot"><span class="annottext">Tensor device 'Int64 (n : ds)
</span><a href="#local-6989586621679708038"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">KnownShape ds =&gt; [Int]
forall (shape :: [Nat]). KnownShape shape =&gt; [Int]
</span><a href="Torch.Typed.Tensor.html#shapeVal"><span class="hs-identifier hs-var">shapeVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708044"><span class="hs-identifier hs-type">ds</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-5118"></span><span>  </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5119"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (ConditionalReduction (n : ds) reduction))
 -&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; IO
     (Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5120"></span><span>      </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype (n : c : ds)
-&gt; Tensor device 'Int64 (n : ds)
-&gt; Tensor device dtype '[c]
-&gt; Int
-&gt; Int
-&gt; IO
     (Tensor device dtype (ConditionalReduction (n : ds) reduction))
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span>
</span><span id="line-5121"></span><span>        </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.nll_loss_tttll</span></a></span><span>
</span><span id="line-5122"></span><span>        </span><span class="annot"><span class="annottext">Tensor device dtype (n : c : ds)
</span><a href="#local-6989586621679708039"><span class="hs-identifier hs-var">prediction</span></a></span><span>
</span><span id="line-5123"></span><span>        </span><span class="annot"><span class="annottext">Tensor device 'Int64 (n : ds)
</span><a href="#local-6989586621679708038"><span class="hs-identifier hs-var">target</span></a></span><span>
</span><span id="line-5124"></span><span>        </span><span class="annot"><span class="annottext">Tensor device dtype '[c]
</span><a href="#local-6989586621679708041"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-5125"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708047"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5126"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708040"><span class="hs-identifier hs-var">ignoreIndex</span></a></span><span>
</span><span id="line-5127"></span><span>  </span><span class="hs-special">[</span><span id="local-6989586621679708036"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708036"><span class="hs-identifier hs-var">_h</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679708035"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708035"><span class="hs-identifier hs-var">_w</span></a></span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5128"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (ConditionalReduction (n : ds) reduction))
 -&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; IO
     (Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5129"></span><span>      </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype (n : c : ds)
-&gt; Tensor device 'Int64 (n : ds)
-&gt; Tensor device dtype '[c]
-&gt; Int
-&gt; Int
-&gt; IO
     (Tensor device dtype (ConditionalReduction (n : ds) reduction))
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span>
</span><span id="line-5130"></span><span>        </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.nll_loss2d_tttll</span></a></span><span>
</span><span id="line-5131"></span><span>        </span><span class="annot"><span class="annottext">Tensor device dtype (n : c : ds)
</span><a href="#local-6989586621679708039"><span class="hs-identifier hs-var">prediction</span></a></span><span>
</span><span id="line-5132"></span><span>        </span><span class="annot"><span class="annottext">Tensor device 'Int64 (n : ds)
</span><a href="#local-6989586621679708038"><span class="hs-identifier hs-var">target</span></a></span><span>
</span><span id="line-5133"></span><span>        </span><span class="annot"><span class="annottext">Tensor device dtype '[c]
</span><a href="#local-6989586621679708041"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-5134"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708047"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5135"></span><span>        </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708040"><span class="hs-identifier hs-var">ignoreIndex</span></a></span><span>
</span><span id="line-5136"></span><span>  </span><span id="local-6989586621679708033"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708033"><span class="hs-identifier hs-var">h</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679708032"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679708032"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708047"><span class="hs-identifier hs-type">reduction</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-5137"></span><span>    </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Tensor -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Tensor.html#UnsafeMkTensor"><span class="hs-identifier hs-var">UnsafeMkTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
 -&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; (Tensor -&gt; Tensor)
-&gt; Tensor
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Tensor.html#reshape"><span class="hs-identifier hs-var">D.reshape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat n =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int -&gt; [Int] -&gt; [Int]
forall a. a -&gt; [a] -&gt; [a]
</span><span class="hs-glyph hs-var">:</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708033"><span class="hs-identifier hs-var">h</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; [Int] -&gt; [Int]
forall a. a -&gt; [a] -&gt; [a]
</span><span class="hs-glyph hs-var">:</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679708032"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor
 -&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction))
-&gt; Tensor
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679708029"><span class="hs-identifier hs-var">out</span></a></span><span>
</span><span id="line-5138"></span><span>    </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
-&gt; Tensor device dtype (ConditionalReduction (n : ds) reduction)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Tensor -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Tensor.html#UnsafeMkTensor"><span class="hs-identifier hs-var">UnsafeMkTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679708029"><span class="hs-identifier hs-var">out</span></a></span><span>
</span><span id="line-5139"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-5140"></span><span>      </span><span id="local-6989586621679708028"><span class="annot"><span class="annottext">t' :: [Int]
</span><a href="#local-6989586621679708028"><span class="hs-identifier hs-var hs-var">t'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int -&gt; Int) -&gt; Int -&gt; [Int] -&gt; Int
forall (t :: Type -&gt; Type) b a.
Foldable t =&gt;
(b -&gt; a -&gt; b) -&gt; b -&gt; t a -&gt; b
</span><span class="hs-identifier hs-var">foldl</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">(*)</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708033"><span class="hs-identifier hs-var">h</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679708032"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5141"></span><span>      </span><span id="local-6989586621679708025"><span class="annot"><span class="annottext">input' :: Tensor
</span><a href="#local-6989586621679708025"><span class="hs-identifier hs-var hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Tensor.html#reshape"><span class="hs-identifier hs-var">D.reshape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat n =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; [Int] -&gt; [Int]
forall a. a -&gt; [a] -&gt; [a]
</span><span class="hs-glyph hs-var">:</span></span><span> </span><span class="annot"><span class="annottext">KnownNat c =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708045"><span class="hs-identifier hs-type">c</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; [Int] -&gt; [Int]
forall a. a -&gt; [a] -&gt; [a]
</span><span class="hs-glyph hs-var">:</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679708028"><span class="hs-identifier hs-var">t'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (n : c : ds) -&gt; Tensor
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Tensor device dtype shape -&gt; Tensor
</span><a href="Torch.Typed.Tensor.html#toDynamic"><span class="hs-identifier hs-var hs-var">toDynamic</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (n : c : ds)
</span><a href="#local-6989586621679708039"><span class="hs-identifier hs-var">prediction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5142"></span><span>      </span><span id="local-6989586621679708023"><span class="annot"><span class="annottext">target' :: Tensor
</span><a href="#local-6989586621679708023"><span class="hs-identifier hs-var hs-var">target'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Tensor.html#reshape"><span class="hs-identifier hs-var">D.reshape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat n =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708046"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; [Int] -&gt; [Int]
forall a. a -&gt; [a] -&gt; [a]
</span><span class="hs-glyph hs-var">:</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679708028"><span class="hs-identifier hs-var">t'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device 'Int64 (n : ds) -&gt; Tensor
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Tensor device dtype shape -&gt; Tensor
</span><a href="Torch.Typed.Tensor.html#toDynamic"><span class="hs-identifier hs-var hs-var">toDynamic</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device 'Int64 (n : ds)
</span><a href="#local-6989586621679708038"><span class="hs-identifier hs-var">target</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5143"></span><span>      </span><span id="local-6989586621679708029"><span class="annot"><span class="annottext">out :: Tensor
</span><a href="#local-6989586621679708029"><span class="hs-identifier hs-var hs-var">out</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5144"></span><span>        </span><span class="annot"><span class="annottext">IO Tensor -&gt; Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Tensor -&gt; Tensor) -&gt; IO Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5145"></span><span>          </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; Int64
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
-&gt; Tensor
-&gt; Tensor device dtype '[c]
-&gt; Int
-&gt; Int
-&gt; IO Tensor
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast5</span></a></span><span>
</span><span id="line-5146"></span><span>            </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; Int64
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.nll_loss2d_tttll</span></a></span><span>
</span><span id="line-5147"></span><span>            </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679708025"><span class="hs-identifier hs-var">input'</span></a></span><span>
</span><span id="line-5148"></span><span>            </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679708023"><span class="hs-identifier hs-var">target'</span></a></span><span>
</span><span id="line-5149"></span><span>            </span><span class="annot"><span class="annottext">Tensor device dtype '[c]
</span><a href="#local-6989586621679708041"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-5150"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708047"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5151"></span><span>            </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679708040"><span class="hs-identifier hs-var">ignoreIndex</span></a></span><span>
</span><span id="line-5152"></span><span>
</span><span id="line-5153"></span><span class="hs-comment">-- | smooth L1 loss</span><span>
</span><span id="line-5154"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5155"></span><span class="hs-comment">--</span><span>
</span><span id="line-5156"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ smoothL1Loss @ReduceNone (ones :: CPUTensor 'D.Float '[2,2]) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-5157"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-5158"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ smoothL1Loss @ReduceSum (ones :: CPUTensor 'D.Float '[2,2]) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-5159"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-5160"></span><span class="annot"><a href="Torch.Typed.Functional.html#smoothL1Loss"><span class="hs-identifier hs-type">smoothL1Loss</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5161"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708021"><span class="annot"><a href="#local-6989586621679708021"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span id="local-6989586621679708020"><span class="annot"><a href="#local-6989586621679708020"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708019"><span class="annot"><a href="#local-6989586621679708019"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708018"><span class="annot"><a href="#local-6989586621679708018"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5162"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708021"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5163"></span><span>  </span><span class="hs-comment">-- | prediction</span><span>
</span><span id="line-5164"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708018"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708019"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708020"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5165"></span><span>  </span><span class="hs-comment">-- | target</span><span>
</span><span id="line-5166"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708018"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708019"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708020"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5167"></span><span>  </span><span class="hs-comment">-- | loss</span><span>
</span><span id="line-5168"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708018"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708019"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-type">ConditionalReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708020"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708021"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5169"></span><span id="smoothL1Loss"><span class="annot"><span class="annottext">smoothL1Loss :: Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
</span><a href="Torch.Typed.Functional.html#smoothL1Loss"><span class="hs-identifier hs-var hs-var">smoothL1Loss</span></a></span></span><span> </span><span id="local-6989586621679708017"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708017"><span class="hs-identifier hs-var">prediction</span></a></span></span><span> </span><span id="local-6989586621679708016"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708016"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5170"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype (ConditionalReduction shape reduction))
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (ConditionalReduction shape reduction))
 -&gt; Tensor device dtype (ConditionalReduction shape reduction))
-&gt; IO (Tensor device dtype (ConditionalReduction shape reduction))
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5171"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype (ConditionalReduction shape reduction))
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.smooth_l1_loss_ttl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708017"><span class="hs-identifier hs-var">prediction</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708016"><span class="hs-identifier hs-var">target</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708021"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5172"></span><span>
</span><span id="line-5173"></span><span class="hs-comment">-- | soft margin loss</span><span>
</span><span id="line-5174"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5175"></span><span class="hs-comment">--</span><span>
</span><span id="line-5176"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ softMarginLoss @ReduceNone (ones :: CPUTensor 'D.Float '[2,2]) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-5177"></span><span class="hs-comment">-- (Float,[2,2])</span><span>
</span><span id="line-5178"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ softMarginLoss @ReduceSum (ones :: CPUTensor 'D.Float '[2,2]) (ones :: CPUTensor 'D.Float '[2,2])</span><span>
</span><span id="line-5179"></span><span class="hs-comment">-- (Float,[])</span><span>
</span><span id="line-5180"></span><span class="annot"><a href="Torch.Typed.Functional.html#softMarginLoss"><span class="hs-identifier hs-type">softMarginLoss</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5181"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708013"><span class="annot"><a href="#local-6989586621679708013"><span class="hs-identifier hs-type">reduction</span></a></span></span><span> </span><span id="local-6989586621679708012"><span class="annot"><a href="#local-6989586621679708012"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708011"><span class="annot"><a href="#local-6989586621679708011"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708010"><span class="annot"><a href="#local-6989586621679708010"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5182"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#KnownReduction"><span class="hs-identifier hs-type">KnownReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708013"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5183"></span><span>  </span><span class="hs-comment">-- | prediction</span><span>
</span><span id="line-5184"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708010"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708011"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708012"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5185"></span><span>  </span><span class="hs-comment">-- | target</span><span>
</span><span id="line-5186"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708010"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708011"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708012"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5187"></span><span>  </span><span class="hs-comment">-- | loss</span><span>
</span><span id="line-5188"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708010"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708011"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#ConditionalReduction"><span class="hs-identifier hs-type">ConditionalReduction</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708012"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708013"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5189"></span><span id="softMarginLoss"><span class="annot"><span class="annottext">softMarginLoss :: Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
</span><a href="Torch.Typed.Functional.html#softMarginLoss"><span class="hs-identifier hs-var hs-var">softMarginLoss</span></a></span></span><span> </span><span id="local-6989586621679708009"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708009"><span class="hs-identifier hs-var">prediciton</span></a></span></span><span> </span><span id="local-6989586621679708008"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708008"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5190"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype (ConditionalReduction shape reduction))
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (ConditionalReduction shape reduction))
 -&gt; Tensor device dtype (ConditionalReduction shape reduction))
-&gt; IO (Tensor device dtype (ConditionalReduction shape reduction))
-&gt; Tensor device dtype (ConditionalReduction shape reduction)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5191"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype shape
-&gt; Int
-&gt; IO (Tensor device dtype (ConditionalReduction shape reduction))
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-5192"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.soft_margin_loss_ttl</span></a></span><span>
</span><span id="line-5193"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708009"><span class="hs-identifier hs-var">prediciton</span></a></span><span>
</span><span id="line-5194"></span><span>      </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679708008"><span class="hs-identifier hs-var">target</span></a></span><span>
</span><span id="line-5195"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownReduction reduction =&gt; Int
forall k (reduction :: k). KnownReduction reduction =&gt; Int
</span><a href="Torch.Typed.Functional.html#reductionVal"><span class="hs-identifier hs-var">reductionVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679708013"><span class="hs-identifier hs-type">reduction</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5196"></span><span>
</span><span id="line-5197"></span><span class="hs-comment">-- | elu</span><span>
</span><span id="line-5198"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5199"></span><span class="hs-comment">--</span><span>
</span><span id="line-5200"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ elu 0.1 0.1 0.3 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-5201"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-5202"></span><span class="annot"><a href="Torch.Typed.Functional.html#elu"><span class="hs-identifier hs-type">elu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5203"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679708005"><span class="annot"><a href="#local-6989586621679708005"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679708004"><span class="annot"><a href="#local-6989586621679708004"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679708003"><span class="annot"><a href="#local-6989586621679708003"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679708002"><span class="annot"><a href="#local-6989586621679708002"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5204"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708003"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708002"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708004"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5205"></span><span>  </span><span class="hs-comment">-- | alpha</span><span>
</span><span id="line-5206"></span><span>  </span><span class="annot"><a href="#local-6989586621679708003"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5207"></span><span>  </span><span class="hs-comment">-- | scale</span><span>
</span><span id="line-5208"></span><span>  </span><span class="annot"><a href="#local-6989586621679708003"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5209"></span><span>  </span><span class="hs-comment">-- | input scale</span><span>
</span><span id="line-5210"></span><span>  </span><span class="annot"><a href="#local-6989586621679708003"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5211"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5212"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708002"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708004"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708005"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5213"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5214"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708002"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708004"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679708005"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-5215"></span><span id="elu"><span class="annot"><span class="annottext">elu :: a
-&gt; a -&gt; a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#elu"><span class="hs-identifier hs-var hs-var">elu</span></a></span></span><span> </span><span id="local-6989586621679708001"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679708001"><span class="hs-identifier hs-var">alpha</span></a></span></span><span> </span><span id="local-6989586621679708000"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679708000"><span class="hs-identifier hs-var">scale</span></a></span></span><span> </span><span id="local-6989586621679707999"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707999"><span class="hs-identifier hs-var">inputScale</span></a></span></span><span> </span><span id="local-6989586621679707998"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707998"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5216"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; a
-&gt; a
-&gt; a
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.elu_tsss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707998"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679708001"><span class="hs-identifier hs-var">alpha</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679708000"><span class="hs-identifier hs-var">scale</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707999"><span class="hs-identifier hs-var">inputScale</span></a></span><span>
</span><span id="line-5217"></span><span>
</span><span id="line-5218"></span><span class="hs-comment">-- | glu</span><span>
</span><span id="line-5219"></span><span class="hs-comment">-- -- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ glu (ones :: CPUTensor 'D.Float '[3,2]) 1</span><span>
</span><span id="line-5220"></span><span class="hs-comment">-- -- (Float,[3,1])</span><span>
</span><span id="line-5221"></span><span class="hs-comment">-- -- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ glu (ones :: CPUTensor 'D.Float '[3,2]) 3</span><span>
</span><span id="line-5222"></span><span class="hs-comment">-- -- (Float,[3,2])</span><span>
</span><span id="line-5223"></span><span class="hs-comment">-- glu :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5224"></span><span class="hs-comment">-- glu _input _dim = unsafePerformIO $ (ATen.cast2 ATen.Managed.glu_tl) _input _dim</span><span>
</span><span id="line-5225"></span><span>
</span><span id="line-5226"></span><span class="hs-comment">-- | hard tanh</span><span>
</span><span id="line-5227"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5228"></span><span class="hs-comment">--</span><span>
</span><span id="line-5229"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ hardTanh 0 1 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-5230"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-5231"></span><span class="annot"><a href="Torch.Typed.Functional.html#hardTanh"><span class="hs-identifier hs-type">hardTanh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5232"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707995"><span class="annot"><a href="#local-6989586621679707995"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707994"><span class="annot"><a href="#local-6989586621679707994"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707993"><span class="annot"><a href="#local-6989586621679707993"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5233"></span><span>  </span><span class="hs-comment">-- | minimum value</span><span>
</span><span id="line-5234"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5235"></span><span>  </span><span class="hs-comment">-- | maximum value</span><span>
</span><span id="line-5236"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5237"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5238"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707993"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707994"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707995"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5239"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5240"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707993"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707994"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707995"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-5241"></span><span id="hardTanh"><span class="annot"><span class="annottext">hardTanh :: Float
-&gt; Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#hardTanh"><span class="hs-identifier hs-var hs-var">hardTanh</span></a></span></span><span> </span><span id="local-6989586621679707992"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679707992"><span class="hs-identifier hs-var">min_val</span></a></span></span><span> </span><span id="local-6989586621679707991"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679707991"><span class="hs-identifier hs-var">max_val</span></a></span></span><span> </span><span id="local-6989586621679707990"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707990"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5242"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Float
-&gt; Float
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.hardtanh_tss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707990"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679707992"><span class="hs-identifier hs-var">min_val</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679707991"><span class="hs-identifier hs-var">max_val</span></a></span><span>
</span><span id="line-5243"></span><span>
</span><span id="line-5244"></span><span class="hs-comment">-- | leaky relu</span><span>
</span><span id="line-5245"></span><span class="hs-comment">--</span><span>
</span><span id="line-5246"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ leakyRelu 0.01 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-5247"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-5248"></span><span class="annot"><a href="Torch.Typed.Functional.html#leakyRelu"><span class="hs-identifier hs-type">leakyRelu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5249"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707987"><span class="annot"><a href="#local-6989586621679707987"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679707986"><span class="annot"><a href="#local-6989586621679707986"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707985"><span class="annot"><a href="#local-6989586621679707985"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707984"><span class="annot"><a href="#local-6989586621679707984"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5250"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707987"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707985"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5251"></span><span>  </span><span class="hs-comment">-- | negative slope</span><span>
</span><span id="line-5252"></span><span>  </span><span class="annot"><a href="#local-6989586621679707987"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5253"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5254"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707985"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707986"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5255"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5256"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707985"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707986"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-5257"></span><span id="leakyRelu"><span class="annot"><span class="annottext">leakyRelu :: a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#leakyRelu"><span class="hs-identifier hs-var hs-var">leakyRelu</span></a></span></span><span> </span><span id="local-6989586621679707983"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707983"><span class="hs-identifier hs-var">negativeSlope</span></a></span></span><span> </span><span id="local-6989586621679707982"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707982"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5258"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; a -&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.leaky_relu_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707982"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707983"><span class="hs-identifier hs-var">negativeSlope</span></a></span><span>
</span><span id="line-5259"></span><span>
</span><span id="line-5260"></span><span class="hs-comment">-- | logarithm of the sigmoid</span><span>
</span><span id="line-5261"></span><span class="hs-comment">--</span><span>
</span><span id="line-5262"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ logSigmoid (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-5263"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-5264"></span><span class="annot"><a href="Torch.Typed.Functional.html#logSigmoid"><span class="hs-identifier hs-type">logSigmoid</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5265"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707979"><span class="annot"><a href="#local-6989586621679707979"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707978"><span class="annot"><a href="#local-6989586621679707978"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707977"><span class="annot"><a href="#local-6989586621679707977"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5266"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#StandardFloatingPointDTypeValidation"><span class="hs-identifier hs-type">StandardFloatingPointDTypeValidation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707977"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707978"><span class="hs-identifier hs-type">dtype</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5267"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5268"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707977"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707978"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707979"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5269"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5270"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707977"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707978"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707979"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-5271"></span><span id="logSigmoid"><span class="annot"><span class="annottext">logSigmoid :: Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#logSigmoid"><span class="hs-identifier hs-var hs-var">logSigmoid</span></a></span></span><span> </span><span id="local-6989586621679707976"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707976"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape -&gt; IO (Tensor device dtype shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.log_sigmoid_t</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707976"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5272"></span><span>
</span><span id="line-5273"></span><span class="hs-comment">-- | softplus</span><span>
</span><span id="line-5274"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5275"></span><span class="hs-comment">-- See https://pytorch.org/docs/stable/nn.functional.html?highlight=softplus#torch.nn.functional.softplus.</span><span>
</span><span id="line-5276"></span><span class="hs-comment">--</span><span>
</span><span id="line-5277"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape &amp;&amp;&amp; (\t -&gt; D.asValue (toDynamic t) :: [[Float]]) $ softplus 1 20 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-5278"></span><span class="hs-comment">-- (Float,([3,2],[[1.3132616,1.3132616],[1.3132616,1.3132616],[1.3132616,1.3132616]]))</span><span>
</span><span id="line-5279"></span><span class="annot"><a href="Torch.Typed.Functional.html#softplus"><span class="hs-identifier hs-type">softplus</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5280"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679711288"><span class="annot"><a href="#local-6989586621679711288"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679711284"><span class="annot"><a href="#local-6989586621679711284"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679711285"><span class="annot"><a href="#local-6989586621679711285"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679711286"><span class="annot"><a href="#local-6989586621679711286"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5281"></span><span>  </span><span class="annot"><a href="Torch.Scalar.html#Scalar"><span class="hs-identifier hs-type">D.Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711288"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5282"></span><span>  </span><span class="annot"><a href="#local-6989586621679711288"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5283"></span><span>  </span><span class="annot"><a href="#local-6989586621679711288"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5284"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711286"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711285"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711284"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5285"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711286"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711285"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679711284"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-5286"></span><span id="softplus"><span class="annot"><span class="annottext">softplus :: a -&gt; a -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#softplus"><span class="hs-identifier hs-var hs-var">softplus</span></a></span></span><span> </span><span id="local-6989586621679707974"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707974"><span class="hs-identifier hs-var">beta</span></a></span></span><span> </span><span id="local-6989586621679707973"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707973"><span class="hs-identifier hs-var">threshold</span></a></span></span><span> </span><span id="local-6989586621679707972"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707972"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; a
-&gt; a
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.softplus_tss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707972"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707974"><span class="hs-identifier hs-var">beta</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679707973"><span class="hs-identifier hs-var">threshold</span></a></span><span>
</span><span id="line-5287"></span><span>
</span><span id="line-5288"></span><span class="hs-comment">-- | soft shrink</span><span>
</span><span id="line-5289"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5290"></span><span class="hs-comment">--</span><span>
</span><span id="line-5291"></span><span class="hs-comment">-- &gt;&gt;&gt; dtype &amp;&amp;&amp; shape $ softShrink 0.2 (ones :: CPUTensor 'D.Float '[3,2])</span><span>
</span><span id="line-5292"></span><span class="hs-comment">-- (Float,[3,2])</span><span>
</span><span id="line-5293"></span><span class="annot"><a href="Torch.Typed.Functional.html#softShrink"><span class="hs-identifier hs-type">softShrink</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5294"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707969"><span class="annot"><a href="#local-6989586621679707969"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707968"><span class="annot"><a href="#local-6989586621679707968"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707967"><span class="annot"><a href="#local-6989586621679707967"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5295"></span><span>  </span><span class="hs-comment">-- | lambda</span><span>
</span><span id="line-5296"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5297"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5298"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707967"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707968"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707969"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5299"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5300"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707967"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707968"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707969"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-5301"></span><span id="softShrink"><span class="annot"><span class="annottext">softShrink :: Float -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Functional.html#softShrink"><span class="hs-identifier hs-var hs-var">softShrink</span></a></span></span><span> </span><span id="local-6989586621679707966"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679707966"><span class="hs-identifier hs-var">lambda</span></a></span></span><span> </span><span id="local-6989586621679707965"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707965"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5302"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype shape) -&gt; Tensor device dtype shape)
-&gt; IO (Tensor device dtype shape) -&gt; Tensor device dtype shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; Float
-&gt; IO (Tensor device dtype shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.softshrink_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707965"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679707966"><span class="hs-identifier hs-var">lambda</span></a></span><span>
</span><span id="line-5303"></span><span>
</span><span id="line-5304"></span><span class="hs-comment">-- | adaptive averaged 2-D pooling</span><span>
</span><span id="line-5305"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5306"></span><span class="hs-comment">--</span><span>
</span><span id="line-5307"></span><span class="hs-comment">-- &gt;&gt;&gt; t = adaptiveAvgPool2d @'(8,16) (ones :: CPUTensor 'D.Float '[1,3,16,32])</span><span>
</span><span id="line-5308"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-5309"></span><span class="hs-comment">-- [1,3,8,16]</span><span>
</span><span id="line-5310"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-5311"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 8, 16]</span><span>
</span><span id="line-5312"></span><span class="annot"><a href="Torch.Typed.Functional.html#adaptiveAvgPool2d"><span class="hs-identifier hs-type">adaptiveAvgPool2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5313"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707962"><span class="annot"><a href="#local-6989586621679707962"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span> </span><span id="local-6989586621679707961"><span class="annot"><a href="#local-6989586621679707961"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679707960"><span class="annot"><a href="#local-6989586621679707960"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span> </span><span id="local-6989586621679707959"><span class="annot"><a href="#local-6989586621679707959"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span> </span><span id="local-6989586621679707958"><span class="annot"><a href="#local-6989586621679707958"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679707957"><span class="annot"><a href="#local-6989586621679707957"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707956"><span class="annot"><a href="#local-6989586621679707956"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5314"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-5315"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-5316"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="#local-6989586621679707961"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5317"></span><span>         </span><span class="annot"><a href="#local-6989586621679707960"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5318"></span><span>         </span><span class="annot"><a href="#local-6989586621679707959"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5319"></span><span>         </span><span class="annot"><a href="#local-6989586621679707958"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5320"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707962"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5321"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707962"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-5322"></span><span>       </span><span class="hs-special">]</span><span>
</span><span id="line-5323"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5324"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5325"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707956"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707957"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707958"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707961"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707960"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707959"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5326"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5327"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707956"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707957"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707958"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707961"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707962"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707962"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5328"></span><span id="adaptiveAvgPool2d"><span class="annot"><span class="annottext">adaptiveAvgPool2d :: Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize]
</span><a href="Torch.Typed.Functional.html#adaptiveAvgPool2d"><span class="hs-identifier hs-var hs-var">adaptiveAvgPool2d</span></a></span></span><span> </span><span id="local-6989586621679707955"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707955"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5329"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
 -&gt; Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5330"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; [Int]
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst outputSize, Snd outputSize])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span>
</span><span id="line-5331"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.adaptive_avg_pool2d_tl</span></a></span><span>
</span><span id="line-5332"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707955"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5333"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707962"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707962"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5334"></span><span>
</span><span id="line-5335"></span><span class="hs-comment">-- | MKLDNN adaptive averaged 2-D pooling</span><span>
</span><span id="line-5336"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5337"></span><span class="hs-comment">-- TODO: broken?</span><span>
</span><span id="line-5338"></span><span class="hs-comment">-- TODO: only defined for MKLDNN device?</span><span>
</span><span id="line-5339"></span><span class="hs-comment">-- TODO: test for availability of MKLDNN device?</span><span>
</span><span id="line-5340"></span><span class="hs-comment">-- TODO: merge with adaptiveAvgPool2d and dispatch based on (availability of MKLDNN) device in the function body?</span><span>
</span><span id="line-5341"></span><span class="hs-comment">--</span><span>
</span><span id="line-5342"></span><span class="hs-comment">-- -- &gt;&gt;&gt; t = mkldnnAdaptiveAvgPool2d @'(8,16) (toMKLDNN (ones :: CPUTensor 'D.Float '[1,3,16,32]))</span><span>
</span><span id="line-5343"></span><span class="hs-comment">-- -- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-5344"></span><span class="hs-comment">-- -- [1,3,8,16]</span><span>
</span><span id="line-5345"></span><span class="hs-comment">-- -- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-5346"></span><span class="hs-comment">-- -- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 8, 16]</span><span>
</span><span id="line-5347"></span><span class="annot"><a href="Torch.Typed.Functional.html#mkldnnAdaptiveAvgPool2d"><span class="hs-identifier hs-type">mkldnnAdaptiveAvgPool2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5348"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707952"><span class="annot"><a href="#local-6989586621679707952"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span> </span><span id="local-6989586621679707951"><span class="annot"><a href="#local-6989586621679707951"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679707950"><span class="annot"><a href="#local-6989586621679707950"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span> </span><span id="local-6989586621679707949"><span class="annot"><a href="#local-6989586621679707949"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span> </span><span id="local-6989586621679707948"><span class="annot"><a href="#local-6989586621679707948"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679707947"><span class="annot"><a href="#local-6989586621679707947"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707946"><span class="annot"><a href="#local-6989586621679707946"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5349"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-5350"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-5351"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="#local-6989586621679707951"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5352"></span><span>         </span><span class="annot"><a href="#local-6989586621679707950"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5353"></span><span>         </span><span class="annot"><a href="#local-6989586621679707949"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5354"></span><span>         </span><span class="annot"><a href="#local-6989586621679707948"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5355"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707952"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5356"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707952"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-5357"></span><span>       </span><span class="hs-special">]</span><span>
</span><span id="line-5358"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5359"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5360"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707946"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707947"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707948"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707951"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707950"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707949"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5361"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5362"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707946"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707947"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707948"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707951"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707952"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707952"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5363"></span><span id="mkldnnAdaptiveAvgPool2d"><span class="annot"><span class="annottext">mkldnnAdaptiveAvgPool2d :: Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize]
</span><a href="Torch.Typed.Functional.html#mkldnnAdaptiveAvgPool2d"><span class="hs-identifier hs-var hs-var">mkldnnAdaptiveAvgPool2d</span></a></span></span><span> </span><span id="local-6989586621679707945"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707945"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5364"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
 -&gt; Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5365"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; [Int]
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst outputSize, Snd outputSize])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span>
</span><span id="line-5366"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.adaptive_avg_pool2d_tl</span></a></span><span>
</span><span id="line-5367"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707945"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5368"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707952"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707952"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5369"></span><span>
</span><span id="line-5370"></span><span class="hs-comment">-- | adaptive averaged 3-D pooling</span><span>
</span><span id="line-5371"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5372"></span><span class="hs-comment">--</span><span>
</span><span id="line-5373"></span><span class="hs-comment">-- &gt;&gt;&gt; t = adaptiveAvgPool3d @'(8,16,2) (ones :: CPUTensor 'D.Float '[1,3,16,32,4])</span><span>
</span><span id="line-5374"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-5375"></span><span class="hs-comment">-- [1,3,8,16,2]</span><span>
</span><span id="line-5376"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-5377"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 8, 16, 2]</span><span>
</span><span id="line-5378"></span><span class="annot"><a href="Torch.Typed.Functional.html#adaptiveAvgPool3d"><span class="hs-identifier hs-type">adaptiveAvgPool3d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5379"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-5380"></span><span>    </span><span id="local-6989586621679707943"><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-5381"></span><span>    </span><span id="local-6989586621679707942"><span class="annot"><a href="#local-6989586621679707942"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span>
</span><span id="line-5382"></span><span>    </span><span id="local-6989586621679707941"><span class="annot"><a href="#local-6989586621679707941"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span>
</span><span id="line-5383"></span><span>    </span><span id="local-6989586621679707940"><span class="annot"><a href="#local-6989586621679707940"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span>
</span><span id="line-5384"></span><span>    </span><span id="local-6989586621679707939"><span class="annot"><a href="#local-6989586621679707939"><span class="hs-identifier hs-type">inputSize2</span></a></span></span><span>
</span><span id="line-5385"></span><span>    </span><span id="local-6989586621679707938"><span class="annot"><a href="#local-6989586621679707938"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-5386"></span><span>    </span><span id="local-6989586621679707937"><span class="annot"><a href="#local-6989586621679707937"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-5387"></span><span>    </span><span id="local-6989586621679707936"><span class="annot"><a href="#local-6989586621679707936"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5388"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-5389"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-5390"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="#local-6989586621679707942"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5391"></span><span>         </span><span class="annot"><a href="#local-6989586621679707941"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5392"></span><span>         </span><span class="annot"><a href="#local-6989586621679707940"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5393"></span><span>         </span><span class="annot"><a href="#local-6989586621679707939"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5394"></span><span>         </span><span class="annot"><a href="#local-6989586621679707938"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5395"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5396"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5397"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-5398"></span><span>       </span><span class="hs-special">]</span><span>
</span><span id="line-5399"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5400"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5401"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707936"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707937"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707938"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707942"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707941"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707940"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707939"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5402"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5403"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707936"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707937"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707938"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707942"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5404"></span><span id="adaptiveAvgPool3d"><span class="annot"><span class="annottext">adaptiveAvgPool3d :: Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
       Trd3 outputSize]
</span><a href="Torch.Typed.Functional.html#adaptiveAvgPool3d"><span class="hs-identifier hs-var hs-var">adaptiveAvgPool3d</span></a></span></span><span> </span><span id="local-6989586621679707935"><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679707935"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5405"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
       Trd3 outputSize])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
       Trd3 outputSize]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize])
 -&gt; Tensor
      device
      dtype
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize])
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
          Trd3 outputSize])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
       Trd3 outputSize]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5406"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; [Int]
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
          Trd3 outputSize])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span>
</span><span id="line-5407"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.adaptive_avg_pool3d_tl</span></a></span><span>
</span><span id="line-5408"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679707935"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5409"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-special">[</span><span> </span><span class="annot"><span class="annottext">KnownNat (Fst3 outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-5410"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Snd3 outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-5411"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Trd3 outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707943"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5412"></span><span>        </span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5413"></span><span>          </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-5414"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-5415"></span><span>
</span><span id="line-5416"></span><span class="hs-comment">-- | adaptive 2-D max-pool</span><span>
</span><span id="line-5417"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5418"></span><span class="hs-comment">--</span><span>
</span><span id="line-5419"></span><span class="hs-comment">-- &gt;&gt;&gt; (t, t') = adaptiveMaxPool2d @'(8,16) (ones :: CPUTensor 'D.Float '[1,3,16,32])</span><span>
</span><span id="line-5420"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-5421"></span><span class="hs-comment">-- [1,3,8,16]</span><span>
</span><span id="line-5422"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-5423"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 8, 16]</span><span>
</span><span id="line-5424"></span><span class="annot"><a href="Torch.Typed.Functional.html#adaptiveMaxPool2d"><span class="hs-identifier hs-type">adaptiveMaxPool2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5425"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707932"><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span> </span><span id="local-6989586621679707931"><span class="annot"><a href="#local-6989586621679707931"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span> </span><span id="local-6989586621679707930"><span class="annot"><a href="#local-6989586621679707930"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span> </span><span id="local-6989586621679707929"><span class="annot"><a href="#local-6989586621679707929"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span> </span><span id="local-6989586621679707928"><span class="annot"><a href="#local-6989586621679707928"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span> </span><span id="local-6989586621679707927"><span class="annot"><a href="#local-6989586621679707927"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707926"><span class="annot"><a href="#local-6989586621679707926"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5426"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-5427"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-5428"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="#local-6989586621679707931"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5429"></span><span>         </span><span class="annot"><a href="#local-6989586621679707930"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5430"></span><span>         </span><span class="annot"><a href="#local-6989586621679707929"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5431"></span><span>         </span><span class="annot"><a href="#local-6989586621679707928"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5432"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5433"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-5434"></span><span>       </span><span class="hs-special">]</span><span>
</span><span id="line-5435"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5436"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5437"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707927"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707928"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707931"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707930"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707929"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5438"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5439"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707927"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707928"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707931"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-5440"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707928"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707931"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5441"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-5442"></span><span id="adaptiveMaxPool2d"><span class="annot"><span class="annottext">adaptiveMaxPool2d :: Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
</span><a href="Torch.Typed.Functional.html#adaptiveMaxPool2d"><span class="hs-identifier hs-var hs-var">adaptiveMaxPool2d</span></a></span></span><span> </span><span id="local-6989586621679707925"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707925"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5443"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, channelSize, Fst outputSize, Snd outputSize],
   Tensor
     device
     'Int64
     '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
 -&gt; (Tensor
       device
       dtype
       '[batchSize, channelSize, Fst outputSize, Snd outputSize],
     Tensor
       device
       'Int64
       '[batchSize, channelSize, Fst outputSize, Snd outputSize]))
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst outputSize, Snd outputSize],
      Tensor
        device
        'Int64
        '[batchSize, channelSize, Fst outputSize, Snd outputSize])
-&gt; (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst outputSize, Snd outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst outputSize, Snd outputSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5444"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor
     device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; [Int]
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst outputSize, Snd outputSize],
      Tensor
        device
        'Int64
        '[batchSize, channelSize, Fst outputSize, Snd outputSize])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span>
</span><span id="line-5445"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.adaptive_max_pool2d_tl</span></a></span><span>
</span><span id="line-5446"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707925"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5447"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707932"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5448"></span><span>
</span><span id="line-5449"></span><span class="hs-comment">-- | adaptive 3-D max-pool</span><span>
</span><span id="line-5450"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5451"></span><span class="hs-comment">--</span><span>
</span><span id="line-5452"></span><span class="hs-comment">-- &gt;&gt;&gt; (t, t') = adaptiveMaxPool3d @'(8,16,2) (ones :: CPUTensor 'D.Float '[1,3,16,32,4])</span><span>
</span><span id="line-5453"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-5454"></span><span class="hs-comment">-- [1,3,8,16,2]</span><span>
</span><span id="line-5455"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-5456"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 8, 16, 2]</span><span>
</span><span id="line-5457"></span><span class="annot"><a href="Torch.Typed.Functional.html#adaptiveMaxPool3d"><span class="hs-identifier hs-type">adaptiveMaxPool3d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5458"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-5459"></span><span>    </span><span id="local-6989586621679707922"><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-5460"></span><span>    </span><span id="local-6989586621679707921"><span class="annot"><a href="#local-6989586621679707921"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span>
</span><span id="line-5461"></span><span>    </span><span id="local-6989586621679707920"><span class="annot"><a href="#local-6989586621679707920"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span>
</span><span id="line-5462"></span><span>    </span><span id="local-6989586621679707919"><span class="annot"><a href="#local-6989586621679707919"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span>
</span><span id="line-5463"></span><span>    </span><span id="local-6989586621679707918"><span class="annot"><a href="#local-6989586621679707918"><span class="hs-identifier hs-type">inputSize2</span></a></span></span><span>
</span><span id="line-5464"></span><span>    </span><span id="local-6989586621679707917"><span class="annot"><a href="#local-6989586621679707917"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-5465"></span><span>    </span><span id="local-6989586621679707916"><span class="annot"><a href="#local-6989586621679707916"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-5466"></span><span>    </span><span id="local-6989586621679707915"><span class="annot"><a href="#local-6989586621679707915"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5467"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-5468"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-5469"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="#local-6989586621679707921"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5470"></span><span>         </span><span class="annot"><a href="#local-6989586621679707920"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5471"></span><span>         </span><span class="annot"><a href="#local-6989586621679707919"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5472"></span><span>         </span><span class="annot"><a href="#local-6989586621679707918"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5473"></span><span>         </span><span class="annot"><a href="#local-6989586621679707917"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5474"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5475"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5476"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-5477"></span><span>       </span><span class="hs-special">]</span><span>
</span><span id="line-5478"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5479"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5480"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707915"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707916"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707917"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707921"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707920"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707919"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707918"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5481"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5482"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707915"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707916"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707917"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707921"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-5483"></span><span>    </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707915"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.DType.html#Int64"><span class="hs-identifier hs-type">D.Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707917"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707921"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5484"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-5485"></span><span id="adaptiveMaxPool3d"><span class="annot"><span class="annottext">adaptiveMaxPool3d :: Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize])
</span><a href="Torch.Typed.Functional.html#adaptiveMaxPool3d"><span class="hs-identifier hs-var hs-var">adaptiveMaxPool3d</span></a></span></span><span> </span><span id="local-6989586621679707914"><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679707914"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5486"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
       Trd3 outputSize],
   Tensor
     device
     'Int64
     '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
       Trd3 outputSize])
-&gt; (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize])
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize])
 -&gt; (Tensor
       device
       dtype
       '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
         Trd3 outputSize],
     Tensor
       device
       'Int64
       '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
         Trd3 outputSize]))
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
          Trd3 outputSize],
      Tensor
        device
        'Int64
        '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
          Trd3 outputSize])
-&gt; (Tensor
      device
      dtype
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize],
    Tensor
      device
      'Int64
      '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
        Trd3 outputSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5487"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor))))
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; [Int]
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
          Trd3 outputSize],
      Tensor
        device
        'Int64
        '[batchSize, channelSize, Fst3 outputSize, Snd3 outputSize,
          Trd3 outputSize])
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; IO (ForeignPtr (StdTuple '(Tensor, Tensor)))
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.adaptive_max_pool3d_tl</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5488"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679707914"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5489"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-special">[</span><span> </span><span class="annot"><span class="annottext">KnownNat (Fst3 outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-5490"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Snd3 outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-5491"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Trd3 outputSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707922"><span class="hs-identifier hs-type">outputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5492"></span><span>        </span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5493"></span><span>          </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-5494"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-5495"></span><span>
</span><span id="line-5496"></span><span class="hs-comment">-- | averaged 2-D pooling</span><span>
</span><span id="line-5497"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5498"></span><span class="hs-comment">--</span><span>
</span><span id="line-5499"></span><span class="hs-comment">-- &gt;&gt;&gt; t = avgPool2d @'(1,1) @'(1,1) @'(0,0) (ones :: CPUTensor 'D.Float '[1,3,4,5])</span><span>
</span><span id="line-5500"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-5501"></span><span class="hs-comment">-- [1,3,4,5]</span><span>
</span><span id="line-5502"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-5503"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 4, 5]</span><span>
</span><span id="line-5504"></span><span class="annot"><a href="Torch.Typed.Functional.html#avgPool2d"><span class="hs-identifier hs-type">avgPool2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5505"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-5506"></span><span>    </span><span id="local-6989586621679707911"><span class="annot"><a href="#local-6989586621679707911"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span>
</span><span id="line-5507"></span><span>    </span><span id="local-6989586621679707910"><span class="annot"><a href="#local-6989586621679707910"><span class="hs-identifier hs-type">stride</span></a></span></span><span>
</span><span id="line-5508"></span><span>    </span><span id="local-6989586621679707909"><span class="annot"><a href="#local-6989586621679707909"><span class="hs-identifier hs-type">padding</span></a></span></span><span>
</span><span id="line-5509"></span><span>    </span><span id="local-6989586621679707908"><span class="annot"><a href="#local-6989586621679707908"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span>
</span><span id="line-5510"></span><span>    </span><span id="local-6989586621679707907"><span class="annot"><a href="#local-6989586621679707907"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span>
</span><span id="line-5511"></span><span>    </span><span id="local-6989586621679707906"><span class="annot"><a href="#local-6989586621679707906"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span>
</span><span id="line-5512"></span><span>    </span><span id="local-6989586621679707905"><span class="annot"><a href="#local-6989586621679707905"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-5513"></span><span>    </span><span id="local-6989586621679707904"><span class="annot"><a href="#local-6989586621679707904"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span>
</span><span id="line-5514"></span><span>    </span><span id="local-6989586621679707903"><span class="annot"><a href="#local-6989586621679707903"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span>
</span><span id="line-5515"></span><span>    </span><span id="local-6989586621679707902"><span class="annot"><a href="#local-6989586621679707902"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-5516"></span><span>    </span><span id="local-6989586621679707901"><span class="annot"><a href="#local-6989586621679707901"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5517"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-5518"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-5519"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707911"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5520"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707911"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5521"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707910"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5522"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707910"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5523"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707909"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5524"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707909"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5525"></span><span>         </span><span class="annot"><a href="#local-6989586621679707908"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5526"></span><span>         </span><span class="annot"><a href="#local-6989586621679707907"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5527"></span><span>         </span><span class="annot"><a href="#local-6989586621679707906"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5528"></span><span>         </span><span class="annot"><a href="#local-6989586621679707905"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-5529"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-5530"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707907"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707911"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707910"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707909"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679707904"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5531"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707906"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707911"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707910"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707909"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679707903"><span class="hs-identifier hs-type">outputSize1</span></a></span><span>
</span><span id="line-5532"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5533"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5534"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707901"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707902"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707905"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707908"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707907"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707906"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5535"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5536"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707901"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707902"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707905"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707908"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707904"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707903"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5537"></span><span id="avgPool2d"><span class="annot"><span class="annottext">avgPool2d :: Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
</span><a href="Torch.Typed.Functional.html#avgPool2d"><span class="hs-identifier hs-var hs-var">avgPool2d</span></a></span></span><span> </span><span id="local-6989586621679707900"><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707900"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5538"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
 -&gt; Tensor
      device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
-&gt; Tensor
     device dtype '[batchSize, channelSize, outputSize0, outputSize1]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5539"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; CBool
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device dtype '[batchSize, channelSize, inputSize0, inputSize1]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Bool
-&gt; Bool
-&gt; Int
-&gt; IO
     (Tensor
        device dtype '[batchSize, channelSize, outputSize0, outputSize1])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast7</span></a></span><span>
</span><span id="line-5540"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; CBool
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.avg_pool2d_tlllbbl</span></a></span><span>
</span><span id="line-5541"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device dtype '[batchSize, channelSize, inputSize0, inputSize1]
</span><a href="#local-6989586621679707900"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5542"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707911"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707911"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5543"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707910"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707910"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5544"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst"><span class="hs-identifier hs-type">Torch.Typed.Aux.Fst</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707909"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd"><span class="hs-identifier hs-type">Torch.Typed.Aux.Snd</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707909"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5545"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-5546"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-5547"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-5548"></span><span>
</span><span id="line-5549"></span><span class="hs-comment">-- | averaged 3-D pooling</span><span>
</span><span id="line-5550"></span><span class="hs-comment">-- TODO: probably only defined for floating point tensors, or maybe numeric type is lifted?</span><span>
</span><span id="line-5551"></span><span class="hs-comment">--</span><span>
</span><span id="line-5552"></span><span class="hs-comment">-- &gt;&gt;&gt; t = avgPool3d @'(1,1,1) @'(1,1,1) @'(0,0,0) (ones :: CPUTensor 'D.Float '[1,3,4,5,6])</span><span>
</span><span id="line-5553"></span><span class="hs-comment">-- &gt;&gt;&gt; shape t</span><span>
</span><span id="line-5554"></span><span class="hs-comment">-- [1,3,4,5,6]</span><span>
</span><span id="line-5555"></span><span class="hs-comment">-- &gt;&gt;&gt; :t t</span><span>
</span><span id="line-5556"></span><span class="hs-comment">-- t :: Tensor '( 'D.CPU, 0) 'D.Float '[1, 3, 4, 5, 6]</span><span>
</span><span id="line-5557"></span><span class="annot"><a href="Torch.Typed.Functional.html#avgPool3d"><span class="hs-identifier hs-type">avgPool3d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5558"></span><span>  </span><span class="hs-keyword">forall</span><span>
</span><span id="line-5559"></span><span>    </span><span id="local-6989586621679707897"><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span></span><span>
</span><span id="line-5560"></span><span>    </span><span id="local-6989586621679707896"><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span></span><span>
</span><span id="line-5561"></span><span>    </span><span id="local-6989586621679707895"><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span></span><span>
</span><span id="line-5562"></span><span>    </span><span id="local-6989586621679707894"><span class="annot"><a href="#local-6989586621679707894"><span class="hs-identifier hs-type">channelSize</span></a></span></span><span>
</span><span id="line-5563"></span><span>    </span><span id="local-6989586621679707893"><span class="annot"><a href="#local-6989586621679707893"><span class="hs-identifier hs-type">inputSize0</span></a></span></span><span>
</span><span id="line-5564"></span><span>    </span><span id="local-6989586621679707892"><span class="annot"><a href="#local-6989586621679707892"><span class="hs-identifier hs-type">inputSize1</span></a></span></span><span>
</span><span id="line-5565"></span><span>    </span><span id="local-6989586621679707891"><span class="annot"><a href="#local-6989586621679707891"><span class="hs-identifier hs-type">inputSize2</span></a></span></span><span>
</span><span id="line-5566"></span><span>    </span><span id="local-6989586621679707890"><span class="annot"><a href="#local-6989586621679707890"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-5567"></span><span>    </span><span id="local-6989586621679707889"><span class="annot"><a href="#local-6989586621679707889"><span class="hs-identifier hs-type">outputSize0</span></a></span></span><span>
</span><span id="line-5568"></span><span>    </span><span id="local-6989586621679707888"><span class="annot"><a href="#local-6989586621679707888"><span class="hs-identifier hs-type">outputSize1</span></a></span></span><span>
</span><span id="line-5569"></span><span>    </span><span id="local-6989586621679707887"><span class="annot"><a href="#local-6989586621679707887"><span class="hs-identifier hs-type">outputSize2</span></a></span></span><span>
</span><span id="line-5570"></span><span>    </span><span id="local-6989586621679707886"><span class="annot"><a href="#local-6989586621679707886"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-5571"></span><span>    </span><span id="local-6989586621679707885"><span class="annot"><a href="#local-6989586621679707885"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5572"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span>
</span><span id="line-5573"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span>
</span><span id="line-5574"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5575"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5576"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5577"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5578"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5579"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5580"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5581"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5582"></span><span>         </span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5583"></span><span>         </span><span class="annot"><a href="#local-6989586621679707894"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5584"></span><span>         </span><span class="annot"><a href="#local-6989586621679707893"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5585"></span><span>         </span><span class="annot"><a href="#local-6989586621679707892"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5586"></span><span>         </span><span class="annot"><a href="#local-6989586621679707891"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5587"></span><span>         </span><span class="annot"><a href="#local-6989586621679707890"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-5588"></span><span>       </span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-5589"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707893"><span class="hs-identifier hs-type">inputSize0</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679707889"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5590"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707892"><span class="hs-identifier hs-type">inputSize1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679707888"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-5591"></span><span>    </span><span class="annot"><a href="Torch.Typed.Functional.html#ConvSideCheck"><span class="hs-identifier hs-type">ConvSideCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707891"><span class="hs-identifier hs-type">inputSize2</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679707887"><span class="hs-identifier hs-type">outputSize2</span></a></span><span>
</span><span id="line-5592"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5593"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-5594"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707885"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707886"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707890"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707894"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707893"><span class="hs-identifier hs-type">inputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707892"><span class="hs-identifier hs-type">inputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707891"><span class="hs-identifier hs-type">inputSize2</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5595"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-5596"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707885"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707886"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679707890"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707894"><span class="hs-identifier hs-type">channelSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707889"><span class="hs-identifier hs-type">outputSize0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707888"><span class="hs-identifier hs-type">outputSize1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679707887"><span class="hs-identifier hs-type">outputSize2</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-5597"></span><span id="avgPool3d"><span class="annot"><span class="annottext">avgPool3d :: Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2]
</span><a href="Torch.Typed.Functional.html#avgPool3d"><span class="hs-identifier hs-var hs-var">avgPool3d</span></a></span></span><span> </span><span id="local-6989586621679707884"><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679707884"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5598"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      device
      dtype
      '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
 -&gt; Tensor
      device
      dtype
      '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, outputSize0, outputSize1, outputSize2]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-5599"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr IntArray
 -&gt; CBool
 -&gt; CBool
 -&gt; Int64
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor
     device
     dtype
     '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
-&gt; [Int]
-&gt; [Int]
-&gt; [Int]
-&gt; Bool
-&gt; Bool
-&gt; Int
-&gt; IO
     (Tensor
        device
        dtype
        '[batchSize, channelSize, outputSize0, outputSize1, outputSize2])
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 x6 cx6 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable x6 cx6,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; cx6 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; x6 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast7</span></a></span><span>
</span><span id="line-5600"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr IntArray
-&gt; CBool
-&gt; CBool
-&gt; Int64
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.avg_pool3d_tlllbbl</span></a></span><span>
</span><span id="line-5601"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[batchSize, channelSize, inputSize0, inputSize1, inputSize2]
</span><a href="#local-6989586621679707884"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-5602"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-special">[</span><span> </span><span class="annot"><span class="annottext">KnownNat (Fst3 kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-5603"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Snd3 kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-5604"></span><span>          </span><span class="annot"><span class="annottext">KnownNat (Trd3 kernelSize) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707897"><span class="hs-identifier hs-type">kernelSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5605"></span><span>        </span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5606"></span><span>          </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-5607"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-5608"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Trd3 stride) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707896"><span class="hs-identifier hs-type">stride</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5609"></span><span>      </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">KnownNat (Fst3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Fst3"><span class="hs-identifier hs-type">Fst3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Snd3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Snd3"><span class="hs-identifier hs-type">Snd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">KnownNat (Trd3 padding) =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Aux.html#Trd3"><span class="hs-identifier hs-type">Trd3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707895"><span class="hs-identifier hs-type">padding</span></a></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5610"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-5611"></span><span>      </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-5612"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-5613"></span><span>
</span><span id="line-5614"></span><span class="hs-comment">-- fractional_max_pool2d :: Tensor device dtype shape -&gt; (Int,Int) -&gt; (Int,Int) -&gt; Tensor device dtype shape -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-5615"></span><span class="hs-comment">-- fractional_max_pool2d _input _kernel_size _output_size _random_samples = unsafePerformIO $ (ATen.cast4 ATen.Managed.fractional_max_pool2d_tllt) _input _kernel_size _output_size _random_samples</span><span>
</span><span id="line-5616"></span><span>
</span><span id="line-5617"></span><span class="hs-comment">-- fractional_max_pool3d :: Tensor device dtype shape -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; Tensor device dtype shape -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-5618"></span><span class="hs-comment">-- fractional_max_pool3d _input _kernel_size _output_size _random_samples = unsafePerformIO $ (ATen.cast4 ATen.Managed.fractional_max_pool3d_tllt) _input _kernel_size _output_size _random_samples</span><span>
</span><span id="line-5619"></span><span>
</span><span id="line-5620"></span><span class="hs-comment">-- max_pool2d_with_indices :: Tensor device dtype shape -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-5621"></span><span class="hs-comment">-- max_pool2d_with_indices _input _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (ATen.cast6 ATen.Managed.max_pool2d_with_indices_tllllb) _input _kernel_size _stride _padding _dilation _ceil_mode</span><span>
</span><span id="line-5622"></span><span>
</span><span id="line-5623"></span><span class="hs-comment">-- max_pool3d_with_indices :: Tensor device dtype shape -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; Bool -&gt; (Tensor device dtype shape,Tensor device dtype shape)</span><span>
</span><span id="line-5624"></span><span class="hs-comment">-- max_pool3d_with_indices _input _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (ATen.cast6 ATen.Managed.max_pool3d_with_indices_tllllb) _input _kernel_size _stride _padding _dilation _ceil_mode</span><span>
</span><span id="line-5625"></span><span>
</span><span id="line-5626"></span><span class="hs-comment">-- max_unpool2d :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; (Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5627"></span><span class="hs-comment">-- max_unpool2d _input _indices _output_size = unsafePerformIO $ (ATen.cast3 ATen.Managed.max_unpool2d_ttl) _input _indices _output_size</span><span>
</span><span id="line-5628"></span><span>
</span><span id="line-5629"></span><span class="hs-comment">-- max_unpool3d :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5630"></span><span class="hs-comment">-- max_unpool3d _input _indices _output_size _stride _padding = unsafePerformIO $ (ATen.cast5 ATen.Managed.max_unpool3d_ttlll) _input _indices _output_size _stride _padding</span><span>
</span><span id="line-5631"></span><span>
</span><span id="line-5632"></span><span class="hs-comment">-- reflection_pad1d :: Tensor device dtype shape -&gt; (Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5633"></span><span class="hs-comment">-- reflection_pad1d _input _padding = unsafePerformIO $ (ATen.cast2 ATen.Managed.reflection_pad1d_tl) _input _padding</span><span>
</span><span id="line-5634"></span><span>
</span><span id="line-5635"></span><span class="hs-comment">-- reflection_pad2d :: Tensor device dtype shape -&gt; (Int,Int,Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5636"></span><span class="hs-comment">-- reflection_pad2d _input _padding = unsafePerformIO $ (ATen.cast2 ATen.Managed.reflection_pad2d_tl) _input _padding</span><span>
</span><span id="line-5637"></span><span>
</span><span id="line-5638"></span><span class="hs-comment">-- replication_pad1d :: Tensor device dtype shape -&gt; (Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5639"></span><span class="hs-comment">-- replication_pad1d _input _padding = unsafePerformIO $ (ATen.cast2 ATen.Managed.replication_pad1d_tl) _input _padding</span><span>
</span><span id="line-5640"></span><span>
</span><span id="line-5641"></span><span class="hs-comment">-- replication_pad2d :: Tensor device dtype shape -&gt; (Int,Int,Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5642"></span><span class="hs-comment">-- replication_pad2d _input _padding = unsafePerformIO $ (ATen.cast2 ATen.Managed.replication_pad2d_tl) _input _padding</span><span>
</span><span id="line-5643"></span><span>
</span><span id="line-5644"></span><span class="hs-comment">-- replication_pad3d :: Tensor device dtype shape -&gt; (Int,Int,Int,Int,Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5645"></span><span class="hs-comment">-- replication_pad3d _input _padding = unsafePerformIO $ (ATen.cast2 ATen.Managed.replication_pad3d_tl) _input _padding</span><span>
</span><span id="line-5646"></span><span>
</span><span id="line-5647"></span><span class="hs-comment">-- upsample_linear1d :: Tensor device dtype shape -&gt; Int -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5648"></span><span class="hs-comment">-- upsample_linear1d _input _output_size _align_corners = unsafePerformIO $ (ATen.cast3 ATen.Managed.upsample_linear1d_tlb) _input _output_size _align_corners</span><span>
</span><span id="line-5649"></span><span>
</span><span id="line-5650"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="Upsample2dCheck"><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2dCheck"><span class="hs-identifier hs-var">Upsample2dCheck</span></a></span></span><span> </span><span id="local-6989586621679707881"><span class="annot"><a href="#local-6989586621679707881"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707880"><span class="annot"><a href="#local-6989586621679707880"><span class="hs-identifier hs-type">h</span></a></span></span><span> </span><span id="local-6989586621679707879"><span class="annot"><a href="#local-6989586621679707879"><span class="hs-identifier hs-type">w</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-5651"></span><span>  </span><span id="Upsample2dCheck"><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2dCheck"><span class="hs-identifier hs-var">Upsample2dCheck</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679707878"><span class="annot"><a href="#local-6989586621679707878"><span class="hs-identifier hs-type hs-type">b</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679707877"><span class="annot"><a href="#local-6989586621679707877"><span class="hs-identifier hs-type hs-type">c</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679707876"><span class="annot"><a href="#local-6989586621679707876"><span class="hs-identifier hs-type hs-type">w</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679707875"><span class="annot"><a href="#local-6989586621679707875"><span class="hs-identifier hs-type hs-type">h</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679707874"><span class="annot"><a href="#local-6989586621679707874"><span class="hs-identifier hs-type hs-type">h'</span></a></span></span><span> </span><span id="local-6989586621679707873"><span class="annot"><a href="#local-6989586621679707873"><span class="hs-identifier hs-type hs-type">w'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5652"></span><span>    </span><span class="annot"><a href="Torch.Typed.Aux.html#If"><span class="hs-identifier hs-type">If</span></a></span><span>
</span><span id="line-5653"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679707875"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=?</span></span><span> </span><span class="annot"><a href="#local-6989586621679707874"><span class="hs-identifier hs-type">h'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5654"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Aux.html#If"><span class="hs-identifier hs-type">If</span></a></span><span>
</span><span id="line-5655"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679707876"><span class="hs-identifier hs-type">w</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=?</span></span><span> </span><span class="annot"><a href="#local-6989586621679707873"><span class="hs-identifier hs-type">w'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5656"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679707878"><span class="hs-identifier hs-type">b</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679707877"><span class="hs-identifier hs-type">c</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679707873"><span class="hs-identifier hs-type">w'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679707874"><span class="hs-identifier hs-type">h'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5657"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Target width must be greater than current width!&quot;</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-5658"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-5659"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Target height must be greater than current height!&quot;</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-5660"></span><span>  </span><span id="Upsample2dCheck"><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2dCheck"><span class="hs-identifier hs-var">Upsample2dCheck</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="annot"><span class="hs-string">&quot;Shape must be 4 dimensional!&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-5661"></span><span>
</span><span id="line-5662"></span><span class="hs-keyword">type</span><span> </span><span id="Upsample2d"><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2d"><span class="hs-identifier hs-var">Upsample2d</span></a></span></span><span> </span><span id="local-6989586621679707872"><span class="annot"><a href="#local-6989586621679707872"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707871"><span class="annot"><a href="#local-6989586621679707871"><span class="hs-identifier hs-type">h</span></a></span></span><span> </span><span id="local-6989586621679707870"><span class="annot"><a href="#local-6989586621679707870"><span class="hs-identifier hs-type">w</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2dCheck"><span class="hs-identifier hs-type">Upsample2dCheck</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707872"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707871"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707870"><span class="hs-identifier hs-type">w</span></a></span><span>
</span><span id="line-5663"></span><span>
</span><span id="line-5664"></span><span class="hs-comment">-- | Applies a 2D bilinear upsampling to an input signal composed of several input channels.</span><span>
</span><span id="line-5665"></span><span class="hs-comment">--</span><span>
</span><span id="line-5666"></span><span class="hs-comment">-- &gt;&gt;&gt; (dtype &amp;&amp;&amp; shape) $ upsample_bilinear2d @3 @5 False (ones :: CPUTensor 'D.Float '[2,3,2,2])</span><span>
</span><span id="line-5667"></span><span class="hs-comment">-- (Float,[2,3,3,5])</span><span>
</span><span id="line-5668"></span><span class="annot"><a href="Torch.Typed.Functional.html#upsample_bilinear2d"><span class="hs-identifier hs-type">upsample_bilinear2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5669"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707868"><span class="annot"><a href="#local-6989586621679707868"><span class="hs-identifier hs-type">w</span></a></span></span><span> </span><span id="local-6989586621679707867"><span class="annot"><a href="#local-6989586621679707867"><span class="hs-identifier hs-type">h</span></a></span></span><span> </span><span id="local-6989586621679707866"><span class="annot"><a href="#local-6989586621679707866"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707865"><span class="annot"><a href="#local-6989586621679707865"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707864"><span class="annot"><a href="#local-6989586621679707864"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5670"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707867"><span class="hs-identifier hs-type">h</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707868"><span class="hs-identifier hs-type">w</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707866"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5671"></span><span>  </span><span class="hs-comment">-- | if True, the corner pixels of the input and output tensors are aligned, and thus preserving the values at those pixels.</span><span>
</span><span id="line-5672"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5673"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707864"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707865"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707866"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5674"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707864"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707865"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2d"><span class="hs-identifier hs-type">Upsample2d</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707866"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707867"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707868"><span class="hs-identifier hs-type">w</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5675"></span><span id="upsample_bilinear2d"><span class="annot"><span class="annottext">upsample_bilinear2d :: Bool
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype (Upsample2d shape h w)
</span><a href="Torch.Typed.Functional.html#upsample_bilinear2d"><span class="hs-identifier hs-var hs-var">upsample_bilinear2d</span></a></span></span><span> </span><span id="local-6989586621679707863"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679707863"><span class="hs-identifier hs-var">_align_corners</span></a></span></span><span> </span><span id="local-6989586621679707862"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707862"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-5676"></span><span>  </span><span class="annot"><span class="annottext">IO (Tensor device dtype (Upsample2d shape h w))
-&gt; Tensor device dtype (Upsample2d shape h w)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (Upsample2d shape h w))
 -&gt; Tensor device dtype (Upsample2d shape h w))
-&gt; IO (Tensor device dtype (Upsample2d shape h w))
-&gt; Tensor device dtype (Upsample2d shape h w)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; [Int]
-&gt; Bool
-&gt; IO (Tensor device dtype (Upsample2d shape h w))
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.upsample_bilinear2d_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707862"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679707860"><span class="hs-identifier hs-var">w</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679707859"><span class="hs-identifier hs-var">h</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679707863"><span class="hs-identifier hs-var">_align_corners</span></a></span><span>
</span><span id="line-5677"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-5678"></span><span>    </span><span id="local-6989586621679707860"><span class="annot"><span class="annottext">w :: Int
</span><a href="#local-6989586621679707860"><span class="hs-identifier hs-var hs-var">w</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat w =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679707868"><span class="hs-identifier hs-type">w</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-5679"></span><span>    </span><span id="local-6989586621679707859"><span class="annot"><span class="annottext">h :: Int
</span><a href="#local-6989586621679707859"><span class="hs-identifier hs-var hs-var">h</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat h =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679707867"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-5680"></span><span>
</span><span id="line-5681"></span><span class="hs-comment">-- | Applies a 2D bicubic upsampling to an input signal composed of several input channels.</span><span>
</span><span id="line-5682"></span><span class="hs-comment">--</span><span>
</span><span id="line-5683"></span><span class="hs-comment">-- &gt;&gt;&gt; (dtype &amp;&amp;&amp; shape) $ upsample_bicubic2d @3 @5 False (ones :: CPUTensor 'D.Float '[2,3,2,2])</span><span>
</span><span id="line-5684"></span><span class="hs-comment">-- (Float,[2,3,3,5])</span><span>
</span><span id="line-5685"></span><span class="annot"><a href="Torch.Typed.Functional.html#upsample_bicubic2d"><span class="hs-identifier hs-type">upsample_bicubic2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5686"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707857"><span class="annot"><a href="#local-6989586621679707857"><span class="hs-identifier hs-type">w</span></a></span></span><span> </span><span id="local-6989586621679707856"><span class="annot"><a href="#local-6989586621679707856"><span class="hs-identifier hs-type">h</span></a></span></span><span> </span><span id="local-6989586621679707855"><span class="annot"><a href="#local-6989586621679707855"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707854"><span class="annot"><a href="#local-6989586621679707854"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707853"><span class="annot"><a href="#local-6989586621679707853"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5687"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707856"><span class="hs-identifier hs-type">h</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707857"><span class="hs-identifier hs-type">w</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707855"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5688"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5689"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707853"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707854"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707855"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5690"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707853"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707854"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2d"><span class="hs-identifier hs-type">Upsample2d</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707855"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707856"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707857"><span class="hs-identifier hs-type">w</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5691"></span><span id="upsample_bicubic2d"><span class="annot"><span class="annottext">upsample_bicubic2d :: Bool
-&gt; Tensor device dtype shape
-&gt; Tensor device dtype (Upsample2d shape h w)
</span><a href="Torch.Typed.Functional.html#upsample_bicubic2d"><span class="hs-identifier hs-var hs-var">upsample_bicubic2d</span></a></span></span><span> </span><span id="local-6989586621679707852"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679707852"><span class="hs-identifier hs-var">_align_corners</span></a></span></span><span> </span><span id="local-6989586621679707851"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707851"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (Upsample2d shape h w))
-&gt; Tensor device dtype (Upsample2d shape h w)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (Upsample2d shape h w))
 -&gt; Tensor device dtype (Upsample2d shape h w))
-&gt; IO (Tensor device dtype (Upsample2d shape h w))
-&gt; Tensor device dtype (Upsample2d shape h w)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; [Int]
-&gt; Bool
-&gt; IO (Tensor device dtype (Upsample2d shape h w))
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.upsample_bicubic2d_tlb</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707851"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679707849"><span class="hs-identifier hs-var">w</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679707848"><span class="hs-identifier hs-var">h</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679707852"><span class="hs-identifier hs-var">_align_corners</span></a></span><span>
</span><span id="line-5692"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-5693"></span><span>    </span><span id="local-6989586621679707849"><span class="annot"><span class="annottext">w :: Int
</span><a href="#local-6989586621679707849"><span class="hs-identifier hs-var hs-var">w</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat w =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679707857"><span class="hs-identifier hs-type">w</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-5694"></span><span>    </span><span id="local-6989586621679707848"><span class="annot"><span class="annottext">h :: Int
</span><a href="#local-6989586621679707848"><span class="hs-identifier hs-var hs-var">h</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat h =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679707856"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-5695"></span><span>
</span><span id="line-5696"></span><span class="hs-comment">-- upsample_trilinear3d :: Tensor device dtype shape -&gt; (Int,Int,Int) -&gt; Bool -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5697"></span><span class="hs-comment">-- upsample_trilinear3d _input _output_size _align_corners = unsafePerformIO $ (ATen.cast3 ATen.Managed.upsample_trilinear3d_tlb) _input _output_size _align_corners</span><span>
</span><span id="line-5698"></span><span>
</span><span id="line-5699"></span><span class="hs-comment">-- upsample_nearest1d :: Tensor device dtype shape -&gt; Int -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5700"></span><span class="hs-comment">-- upsample_nearest1d _input _output_size = unsafePerformIO $ (ATen.cast2 ATen.Managed.upsample_nearest1d_tl) _input _output_size</span><span>
</span><span id="line-5701"></span><span>
</span><span id="line-5702"></span><span class="hs-comment">-- | Applies a 2D bicubic upsampling to an input signal composed of several input channels.</span><span>
</span><span id="line-5703"></span><span class="hs-comment">--</span><span>
</span><span id="line-5704"></span><span class="hs-comment">-- &gt;&gt;&gt; (dtype &amp;&amp;&amp; shape) $ upsample_nearest2d @3 @5 (ones :: CPUTensor 'D.Float '[2,3,2,2])</span><span>
</span><span id="line-5705"></span><span class="hs-comment">-- (Float,[2,3,3,5])</span><span>
</span><span id="line-5706"></span><span class="annot"><a href="Torch.Typed.Functional.html#upsample_nearest2d"><span class="hs-identifier hs-type">upsample_nearest2d</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-5707"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679707846"><span class="annot"><a href="#local-6989586621679707846"><span class="hs-identifier hs-type">w</span></a></span></span><span> </span><span id="local-6989586621679707845"><span class="annot"><a href="#local-6989586621679707845"><span class="hs-identifier hs-type">h</span></a></span></span><span> </span><span id="local-6989586621679707844"><span class="annot"><a href="#local-6989586621679707844"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679707843"><span class="annot"><a href="#local-6989586621679707843"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679707842"><span class="annot"><a href="#local-6989586621679707842"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-5708"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707845"><span class="hs-identifier hs-type">h</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707846"><span class="hs-identifier hs-type">w</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#All"><span class="hs-identifier hs-type">All</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679707844"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-5709"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707842"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707843"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707844"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-5710"></span><span>  </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707842"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707843"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#Upsample2d"><span class="hs-identifier hs-type">Upsample2d</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707844"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707845"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679707846"><span class="hs-identifier hs-type">w</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-5711"></span><span id="upsample_nearest2d"><span class="annot"><span class="annottext">upsample_nearest2d :: Tensor device dtype shape
-&gt; Tensor device dtype (Upsample2d shape h w)
</span><a href="Torch.Typed.Functional.html#upsample_nearest2d"><span class="hs-identifier hs-var hs-var">upsample_nearest2d</span></a></span></span><span> </span><span id="local-6989586621679707841"><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707841"><span class="hs-identifier hs-var">_input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (Upsample2d shape h w))
-&gt; Tensor device dtype (Upsample2d shape h w)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor device dtype (Upsample2d shape h w))
 -&gt; Tensor device dtype (Upsample2d shape h w))
-&gt; IO (Tensor device dtype (Upsample2d shape h w))
-&gt; Tensor device dtype (Upsample2d shape h w)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor device dtype shape
-&gt; [Int]
-&gt; IO (Tensor device dtype (Upsample2d shape h w))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr IntArray -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.Managed.upsample_nearest2d_tl</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype shape
</span><a href="#local-6989586621679707841"><span class="hs-identifier hs-var">_input</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679707839"><span class="hs-identifier hs-var">w</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679707838"><span class="hs-identifier hs-var">h</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-5712"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-5713"></span><span>    </span><span id="local-6989586621679707839"><span class="annot"><span class="annottext">w :: Int
</span><a href="#local-6989586621679707839"><span class="hs-identifier hs-var hs-var">w</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat w =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679707846"><span class="hs-identifier hs-type">w</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-5714"></span><span>    </span><span id="local-6989586621679707838"><span class="annot"><span class="annottext">h :: Int
</span><a href="#local-6989586621679707838"><span class="hs-identifier hs-var hs-var">h</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownNat h =&gt; Int
forall (n :: Nat). KnownNat n =&gt; Int
</span><a href="Torch.Typed.Aux.html#natValI"><span class="hs-identifier hs-var">natValI</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679707845"><span class="hs-identifier hs-type">h</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-5715"></span><span>
</span><span id="line-5716"></span><span class="hs-comment">-- upsample_nearest3d :: Tensor device dtype shape -&gt; (Int,Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5717"></span><span class="hs-comment">-- upsample_nearest3d _input _output_size = unsafePerformIO $ (ATen.cast2 ATen.Managed.upsample_nearest3d_tl) _input _output_size</span><span>
</span><span id="line-5718"></span><span>
</span><span id="line-5719"></span><span class="hs-comment">-- conv_dilated2d :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; (Int,Int) -&gt; Tensor device dtype shape -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5720"></span><span class="hs-comment">-- conv_dilated2d _input _weight _kernel_size _bias _stride _padding _dilation = unsafePerformIO $ (ATen.cast7 ATen.Managed.conv_dilated2d_ttltlll) _input _weight _kernel_size _bias _stride _padding _dilation</span><span>
</span><span id="line-5721"></span><span>
</span><span id="line-5722"></span><span class="hs-comment">-- conv_dilated3d :: Tensor device dtype shape -&gt; Tensor device dtype shape -&gt; (Int,Int,Int) -&gt; Tensor device dtype shape -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; (Int,Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5723"></span><span class="hs-comment">-- conv_dilated3d _input _weight _kernel_size _bias _stride _padding _dilation = unsafePerformIO $ (ATen.cast7 ATen.Managed.conv_dilated3d_ttltlll) _input _weight _kernel_size _bias _stride _padding _dilation</span><span>
</span><span id="line-5724"></span><span>
</span><span id="line-5725"></span><span class="hs-comment">-- col2im :: Tensor device dtype shape -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5726"></span><span class="hs-comment">-- col2im _input _output_size _kernel_size _dilation _padding _stride = unsafePerformIO $ (ATen.cast6 ATen.Managed.col2im_tlllll) _input _output_size _kernel_size _dilation _padding _stride</span><span>
</span><span id="line-5727"></span><span>
</span><span id="line-5728"></span><span class="hs-comment">-- im2col :: Tensor device dtype shape -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; (Int,Int) -&gt; Tensor device dtype shape</span><span>
</span><span id="line-5729"></span><span class="hs-comment">-- im2col _input _kernel_size _dilation _padding _stride = unsafePerformIO $ (ATen.cast5 ATen.Managed.im2col_tllll) _input _kernel_size _dilation _padding _stride</span><span>
</span><span id="line-5730"></span></pre></body></html>