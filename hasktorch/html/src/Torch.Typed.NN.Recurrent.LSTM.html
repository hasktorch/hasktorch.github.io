<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE NoStarIsType #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE OverloadedLists #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE QuantifiedConstraints #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE StrictData #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-20"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-21"></span><span class="hs-pragma">{-# LANGUAGE UndecidableSuperClasses #-}</span><span>
</span><span id="line-22"></span><span class="hs-pragma">{-# LANGUAGE StandaloneDeriving #-}</span><span>
</span><span id="line-23"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-24"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin GHC.TypeLits.Normalise #-}</span><span>
</span><span id="line-25"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin GHC.TypeLits.KnownNat.Solver #-}</span><span>
</span><span id="line-26"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin GHC.TypeLits.Extra.Solver #-}</span><span>
</span><span id="line-27"></span><span class="hs-pragma">{-# OPTIONS_GHC -fno-warn-partial-type-signatures #-}</span><span>
</span><span id="line-28"></span><span>
</span><span id="line-29"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.Typed.NN.Recurrent.LSTM</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-30"></span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span>                 </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier">tanh</span></span><span> </span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.HList.html"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><span class="hs-identifier">Foreign.ForeignPtr</span></span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="../file:///nix/store/4rdd355v4wjgdxhl3jckcl3acr69ynkg-ghc-typelits-extra-lib-ghc-typelits-extra-0.4-doc/share/doc/ghc-typelits-extra/html/src"><span class="hs-identifier">GHC.TypeLits.Extra</span></a></span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><span class="hs-identifier">System.Environment</span></span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span>
</span><span id="line-40"></span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span>                     </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span>                    </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tensor</span></a></span><span>      </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span>                     </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Autograd.html"><span class="hs-identifier">Torch.Autograd</span></a></span><span>                </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">A</span></span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Device.html"><span class="hs-identifier">Torch.Device</span></a></span><span>                  </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.DType.html"><span class="hs-identifier">Torch.DType</span></a></span><span>                   </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Functional.html"><span class="hs-identifier">Torch.Functional</span></a></span><span>              </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.NN.html"><span class="hs-identifier">Torch.NN</span></a></span><span>                      </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">A</span></span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.Tensor.html"><span class="hs-identifier">Torch.Tensor</span></a></span><span>                  </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.TensorFactories.html"><span class="hs-identifier">Torch.TensorFactories</span></a></span><span>         </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">D</span></span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.html"><span class="hs-identifier">Torch.Typed</span></a></span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Factories.html"><span class="hs-identifier">Torch.Typed.Factories</span></a></span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Functional.html"><span class="hs-identifier">Torch.Typed.Functional</span></a></span><span>      </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#sqrt"><span class="hs-identifier">sqrt</span></a></span><span> </span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Tensor.html"><span class="hs-identifier">Torch.Typed.Tensor</span></a></span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.Parameter.html"><span class="hs-identifier">Torch.Typed.Parameter</span></a></span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span>           </span><span class="annot"><a href="Torch.Typed.NN.html"><span class="hs-identifier">Torch.Typed.NN</span></a></span><span>
</span><span id="line-58"></span><span>
</span><span id="line-59"></span><span class="hs-keyword">data</span><span> </span><span id="LSTMLayerSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-var">LSTMLayerSpec</span></a></span></span><span>
</span><span id="line-60"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729307"><span class="annot"><a href="#local-6989586621679729307"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729306"><span class="annot"><a href="#local-6989586621679729306"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729305"><span class="annot"><a href="#local-6989586621679729305"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729304"><span class="annot"><a href="#local-6989586621679729304"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729303"><span class="annot"><a href="#local-6989586621679729303"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="LSTMLayerSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-var">LSTMLayerSpec</span></a></span></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728972"><span id="local-6989586621679728974"><span id="local-6989586621679728976"><span class="annot"><span class="annottext">Int
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; ShowS
[LSTMLayerSpec inputSize hiddenSize directionality dtype device]
-&gt; ShowS
LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; String
(Int
 -&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
 -&gt; ShowS)
-&gt; (LSTMLayerSpec inputSize hiddenSize directionality dtype device
    -&gt; String)
-&gt; ([LSTMLayerSpec
       inputSize hiddenSize directionality dtype device]
    -&gt; ShowS)
-&gt; Show
     (LSTMLayerSpec inputSize hiddenSize directionality dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTMLayerSpec inputSize hiddenSize directionality dtype device]
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; String
showList :: [LSTMLayerSpec inputSize hiddenSize directionality dtype device]
-&gt; ShowS
$cshowList :: forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTMLayerSpec inputSize hiddenSize directionality dtype device]
-&gt; ShowS
show :: LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; String
$cshow :: forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; String
showsPrec :: Int
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; ShowS
$cshowsPrec :: forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679728967"><span id="local-6989586621679728969"><span class="annot"><span class="annottext">LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; Bool
(LSTMLayerSpec inputSize hiddenSize directionality dtype device
 -&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
 -&gt; Bool)
-&gt; (LSTMLayerSpec inputSize hiddenSize directionality dtype device
    -&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
    -&gt; Bool)
-&gt; Eq
     (LSTMLayerSpec inputSize hiddenSize directionality dtype device)
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; Bool
/= :: LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; Bool
$c/= :: forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; Bool
== :: LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; Bool
$c== :: forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span>
</span><span id="line-67"></span><span class="hs-keyword">data</span><span> </span><span id="LSTMLayer"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-var">LSTMLayer</span></a></span></span><span>
</span><span id="line-68"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728965"><span class="annot"><a href="#local-6989586621679728965"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-69"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728964"><span class="annot"><a href="#local-6989586621679728964"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728963"><span class="annot"><a href="#local-6989586621679728963"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-71"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728962"><span class="annot"><a href="#local-6989586621679728962"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-72"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728961"><span class="annot"><a href="#local-6989586621679728961"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-74"></span><span>  </span><span id="local-6989586621679729459"><span id="local-6989586621679729460"><span id="local-6989586621679729461"><span id="local-6989586621679729462"><span id="LSTMUnidirectionalLayer"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMUnidirectionalLayer"><span class="hs-identifier hs-var">LSTMUnidirectionalLayer</span></a></span></span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729462"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729461"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729460"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729459"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729462"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729461"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729460"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729459"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729462"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729461"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729460"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729459"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729462"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729461"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729460"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729459"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-79"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729459"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729460"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729461"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729462"><span class="hs-identifier hs-type">device</span></a></span></span></span></span></span><span>
</span><span id="line-80"></span><span>  </span><span id="local-6989586621679729443"><span id="local-6989586621679729444"><span id="local-6989586621679729445"><span id="local-6989586621679729446"><span id="LSTMBidirectionalLayer"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMBidirectionalLayer"><span class="hs-identifier hs-var">LSTMBidirectionalLayer</span></a></span></span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729443"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729444"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729445"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729446"><span class="hs-identifier hs-type">device</span></a></span></span></span></span></span><span>
</span><span id="line-90"></span><span>
</span><span id="line-91"></span><span id="local-6989586621679728947"><span id="local-6989586621679728949"><span id="local-6989586621679728951"><span id="local-6989586621679728953"><span id="local-6989586621679728954"><span id="local-6989586621679728955"><span id="local-6989586621679728956"><span id="local-6989586621679728957"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728957"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728956"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728955"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728954"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728953"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span><span>
</span><span id="line-92"></span><span class="hs-comment">-- deriving instance Generic (LSTMLayer inputSize hiddenSize directionality dtype device)</span><span>
</span><span id="line-93"></span><span>
</span><span id="line-94"></span><span id="local-6989586621679728938"><span id="local-6989586621679728939"><span id="local-6989586621679728940"><span id="local-6989586621679728941"><span id="local-6989586621679728942"><span id="local-6989586621679728943"><span id="local-6989586621679728944"><span id="local-6989586621679728945"><span id="local-6989586621679728946"><span class="hs-keyword">instance</span><span>
</span><span id="line-95"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679728946"><span class="hs-identifier hs-type">wiShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728945"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728944"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728943"><span class="hs-identifier hs-type">whShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728945"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728944"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728942"><span class="hs-identifier hs-type">biShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728945"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728944"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728941"><span class="hs-identifier hs-type">bhShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728945"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728944"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728940"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728939"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728938"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728946"><span class="hs-identifier hs-type">wiShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728939"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728938"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728943"><span class="hs-identifier hs-type">whShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728939"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728938"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728942"><span class="hs-identifier hs-type">biShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728939"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728938"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728941"><span class="hs-identifier hs-type">bhShape</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-100"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">R</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728944"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728945"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728938"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728939"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728940"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-101"></span><span>  </span><span id="local-6989586621679728934"><span class="annot"><span class="annottext">gFlattenParameters :: K1
  R (LSTMLayer inputSize hiddenSize 'Unidirectional dtype device) a
-&gt; HList parameters
</span><a href="Torch.Typed.Parameter.html#gFlattenParameters"><span class="hs-identifier hs-var hs-var hs-var hs-var">gFlattenParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMUnidirectionalLayer"><span class="hs-identifier hs-type">LSTMUnidirectionalLayer</span></a></span><span> </span><span id="local-6989586621679728931"><span class="annot"><span class="annottext">wi :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728931"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span id="local-6989586621679728930"><span class="annot"><span class="annottext">wh :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728930"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span id="local-6989586621679728929"><span class="annot"><span class="annottext">bi :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728929"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span id="local-6989586621679728928"><span class="annot"><span class="annottext">bh :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728928"><span class="hs-identifier hs-var">bh</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-102"></span><span>    </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728931"><span class="hs-identifier hs-var">wi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728930"><span class="hs-identifier hs-var">wh</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728929"><span class="hs-identifier hs-var">bi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728928"><span class="hs-identifier hs-var">bh</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; HList '[]
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-var">HNil</span></a></span><span>
</span><span id="line-103"></span><span>  </span><span id="local-6989586621679728925"><span class="annot"><span class="annottext">gReplaceParameters :: K1
  R (LSTMLayer inputSize hiddenSize 'Unidirectional dtype device) a
-&gt; HList parameters
-&gt; K1
     R (LSTMLayer inputSize hiddenSize 'Unidirectional dtype device) a
</span><a href="Torch.Typed.Parameter.html#gReplaceParameters"><span class="hs-identifier hs-var hs-var hs-var hs-var">gReplaceParameters</span></a></span></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728923"><span class="annot"><a href="#local-6989586621679728923"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728922"><span class="annot"><a href="#local-6989586621679728922"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728921"><span class="annot"><a href="#local-6989586621679728921"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728920"><span class="annot"><a href="#local-6989586621679728920"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-type">HNil</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-104"></span><span>    </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
-&gt; K1
     R (LSTMLayer inputSize hiddenSize 'Unidirectional dtype device) a
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (inputSize :: Nat).
Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMUnidirectionalLayer"><span class="hs-identifier hs-var">LSTMUnidirectionalLayer</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728923"><span class="hs-identifier hs-var">wi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728922"><span class="hs-identifier hs-var">wh</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728921"><span class="hs-identifier hs-var">bi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728920"><span class="hs-identifier hs-var">bh</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-105"></span><span>
</span><span id="line-106"></span><span id="local-6989586621679728911"><span id="local-6989586621679728912"><span id="local-6989586621679728913"><span id="local-6989586621679728914"><span id="local-6989586621679728915"><span id="local-6989586621679728916"><span id="local-6989586621679728917"><span id="local-6989586621679728918"><span id="local-6989586621679728919"><span class="hs-keyword">instance</span><span>
</span><span id="line-107"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679728919"><span class="hs-identifier hs-type">wiShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWIShape"><span class="hs-identifier hs-type">LSTMWIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728918"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728917"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728916"><span class="hs-identifier hs-type">whShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMWHShape"><span class="hs-identifier hs-type">LSTMWHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728918"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728917"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728915"><span class="hs-identifier hs-type">biShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBIShape"><span class="hs-identifier hs-type">LSTMBIShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728918"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728917"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728914"><span class="hs-identifier hs-type">bhShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMBHShape"><span class="hs-identifier hs-type">LSTMBHShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728918"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728917"><span class="hs-identifier hs-type">inputSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728913"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728919"><span class="hs-identifier hs-type">wiShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728916"><span class="hs-identifier hs-type">whShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728915"><span class="hs-identifier hs-type">biShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728914"><span class="hs-identifier hs-type">bhShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728919"><span class="hs-identifier hs-type">wiShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728916"><span class="hs-identifier hs-type">whShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728915"><span class="hs-identifier hs-type">biShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728914"><span class="hs-identifier hs-type">bhShape</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-112"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">R</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728917"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728918"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728911"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728912"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728913"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-113"></span><span>  </span><span id="local-6989586621679728908"><span class="annot"><span class="annottext">gFlattenParameters :: K1 R (LSTMLayer inputSize hiddenSize 'Bidirectional dtype device) a
-&gt; HList parameters
</span><a href="#local-6989586621679728908"><span class="hs-identifier hs-var hs-var hs-var hs-var">gFlattenParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMBidirectionalLayer"><span class="hs-identifier hs-type">LSTMBidirectionalLayer</span></a></span><span> </span><span id="local-6989586621679728907"><span class="annot"><span class="annottext">wi :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728907"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span id="local-6989586621679728906"><span class="annot"><span class="annottext">wh :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728906"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span id="local-6989586621679728905"><span class="annot"><span class="annottext">bi :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728905"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span id="local-6989586621679728904"><span class="annot"><span class="annottext">bh :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728904"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span id="local-6989586621679728903"><span class="annot"><span class="annottext">wi' :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728903"><span class="hs-identifier hs-var">wi'</span></a></span></span><span> </span><span id="local-6989586621679728902"><span class="annot"><span class="annottext">wh' :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728902"><span class="hs-identifier hs-var">wh'</span></a></span></span><span> </span><span id="local-6989586621679728901"><span class="annot"><span class="annottext">bi' :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728901"><span class="hs-identifier hs-var">bi'</span></a></span></span><span> </span><span id="local-6989586621679728900"><span class="annot"><span class="annottext">bh' :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728900"><span class="hs-identifier hs-var">bh'</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728907"><span class="hs-identifier hs-var">wi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728906"><span class="hs-identifier hs-var">wh</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728905"><span class="hs-identifier hs-var">bi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728904"><span class="hs-identifier hs-var">bh</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728903"><span class="hs-identifier hs-var">wi'</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMWIShape hiddenSize inputSize),
       Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728902"><span class="hs-identifier hs-var">wh'</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMWHShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728901"><span class="hs-identifier hs-var">bi'</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize),
       Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728900"><span class="hs-identifier hs-var">bh'</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; HList '[]
-&gt; HList
     '[Parameter device dtype (LSTMBIShape hiddenSize inputSize)]
forall x (xs :: [Type]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="Torch.HList.html#%3A."><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-var">HNil</span></a></span><span>
</span><span id="line-115"></span><span>  </span><span id="local-6989586621679728899"><span class="annot"><span class="annottext">gReplaceParameters :: K1 R (LSTMLayer inputSize hiddenSize 'Bidirectional dtype device) a
-&gt; HList parameters
-&gt; K1
     R (LSTMLayer inputSize hiddenSize 'Bidirectional dtype device) a
</span><a href="#local-6989586621679728899"><span class="hs-identifier hs-var hs-var hs-var hs-var">gReplaceParameters</span></a></span></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728898"><span class="annot"><a href="#local-6989586621679728898"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728897"><span class="annot"><a href="#local-6989586621679728897"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728896"><span class="annot"><a href="#local-6989586621679728896"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728895"><span class="annot"><a href="#local-6989586621679728895"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728894"><span class="annot"><a href="#local-6989586621679728894"><span class="hs-identifier hs-var">wi'</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728893"><span class="annot"><a href="#local-6989586621679728893"><span class="hs-identifier hs-var">wh'</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728892"><span class="annot"><a href="#local-6989586621679728892"><span class="hs-identifier hs-var">bi'</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679728891"><span class="annot"><a href="#local-6989586621679728891"><span class="hs-identifier hs-var">bh'</span></a></span></span><span> </span><span class="annot"><a href="Torch.HList.html#%3A."><span class="hs-operator hs-type">:.</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#HNil"><span class="hs-identifier hs-type">HNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
-&gt; K1
     R (LSTMLayer inputSize hiddenSize 'Bidirectional dtype device) a
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (inputSize :: Nat).
Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMBidirectionalLayer"><span class="hs-identifier hs-var">LSTMBidirectionalLayer</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728898"><span class="hs-identifier hs-var">wi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728897"><span class="hs-identifier hs-var">wh</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728896"><span class="hs-identifier hs-var">bi</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728895"><span class="hs-identifier hs-var">bh</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728894"><span class="hs-identifier hs-var">wi'</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728893"><span class="hs-identifier hs-var">wh'</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728892"><span class="hs-identifier hs-var">bi'</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728891"><span class="hs-identifier hs-var">bh'</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-117"></span><span>
</span><span id="line-118"></span><span id="local-6989586621679728887"><span id="local-6989586621679728888"><span id="local-6989586621679728889"><span id="local-6989586621679728890"><span class="hs-keyword">instance</span><span>
</span><span id="line-119"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728890"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728889"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-120"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728888"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-121"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728887"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-122"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728889"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-123"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728890"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-124"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-type">LSTMLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728888"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728887"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728889"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728890"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728888"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728887"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Unidirectional"><span class="hs-identifier hs-type">Unidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728889"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728890"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-127"></span><span>  </span><span id="local-6989586621679728884"><span class="annot"><span class="annottext">sample :: LSTMLayerSpec inputSize hiddenSize 'Unidirectional dtype device
-&gt; IO (LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (inputSize :: Nat).
Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMUnidirectionalLayer"><span class="hs-identifier hs-var">LSTMUnidirectionalLayer</span></a></span><span>
</span><span id="line-129"></span><span>      </span><span class="annot"><span class="annottext">(Parameter device dtype (LSTMWIShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMWHShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMWIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMWIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (LSTMWIShape hiddenSize inputSize))
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (featureSize :: Nat).
(KnownDType dtype, KnownNat hiddenSize, KnownNat featureSize,
 KnownDevice device, RandDTypeIsValid device dtype) =&gt;
IO (Tensor device dtype '[4 * hiddenSize, featureSize])
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-var">xavierUniformLSTM</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMWHShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMWHShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMWHShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (LSTMWHShape hiddenSize inputSize))
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (featureSize :: Nat).
(KnownDType dtype, KnownNat hiddenSize, KnownNat featureSize,
 KnownDevice device, RandDTypeIsValid device dtype) =&gt;
IO (Tensor device dtype '[4 * hiddenSize, featureSize])
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-var">xavierUniformLSTM</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-131"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-132"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-133"></span><span>
</span><span id="line-134"></span><span id="local-6989586621679728874"><span id="local-6989586621679728875"><span id="local-6989586621679728876"><span id="local-6989586621679728877"><span class="hs-keyword">instance</span><span>
</span><span id="line-135"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728877"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728876"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-136"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728875"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-137"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728874"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-138"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728876"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-139"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728877"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-140"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-type">LSTMLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728875"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728874"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728876"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728877"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728875"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728874"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.Functional.html#Bidirectional"><span class="hs-identifier hs-type">Bidirectional</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728876"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728877"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-143"></span><span>  </span><span id="local-6989586621679728872"><span class="annot"><span class="annottext">sample :: LSTMLayerSpec inputSize hiddenSize 'Bidirectional dtype device
-&gt; IO (LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
</span><a href="#local-6989586621679728872"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-144"></span><span>    </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (inputSize :: Nat).
Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMBidirectionalLayer"><span class="hs-identifier hs-var">LSTMBidirectionalLayer</span></a></span><span>
</span><span id="line-145"></span><span>      </span><span class="annot"><span class="annottext">(Parameter device dtype (LSTMWIShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMWHShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMWIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMWIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (LSTMWIShape hiddenSize inputSize))
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (featureSize :: Nat).
(KnownDType dtype, KnownNat hiddenSize, KnownNat featureSize,
 KnownDevice device, RandDTypeIsValid device dtype) =&gt;
IO (Tensor device dtype '[4 * hiddenSize, featureSize])
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-var">xavierUniformLSTM</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMWHShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMWHShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMWHShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (LSTMWHShape hiddenSize inputSize))
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (featureSize :: Nat).
(KnownDType dtype, KnownNat hiddenSize, KnownNat featureSize,
 KnownDevice device, RandDTypeIsValid device dtype) =&gt;
IO (Tensor device dtype '[4 * hiddenSize, featureSize])
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-var">xavierUniformLSTM</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMWIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMWIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMWHShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMWIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMWIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMWIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (LSTMWIShape hiddenSize inputSize))
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (featureSize :: Nat).
(KnownDType dtype, KnownNat hiddenSize, KnownNat featureSize,
 KnownDevice device, RandDTypeIsValid device dtype) =&gt;
IO (Tensor device dtype '[4 * hiddenSize, featureSize])
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-var">xavierUniformLSTM</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMWHShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMWHShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMWHShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMWHShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype (LSTMWHShape hiddenSize inputSize))
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (featureSize :: Nat).
(KnownDType dtype, KnownNat hiddenSize, KnownNat featureSize,
 KnownDevice device, RandDTypeIsValid device dtype) =&gt;
IO (Tensor device dtype '[4 * hiddenSize, featureSize])
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-var">xavierUniformLSTM</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO
     (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
      -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter device dtype (LSTMBIShape hiddenSize inputSize)
   -&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor device dtype (LSTMBIShape hiddenSize inputSize)
 -&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize)))
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
-&gt; IO (Parameter device dtype (LSTMBIShape hiddenSize inputSize))
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; IO (Tensor device dtype (LSTMBIShape hiddenSize inputSize))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype (LSTMBIShape hiddenSize inputSize)
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-153"></span><span>
</span><span id="line-154"></span><span id="local-6989586621679728867"><span id="local-6989586621679728868"><span id="local-6989586621679728869"><span id="local-6989586621679728870"><span id="local-6989586621679728871"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.NN.html#Parameterized"><span class="hs-identifier hs-type">A.Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728871"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728870"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728869"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728868"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728867"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-155"></span><span>  </span><span id="local-6989586621679728863"><span class="annot"><span class="annottext">flattenParameters :: LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; [Parameter]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var hs-var hs-var hs-var">flattenParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMUnidirectionalLayer"><span class="hs-identifier hs-type">LSTMUnidirectionalLayer</span></a></span><span> </span><span id="local-6989586621679728861"><span class="annot"><span class="annottext">wi :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728861"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span id="local-6989586621679728860"><span class="annot"><span class="annottext">wh :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728860"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span id="local-6989586621679728859"><span class="annot"><span class="annottext">bi :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728859"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span id="local-6989586621679728858"><span class="annot"><span class="annottext">bh :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728858"><span class="hs-identifier hs-var">bh</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-156"></span><span>      </span><span class="hs-special">[</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728861"><span class="hs-identifier hs-var">wi</span></a></span><span>
</span><span id="line-157"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728860"><span class="hs-identifier hs-var">wh</span></a></span><span>
</span><span id="line-158"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728859"><span class="hs-identifier hs-var">bi</span></a></span><span>
</span><span id="line-159"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728858"><span class="hs-identifier hs-var">bh</span></a></span><span>
</span><span id="line-160"></span><span>      </span><span class="hs-special">]</span><span>
</span><span id="line-161"></span><span>  </span><span class="annot"><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMBidirectionalLayer"><span class="hs-identifier hs-type">LSTMBidirectionalLayer</span></a></span><span> </span><span id="local-6989586621679728856"><span class="annot"><span class="annottext">wi :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728856"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span id="local-6989586621679728855"><span class="annot"><span class="annottext">wh :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728855"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span id="local-6989586621679728854"><span class="annot"><span class="annottext">bi :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728854"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span id="local-6989586621679728853"><span class="annot"><span class="annottext">bh :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728853"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span id="local-6989586621679728852"><span class="annot"><span class="annottext">wi' :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728852"><span class="hs-identifier hs-var">wi'</span></a></span></span><span> </span><span id="local-6989586621679728851"><span class="annot"><span class="annottext">wh' :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728851"><span class="hs-identifier hs-var">wh'</span></a></span></span><span> </span><span id="local-6989586621679728850"><span class="annot"><span class="annottext">bi' :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728850"><span class="hs-identifier hs-var">bi'</span></a></span></span><span> </span><span id="local-6989586621679728849"><span class="annot"><span class="annottext">bh' :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728849"><span class="hs-identifier hs-var">bh'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-162"></span><span>      </span><span class="hs-special">[</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728856"><span class="hs-identifier hs-var">wi</span></a></span><span>
</span><span id="line-163"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728855"><span class="hs-identifier hs-var">wh</span></a></span><span>
</span><span id="line-164"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728854"><span class="hs-identifier hs-var">bi</span></a></span><span>
</span><span id="line-165"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728853"><span class="hs-identifier hs-var">bh</span></a></span><span>
</span><span id="line-166"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728852"><span class="hs-identifier hs-var">wi'</span></a></span><span>
</span><span id="line-167"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728851"><span class="hs-identifier hs-var">wh'</span></a></span><span>
</span><span id="line-168"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728850"><span class="hs-identifier hs-var">bi'</span></a></span><span>
</span><span id="line-169"></span><span>      </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728849"><span class="hs-identifier hs-var">bh'</span></a></span><span>
</span><span id="line-170"></span><span>      </span><span class="hs-special">]</span><span>
</span><span id="line-171"></span><span>  </span><span id="local-6989586621679728848"><span class="annot"><span class="annottext">replaceOwnParameters :: LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; ParamStream
     (LSTMLayer inputSize hiddenSize directionality dtype device)
</span><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var hs-var hs-var hs-var">replaceOwnParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMUnidirectionalLayer"><span class="hs-identifier hs-type">LSTMUnidirectionalLayer</span></a></span><span> </span><span id="local-6989586621679728846"><span class="annot"><span class="annottext">_wi :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728846"><span class="hs-identifier hs-var">_wi</span></a></span></span><span> </span><span id="local-6989586621679728845"><span class="annot"><span class="annottext">_wh :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728845"><span class="hs-identifier hs-var">_wh</span></a></span></span><span> </span><span id="local-6989586621679728844"><span class="annot"><span class="annottext">_bi :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728844"><span class="hs-identifier hs-var">_bi</span></a></span></span><span> </span><span id="local-6989586621679728843"><span class="annot"><span class="annottext">_bh :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728843"><span class="hs-identifier hs-var">_bh</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-172"></span><span>    </span><span id="local-6989586621679728842"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728842"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-173"></span><span>    </span><span id="local-6989586621679728840"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728840"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-174"></span><span>    </span><span id="local-6989586621679728839"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728839"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-175"></span><span>    </span><span id="local-6989586621679728838"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728838"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-176"></span><span>    </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
-&gt; StateT
     [Parameter]
     Identity
     (LSTMLayer inputSize hiddenSize 'Unidirectional dtype device)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (inputSize :: Nat).
Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Unidirectional dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMUnidirectionalLayer"><span class="hs-identifier hs-var">LSTMUnidirectionalLayer</span></a></span><span>
</span><span id="line-177"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728842"><span class="hs-identifier hs-var">wi</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728840"><span class="hs-identifier hs-var">wh</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728839"><span class="hs-identifier hs-var">bi</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728838"><span class="hs-identifier hs-var">bh</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-181"></span><span>            </span><span class="hs-special">)</span><span>
</span><span id="line-182"></span><span>  </span><span class="annot"><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">replaceOwnParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMBidirectionalLayer"><span class="hs-identifier hs-type">LSTMBidirectionalLayer</span></a></span><span> </span><span id="local-6989586621679728836"><span class="annot"><span class="annottext">_wi :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728836"><span class="hs-identifier hs-var">_wi</span></a></span></span><span> </span><span id="local-6989586621679728835"><span class="annot"><span class="annottext">_wh :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728835"><span class="hs-identifier hs-var">_wh</span></a></span></span><span> </span><span id="local-6989586621679728834"><span class="annot"><span class="annottext">_bi :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728834"><span class="hs-identifier hs-var">_bi</span></a></span></span><span> </span><span id="local-6989586621679728833"><span class="annot"><span class="annottext">_bh :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728833"><span class="hs-identifier hs-var">_bh</span></a></span></span><span> </span><span id="local-6989586621679728832"><span class="annot"><span class="annottext">_wi' :: Parameter device dtype (LSTMWIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728832"><span class="hs-identifier hs-var">_wi'</span></a></span></span><span> </span><span id="local-6989586621679728831"><span class="annot"><span class="annottext">_wh' :: Parameter device dtype (LSTMWHShape hiddenSize inputSize)
</span><a href="#local-6989586621679728831"><span class="hs-identifier hs-var">_wh'</span></a></span></span><span> </span><span id="local-6989586621679728830"><span class="annot"><span class="annottext">_bi' :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728830"><span class="hs-identifier hs-var">_bi'</span></a></span></span><span> </span><span id="local-6989586621679728829"><span class="annot"><span class="annottext">_bh' :: Parameter device dtype (LSTMBIShape hiddenSize inputSize)
</span><a href="#local-6989586621679728829"><span class="hs-identifier hs-var">_bh'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-183"></span><span>    </span><span id="local-6989586621679728828"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728828"><span class="hs-identifier hs-var">wi</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-184"></span><span>    </span><span id="local-6989586621679728827"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728827"><span class="hs-identifier hs-var">wh</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-185"></span><span>    </span><span id="local-6989586621679728826"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728826"><span class="hs-identifier hs-var">bi</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-186"></span><span>    </span><span id="local-6989586621679728825"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728825"><span class="hs-identifier hs-var">bh</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span id="local-6989586621679728824"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728824"><span class="hs-identifier hs-var">wi'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-188"></span><span>    </span><span id="local-6989586621679728823"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728823"><span class="hs-identifier hs-var">wh'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-189"></span><span>    </span><span id="local-6989586621679728822"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728822"><span class="hs-identifier hs-var">bi'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-190"></span><span>    </span><span id="local-6989586621679728821"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728821"><span class="hs-identifier hs-var">bh'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-191"></span><span>    </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
-&gt; StateT
     [Parameter]
     Identity
     (LSTMLayer inputSize hiddenSize 'Bidirectional dtype device)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (hiddenSize :: Nat) (inputSize :: Nat).
Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
-&gt; LSTMLayer inputSize hiddenSize 'Bidirectional dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMBidirectionalLayer"><span class="hs-identifier hs-var">LSTMBidirectionalLayer</span></a></span><span>
</span><span id="line-192"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728828"><span class="hs-identifier hs-var">wi</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-193"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728827"><span class="hs-identifier hs-var">wh</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-194"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728826"><span class="hs-identifier hs-var">bi</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-195"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728825"><span class="hs-identifier hs-var">bh</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-196"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMWIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728824"><span class="hs-identifier hs-var">wi'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMWHShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728823"><span class="hs-identifier hs-var">wh'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-198"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728822"><span class="hs-identifier hs-var">bi'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-199"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter device dtype (LSTMBIShape hiddenSize inputSize)
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728821"><span class="hs-identifier hs-var">bh'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-200"></span><span>            </span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-201"></span><span>
</span><span id="line-202"></span><span class="hs-keyword">data</span><span> </span><span id="LSTMLayerStackSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-var">LSTMLayerStackSpec</span></a></span></span><span>
</span><span id="line-203"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729296"><span class="annot"><a href="#local-6989586621679729296"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729295"><span class="annot"><a href="#local-6989586621679729295"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-205"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729294"><span class="annot"><a href="#local-6989586621679729294"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-206"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729293"><span class="annot"><a href="#local-6989586621679729293"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-207"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729292"><span class="annot"><a href="#local-6989586621679729292"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729291"><span class="annot"><a href="#local-6989586621679729291"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-209"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="LSTMLayerStackSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-var">LSTMLayerStackSpec</span></a></span></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728814"><span id="local-6989586621679728816"><span id="local-6989586621679728818"><span class="annot"><span class="annottext">Int
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
[LSTMLayerStackSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; String
(Int
 -&gt; LSTMLayerStackSpec
      inputSize hiddenSize numLayers directionality dtype device
 -&gt; ShowS)
-&gt; (LSTMLayerStackSpec
      inputSize hiddenSize numLayers directionality dtype device
    -&gt; String)
-&gt; ([LSTMLayerStackSpec
       inputSize hiddenSize numLayers directionality dtype device]
    -&gt; ShowS)
-&gt; Show
     (LSTMLayerStackSpec
        inputSize hiddenSize numLayers directionality dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTMLayerStackSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; String
showList :: [LSTMLayerStackSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
$cshowList :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTMLayerStackSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
show :: LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; String
$cshow :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; String
showsPrec :: Int
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
$cshowsPrec :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679728810"><span id="local-6989586621679728812"><span class="annot"><span class="annottext">LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; Bool
(LSTMLayerStackSpec
   inputSize hiddenSize numLayers directionality dtype device
 -&gt; LSTMLayerStackSpec
      inputSize hiddenSize numLayers directionality dtype device
 -&gt; Bool)
-&gt; (LSTMLayerStackSpec
      inputSize hiddenSize numLayers directionality dtype device
    -&gt; LSTMLayerStackSpec
         inputSize hiddenSize numLayers directionality dtype device
    -&gt; Bool)
-&gt; Eq
     (LSTMLayerStackSpec
        inputSize hiddenSize numLayers directionality dtype device)
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; Bool
/= :: LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; Bool
$c/= :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; Bool
== :: LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; Bool
$c== :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-210"></span><span>
</span><span id="line-211"></span><span class="hs-comment">-- Input-to-hidden, hidden-to-hidden, and bias parameters for a mulilayered</span><span>
</span><span id="line-212"></span><span class="hs-comment">-- (and optionally) bidirectional LSTM.</span><span>
</span><span id="line-213"></span><span class="hs-comment">--</span><span>
</span><span id="line-214"></span><span class="hs-keyword">data</span><span> </span><span id="LSTMLayerStack"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-var">LSTMLayerStack</span></a></span></span><span>
</span><span id="line-215"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728809"><span class="annot"><a href="#local-6989586621679728809"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-216"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728808"><span class="annot"><a href="#local-6989586621679728808"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728807"><span class="annot"><a href="#local-6989586621679728807"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-218"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728806"><span class="annot"><a href="#local-6989586621679728806"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-219"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728805"><span class="annot"><a href="#local-6989586621679728805"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-220"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728804"><span class="annot"><a href="#local-6989586621679728804"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-222"></span><span>  </span><span id="local-6989586621679729352"><span id="local-6989586621679729353"><span id="local-6989586621679729354"><span id="local-6989586621679729355"><span id="local-6989586621679729356"><span id="LSTMLayer1"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-var">LSTMLayer1</span></a></span></span><span>
</span><span id="line-223"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729356"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729355"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729354"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729353"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729352"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-224"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729356"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729355"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679729354"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729353"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729352"><span class="hs-identifier hs-type">device</span></a></span></span></span></span></span></span><span>
</span><span id="line-225"></span><span>  </span><span id="local-6989586621679729316"><span id="local-6989586621679729317"><span id="local-6989586621679729318"><span id="local-6989586621679729319"><span id="local-6989586621679729320"><span id="local-6989586621679729321"><span id="LSTMLayerK"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-var">LSTMLayerK</span></a></span></span><span>
</span><span id="line-226"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679729321"><span class="hs-identifier hs-type">numLayers</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>    </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729320"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729319"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679729321"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679729318"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729317"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729316"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-228"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679729319"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729318"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679729319"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729318"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729317"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729316"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-229"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729320"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729319"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729321"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729318"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729317"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729316"><span class="hs-identifier hs-type">device</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-230"></span><span>
</span><span id="line-231"></span><span id="local-6989586621679728790"><span id="local-6989586621679728792"><span id="local-6989586621679728794"><span id="local-6989586621679728796"><span id="local-6989586621679728797"><span id="local-6989586621679728798"><span id="local-6989586621679728799"><span id="local-6989586621679728800"><span id="local-6989586621679728801"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728801"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728800"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728799"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728798"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728797"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728796"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-232"></span><span class="hs-comment">--  TODO: Generics? see https://gist.github.com/RyanGlScott/71d9f933e823b4a03f99de54d4b94d51</span><span>
</span><span id="line-233"></span><span class="hs-comment">-- deriving instance Generic (LSTMLayerStack inputSize hiddenSize numLayers directionality dtype device)</span><span>
</span><span id="line-234"></span><span>
</span><span id="line-235"></span><span id="local-6989586621679728783"><span id="local-6989586621679728784"><span id="local-6989586621679728785"><span id="local-6989586621679728786"><span id="local-6989586621679728787"><span id="local-6989586621679728788"><span id="local-6989586621679728789"><span class="hs-keyword">instance</span><span> </span><span class="hs-pragma">{-# OVERLAPS</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-236"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679728789"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">R</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728788"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728787"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728786"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728785"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728784"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-237"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728789"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728783"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-238"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">R</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728788"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728787"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679728786"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728785"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728784"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728783"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-239"></span><span>  </span><span id="local-6989586621679728780"><span class="annot"><span class="annottext">gFlattenParameters :: K1
  R
  (LSTMLayerStack inputSize hiddenSize 1 directionality dtype device)
  a
-&gt; HList parameters
</span><a href="#local-6989586621679728780"><span class="hs-identifier hs-var hs-var hs-var hs-var">gFlattenParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-type">LSTMLayer1</span></a></span><span> </span><span id="local-6989586621679728779"><span class="annot"><span class="annottext">lstmLayer :: LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728779"><span class="hs-identifier hs-var">lstmLayer</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-240"></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">layer Any -&gt; HList parameters
forall (f :: Type -&gt; Type) (as :: [Type]) a.
GParameterized f as =&gt;
f a -&gt; HList as
</span><a href="Torch.Typed.Parameter.html#gFlattenParameters"><span class="hs-identifier hs-var">gFlattenParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; K1
     R (LSTMLayer inputSize hiddenSize directionality dtype device) _
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728779"><span class="hs-identifier hs-var">lstmLayer</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728789"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>  </span><span id="local-6989586621679728778"><span class="annot"><span class="annottext">gReplaceParameters :: K1
  R
  (LSTMLayerStack inputSize hiddenSize 1 directionality dtype device)
  a
-&gt; HList parameters
-&gt; K1
     R
     (LSTMLayerStack inputSize hiddenSize 1 directionality dtype device)
     a
</span><a href="#local-6989586621679728778"><span class="hs-identifier hs-var hs-var hs-var hs-var">gReplaceParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-type">LSTMLayer1</span></a></span><span> </span><span id="local-6989586621679728777"><span class="annot"><span class="annottext">lstmLayer :: LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728777"><span class="hs-identifier hs-var">lstmLayer</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679728776"><span class="annot"><span class="annottext">parameters :: HList parameters
</span><a href="#local-6989586621679728776"><span class="hs-identifier hs-var">parameters</span></a></span></span><span>
</span><span id="line-242"></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack inputSize hiddenSize 1 directionality dtype device
-&gt; K1
     R
     (LSTMLayerStack inputSize hiddenSize 1 directionality dtype device)
     a
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerStack
     inputSize hiddenSize 1 directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerStack
     inputSize hiddenSize 1 directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-var">LSTMLayer1</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">K1
  R (LSTMLayer inputSize hiddenSize directionality dtype device) Any
-&gt; LSTMLayer inputSize hiddenSize directionality dtype device
forall i c k (p :: k). K1 i c p -&gt; c
</span><span class="hs-identifier hs-var hs-var">unK1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layer Any -&gt; HList parameters -&gt; layer Any
forall (f :: Type -&gt; Type) (as :: [Type]) a.
GParameterized f as =&gt;
f a -&gt; HList as -&gt; f a
</span><a href="Torch.Typed.Parameter.html#gReplaceParameters"><span class="hs-identifier hs-var">gReplaceParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; K1
     R (LSTMLayer inputSize hiddenSize directionality dtype device) _
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728777"><span class="hs-identifier hs-var">lstmLayer</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728789"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679728776"><span class="hs-identifier hs-var">parameters</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span><span>
</span><span id="line-243"></span><span>
</span><span id="line-244"></span><span id="local-6989586621679728764"><span id="local-6989586621679728765"><span id="local-6989586621679728766"><span id="local-6989586621679728767"><span id="local-6989586621679728768"><span id="local-6989586621679728769"><span id="local-6989586621679728770"><span id="local-6989586621679728771"><span id="local-6989586621679728772"><span id="local-6989586621679728773"><span id="local-6989586621679728774"><span class="hs-keyword">instance</span><span> </span><span class="hs-pragma">{-# OVERLAPPABLE</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-245"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679728774"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-246"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728773"><span class="hs-identifier hs-type">layerStack</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">R</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728772"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728771"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728774"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728770"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728769"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728768"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728767"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">R</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728771"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728770"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728771"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728770"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728769"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728768"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-248"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728767"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728766"><span class="hs-identifier hs-type">parameters'</span></a></span><span>
</span><span id="line-249"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728773"><span class="hs-identifier hs-type">layerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728765"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-250"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728767"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728766"><span class="hs-identifier hs-type">parameters'</span></a></span><span>
</span><span id="line-251"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HAppendFD"><span class="hs-identifier hs-type">HAppendFD</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728765"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728766"><span class="hs-identifier hs-type">parameters'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728764"><span class="hs-identifier hs-type">parameters''</span></a></span><span>
</span><span id="line-252"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728764"><span class="hs-identifier hs-type">parameters''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728765"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="Torch.HList.html#%2B%2B"><span class="hs-operator hs-type">++</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728766"><span class="hs-identifier hs-type">parameters'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#GParameterized"><span class="hs-identifier hs-type">GParameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">R</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728772"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728771"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728774"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728770"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728769"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728768"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728764"><span class="hs-identifier hs-type">parameters''</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-254"></span><span>  </span><span id="local-6989586621679728761"><span class="annot"><span class="annottext">gFlattenParameters :: K1
  R
  (LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device)
  a
-&gt; HList parameters''
</span><a href="#local-6989586621679728761"><span class="hs-identifier hs-var hs-var hs-var hs-var">gFlattenParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-type">LSTMLayerK</span></a></span><span> </span><span id="local-6989586621679728760"><span class="annot"><span class="annottext">lstmLayerStack :: LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728760"><span class="hs-identifier hs-var">lstmLayerStack</span></a></span></span><span> </span><span id="local-6989586621679728759"><span class="annot"><span class="annottext">lstmLayer :: LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728759"><span class="hs-identifier hs-var">lstmLayer</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679728758"><span class="annot"><span class="annottext">parameters :: HList parameters
</span><a href="#local-6989586621679728758"><span class="hs-identifier hs-var hs-var">parameters</span></a></span></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">layerStack Any -&gt; HList parameters
forall (f :: Type -&gt; Type) (as :: [Type]) a.
GParameterized f as =&gt;
f a -&gt; HList as
</span><a href="Torch.Typed.Parameter.html#gFlattenParameters"><span class="hs-identifier hs-var">gFlattenParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; K1
     R
     (LSTMLayerStack
        inputSize hiddenSize (numLayers - 1) directionality dtype device)
     _
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728760"><span class="hs-identifier hs-var">lstmLayerStack</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728773"><span class="hs-identifier hs-type">layerStack</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>          </span><span id="local-6989586621679728757"><span class="annot"><span class="annottext">parameters' :: HList parameters'
</span><a href="#local-6989586621679728757"><span class="hs-identifier hs-var hs-var">parameters'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">layer Any -&gt; HList parameters'
forall (f :: Type -&gt; Type) (as :: [Type]) a.
GParameterized f as =&gt;
f a -&gt; HList as
</span><a href="Torch.Typed.Parameter.html#gFlattenParameters"><span class="hs-identifier hs-var">gFlattenParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
-&gt; K1
     R
     (LSTMLayer
        (hiddenSize * NumberOfDirections directionality)
        hiddenSize
        directionality
        dtype
        device)
     _
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728759"><span class="hs-identifier hs-var">lstmLayer</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728767"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>      </span><span class="hs-keyword">in</span><span>  </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679728758"><span class="hs-identifier hs-var">parameters</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters -&gt; HList parameters' -&gt; HList parameters''
forall k (a :: [k]) (b :: [k]) (ab :: [k]).
HAppendFD a b ab =&gt;
HList a -&gt; HList b -&gt; HList ab
</span><a href="Torch.HList.html#happendFD"><span class="hs-operator hs-var">`happendFD`</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters'
</span><a href="#local-6989586621679728757"><span class="hs-identifier hs-var">parameters'</span></a></span><span>
</span><span id="line-258"></span><span>  </span><span id="local-6989586621679728755"><span class="annot"><span class="annottext">gReplaceParameters :: K1
  R
  (LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device)
  a
-&gt; HList parameters''
-&gt; K1
     R
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
     a
</span><a href="#local-6989586621679728755"><span class="hs-identifier hs-var hs-var hs-var hs-var">gReplaceParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-type">LSTMLayerK</span></a></span><span> </span><span id="local-6989586621679728754"><span class="annot"><span class="annottext">lstmLayerStack :: LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728754"><span class="hs-identifier hs-var">lstmLayerStack</span></a></span></span><span> </span><span id="local-6989586621679728753"><span class="annot"><span class="annottext">lstmLayer :: LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728753"><span class="hs-identifier hs-var">lstmLayer</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679728752"><span class="annot"><span class="annottext">parameters'' :: HList parameters''
</span><a href="#local-6989586621679728752"><span class="hs-identifier hs-var">parameters''</span></a></span></span><span>
</span><span id="line-259"></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728751"><span class="annot"><span class="annottext">parameters :: HList parameters
</span><a href="#local-6989586621679728751"><span class="hs-identifier hs-var">parameters</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679728750"><span class="annot"><span class="annottext">parameters' :: HList parameters'
</span><a href="#local-6989586621679728750"><span class="hs-identifier hs-var">parameters'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList parameters'' -&gt; (HList parameters, HList parameters')
forall k (a :: [k]) (b :: [k]) (ab :: [k]).
HAppendFD a b ab =&gt;
HList ab -&gt; (HList a, HList b)
</span><a href="Torch.HList.html#hunappendFD"><span class="hs-identifier hs-var">hunappendFD</span></a></span><span> </span><span class="annot"><span class="annottext">HList parameters''
</span><a href="#local-6989586621679728752"><span class="hs-identifier hs-var">parameters''</span></a></span><span>
</span><span id="line-260"></span><span>          </span><span id="local-6989586621679728748"><span class="annot"><span class="annottext">lstmLayerStack' :: LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728748"><span class="hs-identifier hs-var hs-var">lstmLayerStack'</span></a></span></span><span>           </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">K1
  R
  (LSTMLayerStack
     inputSize hiddenSize (numLayers - 1) directionality dtype device)
  Any
-&gt; LSTMLayerStack
     inputSize hiddenSize (numLayers - 1) directionality dtype device
forall i c k (p :: k). K1 i c p -&gt; c
</span><span class="hs-identifier hs-var hs-var">unK1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layerStack Any -&gt; HList parameters -&gt; layerStack Any
forall (f :: Type -&gt; Type) (as :: [Type]) a.
GParameterized f as =&gt;
f a -&gt; HList as -&gt; f a
</span><a href="Torch.Typed.Parameter.html#gReplaceParameters"><span class="hs-identifier hs-var">gReplaceParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; K1
     R
     (LSTMLayerStack
        inputSize hiddenSize (numLayers - 1) directionality dtype device)
     _
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728754"><span class="hs-identifier hs-var">lstmLayerStack</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728773"><span class="hs-identifier hs-type">layerStack</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList parameters
</span><a href="#local-6989586621679728751"><span class="hs-identifier hs-var">parameters</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>          </span><span id="local-6989586621679728747"><span class="annot"><span class="annottext">lstmLayer' :: LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728747"><span class="hs-identifier hs-var hs-var">lstmLayer'</span></a></span></span><span>                </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">K1
  R
  (LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device)
  Any
-&gt; LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
forall i c k (p :: k). K1 i c p -&gt; c
</span><span class="hs-identifier hs-var hs-var">unK1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layer Any -&gt; HList parameters' -&gt; layer Any
forall (f :: Type -&gt; Type) (as :: [Type]) a.
GParameterized f as =&gt;
f a -&gt; HList as -&gt; f a
</span><a href="Torch.Typed.Parameter.html#gReplaceParameters"><span class="hs-identifier hs-var">gReplaceParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
-&gt; K1
     R
     (LSTMLayer
        (hiddenSize * NumberOfDirections directionality)
        hiddenSize
        directionality
        dtype
        device)
     _
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728753"><span class="hs-identifier hs-var">lstmLayer</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679728767"><span class="hs-identifier hs-type">layer</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span>      </span><span class="annot"><span class="annottext">HList parameters'
</span><a href="#local-6989586621679728750"><span class="hs-identifier hs-var">parameters'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>      </span><span class="hs-keyword">in</span><span>  </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; K1
     R
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
     a
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
forall (numLayers :: Nat) (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(2 &lt;= numLayers) =&gt;
LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-var">LSTMLayerK</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728748"><span class="hs-identifier hs-var">lstmLayerStack'</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728747"><span class="hs-identifier hs-var">lstmLayer'</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-263"></span><span>
</span><span id="line-264"></span><span id="local-6989586621679728742"><span id="local-6989586621679728743"><span id="local-6989586621679728744"><span id="local-6989586621679728745"><span id="local-6989586621679728746"><span class="hs-keyword">instance</span><span> </span><span class="hs-pragma">{-# OVERLAPS</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-265"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728746"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728745"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-266"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728744"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-267"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728743"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-268"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728745"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-269"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728746"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-270"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-type">LSTMLayerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728744"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728743"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728742"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728745"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728746"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-271"></span><span>                   </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728744"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728743"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728742"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728745"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728746"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-272"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-type">LSTMLayerStackSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728744"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728743"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679728742"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728745"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728746"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-273"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728744"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728743"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679728742"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728745"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728746"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-274"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-275"></span><span>  </span><span id="local-6989586621679728740"><span class="annot"><span class="annottext">sample :: LSTMLayerStackSpec
  inputSize hiddenSize 1 directionality dtype device
-&gt; IO
     (LSTMLayerStack inputSize hiddenSize 1 directionality dtype device)
</span><a href="#local-6989586621679728740"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerStack
     inputSize hiddenSize 1 directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerStack
     inputSize hiddenSize 1 directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-var">LSTMLayer1</span></a></span><span> </span><span class="annot"><span class="annottext">(LSTMLayer inputSize hiddenSize directionality dtype device
 -&gt; LSTMLayerStack
      inputSize hiddenSize 1 directionality dtype device)
-&gt; IO (LSTMLayer inputSize hiddenSize directionality dtype device)
-&gt; IO
     (LSTMLayerStack inputSize hiddenSize 1 directionality dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; IO (LSTMLayer inputSize hiddenSize directionality dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">(LSTMLayerSpec inputSize hiddenSize directionality dtype device
 -&gt; IO (LSTMLayer inputSize hiddenSize directionality dtype device))
-&gt; LSTMLayerSpec inputSize hiddenSize directionality dtype device
-&gt; IO (LSTMLayer inputSize hiddenSize directionality dtype device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayerSpec inputSize hiddenSize directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerSpec inputSize hiddenSize directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-var">LSTMLayerSpec</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728744"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728743"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728742"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728745"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728746"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-276"></span><span>
</span><span id="line-277"></span><span id="local-6989586621679728734"><span id="local-6989586621679728735"><span id="local-6989586621679728736"><span id="local-6989586621679728737"><span id="local-6989586621679728738"><span id="local-6989586621679728739"><span class="hs-keyword">instance</span><span> </span><span class="hs-pragma">{-# OVERLAPPABLE</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-278"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">&lt;=</span></span><span> </span><span class="annot"><a href="#local-6989586621679728739"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-280"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728736"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-281"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-282"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-283"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-284"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-type">LSTMLayerStackSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728736"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728739"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>                   </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728736"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728739"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-286"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-type">LSTMLayerSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-287"></span><span>                   </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer"><span class="hs-identifier hs-type">LSTMLayer</span></a></span><span>     </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-type">LSTMLayerStackSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728736"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728739"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728736"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728739"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-291"></span><span>  </span><span id="local-6989586621679728732"><span class="annot"><span class="annottext">sample :: LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; IO
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
</span><a href="#local-6989586621679728732"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-292"></span><span>    </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
forall (numLayers :: Nat) (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(2 &lt;= numLayers) =&gt;
LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-var">LSTMLayerK</span></a></span><span>
</span><span id="line-293"></span><span>      </span><span class="annot"><span class="annottext">(LSTMLayerStack
   inputSize hiddenSize (numLayers - 1) directionality dtype device
 -&gt; LSTMLayer
      (hiddenSize * NumberOfDirections directionality)
      hiddenSize
      directionality
      dtype
      device
 -&gt; LSTMLayerStack
      inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO
     (LSTMLayerStack
        inputSize hiddenSize (numLayers - 1) directionality dtype device)
-&gt; IO
     (LSTMLayer
        (hiddenSize * NumberOfDirections directionality)
        hiddenSize
        directionality
        dtype
        device
      -&gt; LSTMLayerStack
           inputSize hiddenSize numLayers directionality dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayerStackSpec
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; IO
     (LSTMLayerStack
        inputSize hiddenSize (numLayers - 1) directionality dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">(LSTMLayerStackSpec
   inputSize hiddenSize (numLayers - 1) directionality dtype device
 -&gt; IO
      (LSTMLayerStack
         inputSize hiddenSize (numLayers - 1) directionality dtype device))
-&gt; LSTMLayerStackSpec
     inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; IO
     (LSTMLayerStack
        inputSize hiddenSize (numLayers - 1) directionality dtype device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStackSpec
  inputSize hiddenSize (numLayers - 1) directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-var">LSTMLayerStackSpec</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728736"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728739"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-294"></span><span>      </span><span class="annot"><span class="annottext">IO
  (LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
   -&gt; LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO
     (LSTMLayer
        (hiddenSize * NumberOfDirections directionality)
        hiddenSize
        directionality
        dtype
        device)
-&gt; IO
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayerSpec
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
-&gt; IO
     (LSTMLayer
        (hiddenSize * NumberOfDirections directionality)
        hiddenSize
        directionality
        dtype
        device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">(LSTMLayerSpec
   (hiddenSize * NumberOfDirections directionality)
   hiddenSize
   directionality
   dtype
   device
 -&gt; IO
      (LSTMLayer
         (hiddenSize * NumberOfDirections directionality)
         hiddenSize
         directionality
         dtype
         device))
-&gt; LSTMLayerSpec
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
-&gt; IO
     (LSTMLayer
        (hiddenSize * NumberOfDirections directionality)
        hiddenSize
        directionality
        dtype
        device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayerSpec
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerSpec inputSize hiddenSize directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerSpec"><span class="hs-identifier hs-var">LSTMLayerSpec</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728735"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728734"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728737"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728738"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-295"></span><span>
</span><span id="line-296"></span><span id="local-6989586621679728726"><span id="local-6989586621679728727"><span id="local-6989586621679728728"><span id="local-6989586621679728729"><span id="local-6989586621679728730"><span id="local-6989586621679728731"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.NN.html#Parameterized"><span class="hs-identifier hs-type">A.Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728731"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728730"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728729"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728728"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728727"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728726"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-297"></span><span>  </span><span id="local-6989586621679728723"><span class="annot"><span class="annottext">flattenParameters :: LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; [Parameter]
</span><a href="#local-6989586621679728723"><span class="hs-identifier hs-var hs-var hs-var hs-var">flattenParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-type">LSTMLayer1</span></a></span><span> </span><span id="local-6989586621679728722"><span class="annot"><span class="annottext">layer :: LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728722"><span class="hs-identifier hs-var">layer</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-298"></span><span>           </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; [Parameter]
forall f. Parameterized f =&gt; f -&gt; [Parameter]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">A.flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728722"><span class="hs-identifier hs-var">layer</span></a></span><span>
</span><span id="line-299"></span><span>  </span><span class="annot"><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-type">LSTMLayerK</span></a></span><span> </span><span id="local-6989586621679728721"><span class="annot"><span class="annottext">stack :: LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728721"><span class="hs-identifier hs-var">stack</span></a></span></span><span> </span><span id="local-6989586621679728720"><span class="annot"><span class="annottext">layer :: LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728720"><span class="hs-identifier hs-var">layer</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-300"></span><span>           </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; [Parameter]
forall f. Parameterized f =&gt; f -&gt; [Parameter]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">A.flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728721"><span class="hs-identifier hs-var">stack</span></a></span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><span class="annottext">[Parameter] -&gt; [Parameter] -&gt; [Parameter]
forall a. [a] -&gt; [a] -&gt; [a]
</span><span class="hs-operator hs-var">++</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
-&gt; [Parameter]
forall f. Parameterized f =&gt; f -&gt; [Parameter]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">A.flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728720"><span class="hs-identifier hs-var">layer</span></a></span><span>
</span><span id="line-302"></span><span>  </span><span id="local-6989586621679728719"><span class="annot"><span class="annottext">replaceOwnParameters :: LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
</span><a href="#local-6989586621679728719"><span class="hs-identifier hs-var hs-var hs-var hs-var">replaceOwnParameters</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-type">LSTMLayer1</span></a></span><span> </span><span id="local-6989586621679728718"><span class="annot"><span class="annottext">layer :: LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728718"><span class="hs-identifier hs-var">layer</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-303"></span><span>    </span><span id="local-6989586621679728717"><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728717"><span class="hs-identifier hs-var">layer'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; ParamStream
     (LSTMLayer inputSize hiddenSize directionality dtype device)
forall f. Parameterized f =&gt; f -&gt; ParamStream f
</span><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">A.replaceOwnParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728718"><span class="hs-identifier hs-var">layer</span></a></span><span>
</span><span id="line-304"></span><span>    </span><span class="annot"><span class="annottext">LSTMLayerStack inputSize hiddenSize 1 directionality dtype device
-&gt; ParamStream
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(LSTMLayerStack inputSize hiddenSize 1 directionality dtype device
 -&gt; ParamStream
      (LSTMLayerStack
         inputSize hiddenSize numLayers directionality dtype device))
-&gt; LSTMLayerStack
     inputSize hiddenSize 1 directionality dtype device
-&gt; ParamStream
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerStack
     inputSize hiddenSize 1 directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayer inputSize hiddenSize directionality dtype device
-&gt; LSTMLayerStack
     inputSize hiddenSize 1 directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayer1"><span class="hs-identifier hs-var">LSTMLayer1</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayer inputSize hiddenSize directionality dtype device
</span><a href="#local-6989586621679728717"><span class="hs-identifier hs-var">layer'</span></a></span><span>
</span><span id="line-305"></span><span>  </span><span class="annot"><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">replaceOwnParameters</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-type">LSTMLayerK</span></a></span><span> </span><span id="local-6989586621679728716"><span class="annot"><span class="annottext">stack :: LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728716"><span class="hs-identifier hs-var">stack</span></a></span></span><span> </span><span id="local-6989586621679728715"><span class="annot"><span class="annottext">layer :: LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728715"><span class="hs-identifier hs-var">layer</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-306"></span><span>    </span><span id="local-6989586621679728714"><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728714"><span class="hs-identifier hs-var">stack'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; ParamStream
     (LSTMLayerStack
        inputSize hiddenSize (numLayers - 1) directionality dtype device)
forall f. Parameterized f =&gt; f -&gt; ParamStream f
</span><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">A.replaceOwnParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728716"><span class="hs-identifier hs-var">stack</span></a></span><span>
</span><span id="line-307"></span><span>    </span><span id="local-6989586621679728713"><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728713"><span class="hs-identifier hs-var">layer'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
-&gt; ParamStream
     (LSTMLayer
        (hiddenSize * NumberOfDirections directionality)
        hiddenSize
        directionality
        dtype
        device)
forall f. Parameterized f =&gt; f -&gt; ParamStream f
</span><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">A.replaceOwnParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728715"><span class="hs-identifier hs-var">layer</span></a></span><span>
</span><span id="line-308"></span><span>    </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(LSTMLayerStack
   inputSize hiddenSize numLayers directionality dtype device
 -&gt; ParamStream
      (LSTMLayerStack
         inputSize hiddenSize numLayers directionality dtype device))
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
forall (numLayers :: Nat) (inputSize :: Nat) (hiddenSize :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(2 &lt;= numLayers) =&gt;
LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
-&gt; LSTMLayer
     (hiddenSize * NumberOfDirections directionality)
     hiddenSize
     directionality
     dtype
     device
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerK"><span class="hs-identifier hs-var">LSTMLayerK</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize (numLayers - 1) directionality dtype device
</span><a href="#local-6989586621679728714"><span class="hs-identifier hs-var">stack'</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayer
  (hiddenSize * NumberOfDirections directionality)
  hiddenSize
  directionality
  dtype
  device
</span><a href="#local-6989586621679728713"><span class="hs-identifier hs-var">layer'</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-309"></span><span>
</span><span id="line-310"></span><span id="local-6989586621679728711"><span id="local-6989586621679728712"></span></span><span class="hs-keyword">newtype</span><span> </span><span id="LSTMSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-var">LSTMSpec</span></a></span></span><span>
</span><span id="line-311"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728710"><span class="annot"><a href="#local-6989586621679728710"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728709"><span class="annot"><a href="#local-6989586621679728709"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728708"><span class="annot"><a href="#local-6989586621679728708"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-314"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728707"><span class="annot"><a href="#local-6989586621679728707"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728706"><span class="annot"><a href="#local-6989586621679728706"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728705"><span class="annot"><a href="#local-6989586621679728705"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="LSTMSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-var">LSTMSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#DropoutSpec"><span class="hs-identifier hs-type">DropoutSpec</span></a></span><span>
</span><span id="line-318"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728698"><span id="local-6989586621679728700"><span id="local-6989586621679728702"><span class="annot"><span class="annottext">Int
-&gt; LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
[LSTMSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; String
(Int
 -&gt; LSTMSpec
      inputSize hiddenSize numLayers directionality dtype device
 -&gt; ShowS)
-&gt; (LSTMSpec
      inputSize hiddenSize numLayers directionality dtype device
    -&gt; String)
-&gt; ([LSTMSpec
       inputSize hiddenSize numLayers directionality dtype device]
    -&gt; ShowS)
-&gt; Show
     (LSTMSpec
        inputSize hiddenSize numLayers directionality dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTMSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; String
showList :: [LSTMSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
$cshowList :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTMSpec
   inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
show :: LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; String
$cshow :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; String
showsPrec :: Int
-&gt; LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
$cshowsPrec :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 LSTMSpec inputSize hiddenSize numLayers directionality dtype device
 -&gt; Rep
      (LSTMSpec
         inputSize hiddenSize numLayers directionality dtype device)
      x)
-&gt; (forall x.
    Rep
      (LSTMSpec
         inputSize hiddenSize numLayers directionality dtype device)
      x
    -&gt; LSTMSpec
         inputSize hiddenSize numLayers directionality dtype device)
-&gt; Generic
     (LSTMSpec
        inputSize hiddenSize numLayers directionality dtype device)
forall x.
Rep
  (LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device)
  x
-&gt; LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device
forall x.
LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; Rep
     (LSTMSpec
        inputSize hiddenSize numLayers directionality dtype device)
     x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep
  (LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device)
  x
-&gt; LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; Rep
     (LSTMSpec
        inputSize hiddenSize numLayers directionality dtype device)
     x
$cto :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep
  (LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device)
  x
-&gt; LSTMSpec
     inputSize hiddenSize numLayers directionality dtype device
$cfrom :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; Rep
     (LSTMSpec
        inputSize hiddenSize numLayers directionality dtype device)
     x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>
</span><span id="line-320"></span><span id="local-6989586621679728693"><span id="local-6989586621679728694"></span></span><span class="hs-keyword">data</span><span> </span><span id="LSTM"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-var">LSTM</span></a></span></span><span>
</span><span id="line-321"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729231"><span class="annot"><a href="#local-6989586621679729231"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729230"><span class="annot"><a href="#local-6989586621679729230"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-323"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729229"><span class="annot"><a href="#local-6989586621679729229"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-324"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729228"><span class="annot"><a href="#local-6989586621679729228"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-325"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729227"><span class="annot"><a href="#local-6989586621679729227"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-326"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679729226"><span class="annot"><a href="#local-6989586621679729226"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="LSTM"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-var">LSTM</span></a></span></span><span>
</span><span id="line-328"></span><span>      </span><span class="hs-special">{</span><span> </span><span id="lstm_layer_stack"><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; LSTMLayerStack
     inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm_layer_stack"><span class="hs-identifier hs-var hs-var">lstm_layer_stack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729231"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729230"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729229"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729228"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729227"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729226"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-329"></span><span>      </span><span class="hs-special">,</span><span> </span><span id="lstm_dropout"><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Dropout
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm_dropout"><span class="hs-identifier hs-var hs-var">lstm_dropout</span></a></span></span><span>     </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-330"></span><span>      </span><span class="hs-special">}</span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728684"><span id="local-6989586621679728686"><span id="local-6989586621679728688"><span class="annot"><span class="annottext">Int
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
[LSTM inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; String
(Int
 -&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; ShowS)
-&gt; (LSTM inputSize hiddenSize numLayers directionality dtype device
    -&gt; String)
-&gt; ([LSTM
       inputSize hiddenSize numLayers directionality dtype device]
    -&gt; ShowS)
-&gt; Show
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTM inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; String
showList :: [LSTM inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
$cshowList :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
[LSTM inputSize hiddenSize numLayers directionality dtype device]
-&gt; ShowS
show :: LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; String
$cshow :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; String
showsPrec :: Int
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
$cshowsPrec :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Int
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; Rep
      (LSTM inputSize hiddenSize numLayers directionality dtype device)
      x)
-&gt; (forall x.
    Rep
      (LSTM inputSize hiddenSize numLayers directionality dtype device) x
    -&gt; LSTM inputSize hiddenSize numLayers directionality dtype device)
-&gt; Generic
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall x.
Rep
  (LSTM inputSize hiddenSize numLayers directionality dtype device) x
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
forall x.
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Rep
     (LSTM inputSize hiddenSize numLayers directionality dtype device) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep
  (LSTM inputSize hiddenSize numLayers directionality dtype device) x
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Rep
     (LSTM inputSize hiddenSize numLayers directionality dtype device) x
$cto :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
Rep
  (LSTM inputSize hiddenSize numLayers directionality dtype device) x
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
$cfrom :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)) x.
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Rep
     (LSTM inputSize hiddenSize numLayers directionality dtype device) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-332"></span><span>
</span><span id="line-333"></span><span class="hs-comment">-- TODO: when we have cannonical initializers do this correctly:</span><span>
</span><span id="line-334"></span><span class="hs-comment">-- https://github.com/pytorch/pytorch/issues/9221</span><span>
</span><span id="line-335"></span><span class="hs-comment">-- https://discuss.pytorch.org/t/initializing-rnn-gru-and-lstm-correctly/23605</span><span>
</span><span id="line-336"></span><span>
</span><span id="line-337"></span><span id="local-6989586621679728676"><span id="local-6989586621679728677"><span id="local-6989586621679728678"><span id="local-6989586621679728679"><span id="local-6989586621679728680"><span id="local-6989586621679728681"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.NN.html#Parameterized"><span class="hs-identifier hs-type">A.Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728681"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728680"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728679"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728678"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728677"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728676"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-338"></span><span>  </span><span id="local-6989586621679728673"><span class="annot"><span class="annottext">flattenParameters :: LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; [Parameter]
</span><a href="#local-6989586621679728673"><span class="hs-identifier hs-var hs-var hs-var hs-var">flattenParameters</span></a></span></span><span> </span><span id="local-6989586621679728671"><span id="local-6989586621679728672"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; [Parameter]
forall f. Parameterized f =&gt; f -&gt; [Parameter]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">A.flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728672"><span class="hs-identifier hs-var">lstm_layer_stack</span></a></span><span>
</span><span id="line-339"></span><span>  </span><span id="local-6989586621679728670"><span class="annot"><span class="annottext">replaceOwnParameters :: LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
</span><a href="#local-6989586621679728670"><span class="hs-identifier hs-var hs-var hs-var hs-var">replaceOwnParameters</span></a></span></span><span> </span><span id="local-6989586621679728668"><span id="local-6989586621679728669"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-340"></span><span>    </span><span id="local-6989586621679728667"><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728667"><span class="hs-identifier hs-var">lstm_layer_stack'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
forall f. Parameterized f =&gt; f -&gt; ParamStream f
</span><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">A.replaceOwnParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728669"><span class="hs-identifier hs-var">lstm_layer_stack</span></a></span><span>
</span><span id="line-341"></span><span>    </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; ParamStream
      (LSTM inputSize hiddenSize numLayers directionality dtype device))
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">$WLSTM :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; Dropout
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#%24WLSTM"><span class="hs-identifier hs-type hs-type">LSTM</span></a></span><span>
</span><span id="line-342"></span><span>                 </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">lstm_layer_stack :: LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm_layer_stack"><span class="hs-identifier hs-var">lstm_layer_stack</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728667"><span class="hs-identifier hs-var">lstm_layer_stack'</span></a></span><span>
</span><span id="line-343"></span><span>                 </span><span class="hs-special">,</span><span> </span><span class="hs-glyph">..</span><span>
</span><span id="line-344"></span><span>                 </span><span class="hs-special">}</span></span></span></span></span></span></span><span>
</span><span id="line-345"></span><span>
</span><span id="line-346"></span><span class="hs-comment">-- | Helper to do xavier uniform initializations on weight matrices and</span><span>
</span><span id="line-347"></span><span class="hs-comment">-- orthagonal initializations for the gates. (When implemented.)</span><span>
</span><span id="line-348"></span><span class="hs-comment">--</span><span>
</span><span id="line-349"></span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-type">xavierUniformLSTM</span></a></span><span>
</span><span id="line-350"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679729419"><span class="annot"><a href="#local-6989586621679729419"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679729422"><span class="annot"><a href="#local-6989586621679729422"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679729421"><span class="annot"><a href="#local-6989586621679729421"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679729420"><span class="annot"><a href="#local-6989586621679729420"><span class="hs-identifier hs-type">featureSize</span></a></span></span><span>
</span><span id="line-351"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729422"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-352"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679729421"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-353"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679729420"><span class="hs-identifier hs-type">featureSize</span></a></span><span>
</span><span id="line-354"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729419"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-355"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729419"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729422"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-356"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729419"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729422"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679729421"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729420"><span class="hs-identifier hs-type">featureSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-358"></span><span id="xavierUniformLSTM"><span class="annot"><span class="annottext">xavierUniformLSTM :: IO (Tensor device dtype '[4 * hiddenSize, featureSize])
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformLSTM"><span class="hs-identifier hs-var hs-var">xavierUniformLSTM</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-359"></span><span>  </span><span id="local-6989586621679728665"><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, featureSize]
</span><a href="#local-6989586621679728665"><span class="hs-identifier hs-var">init</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">IO (Tensor device dtype '[4 * hiddenSize, featureSize])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(TensorOptions shape dtype device,
 RandDTypeIsValid device dtype) =&gt;
IO (Tensor device dtype shape)
</span><a href="Torch.Typed.Factories.html#randn"><span class="hs-identifier hs-var">randn</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729419"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729422"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679729421"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729420"><span class="hs-identifier hs-type">featureSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-360"></span><span>  </span><span class="annot"><span class="annottext">Tensor -&gt; Tensor device dtype '[4 * hiddenSize, featureSize]
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Tensor -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Tensor.html#UnsafeMkTensor"><span class="hs-identifier hs-var">UnsafeMkTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor -&gt; Tensor device dtype '[4 * hiddenSize, featureSize])
-&gt; IO Tensor
-&gt; IO (Tensor device dtype '[4 * hiddenSize, featureSize])
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; Float -&gt; [Int] -&gt; IO Tensor
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformFIXME"><span class="hs-identifier hs-var">xavierUniformFIXME</span></a></span><span>
</span><span id="line-361"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, featureSize] -&gt; Tensor
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Tensor device dtype shape -&gt; Tensor
</span><a href="Torch.Typed.Tensor.html#toDynamic"><span class="hs-identifier hs-var hs-var">toDynamic</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, featureSize]
</span><a href="#local-6989586621679728665"><span class="hs-identifier hs-var">init</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">5.0</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span>
</span><span id="line-363"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, featureSize] -&gt; [Int]
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape -&gt; [Int]
</span><a href="Torch.Typed.Tensor.html#shape"><span class="hs-identifier hs-var">shape</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729419"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729422"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><span class="hs-number">4</span></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="#local-6989586621679729421"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729420"><span class="hs-identifier hs-type">featureSize</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype '[4 * hiddenSize, featureSize]
</span><a href="#local-6989586621679728665"><span class="hs-identifier hs-var">init</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-364"></span><span>
</span><span id="line-365"></span><span class="hs-comment">-- TODO: This is taken from the initializers example code and should be replaced with cannonical,</span><span>
</span><span id="line-366"></span><span class="hs-comment">-- tested versions. However, even a potentially incorrect implementation will likely perform</span><span>
</span><span id="line-367"></span><span class="hs-comment">-- better than an ad-hoc random-normal distribution.</span><span>
</span><span id="line-368"></span><span class="hs-comment">-- | Fan-in / Fan-out scaling calculation</span><span>
</span><span id="line-369"></span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#calculateFan"><span class="hs-identifier hs-type">calculateFan</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-370"></span><span id="calculateFan"><span class="annot"><span class="annottext">calculateFan :: [Int] -&gt; (Int, Int)
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#calculateFan"><span class="hs-identifier hs-var hs-var">calculateFan</span></a></span></span><span> </span><span id="local-6989586621679728657"><span class="annot"><span class="annottext">shape :: [Int]
</span><a href="#local-6989586621679728657"><span class="hs-identifier hs-var">shape</span></a></span></span><span>
</span><span id="line-371"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728656"><span class="hs-identifier hs-var">dimT</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span>
</span><span id="line-372"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; (Int, Int)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span>
</span><span id="line-373"></span><span>    </span><span class="annot"><span class="hs-string">&quot;Fan in and fan out can not be computed for tensor with fewer than 2 dimensions&quot;</span></span><span>
</span><span id="line-374"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728656"><span class="hs-identifier hs-var">dimT</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span>
</span><span id="line-375"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728653"><span class="hs-identifier hs-var">numInputFmaps</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728652"><span class="hs-identifier hs-var">numOutputFmaps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-376"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span>
</span><span id="line-377"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728653"><span class="hs-identifier hs-var">numInputFmaps</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728650"><span class="hs-identifier hs-var">receptiveFieldSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728652"><span class="hs-identifier hs-var">numOutputFmaps</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728650"><span class="hs-identifier hs-var">receptiveFieldSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-378"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-379"></span><span>  </span><span id="local-6989586621679728656"><span class="annot"><span class="annottext">dimT :: Int
</span><a href="#local-6989586621679728656"><span class="hs-identifier hs-var hs-var">dimT</span></a></span></span><span>               </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: Type -&gt; Type) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679728657"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-380"></span><span>  </span><span id="local-6989586621679728653"><span class="annot"><span class="annottext">numInputFmaps :: Int
</span><a href="#local-6989586621679728653"><span class="hs-identifier hs-var hs-var">numInputFmaps</span></a></span></span><span>      </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679728657"><span class="hs-identifier hs-var">shape</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int -&gt; Int
forall a. [a] -&gt; Int -&gt; a
</span><span class="hs-operator hs-var">!!</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-381"></span><span>  </span><span id="local-6989586621679728652"><span class="annot"><span class="annottext">numOutputFmaps :: Int
</span><a href="#local-6989586621679728652"><span class="hs-identifier hs-var hs-var">numOutputFmaps</span></a></span></span><span>     </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679728657"><span class="hs-identifier hs-var">shape</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int -&gt; Int
forall a. [a] -&gt; Int -&gt; a
</span><span class="hs-operator hs-var">!!</span></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span>
</span><span id="line-382"></span><span>  </span><span id="local-6989586621679728650"><span class="annot"><span class="annottext">receptiveFieldSize :: Int
</span><a href="#local-6989586621679728650"><span class="hs-identifier hs-var hs-var">receptiveFieldSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: Type -&gt; Type) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; Int) -&gt; [Int] -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int]
forall a. [a] -&gt; [a]
</span><span class="hs-identifier hs-var">tail</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679728657"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-383"></span><span>
</span><span id="line-384"></span><span class="hs-comment">-- | Xavier Initialization - Uniform</span><span>
</span><span id="line-385"></span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformFIXME"><span class="hs-identifier hs-type">xavierUniformFIXME</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.Tensor.html#Tensor"><span class="hs-identifier hs-type">D.Tensor</span></a></span><span>
</span><span id="line-386"></span><span id="xavierUniformFIXME"><span class="annot"><span class="annottext">xavierUniformFIXME :: Tensor -&gt; Float -&gt; [Int] -&gt; IO Tensor
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#xavierUniformFIXME"><span class="hs-identifier hs-var hs-var">xavierUniformFIXME</span></a></span></span><span> </span><span id="local-6989586621679728645"><span class="annot"><span class="annottext">init :: Tensor
</span><a href="#local-6989586621679728645"><span class="hs-identifier hs-var">init</span></a></span></span><span> </span><span id="local-6989586621679728644"><span class="annot"><span class="annottext">gain :: Float
</span><a href="#local-6989586621679728644"><span class="hs-identifier hs-var">gain</span></a></span></span><span> </span><span id="local-6989586621679728643"><span class="annot"><span class="annottext">shape :: [Int]
</span><a href="#local-6989586621679728643"><span class="hs-identifier hs-var">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; IO Tensor
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-387"></span><span>  </span><span class="annot"><span class="annottext">(Tensor -&gt; IO Tensor) -&gt; Tensor -&gt; IO Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Tensor -&gt; Tensor
forall a. Scalar a =&gt; a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#subScalar"><span class="hs-identifier hs-var">D.subScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679728641"><span class="hs-identifier hs-var">bound</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor -&gt; Tensor) -&gt; Tensor -&gt; Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Tensor -&gt; Tensor
forall a. Scalar a =&gt; a -&gt; Tensor -&gt; Tensor
</span><a href="Torch.Functional.html#mulScalar"><span class="hs-identifier hs-var">D.mulScalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679728641"><span class="hs-identifier hs-var">bound</span></a></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="hs-number">2.0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
</span><a href="#local-6989586621679728645"><span class="hs-identifier hs-var">init</span></a></span><span>
</span><span id="line-388"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-389"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728639"><span class="annot"><span class="annottext">fanIn :: Int
</span><a href="#local-6989586621679728639"><span class="hs-identifier hs-var">fanIn</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679728638"><span class="annot"><span class="annottext">fanOut :: Int
</span><a href="#local-6989586621679728638"><span class="hs-identifier hs-var">fanOut</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; (Int, Int)
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#calculateFan"><span class="hs-identifier hs-var">calculateFan</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679728643"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-390"></span><span>  </span><span id="local-6989586621679728637"><span class="annot"><span class="annottext">std :: Float
</span><a href="#local-6989586621679728637"><span class="hs-identifier hs-var hs-var">std</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679728644"><span class="hs-identifier hs-var">gain</span></a></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-number">2.0</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Float
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728639"><span class="hs-identifier hs-var">fanIn</span></a></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Float
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728638"><span class="hs-identifier hs-var">fanOut</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-391"></span><span>  </span><span id="local-6989586621679728641"><span class="annot"><span class="annottext">bound :: Float
</span><a href="#local-6989586621679728641"><span class="hs-identifier hs-var hs-var">bound</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="hs-number">3.0</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679728637"><span class="hs-identifier hs-var">std</span></a></span><span>
</span><span id="line-392"></span><span>
</span><span id="line-393"></span><span id="local-6989586621679728629"><span id="local-6989586621679728630"><span id="local-6989586621679728631"><span id="local-6989586621679728632"><span id="local-6989586621679728633"><span id="local-6989586621679728634"><span class="hs-keyword">instance</span><span>
</span><span id="line-394"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728634"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-395"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728633"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-396"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728632"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-397"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728631"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-398"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728630"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-399"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Factories.html#RandDTypeIsValid"><span class="hs-identifier hs-type">RandDTypeIsValid</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728633"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728634"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-400"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-type">LSTMLayerStackSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728632"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728631"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728629"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728630"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728634"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728633"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-401"></span><span>                   </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStack"><span class="hs-identifier hs-type">LSTMLayerStack</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728632"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728631"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728629"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728630"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728634"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728633"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-402"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-type">LSTMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728632"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728631"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728629"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728630"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728634"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728633"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-403"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728632"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728631"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728629"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728630"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728634"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728633"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-404"></span><span>  </span><span id="local-6989586621679728627"><span class="annot"><span class="annottext">sample :: LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
</span><a href="#local-6989586621679728627"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-type">LSTMSpec</span></a></span><span> </span><span id="local-6989586621679728626"><span class="annot"><span class="annottext">dropoutSpec :: DropoutSpec
</span><a href="#local-6989586621679728626"><span class="hs-identifier hs-var">dropoutSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-405"></span><span>    </span><span class="annot"><span class="annottext">LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; Dropout
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStack
  inputSize hiddenSize numLayers directionality dtype device
-&gt; Dropout
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-var">LSTM</span></a></span><span>
</span><span id="line-406"></span><span>      </span><span class="annot"><span class="annottext">(LSTMLayerStack
   inputSize hiddenSize numLayers directionality dtype device
 -&gt; Dropout
 -&gt; LSTM inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO
     (Dropout
      -&gt; LSTM inputSize hiddenSize numLayers directionality dtype device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
-&gt; IO
     (LSTMLayerStack
        inputSize hiddenSize numLayers directionality dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTMLayerStackSpec
  inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMLayerStackSpec"><span class="hs-identifier hs-var">LSTMLayerStackSpec</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728632"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728631"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728629"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728630"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728634"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728633"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-407"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Dropout
   -&gt; LSTM inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO Dropout
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">DropoutSpec -&gt; IO Dropout
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">DropoutSpec
</span><a href="#local-6989586621679728626"><span class="hs-identifier hs-var">dropoutSpec</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-408"></span><span>
</span><span id="line-409"></span><span id="local-6989586621679728624"><span id="local-6989586621679728625"></span></span><span class="hs-keyword">data</span><span> </span><span id="RNNInitialization"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#RNNInitialization"><span class="hs-identifier hs-var">RNNInitialization</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ConstantInitialization"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-var">ConstantInitialization</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="LearnedInitialization"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LearnedInitialization"><span class="hs-identifier hs-var">LearnedInitialization</span></a></span></span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728618"><span id="local-6989586621679728620"><span id="local-6989586621679728622"><span class="annot"><span class="annottext">Int -&gt; RNNInitialization -&gt; ShowS
[RNNInitialization] -&gt; ShowS
RNNInitialization -&gt; String
(Int -&gt; RNNInitialization -&gt; ShowS)
-&gt; (RNNInitialization -&gt; String)
-&gt; ([RNNInitialization] -&gt; ShowS)
-&gt; Show RNNInitialization
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [RNNInitialization] -&gt; ShowS
$cshowList :: [RNNInitialization] -&gt; ShowS
show :: RNNInitialization -&gt; String
$cshow :: RNNInitialization -&gt; String
showsPrec :: Int -&gt; RNNInitialization -&gt; ShowS
$cshowsPrec :: Int -&gt; RNNInitialization -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. RNNInitialization -&gt; Rep RNNInitialization x)
-&gt; (forall x. Rep RNNInitialization x -&gt; RNNInitialization)
-&gt; Generic RNNInitialization
forall x. Rep RNNInitialization x -&gt; RNNInitialization
forall x. RNNInitialization -&gt; Rep RNNInitialization x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep RNNInitialization x -&gt; RNNInitialization
$cfrom :: forall x. RNNInitialization -&gt; Rep RNNInitialization x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-410"></span><span>
</span><span id="line-411"></span><span class="hs-comment">-- | A specification for a long, short-term memory layer.</span><span>
</span><span id="line-412"></span><span class="hs-comment">--</span><span>
</span><span id="line-413"></span><span class="hs-keyword">data</span><span> </span><span id="LSTMWithInitSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInitSpec"><span class="hs-identifier hs-var">LSTMWithInitSpec</span></a></span></span><span>
</span><span id="line-414"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728615"><span class="annot"><a href="#local-6989586621679728615"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-415"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728614"><span class="annot"><a href="#local-6989586621679728614"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-416"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728613"><span class="annot"><a href="#local-6989586621679728613"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-417"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728612"><span class="annot"><a href="#local-6989586621679728612"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-418"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728611"><span class="annot"><a href="#local-6989586621679728611"><span class="hs-identifier hs-type">initialization</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#RNNInitialization"><span class="hs-identifier hs-type">RNNInitialization</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-419"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728610"><span class="annot"><a href="#local-6989586621679728610"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-420"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728609"><span class="annot"><a href="#local-6989586621679728609"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-421"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-422"></span><span>  </span><span class="hs-comment">-- | Weights drawn from Xavier-Uniform</span><span>
</span><span id="line-423"></span><span>  </span><span class="hs-comment">--   with zeros-value initialized biases and cell states.</span><span>
</span><span id="line-424"></span><span>  </span><span id="LSTMWithZerosInitSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithZerosInitSpec"><span class="hs-identifier hs-var">LSTMWithZerosInitSpec</span></a></span></span><span>
</span><span id="line-425"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679728607"><span class="annot"><a href="#local-6989586621679728607"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679728606"><span class="annot"><a href="#local-6989586621679728606"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679728605"><span class="annot"><a href="#local-6989586621679728605"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679728604"><span class="annot"><a href="#local-6989586621679728604"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span id="local-6989586621679728603"><span class="annot"><a href="#local-6989586621679728603"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679728602"><span class="annot"><a href="#local-6989586621679728602"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-426"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-type">LSTMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728607"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728606"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728605"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728604"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728603"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728602"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-427"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInitSpec"><span class="hs-identifier hs-type">LSTMWithInitSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728607"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728606"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728605"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728604"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-type">ConstantInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728603"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728602"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-428"></span><span>  </span><span class="hs-comment">-- | Weights drawn from Xavier-Uniform</span><span>
</span><span id="line-429"></span><span>  </span><span class="hs-comment">--   with zeros-value initialized biases</span><span>
</span><span id="line-430"></span><span>  </span><span class="hs-comment">--   and user-provided cell states.</span><span>
</span><span id="line-431"></span><span>  </span><span id="LSTMWithConstInitSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInitSpec"><span class="hs-identifier hs-var">LSTMWithConstInitSpec</span></a></span></span><span>
</span><span id="line-432"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679728600"><span class="annot"><a href="#local-6989586621679728600"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679728599"><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679728598"><span class="annot"><a href="#local-6989586621679728598"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679728597"><span class="annot"><a href="#local-6989586621679728597"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span id="local-6989586621679728596"><span class="annot"><a href="#local-6989586621679728596"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679728595"><span class="annot"><a href="#local-6989586621679728595"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-433"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-type">LSTMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728600"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728598"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728597"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728596"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728595"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-434"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728595"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728596"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728598"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728597"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ The initial values of the memory cell</span><span>
</span><span id="line-435"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728595"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728596"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728598"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728597"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ The initial values of the hidden state</span><span>
</span><span id="line-436"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInitSpec"><span class="hs-identifier hs-type">LSTMWithInitSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728600"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728598"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728597"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-type">ConstantInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728596"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728595"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-437"></span><span>  </span><span class="hs-comment">-- | Weights drawn from Xavier-Uniform</span><span>
</span><span id="line-438"></span><span>  </span><span class="hs-comment">--   with zeros-value initialized biases</span><span>
</span><span id="line-439"></span><span>  </span><span class="hs-comment">--   and learned cell states.</span><span>
</span><span id="line-440"></span><span>  </span><span id="LSTMWithLearnedInitSpec"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInitSpec"><span class="hs-identifier hs-var">LSTMWithLearnedInitSpec</span></a></span></span><span>
</span><span id="line-441"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679728593"><span class="annot"><a href="#local-6989586621679728593"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679728592"><span class="annot"><a href="#local-6989586621679728592"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679728591"><span class="annot"><a href="#local-6989586621679728591"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679728590"><span class="annot"><a href="#local-6989586621679728590"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span id="local-6989586621679728589"><span class="annot"><a href="#local-6989586621679728589"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679728588"><span class="annot"><a href="#local-6989586621679728588"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-442"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-type">LSTMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728593"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728592"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728591"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728590"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728589"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728588"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-443"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728588"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728589"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728591"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728590"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728592"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ The initial (learnable)</span><span>
</span><span id="line-444"></span><span>                                                                                        </span><span class="hs-comment">-- values of the memory cell</span><span>
</span><span id="line-445"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728588"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728589"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728591"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728590"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728592"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-comment">-- ^ The initial (learnable)</span><span>
</span><span id="line-446"></span><span>                                                                                        </span><span class="hs-comment">-- values of the hidden state</span><span>
</span><span id="line-447"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInitSpec"><span class="hs-identifier hs-type">LSTMWithInitSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728593"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728592"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728591"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728590"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LearnedInitialization"><span class="hs-identifier hs-type">LearnedInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728589"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728588"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-448"></span><span>
</span><span id="line-449"></span><span id="local-6989586621679728575"><span id="local-6989586621679728577"><span id="local-6989586621679728579"><span id="local-6989586621679728581"><span id="local-6989586621679728582"><span id="local-6989586621679728583"><span id="local-6989586621679728584"><span id="local-6989586621679728585"><span id="local-6989586621679728586"><span id="local-6989586621679728587"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInitSpec"><span class="hs-identifier hs-type">LSTMWithInitSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728587"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728586"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728585"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728584"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728583"><span class="hs-identifier hs-type">initialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728582"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728581"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-450"></span><span class="hs-comment">-- deriving instance Generic (LSTMWithInitSpec inputSize hiddenSize numLayers directionality initialization dtype device)</span><span>
</span><span id="line-451"></span><span>
</span><span id="line-452"></span><span class="hs-comment">-- | A long, short-term memory layer with either fixed initial</span><span>
</span><span id="line-453"></span><span class="hs-comment">-- states for the memory cells and hidden state or learnable</span><span>
</span><span id="line-454"></span><span class="hs-comment">-- inital states for the memory cells and hidden state.</span><span>
</span><span id="line-455"></span><span class="hs-comment">--</span><span>
</span><span id="line-456"></span><span class="hs-keyword">data</span><span> </span><span id="LSTMWithInit"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-var">LSTMWithInit</span></a></span></span><span>
</span><span id="line-457"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728574"><span class="annot"><a href="#local-6989586621679728574"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-458"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728573"><span class="annot"><a href="#local-6989586621679728573"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-459"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728572"><span class="annot"><a href="#local-6989586621679728572"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-460"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728571"><span class="annot"><a href="#local-6989586621679728571"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNDirectionality"><span class="hs-identifier hs-type">RNNDirectionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-461"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728570"><span class="annot"><a href="#local-6989586621679728570"><span class="hs-identifier hs-type">initialization</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#RNNInitialization"><span class="hs-identifier hs-type">RNNInitialization</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-462"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728569"><span class="annot"><a href="#local-6989586621679728569"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.DType.html#DType"><span class="hs-identifier hs-type">D.DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-463"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679728568"><span class="annot"><a href="#local-6989586621679728568"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Device.html#DeviceType"><span class="hs-identifier hs-type">D.DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-464"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-465"></span><span>  </span><span id="LSTMWithConstInit"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-var">LSTMWithConstInit</span></a></span></span><span>
</span><span id="line-466"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679729124"><span class="annot"><a href="#local-6989586621679729124"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679729123"><span class="annot"><a href="#local-6989586621679729123"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679729122"><span class="annot"><a href="#local-6989586621679729122"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679729121"><span class="annot"><a href="#local-6989586621679729121"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span id="local-6989586621679729120"><span class="annot"><a href="#local-6989586621679729120"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679729119"><span class="annot"><a href="#local-6989586621679729119"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-467"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="lstmWithConstInit_lstm"><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'ConstantInitialization
  dtype
  device
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithConstInit_lstm"><span class="hs-identifier hs-var hs-var">lstmWithConstInit_lstm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729124"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729123"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729122"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729121"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729120"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729119"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-468"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="lstmWithConstInit_c"><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'ConstantInitialization
  dtype
  device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithConstInit_c"><span class="hs-identifier hs-var hs-var">lstmWithConstInit_c</span></a></span></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729120"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729122"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729121"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729123"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-469"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="lstmWithConstInit_h"><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'ConstantInitialization
  dtype
  device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithConstInit_h"><span class="hs-identifier hs-var hs-var">lstmWithConstInit_h</span></a></span></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729120"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729122"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729121"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729123"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-470"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-471"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729124"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729123"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729122"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729121"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-type">ConstantInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729120"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729119"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-472"></span><span>  </span><span id="LSTMWithLearnedInit"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInit"><span class="hs-identifier hs-var">LSTMWithLearnedInit</span></a></span></span><span>
</span><span id="line-473"></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679729106"><span class="annot"><a href="#local-6989586621679729106"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span> </span><span id="local-6989586621679729105"><span class="annot"><a href="#local-6989586621679729105"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span> </span><span id="local-6989586621679729104"><span class="annot"><a href="#local-6989586621679729104"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679729103"><span class="annot"><a href="#local-6989586621679729103"><span class="hs-identifier hs-type">directionality</span></a></span></span><span> </span><span id="local-6989586621679729102"><span class="annot"><a href="#local-6989586621679729102"><span class="hs-identifier hs-type">dtype</span></a></span></span><span> </span><span id="local-6989586621679729101"><span class="annot"><a href="#local-6989586621679729101"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-474"></span><span>     </span><span class="hs-operator">.</span><span> </span><span class="hs-special">{</span><span> </span><span id="lstmWithLearnedInit_lstm"><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'LearnedInitialization
  dtype
  device
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithLearnedInit_lstm"><span class="hs-identifier hs-var hs-var">lstmWithLearnedInit_lstm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729106"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729105"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729104"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729103"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729102"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729101"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-475"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="lstmWithLearnedInit_c"><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'LearnedInitialization
  dtype
  device
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithLearnedInit_c"><span class="hs-identifier hs-var hs-var">lstmWithLearnedInit_c</span></a></span></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729101"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729102"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729104"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729103"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729105"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-476"></span><span>       </span><span class="hs-special">,</span><span> </span><span id="lstmWithLearnedInit_h"><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'LearnedInitialization
  dtype
  device
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithLearnedInit_h"><span class="hs-identifier hs-var hs-var">lstmWithLearnedInit_h</span></a></span></span><span>    </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729101"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729102"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729104"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729103"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729105"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-477"></span><span>       </span><span class="hs-special">}</span><span>
</span><span id="line-478"></span><span>    </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729106"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729105"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729104"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729103"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LearnedInitialization"><span class="hs-identifier hs-type">LearnedInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729102"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729101"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-479"></span><span>
</span><span id="line-480"></span><span id="local-6989586621679728547"><span id="local-6989586621679728549"><span id="local-6989586621679728551"><span id="local-6989586621679728553"><span id="local-6989586621679728554"><span id="local-6989586621679728555"><span id="local-6989586621679728556"><span id="local-6989586621679728557"><span id="local-6989586621679728558"><span id="local-6989586621679728559"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728559"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728558"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728557"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728556"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728555"><span class="hs-identifier hs-type">initialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728554"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728553"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-481"></span><span class="hs-comment">-- TODO: https://ryanglscott.github.io/2018/02/11/how-to-derive-generic-for-some-gadts/</span><span>
</span><span id="line-482"></span><span class="hs-comment">-- deriving instance Generic (LSTMWithInit inputSize hiddenSize numLayers directionality 'ConstantInitialization dtype device)</span><span>
</span><span id="line-483"></span><span>
</span><span id="line-484"></span><span id="local-6989586621679728541"><span id="local-6989586621679728542"><span id="local-6989586621679728543"><span id="local-6989586621679728544"><span id="local-6989586621679728545"><span id="local-6989586621679728546"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Generic</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728546"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728544"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728543"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-type">ConstantInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728542"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728541"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-485"></span><span>  </span><span class="hs-keyword">type</span><span> </span><span id="Rep"><span class="annot"><span class="hs-identifier hs-var">Rep</span></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728546"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728544"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728543"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-type">ConstantInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728542"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728541"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-486"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Rec0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728546"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728544"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728543"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728542"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728541"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>      </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Rec0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728541"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728542"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728544"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728543"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-488"></span><span>      </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Rec0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728541"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728542"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728544"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728543"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-489"></span><span>
</span><span id="line-490"></span><span>  </span><span id="local-6989586621679728538"><span class="annot"><span class="annottext">from :: LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'ConstantInitialization
  dtype
  device
-&gt; Rep
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
     x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">from</span></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728534"><span id="local-6989586621679728535"><span id="local-6989586621679728536"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-type">LSTMWithConstInit</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; K1
     R
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
     x
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728536"><span class="hs-identifier hs-var">lstmWithConstInit_lstm</span></a></span><span> </span><span class="annot"><span class="annottext">K1
  R
  (LSTM inputSize hiddenSize numLayers directionality dtype device)
  x
-&gt; (:*:)
     (K1
        R
        (Tensor
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     (K1
        R
        (Tensor
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     x
-&gt; (:*:)
     (K1
        R
        (LSTM inputSize hiddenSize numLayers directionality dtype device))
     (K1
        R
        (Tensor
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize])
      :*: K1
            R
            (Tensor
               device
               dtype
               '[numLayers * NumberOfDirections directionality, hiddenSize]))
     x
forall k (f :: k -&gt; Type) (g :: k -&gt; Type) (p :: k).
f p -&gt; g p -&gt; (:*:) f g p
</span><span class="hs-operator hs-var">:*:</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; K1
     R
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
     x
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728535"><span class="hs-identifier hs-var">lstmWithConstInit_c</span></a></span><span> </span><span class="annot"><span class="annottext">K1
  R
  (Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize])
  x
-&gt; K1
     R
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
     x
-&gt; (:*:)
     (K1
        R
        (Tensor
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     (K1
        R
        (Tensor
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     x
forall k (f :: k -&gt; Type) (g :: k -&gt; Type) (p :: k).
f p -&gt; g p -&gt; (:*:) f g p
</span><span class="hs-operator hs-var">:*:</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; K1
     R
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
     x
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728534"><span class="hs-identifier hs-var">lstmWithConstInit_h</span></a></span><span>
</span><span id="line-491"></span><span>  </span><span id="local-6989586621679728532"><span class="annot"><span class="annottext">to :: Rep
  (LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device)
  x
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">to</span></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span id="local-6989586621679728530"><span class="annot"><a href="#local-6989586621679728530"><span class="hs-identifier hs-var">lstm</span></a></span></span><span> </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span id="local-6989586621679728529"><span class="annot"><a href="#local-6989586621679728529"><span class="hs-identifier hs-var">c</span></a></span></span><span> </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span id="local-6989586621679728528"><span class="annot"><a href="#local-6989586621679728528"><span class="hs-identifier hs-var">h</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-var">LSTMWithConstInit</span></a></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728530"><span class="hs-identifier hs-var">lstm</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728529"><span class="hs-identifier hs-var">c</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728528"><span class="hs-identifier hs-var">h</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-492"></span><span>
</span><span id="line-493"></span><span id="local-6989586621679728522"><span id="local-6989586621679728523"><span id="local-6989586621679728524"><span id="local-6989586621679728525"><span id="local-6989586621679728526"><span id="local-6989586621679728527"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Generic</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728527"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728526"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728525"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728524"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LearnedInitialization"><span class="hs-identifier hs-type">LearnedInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728523"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728522"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-494"></span><span>  </span><span class="hs-keyword">type</span><span> </span><span id="Rep"><span class="annot"><span class="hs-identifier hs-var">Rep</span></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728527"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728526"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728525"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728524"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LearnedInitialization"><span class="hs-identifier hs-type">LearnedInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728523"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728522"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-495"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Rec0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728527"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728526"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728525"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728524"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728523"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728522"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-496"></span><span>      </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Rec0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728522"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728523"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728525"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728524"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728526"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-497"></span><span>      </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Rec0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameter"><span class="hs-identifier hs-type">Parameter</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728522"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728523"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728525"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728524"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728526"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-498"></span><span>
</span><span id="line-499"></span><span>  </span><span id="local-6989586621679728519"><span class="annot"><span class="annottext">from :: LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'LearnedInitialization
  dtype
  device
-&gt; Rep
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'LearnedInitialization
        dtype
        device)
     x
</span><a href="#local-6989586621679728519"><span class="hs-identifier hs-var hs-var hs-var hs-var">from</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728516"><span id="local-6989586621679728517"><span id="local-6989586621679728518"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInit"><span class="hs-identifier hs-type">LSTMWithLearnedInit</span></a></span><span> </span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; K1
     R
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
     x
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728518"><span class="hs-identifier hs-var">lstmWithLearnedInit_lstm</span></a></span><span> </span><span class="annot"><span class="annottext">K1
  R
  (LSTM inputSize hiddenSize numLayers directionality dtype device)
  x
-&gt; (:*:)
     (K1
        R
        (Parameter
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     (K1
        R
        (Parameter
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     x
-&gt; (:*:)
     (K1
        R
        (LSTM inputSize hiddenSize numLayers directionality dtype device))
     (K1
        R
        (Parameter
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize])
      :*: K1
            R
            (Parameter
               device
               dtype
               '[numLayers * NumberOfDirections directionality, hiddenSize]))
     x
forall k (f :: k -&gt; Type) (g :: k -&gt; Type) (p :: k).
f p -&gt; g p -&gt; (:*:) f g p
</span><span class="hs-operator hs-var">:*:</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; K1
     R
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
     x
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728517"><span class="hs-identifier hs-var">lstmWithLearnedInit_c</span></a></span><span> </span><span class="annot"><span class="annottext">K1
  R
  (Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize])
  x
-&gt; K1
     R
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
     x
-&gt; (:*:)
     (K1
        R
        (Parameter
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     (K1
        R
        (Parameter
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]))
     x
forall k (f :: k -&gt; Type) (g :: k -&gt; Type) (p :: k).
f p -&gt; g p -&gt; (:*:) f g p
</span><span class="hs-operator hs-var">:*:</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; K1
     R
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
     x
forall k i c (p :: k). c -&gt; K1 i c p
</span><span class="hs-identifier hs-var">K1</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728516"><span class="hs-identifier hs-var">lstmWithLearnedInit_h</span></a></span><span>
</span><span id="line-500"></span><span>  </span><span id="local-6989586621679728515"><span class="annot"><span class="annottext">to :: Rep
  (LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device)
  x
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device
</span><a href="#local-6989586621679728515"><span class="hs-identifier hs-var hs-var hs-var hs-var">to</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span id="local-6989586621679728514"><span class="annot"><a href="#local-6989586621679728514"><span class="hs-identifier hs-var">lstm</span></a></span></span><span> </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span id="local-6989586621679728513"><span class="annot"><a href="#local-6989586621679728513"><span class="hs-identifier hs-var">c</span></a></span></span><span> </span><span class="annot"><span class="hs-operator hs-type">:*:</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">K1</span></span><span> </span><span id="local-6989586621679728512"><span class="annot"><a href="#local-6989586621679728512"><span class="hs-identifier hs-var">h</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInit"><span class="hs-identifier hs-var">LSTMWithLearnedInit</span></a></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728514"><span class="hs-identifier hs-var">lstm</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728513"><span class="hs-identifier hs-var">c</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728512"><span class="hs-identifier hs-var">h</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-501"></span><span>
</span><span id="line-502"></span><span id="local-6989586621679728506"><span id="local-6989586621679728507"><span id="local-6989586621679728508"><span id="local-6989586621679728509"><span id="local-6989586621679728510"><span id="local-6989586621679728511"><span class="hs-keyword">instance</span><span>
</span><span id="line-503"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728511"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-504"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728510"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-505"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728509"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-506"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728508"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-507"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728507"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-508"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-type">LSTMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728506"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728511"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728510"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728509"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728507"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-509"></span><span>                   </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728506"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728511"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728510"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728509"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728507"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-510"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInitSpec"><span class="hs-identifier hs-type">LSTMWithInitSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728506"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728511"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728510"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728509"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-type">ConstantInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728507"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-511"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728506"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728511"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728510"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728509"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#ConstantInitialization"><span class="hs-identifier hs-type">ConstantInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728508"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728507"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-512"></span><span>  </span><span id="local-6989586621679728504"><span class="annot"><span class="annottext">sample :: LSTMWithInitSpec
  inputSize
  hiddenSize
  numLayers
  directionality
  'ConstantInitialization
  dtype
  device
-&gt; IO
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
</span><a href="#local-6989586621679728504"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithZerosInitSpec"><span class="hs-identifier hs-type">LSTMWithZerosInitSpec</span></a></span><span> </span><span id="local-6989586621679728503"><span class="annot"><span class="annottext">lstmSpec :: LSTMSpec inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728503"><span class="hs-identifier hs-var">lstmSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-513"></span><span>    </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-var">LSTMWithConstInit</span></a></span><span>
</span><span id="line-514"></span><span>      </span><span class="annot"><span class="annottext">(LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; Tensor
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; LSTMWithInit
      inputSize
      hiddenSize
      numLayers
      directionality
      'ConstantInitialization
      dtype
      device)
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; Tensor
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; LSTMWithInit
           inputSize
           hiddenSize
           numLayers
           directionality
           'ConstantInitialization
           dtype
           device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMSpec inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728503"><span class="hs-identifier hs-var">lstmSpec</span></a></span><span>
</span><span id="line-515"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; LSTMWithInit
           inputSize
           hiddenSize
           numLayers
           directionality
           'ConstantInitialization
           dtype
           device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span>
</span><span id="line-516"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
TensorOptions shape dtype device =&gt;
Tensor device dtype shape
</span><a href="Torch.Typed.Factories.html#zeros"><span class="hs-identifier hs-var">zeros</span></a></span><span>
</span><span id="line-517"></span><span>  </span><span class="annot"><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">sample</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInitSpec"><span class="hs-identifier hs-type">LSTMWithConstInitSpec</span></a></span><span> </span><span id="local-6989586621679728502"><span class="annot"><span class="annottext">lstmSpec :: LSTMSpec inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728502"><span class="hs-identifier hs-var">lstmSpec</span></a></span></span><span> </span><span id="local-6989586621679728501"><span class="annot"><span class="annottext">c :: Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728501"><span class="hs-identifier hs-var">c</span></a></span></span><span> </span><span id="local-6989586621679728500"><span class="annot"><span class="annottext">h :: Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728500"><span class="hs-identifier hs-var">h</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-518"></span><span>    </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-var">LSTMWithConstInit</span></a></span><span>
</span><span id="line-519"></span><span>      </span><span class="annot"><span class="annottext">(LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; Tensor
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; LSTMWithInit
      inputSize
      hiddenSize
      numLayers
      directionality
      'ConstantInitialization
      dtype
      device)
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; Tensor
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; LSTMWithInit
           inputSize
           hiddenSize
           numLayers
           directionality
           'ConstantInitialization
           dtype
           device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMSpec inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728502"><span class="hs-identifier hs-var">lstmSpec</span></a></span><span>
</span><span id="line-520"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; LSTMWithInit
           inputSize
           hiddenSize
           numLayers
           directionality
           'ConstantInitialization
           dtype
           device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728501"><span class="hs-identifier hs-var">c</span></a></span><span>
</span><span id="line-521"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'ConstantInitialization
        dtype
        device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728500"><span class="hs-identifier hs-var">h</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-522"></span><span>
</span><span id="line-523"></span><span id="local-6989586621679728494"><span id="local-6989586621679728495"><span id="local-6989586621679728496"><span id="local-6989586621679728497"><span id="local-6989586621679728498"><span id="local-6989586621679728499"><span class="hs-keyword">instance</span><span>
</span><span id="line-524"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728499"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-525"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728498"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-526"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728497"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-527"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728496"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-528"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#KnownDevice"><span class="hs-identifier hs-type">KnownDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728495"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-529"></span><span>  </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMSpec"><span class="hs-identifier hs-type">LSTMSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728494"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728499"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728498"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728497"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728496"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728495"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-530"></span><span>                   </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728494"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728499"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728498"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728497"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728496"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728495"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-531"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.NN.html#Randomizable"><span class="hs-identifier hs-type">A.Randomizable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInitSpec"><span class="hs-identifier hs-type">LSTMWithInitSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728494"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728499"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728498"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728497"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LearnedInitialization"><span class="hs-identifier hs-type">LearnedInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728496"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728495"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-532"></span><span>                      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span>     </span><span class="annot"><a href="#local-6989586621679728494"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728499"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728498"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728497"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LearnedInitialization"><span class="hs-identifier hs-type">LearnedInitialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728496"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728495"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-533"></span><span>  </span><span id="local-6989586621679728492"><span class="annot"><span class="annottext">sample :: LSTMWithInitSpec
  inputSize
  hiddenSize
  numLayers
  directionality
  'LearnedInitialization
  dtype
  device
-&gt; IO
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'LearnedInitialization
        dtype
        device)
</span><a href="#local-6989586621679728492"><span class="hs-identifier hs-var hs-var hs-var hs-var">sample</span></a></span></span><span> </span><span id="local-6989586621679728491"><span class="annot"><span class="annottext">s :: LSTMWithInitSpec
  inputSize
  hiddenSize
  numLayers
  directionality
  'LearnedInitialization
  dtype
  device
</span><a href="#local-6989586621679728491"><span class="hs-identifier hs-var">s</span></a></span></span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInitSpec"><span class="hs-identifier hs-type">LSTMWithLearnedInitSpec</span></a></span><span> </span><span id="local-6989586621679728490"><span class="annot"><span class="annottext">lstmSpec :: LSTMSpec inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728490"><span class="hs-identifier hs-var">lstmSpec</span></a></span></span><span> </span><span id="local-6989586621679728489"><span class="annot"><span class="annottext">c :: Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728489"><span class="hs-identifier hs-var">c</span></a></span></span><span> </span><span id="local-6989586621679728488"><span class="annot"><span class="annottext">h :: Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728488"><span class="hs-identifier hs-var">h</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-534"></span><span>    </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device
forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInit"><span class="hs-identifier hs-var">LSTMWithLearnedInit</span></a></span><span>
</span><span id="line-535"></span><span>      </span><span class="annot"><span class="annottext">(LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; Parameter
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Parameter
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; LSTMWithInit
      inputSize
      hiddenSize
      numLayers
      directionality
      'LearnedInitialization
      dtype
      device)
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; Parameter
           device
           dtype
           '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; LSTMWithInit
           inputSize
           hiddenSize
           numLayers
           directionality
           'LearnedInitialization
           dtype
           device)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">LSTMSpec inputSize hiddenSize numLayers directionality dtype device
-&gt; IO
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall spec f. Randomizable spec f =&gt; spec -&gt; IO f
</span><a href="Torch.NN.html#sample"><span class="hs-identifier hs-var">A.sample</span></a></span><span> </span><span class="annot"><span class="annottext">LSTMSpec inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728490"><span class="hs-identifier hs-var">lstmSpec</span></a></span><span>
</span><span id="line-536"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'LearnedInitialization
        dtype
        device)
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize]
      -&gt; LSTMWithInit
           inputSize
           hiddenSize
           numLayers
           directionality
           'LearnedInitialization
           dtype
           device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; IO
      (Parameter
         device
         dtype
         '[numLayers * NumberOfDirections directionality, hiddenSize]))
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728489"><span class="hs-identifier hs-var">c</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-537"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
   -&gt; LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'LearnedInitialization
        dtype
        device)
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        'LearnedInitialization
        dtype
        device)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Tensor device dtype shape -&gt; IO (Parameter device dtype shape)
</span><a href="Torch.Typed.Parameter.html#makeIndependent"><span class="hs-identifier hs-var">makeIndependent</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; IO
      (Parameter
         device
         dtype
         '[numLayers * NumberOfDirections directionality, hiddenSize]))
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; IO
     (Parameter
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (m :: Type -&gt; Type) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; IO
     (Tensor
        device
        dtype
        '[numLayers * NumberOfDirections directionality, hiddenSize])
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728488"><span class="hs-identifier hs-var">h</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-538"></span><span>
</span><span id="line-539"></span><span id="local-6989586621679728481"><span id="local-6989586621679728482"><span id="local-6989586621679728483"><span id="local-6989586621679728484"><span id="local-6989586621679728485"><span id="local-6989586621679728486"><span id="local-6989586621679728487"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.NN.html#Parameterized"><span class="hs-identifier hs-type">A.Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728487"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728486"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728485"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728484"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728483"><span class="hs-identifier hs-type">initialization</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728482"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728481"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-540"></span><span>  </span><span id="local-6989586621679728478"><span class="annot"><span class="annottext">flattenParameters :: LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  initialization
  dtype
  device
-&gt; [Parameter]
</span><a href="#local-6989586621679728478"><span class="hs-identifier hs-var hs-var hs-var hs-var">flattenParameters</span></a></span></span><span> </span><span id="local-6989586621679728475"><span id="local-6989586621679728476"><span id="local-6989586621679728477"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-type">LSTMWithConstInit</span></a></span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-541"></span><span>           </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; [Parameter]
forall f. Parameterized f =&gt; f -&gt; [Parameter]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">A.flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728477"><span class="hs-identifier hs-var">lstmWithConstInit_lstm</span></a></span><span>
</span><span id="line-542"></span><span>  </span><span class="annot"><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span id="local-6989586621679728472"><span id="local-6989586621679728473"><span id="local-6989586621679728474"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInit"><span class="hs-identifier hs-type">LSTMWithLearnedInit</span></a></span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-543"></span><span>           </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; [Parameter]
forall f. Parameterized f =&gt; f -&gt; [Parameter]
</span><a href="Torch.NN.html#flattenParameters"><span class="hs-identifier hs-var">A.flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728474"><span class="hs-identifier hs-var">lstmWithLearnedInit_lstm</span></a></span><span>
</span><span id="line-544"></span><span>        </span><span class="annot"><span class="annottext">[Parameter] -&gt; [Parameter] -&gt; [Parameter]
forall a. [a] -&gt; [a] -&gt; [a]
</span><span class="hs-operator hs-var">++</span></span><span> </span><span class="annot"><span class="annottext">(Parameter
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Parameter)
-&gt; [Parameter
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]]
-&gt; [Parameter]
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Parameter
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter device dtype shape -&gt; Parameter
</span><a href="Torch.Typed.Parameter.html#untypeParam"><span class="hs-identifier hs-var">untypeParam</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Item
  [Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]]
Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728473"><span class="hs-identifier hs-var">lstmWithLearnedInit_c</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Item
  [Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]]
Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728472"><span class="hs-identifier hs-var">lstmWithLearnedInit_h</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-545"></span><span>  </span><span id="local-6989586621679728471"><span class="annot"><span class="annottext">replaceOwnParameters :: LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  initialization
  dtype
  device
-&gt; ParamStream
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        initialization
        dtype
        device)
</span><a href="#local-6989586621679728471"><span class="hs-identifier hs-var hs-var hs-var hs-var">replaceOwnParameters</span></a></span></span><span> </span><span id="local-6989586621679728468"><span id="local-6989586621679728469"><span id="local-6989586621679728470"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-type">LSTMWithConstInit</span></a></span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-546"></span><span>    </span><span id="local-6989586621679728467"><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728467"><span class="hs-identifier hs-var">lstmWithConstInit_lstm'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall f. Parameterized f =&gt; f -&gt; ParamStream f
</span><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">A.replaceOwnParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728470"><span class="hs-identifier hs-var">lstmWithConstInit_lstm</span></a></span><span>
</span><span id="line-547"></span><span>    </span><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'ConstantInitialization
  dtype
  device
-&gt; ParamStream
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        initialization
        dtype
        device)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(LSTMWithInit
   inputSize
   hiddenSize
   numLayers
   directionality
   'ConstantInitialization
   dtype
   device
 -&gt; ParamStream
      (LSTMWithInit
         inputSize
         hiddenSize
         numLayers
         directionality
         initialization
         dtype
         device))
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
-&gt; ParamStream
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        initialization
        dtype
        device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">$WLSTMWithConstInit :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'ConstantInitialization
     dtype
     device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#%24WLSTMWithConstInit"><span class="hs-identifier hs-type hs-type">LSTMWithConstInit</span></a></span><span>
</span><span id="line-548"></span><span>                 </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">lstmWithConstInit_lstm :: LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithConstInit_lstm"><span class="hs-identifier hs-var">lstmWithConstInit_lstm</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728467"><span class="hs-identifier hs-var">lstmWithConstInit_lstm'</span></a></span><span>
</span><span id="line-549"></span><span>                 </span><span class="hs-special">,</span><span> </span><span class="hs-glyph">..</span><span>
</span><span id="line-550"></span><span>                 </span><span class="hs-special">}</span><span>
</span><span id="line-551"></span><span>  </span><span class="annot"><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">replaceOwnParameters</span></a></span><span> </span><span id="local-6989586621679728463"><span id="local-6989586621679728464"><span id="local-6989586621679728465"><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInit"><span class="hs-identifier hs-type">LSTMWithLearnedInit</span></a></span><span class="hs-special">{</span><span class="hs-glyph">..</span><span class="hs-special">}</span></span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-552"></span><span>    </span><span id="local-6989586621679728462"><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728462"><span class="hs-identifier hs-var">lstmWithLearnedInit_lstm'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; ParamStream
     (LSTM inputSize hiddenSize numLayers directionality dtype device)
forall f. Parameterized f =&gt; f -&gt; ParamStream f
</span><a href="Torch.NN.html#replaceOwnParameters"><span class="hs-identifier hs-var">A.replaceOwnParameters</span></a></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728465"><span class="hs-identifier hs-var">lstmWithLearnedInit_lstm</span></a></span><span>
</span><span id="line-553"></span><span>    </span><span id="local-6989586621679728461"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728461"><span class="hs-identifier hs-var">lstmWithLearnedInit_c'</span></a></span></span><span>    </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-554"></span><span>    </span><span id="local-6989586621679728460"><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728460"><span class="hs-identifier hs-var">lstmWithLearnedInit_h'</span></a></span></span><span>    </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ParamStream Parameter
</span><a href="Torch.NN.html#nextParameter"><span class="hs-identifier hs-var">A.nextParameter</span></a></span><span>
</span><span id="line-555"></span><span>    </span><span class="annot"><span class="annottext">LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  'LearnedInitialization
  dtype
  device
-&gt; ParamStream
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        initialization
        dtype
        device)
forall (m :: Type -&gt; Type) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">(LSTMWithInit
   inputSize
   hiddenSize
   numLayers
   directionality
   'LearnedInitialization
   dtype
   device
 -&gt; ParamStream
      (LSTMWithInit
         inputSize
         hiddenSize
         numLayers
         directionality
         initialization
         dtype
         device))
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device
-&gt; ParamStream
     (LSTMWithInit
        inputSize
        hiddenSize
        numLayers
        directionality
        initialization
        dtype
        device)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">$WLSTMWithLearnedInit :: forall (inputSize :: Nat) (hiddenSize :: Nat) (numLayers :: Nat)
       (directionality :: RNNDirectionality) (dtype :: DType)
       (device :: (DeviceType, Nat)).
LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     'LearnedInitialization
     dtype
     device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#%24WLSTMWithLearnedInit"><span class="hs-identifier hs-type hs-type">LSTMWithLearnedInit</span></a></span><span>
</span><span id="line-556"></span><span>                 </span><span class="hs-special">{</span><span> </span><span class="annot"><span class="annottext">lstmWithLearnedInit_lstm :: LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithLearnedInit_lstm"><span class="hs-identifier hs-var">lstmWithLearnedInit_lstm</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728462"><span class="hs-identifier hs-var">lstmWithLearnedInit_lstm'</span></a></span><span>
</span><span id="line-557"></span><span>                 </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lstmWithLearnedInit_c :: Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithLearnedInit_c"><span class="hs-identifier hs-var">lstmWithLearnedInit_c</span></a></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728461"><span class="hs-identifier hs-var">lstmWithLearnedInit_c'</span></a></span><span>
</span><span id="line-558"></span><span>                 </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">lstmWithLearnedInit_h :: Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithLearnedInit_h"><span class="hs-identifier hs-var">lstmWithLearnedInit_h</span></a></span><span>    </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Parameter
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
forall (device :: (DeviceType, Nat)) (dtype :: DType)
       (shape :: [Nat]).
Parameter -&gt; Parameter device dtype shape
</span><a href="Torch.Typed.Parameter.html#UnsafeMkParameter"><span class="hs-identifier hs-var">UnsafeMkParameter</span></a></span><span> </span><span class="annot"><span class="annottext">Parameter
</span><a href="#local-6989586621679728460"><span class="hs-identifier hs-var">lstmWithLearnedInit_h'</span></a></span><span>
</span><span id="line-559"></span><span>                 </span><span class="hs-special">}</span></span></span></span></span></span></span></span><span>
</span><span id="line-560"></span><span>
</span><span id="line-561"></span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm"><span class="hs-identifier hs-type">lstm</span></a></span><span>
</span><span id="line-562"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span>
</span><span id="line-563"></span><span>       </span><span id="local-6989586621679729002"><span class="annot"><a href="#local-6989586621679729002"><span class="hs-identifier hs-type">shapeOrder</span></a></span></span><span>
</span><span id="line-564"></span><span>       </span><span id="local-6989586621679729004"><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-565"></span><span>       </span><span id="local-6989586621679728999"><span class="annot"><a href="#local-6989586621679728999"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span>
</span><span id="line-566"></span><span>       </span><span id="local-6989586621679729006"><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span></span><span>
</span><span id="line-567"></span><span>       </span><span id="local-6989586621679728991"><span class="annot"><a href="#local-6989586621679728991"><span class="hs-identifier hs-type">initialization</span></a></span></span><span>
</span><span id="line-568"></span><span>       </span><span id="local-6989586621679729005"><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span>
</span><span id="line-569"></span><span>       </span><span id="local-6989586621679728998"><span class="annot"><a href="#local-6989586621679728998"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span>
</span><span id="line-570"></span><span>       </span><span id="local-6989586621679729001"><span class="annot"><a href="#local-6989586621679729001"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-571"></span><span>       </span><span id="local-6989586621679729003"><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span>
</span><span id="line-572"></span><span>       </span><span id="local-6989586621679729000"><span class="annot"><a href="#local-6989586621679729000"><span class="hs-identifier hs-type">inputShape</span></a></span></span><span>
</span><span id="line-573"></span><span>       </span><span id="local-6989586621679728997"><span class="annot"><a href="#local-6989586621679728997"><span class="hs-identifier hs-type">outputShape</span></a></span></span><span>
</span><span id="line-574"></span><span>       </span><span id="local-6989586621679728996"><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span></span><span>
</span><span id="line-575"></span><span>       </span><span id="local-6989586621679728993"><span class="annot"><a href="#local-6989586621679728993"><span class="hs-identifier hs-type">parameters</span></a></span></span><span>
</span><span id="line-576"></span><span>       </span><span id="local-6989586621679728992"><span class="annot"><a href="#local-6989586621679728992"><span class="hs-identifier hs-type">tensorParameters</span></a></span></span><span>
</span><span id="line-577"></span><span>       </span><span id="local-6989586621679728995"><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-578"></span><span>       </span><span id="local-6989586621679728994"><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-579"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-580"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-581"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-582"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-583"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNShapeOrder"><span class="hs-identifier hs-type">KnownRNNShapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729002"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span>
</span><span id="line-584"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNDirectionality"><span class="hs-identifier hs-type">KnownRNNDirectionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-585"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729001"><span class="hs-identifier hs-type">outputSize</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-586"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729000"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729002"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728999"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728998"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-587"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728997"><span class="hs-identifier hs-type">outputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729002"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728999"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729001"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-588"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-589"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728998"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728993"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-590"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728992"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR"><span class="hs-identifier hs-type">LSTMR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728998"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-591"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728992"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-592"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-type">ToDependent</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728993"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728992"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span>
</span><span id="line-593"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-594"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span>
</span><span id="line-595"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span>
</span><span id="line-596"></span><span>       </span><span class="annot"><a href="#local-6989586621679728998"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-597"></span><span>       </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-598"></span><span>       </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-599"></span><span>       </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-600"></span><span>       </span><span class="annot"><a href="#local-6989586621679728991"><span class="hs-identifier hs-type">initialization</span></a></span><span>
</span><span id="line-601"></span><span>       </span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-602"></span><span>       </span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-603"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729000"><span class="hs-identifier hs-type">inputShape</span></a></span><span>
</span><span id="line-604"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728997"><span class="hs-identifier hs-type">outputShape</span></a></span><span>
</span><span id="line-605"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-606"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-607"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-608"></span><span id="lstm"><span class="annot"><span class="annottext">lstm :: Bool
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     initialization
     dtype
     device
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm"><span class="hs-identifier hs-var hs-var">lstm</span></a></span></span><span> </span><span id="local-6989586621679728457"><span class="annot"><span class="annottext">dropoutOn :: Bool
</span><a href="#local-6989586621679728457"><span class="hs-identifier hs-var">dropoutOn</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithConstInit"><span class="hs-identifier hs-type">LSTMWithConstInit</span></a></span><span> </span><span id="local-6989586621679728456"><span class="annot"><span class="annottext">lstm :: LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728456"><span class="hs-identifier hs-var">lstm</span></a></span></span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span id="local-6989586621679728454"><span class="annot"><span class="annottext">dropoutProb :: Double
</span><a href="#local-6989586621679728454"><span class="hs-identifier hs-var">dropoutProb</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679728453"><span class="annot"><span class="annottext">cc :: Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728453"><span class="hs-identifier hs-var">cc</span></a></span></span><span> </span><span id="local-6989586621679728452"><span class="annot"><span class="annottext">hc :: Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728452"><span class="hs-identifier hs-var">hc</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679728451"><span class="annot"><span class="annottext">input :: Tensor device dtype inputShape
</span><a href="#local-6989586621679728451"><span class="hs-identifier hs-var">input</span></a></span></span><span>
</span><span id="line-609"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList tensorParameters
-&gt; Double
-&gt; Bool
-&gt; (Tensor device dtype hxShape, Tensor device dtype hxShape)
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
forall k (shapeOrder :: RNNShapeOrder)
       (directionality :: RNNDirectionality) (numLayers :: Nat)
       (seqLen :: Nat) (batchSize :: Nat) (inputSize :: Nat)
       (outputSize :: Nat) (hiddenSize :: Nat) (inputShape :: [Nat])
       (outputShape :: [Nat]) (hxShape :: [Nat]) (tensorParameters :: [k])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat numLayers, KnownRNNShapeOrder shapeOrder,
 KnownRNNDirectionality directionality,
 outputSize ~ (hiddenSize * NumberOfDirections directionality),
 inputShape ~ RNNShape shapeOrder seqLen batchSize inputSize,
 outputShape ~ RNNShape shapeOrder seqLen batchSize outputSize,
 hxShape
 ~ '[numLayers * NumberOfDirections directionality, batchSize,
     hiddenSize],
 tensorParameters
 ~ LSTMR inputSize hiddenSize numLayers directionality dtype device,
 Castable (HList tensorParameters) [ATenTensor]) =&gt;
HList tensorParameters
-&gt; Double
-&gt; Bool
-&gt; (Tensor device dtype hxShape, Tensor device dtype hxShape)
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.Functional.html#lstm"><span class="hs-identifier hs-var">Torch.Typed.Functional.lstm</span></a></span><span>
</span><span id="line-610"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729002"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span>
</span><span id="line-611"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-612"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-613"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728999"><span class="hs-identifier hs-type">seqLen</span></a></span><span>
</span><span id="line-614"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-615"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728998"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-616"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729001"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-617"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-618"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729000"><span class="hs-identifier hs-type">inputShape</span></a></span><span>
</span><span id="line-619"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728997"><span class="hs-identifier hs-type">outputShape</span></a></span><span>
</span><span id="line-620"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-621"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728992"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span>
</span><span id="line-622"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-623"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-624"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ToDependent -&gt; HList parameters -&gt; HList tensorParameters
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ToDependent
</span><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-var">ToDependent</span></a></span><span> </span><span class="annot"><span class="annottext">(HList parameters -&gt; HList tensorParameters)
-&gt; (LSTM inputSize hiddenSize numLayers directionality dtype device
    -&gt; HList parameters)
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; HList tensorParameters
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; HList parameters
forall f (as :: [Type]). Parameterized f as =&gt; f -&gt; HList as
</span><a href="Torch.Typed.Parameter.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">(LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; HList tensorParameters)
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; HList tensorParameters
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728456"><span class="hs-identifier hs-var">lstm</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-625"></span><span>    </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679728454"><span class="hs-identifier hs-var">dropoutProb</span></a></span><span>
</span><span id="line-626"></span><span>    </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679728457"><span class="hs-identifier hs-var">dropoutOn</span></a></span><span>
</span><span id="line-627"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679728445"><span class="hs-identifier hs-var">cc'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679728444"><span class="hs-identifier hs-var">hc'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-628"></span><span>    </span><span class="annot"><span class="annottext">Tensor device dtype inputShape
</span><a href="#local-6989586621679728451"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-629"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-630"></span><span>  </span><span id="local-6989586621679728445"><span class="annot"><span class="annottext">cc' :: Tensor device dtype hxShape
</span><a href="#local-6989586621679728445"><span class="hs-identifier hs-var hs-var">cc'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-631"></span><span>    </span><span class="annot"><span class="annottext">forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', Numel shape ~ Numel shape') =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape hxShape, Numel shape ~ Numel hxShape) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype hxShape
</span><a href="Torch.Typed.Tensor.html#reshape"><span class="hs-identifier hs-var">reshape</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-632"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[batchSize, numLayers * NumberOfDirections directionality,
     hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; (Tensor
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
    -&gt; Tensor
         device
         dtype
         '[batchSize, numLayers * NumberOfDirections directionality,
           hiddenSize])
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Bool
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[batchSize, numLayers * NumberOfDirections directionality,
       hiddenSize]
forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', shape' ~ Broadcast shape shape') =&gt;
Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#expand"><span class="hs-identifier hs-var">expand</span></a></span><span>
</span><span id="line-633"></span><span>          </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-634"></span><span>          </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="hs-comment">-- TODO: What does the bool do?</span><span>
</span><span id="line-635"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728453"><span class="hs-identifier hs-var">cc</span></a></span><span>
</span><span id="line-636"></span><span>  </span><span id="local-6989586621679728444"><span class="annot"><span class="annottext">hc' :: Tensor device dtype hxShape
</span><a href="#local-6989586621679728444"><span class="hs-identifier hs-var hs-var">hc'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-637"></span><span>    </span><span class="annot"><span class="annottext">forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', Numel shape ~ Numel shape') =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape hxShape, Numel shape ~ Numel hxShape) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype hxShape
</span><a href="Torch.Typed.Tensor.html#reshape"><span class="hs-identifier hs-var">reshape</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-638"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[batchSize, numLayers * NumberOfDirections directionality,
     hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; (Tensor
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
    -&gt; Tensor
         device
         dtype
         '[batchSize, numLayers * NumberOfDirections directionality,
           hiddenSize])
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Bool
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[batchSize, numLayers * NumberOfDirections directionality,
       hiddenSize]
forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', shape' ~ Broadcast shape shape') =&gt;
Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#expand"><span class="hs-identifier hs-var">expand</span></a></span><span>
</span><span id="line-639"></span><span>          </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-640"></span><span>          </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="hs-comment">-- TODO: What does the bool do?</span><span>
</span><span id="line-641"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728452"><span class="hs-identifier hs-var">hc</span></a></span><span>
</span><span id="line-642"></span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm"><span class="hs-identifier hs-var">lstm</span></a></span><span> </span><span id="local-6989586621679728441"><span class="annot"><span class="annottext">dropoutOn :: Bool
</span><a href="#local-6989586621679728441"><span class="hs-identifier hs-var">dropoutOn</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithLearnedInit"><span class="hs-identifier hs-type">LSTMWithLearnedInit</span></a></span><span> </span><span id="local-6989586621679728440"><span class="annot"><span class="annottext">lstm :: LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728440"><span class="hs-identifier hs-var">lstm</span></a></span></span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="hs-identifier">_</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span id="local-6989586621679728439"><span class="annot"><span class="annottext">dropoutProb :: Double
</span><a href="#local-6989586621679728439"><span class="hs-identifier hs-var">dropoutProb</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679728438"><span class="annot"><span class="annottext">cc :: Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728438"><span class="hs-identifier hs-var">cc</span></a></span></span><span> </span><span id="local-6989586621679728437"><span class="annot"><span class="annottext">hc :: Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728437"><span class="hs-identifier hs-var">hc</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679728436"><span class="annot"><span class="annottext">input :: Tensor device dtype inputShape
</span><a href="#local-6989586621679728436"><span class="hs-identifier hs-var">input</span></a></span></span><span>
</span><span id="line-643"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList tensorParameters
-&gt; Double
-&gt; Bool
-&gt; (Tensor device dtype hxShape, Tensor device dtype hxShape)
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
forall k (shapeOrder :: RNNShapeOrder)
       (directionality :: RNNDirectionality) (numLayers :: Nat)
       (seqLen :: Nat) (batchSize :: Nat) (inputSize :: Nat)
       (outputSize :: Nat) (hiddenSize :: Nat) (inputShape :: [Nat])
       (outputShape :: [Nat]) (hxShape :: [Nat]) (tensorParameters :: [k])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat numLayers, KnownRNNShapeOrder shapeOrder,
 KnownRNNDirectionality directionality,
 outputSize ~ (hiddenSize * NumberOfDirections directionality),
 inputShape ~ RNNShape shapeOrder seqLen batchSize inputSize,
 outputShape ~ RNNShape shapeOrder seqLen batchSize outputSize,
 hxShape
 ~ '[numLayers * NumberOfDirections directionality, batchSize,
     hiddenSize],
 tensorParameters
 ~ LSTMR inputSize hiddenSize numLayers directionality dtype device,
 Castable (HList tensorParameters) [ATenTensor]) =&gt;
HList tensorParameters
-&gt; Double
-&gt; Bool
-&gt; (Tensor device dtype hxShape, Tensor device dtype hxShape)
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.Functional.html#lstm"><span class="hs-identifier hs-var">Torch.Typed.Functional.lstm</span></a></span><span>
</span><span id="line-644"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729002"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span>
</span><span id="line-645"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-646"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-647"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728999"><span class="hs-identifier hs-type">seqLen</span></a></span><span>
</span><span id="line-648"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-649"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728998"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-650"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729001"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-651"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-652"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679729000"><span class="hs-identifier hs-type">inputShape</span></a></span><span>
</span><span id="line-653"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728997"><span class="hs-identifier hs-type">outputShape</span></a></span><span>
</span><span id="line-654"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-655"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728992"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span>
</span><span id="line-656"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728995"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-657"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728994"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-658"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ToDependent -&gt; HList parameters -&gt; HList tensorParameters
forall k f (xs :: [k]) (ys :: [k]).
HMap' f xs ys =&gt;
f -&gt; HList xs -&gt; HList ys
</span><a href="Torch.HList.html#hmap%27"><span class="hs-identifier hs-var">hmap'</span></a></span><span> </span><span class="annot"><span class="annottext">ToDependent
</span><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-var">ToDependent</span></a></span><span> </span><span class="annot"><span class="annottext">(HList parameters -&gt; HList tensorParameters)
-&gt; (LSTM inputSize hiddenSize numLayers directionality dtype device
    -&gt; HList parameters)
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; HList tensorParameters
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; HList parameters
forall f (as :: [Type]). Parameterized f as =&gt; f -&gt; HList as
</span><a href="Torch.Typed.Parameter.html#flattenParameters"><span class="hs-identifier hs-var">flattenParameters</span></a></span><span> </span><span class="annot"><span class="annottext">(LSTM inputSize hiddenSize numLayers directionality dtype device
 -&gt; HList tensorParameters)
-&gt; LSTM inputSize hiddenSize numLayers directionality dtype device
-&gt; HList tensorParameters
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LSTM inputSize hiddenSize numLayers directionality dtype device
</span><a href="#local-6989586621679728440"><span class="hs-identifier hs-var">lstm</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-659"></span><span>    </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679728439"><span class="hs-identifier hs-var">dropoutProb</span></a></span><span>
</span><span id="line-660"></span><span>    </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679728441"><span class="hs-identifier hs-var">dropoutOn</span></a></span><span>
</span><span id="line-661"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679728435"><span class="hs-identifier hs-var">cc'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor device dtype hxShape
</span><a href="#local-6989586621679728434"><span class="hs-identifier hs-var">hc'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-662"></span><span>    </span><span class="annot"><span class="annottext">Tensor device dtype inputShape
</span><a href="#local-6989586621679728436"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-663"></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-664"></span><span>  </span><span id="local-6989586621679728435"><span class="annot"><span class="annottext">cc' :: Tensor device dtype hxShape
</span><a href="#local-6989586621679728435"><span class="hs-identifier hs-var hs-var">cc'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-665"></span><span>    </span><span class="annot"><span class="annottext">forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', Numel shape ~ Numel shape') =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape hxShape, Numel shape ~ Numel hxShape) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype hxShape
</span><a href="Torch.Typed.Tensor.html#reshape"><span class="hs-identifier hs-var">reshape</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-666"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[batchSize, numLayers * NumberOfDirections directionality,
     hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; (Parameter
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
    -&gt; Tensor
         device
         dtype
         '[batchSize, numLayers * NumberOfDirections directionality,
           hiddenSize])
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Bool
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[batchSize, numLayers * NumberOfDirections directionality,
       hiddenSize]
forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', shape' ~ Broadcast shape shape') =&gt;
Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#expand"><span class="hs-identifier hs-var">expand</span></a></span><span>
</span><span id="line-667"></span><span>          </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-668"></span><span>          </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="hs-comment">-- TODO: What does the bool do?</span><span>
</span><span id="line-669"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor
      device
      dtype
      '[batchSize, numLayers * NumberOfDirections directionality,
        hiddenSize])
-&gt; (Parameter
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
    -&gt; Tensor
         device
         dtype
         '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[batchSize, numLayers * NumberOfDirections directionality,
       hiddenSize]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Parameter device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Parameter.html#toDependent"><span class="hs-identifier hs-var">toDependent</span></a></span><span>
</span><span id="line-670"></span><span>      </span><span class="annot"><span class="annottext">(Parameter
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728438"><span class="hs-identifier hs-var">cc</span></a></span><span>
</span><span id="line-671"></span><span>  </span><span id="local-6989586621679728434"><span class="annot"><span class="annottext">hc' :: Tensor device dtype hxShape
</span><a href="#local-6989586621679728434"><span class="hs-identifier hs-var hs-var">hc'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-672"></span><span>    </span><span class="annot"><span class="annottext">forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', Numel shape ~ Numel shape') =&gt;
Tensor device dtype shape -&gt; Tensor device dtype shape'
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape hxShape, Numel shape ~ Numel hxShape) =&gt;
Tensor device dtype shape -&gt; Tensor device dtype hxShape
</span><a href="Torch.Typed.Tensor.html#reshape"><span class="hs-identifier hs-var">reshape</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728996"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-673"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[batchSize, numLayers * NumberOfDirections directionality,
     hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; (Parameter
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
    -&gt; Tensor
         device
         dtype
         '[batchSize, numLayers * NumberOfDirections directionality,
           hiddenSize])
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Bool
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[batchSize, numLayers * NumberOfDirections directionality,
       hiddenSize]
forall (shape' :: [Nat]) (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
(KnownShape shape', shape' ~ Broadcast shape shape') =&gt;
Bool -&gt; Tensor device dtype shape -&gt; Tensor device dtype shape'
</span><a href="Torch.Typed.Functional.html#expand"><span class="hs-identifier hs-var">expand</span></a></span><span>
</span><span id="line-674"></span><span>          </span><span class="hs-glyph">@</span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679729004"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729005"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679729006"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679729003"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-675"></span><span>          </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span> </span><span class="hs-comment">-- TODO: What does the bool do?</span><span>
</span><span id="line-676"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor
      device
      dtype
      '[batchSize, numLayers * NumberOfDirections directionality,
        hiddenSize])
-&gt; (Parameter
      device
      dtype
      '[numLayers * NumberOfDirections directionality, hiddenSize]
    -&gt; Tensor
         device
         dtype
         '[numLayers * NumberOfDirections directionality, hiddenSize])
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[batchSize, numLayers * NumberOfDirections directionality,
       hiddenSize]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
forall (shape :: [Nat]) (dtype :: DType)
       (device :: (DeviceType, Nat)).
Parameter device dtype shape -&gt; Tensor device dtype shape
</span><a href="Torch.Typed.Parameter.html#toDependent"><span class="hs-identifier hs-var">toDependent</span></a></span><span>
</span><span id="line-677"></span><span>      </span><span class="annot"><span class="annottext">(Parameter
   device
   dtype
   '[numLayers * NumberOfDirections directionality, hiddenSize]
 -&gt; Tensor device dtype hxShape)
-&gt; Parameter
     device
     dtype
     '[numLayers * NumberOfDirections directionality, hiddenSize]
-&gt; Tensor device dtype hxShape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Parameter
  device
  dtype
  '[numLayers * NumberOfDirections directionality, hiddenSize]
</span><a href="#local-6989586621679728437"><span class="hs-identifier hs-var">hc</span></a></span><span>
</span><span id="line-678"></span><span>
</span><span id="line-679"></span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithDropout"><span class="hs-identifier hs-type">lstmWithDropout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithoutDropout"><span class="hs-identifier hs-type">lstmWithoutDropout</span></a></span><span>
</span><span id="line-680"></span><span>  </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span>
</span><span id="line-681"></span><span>       </span><span id="local-6989586621679728430"><span class="annot"><a href="#local-6989586621679728430"><span class="hs-identifier hs-type">shapeOrder</span></a></span></span><span>
</span><span id="line-682"></span><span>       </span><span id="local-6989586621679728429"><span class="annot"><a href="#local-6989586621679728429"><span class="hs-identifier hs-type">batchSize</span></a></span></span><span>
</span><span id="line-683"></span><span>       </span><span id="local-6989586621679728428"><span class="annot"><a href="#local-6989586621679728428"><span class="hs-identifier hs-type">seqLen</span></a></span></span><span>
</span><span id="line-684"></span><span>       </span><span id="local-6989586621679728427"><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span></span><span>
</span><span id="line-685"></span><span>       </span><span id="local-6989586621679728426"><span class="annot"><a href="#local-6989586621679728426"><span class="hs-identifier hs-type">initialization</span></a></span></span><span>
</span><span id="line-686"></span><span>       </span><span id="local-6989586621679728425"><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span>
</span><span id="line-687"></span><span>       </span><span id="local-6989586621679728424"><span class="annot"><a href="#local-6989586621679728424"><span class="hs-identifier hs-type">inputSize</span></a></span></span><span>
</span><span id="line-688"></span><span>       </span><span id="local-6989586621679728423"><span class="annot"><a href="#local-6989586621679728423"><span class="hs-identifier hs-type">outputSize</span></a></span></span><span>
</span><span id="line-689"></span><span>       </span><span id="local-6989586621679728422"><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span></span><span>
</span><span id="line-690"></span><span>       </span><span id="local-6989586621679728421"><span class="annot"><a href="#local-6989586621679728421"><span class="hs-identifier hs-type">inputShape</span></a></span></span><span>
</span><span id="line-691"></span><span>       </span><span id="local-6989586621679728420"><span class="annot"><a href="#local-6989586621679728420"><span class="hs-identifier hs-type">outputShape</span></a></span></span><span>
</span><span id="line-692"></span><span>       </span><span id="local-6989586621679728419"><span class="annot"><a href="#local-6989586621679728419"><span class="hs-identifier hs-type">hxShape</span></a></span></span><span>
</span><span id="line-693"></span><span>       </span><span id="local-6989586621679728418"><span class="annot"><a href="#local-6989586621679728418"><span class="hs-identifier hs-type">parameters</span></a></span></span><span>
</span><span id="line-694"></span><span>       </span><span id="local-6989586621679728417"><span class="annot"><a href="#local-6989586621679728417"><span class="hs-identifier hs-type">tensorParameters</span></a></span></span><span>
</span><span id="line-695"></span><span>       </span><span id="local-6989586621679728416"><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span></span><span>
</span><span id="line-696"></span><span>       </span><span id="local-6989586621679728415"><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span></span><span>
</span><span id="line-697"></span><span>   </span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-698"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-699"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728429"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-700"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-701"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNShapeOrder"><span class="hs-identifier hs-type">KnownRNNShapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728430"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span>
</span><span id="line-702"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#KnownRNNDirectionality"><span class="hs-identifier hs-type">KnownRNNDirectionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-703"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728423"><span class="hs-identifier hs-type">outputSize</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-704"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728421"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728430"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728428"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728429"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728424"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-705"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728420"><span class="hs-identifier hs-type">outputShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#RNNShape"><span class="hs-identifier hs-type">RNNShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728430"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728428"><span class="hs-identifier hs-type">seqLen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728429"><span class="hs-identifier hs-type">batchSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728423"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-706"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728419"><span class="hs-identifier hs-type">hxShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">*</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#NumberOfDirections"><span class="hs-identifier hs-type">NumberOfDirections</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728429"><span class="hs-identifier hs-type">batchSize</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-707"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#Parameterized"><span class="hs-identifier hs-type">Parameterized</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTM"><span class="hs-identifier hs-type">LSTM</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728424"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728418"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-708"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728417"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.Typed.Functional.html#LSTMR"><span class="hs-identifier hs-type">LSTMR</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728424"><span class="hs-identifier hs-type">inputSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-709"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.HList.html#HList"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728417"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.Tensor.html#ATenTensor"><span class="hs-identifier hs-type">D.ATenTensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-710"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.HList.html#HMap%27"><span class="hs-identifier hs-type">HMap'</span></a></span><span> </span><span class="annot"><a href="Torch.Typed.Parameter.html#ToDependent"><span class="hs-identifier hs-type">ToDependent</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728418"><span class="hs-identifier hs-type">parameters</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728417"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span>
</span><span id="line-711"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-712"></span><span>  </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.NN.Recurrent.LSTM.html#LSTMWithInit"><span class="hs-identifier hs-type">LSTMWithInit</span></a></span><span>
</span><span id="line-713"></span><span>       </span><span class="annot"><a href="#local-6989586621679728424"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-714"></span><span>       </span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-715"></span><span>       </span><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-716"></span><span>       </span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-717"></span><span>       </span><span class="annot"><a href="#local-6989586621679728426"><span class="hs-identifier hs-type">initialization</span></a></span><span>
</span><span id="line-718"></span><span>       </span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-719"></span><span>       </span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-720"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728421"><span class="hs-identifier hs-type">inputShape</span></a></span><span>
</span><span id="line-721"></span><span>  </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728420"><span class="hs-identifier hs-type">outputShape</span></a></span><span>
</span><span id="line-722"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728419"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-723"></span><span>     </span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.Typed.Tensor.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728419"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-724"></span><span>     </span><span class="hs-special">)</span><span>
</span><span id="line-725"></span><span class="hs-comment">-- ^ Forward propagate the `LSTM` module and apply dropout on the outputs of each layer.</span><span>
</span><span id="line-726"></span><span class="hs-comment">--</span><span>
</span><span id="line-727"></span><span class="hs-comment">-- &gt;&gt;&gt; input :: CPUTensor 'D.Float '[5,16,10] &lt;- randn</span><span>
</span><span id="line-728"></span><span class="hs-comment">-- &gt;&gt;&gt; spec = LSTMWithZerosInitSpec @10 @30 @3 @'Bidirectional @'D.Float @'( 'D.CPU, 0) (LSTMSpec (DropoutSpec 0.5))</span><span>
</span><span id="line-729"></span><span class="hs-comment">-- &gt;&gt;&gt; model &lt;- A.sample spec</span><span>
</span><span id="line-730"></span><span class="hs-comment">-- &gt;&gt;&gt; :t lstmWithDropout @'BatchFirst model input</span><span>
</span><span id="line-731"></span><span class="hs-comment">-- lstmWithDropout @'BatchFirst model input</span><span>
</span><span id="line-732"></span><span class="hs-comment">--   :: (Tensor '( 'D.CPU, 0) 'D.Float '[5, 16, 60],</span><span>
</span><span id="line-733"></span><span class="hs-comment">--       Tensor '( 'D.CPU, 0) 'D.Float '[6, 5, 30],</span><span>
</span><span id="line-734"></span><span class="hs-comment">--       Tensor '( 'D.CPU, 0) 'D.Float '[6, 5, 30])</span><span>
</span><span id="line-735"></span><span class="hs-comment">-- &gt;&gt;&gt; lstmWithDropout @'BatchFirst model input</span><span>
</span><span id="line-736"></span><span class="hs-comment">-- (Tensor Float [5,16,60] ,Tensor Float [6,5,30] ,Tensor Float [6,5,30] )</span><span>
</span><span id="line-737"></span><span id="lstmWithDropout"><span class="annot"><span class="annottext">lstmWithDropout :: LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  initialization
  dtype
  device
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithDropout"><span class="hs-identifier hs-var hs-var">lstmWithDropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-738"></span><span>  </span><span class="annot"><span class="annottext">Bool
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     initialization
     dtype
     device
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
forall (shapeOrder :: RNNShapeOrder) (batchSize :: Nat)
       (seqLen :: Nat) (directionality :: RNNDirectionality)
       (initialization :: RNNInitialization) (numLayers :: Nat)
       (inputSize :: Nat) (outputSize :: Nat) (hiddenSize :: Nat)
       (inputShape :: [Nat]) (outputShape :: [Nat]) (hxShape :: [Nat])
       (parameters :: [Type]) (tensorParameters :: [Type])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat (NumberOfDirections directionality), KnownNat numLayers,
 KnownNat batchSize, KnownNat hiddenSize,
 KnownRNNShapeOrder shapeOrder,
 KnownRNNDirectionality directionality,
 outputSize ~ (hiddenSize * NumberOfDirections directionality),
 inputShape ~ RNNShape shapeOrder seqLen batchSize inputSize,
 outputShape ~ RNNShape shapeOrder seqLen batchSize outputSize,
 hxShape
 ~ '[numLayers * NumberOfDirections directionality, batchSize,
     hiddenSize],
 Parameterized
   (LSTM inputSize hiddenSize numLayers directionality dtype device)
   parameters,
 tensorParameters
 ~ LSTMR inputSize hiddenSize numLayers directionality dtype device,
 Castable (HList tensorParameters) [ATenTensor],
 HMap' ToDependent parameters tensorParameters) =&gt;
Bool
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     initialization
     dtype
     device
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm"><span class="hs-identifier hs-var">Torch.Typed.NN.Recurrent.LSTM.lstm</span></a></span><span>
</span><span id="line-739"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728430"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span>
</span><span id="line-740"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728429"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-741"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728428"><span class="hs-identifier hs-type">seqLen</span></a></span><span>
</span><span id="line-742"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-743"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728426"><span class="hs-identifier hs-type">initialization</span></a></span><span>
</span><span id="line-744"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-745"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728424"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-746"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728423"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-747"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-748"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728421"><span class="hs-identifier hs-type">inputShape</span></a></span><span>
</span><span id="line-749"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728420"><span class="hs-identifier hs-type">outputShape</span></a></span><span>
</span><span id="line-750"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728419"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-751"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728418"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-752"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728417"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span>
</span><span id="line-753"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-754"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-755"></span><span>    </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-756"></span><span class="hs-comment">-- ^ Forward propagate the `LSTM` module (without applying dropout on the outputs of each layer).</span><span>
</span><span id="line-757"></span><span class="hs-comment">--</span><span>
</span><span id="line-758"></span><span class="hs-comment">-- &gt;&gt;&gt; input :: CPUTensor 'D.Float '[5,16,10] &lt;- randn</span><span>
</span><span id="line-759"></span><span class="hs-comment">-- &gt;&gt;&gt; spec = LSTMWithZerosInitSpec @10 @30 @3 @'Bidirectional @'D.Float @'( 'D.CPU, 0) (LSTMSpec (DropoutSpec 0.5))</span><span>
</span><span id="line-760"></span><span class="hs-comment">-- &gt;&gt;&gt; model &lt;- A.sample spec</span><span>
</span><span id="line-761"></span><span class="hs-comment">-- &gt;&gt;&gt; :t lstmWithoutDropout @'BatchFirst model input</span><span>
</span><span id="line-762"></span><span class="hs-comment">-- lstmWithoutDropout @'BatchFirst model input</span><span>
</span><span id="line-763"></span><span class="hs-comment">--   :: (Tensor '( 'D.CPU, 0) 'D.Float '[5, 16, 60],</span><span>
</span><span id="line-764"></span><span class="hs-comment">--       Tensor '( 'D.CPU, 0) 'D.Float '[6, 5, 30],</span><span>
</span><span id="line-765"></span><span class="hs-comment">--       Tensor '( 'D.CPU, 0) 'D.Float '[6, 5, 30])</span><span>
</span><span id="line-766"></span><span class="hs-comment">-- &gt;&gt;&gt; lstmWithoutDropout @'BatchFirst model input</span><span>
</span><span id="line-767"></span><span class="hs-comment">-- (Tensor Float [5,16,60] ,Tensor Float [6,5,30] ,Tensor Float [6,5,30] )</span><span>
</span><span id="line-768"></span><span id="lstmWithoutDropout"><span class="annot"><span class="annottext">lstmWithoutDropout :: LSTMWithInit
  inputSize
  hiddenSize
  numLayers
  directionality
  initialization
  dtype
  device
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstmWithoutDropout"><span class="hs-identifier hs-var hs-var">lstmWithoutDropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-769"></span><span>  </span><span class="annot"><span class="annottext">Bool
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     initialization
     dtype
     device
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
forall (shapeOrder :: RNNShapeOrder) (batchSize :: Nat)
       (seqLen :: Nat) (directionality :: RNNDirectionality)
       (initialization :: RNNInitialization) (numLayers :: Nat)
       (inputSize :: Nat) (outputSize :: Nat) (hiddenSize :: Nat)
       (inputShape :: [Nat]) (outputShape :: [Nat]) (hxShape :: [Nat])
       (parameters :: [Type]) (tensorParameters :: [Type])
       (dtype :: DType) (device :: (DeviceType, Nat)).
(KnownNat (NumberOfDirections directionality), KnownNat numLayers,
 KnownNat batchSize, KnownNat hiddenSize,
 KnownRNNShapeOrder shapeOrder,
 KnownRNNDirectionality directionality,
 outputSize ~ (hiddenSize * NumberOfDirections directionality),
 inputShape ~ RNNShape shapeOrder seqLen batchSize inputSize,
 outputShape ~ RNNShape shapeOrder seqLen batchSize outputSize,
 hxShape
 ~ '[numLayers * NumberOfDirections directionality, batchSize,
     hiddenSize],
 Parameterized
   (LSTM inputSize hiddenSize numLayers directionality dtype device)
   parameters,
 tensorParameters
 ~ LSTMR inputSize hiddenSize numLayers directionality dtype device,
 Castable (HList tensorParameters) [ATenTensor],
 HMap' ToDependent parameters tensorParameters) =&gt;
Bool
-&gt; LSTMWithInit
     inputSize
     hiddenSize
     numLayers
     directionality
     initialization
     dtype
     device
-&gt; Tensor device dtype inputShape
-&gt; (Tensor device dtype outputShape, Tensor device dtype hxShape,
    Tensor device dtype hxShape)
</span><a href="Torch.Typed.NN.Recurrent.LSTM.html#lstm"><span class="hs-identifier hs-var">Torch.Typed.NN.Recurrent.LSTM.lstm</span></a></span><span>
</span><span id="line-770"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728430"><span class="hs-identifier hs-type">shapeOrder</span></a></span><span>
</span><span id="line-771"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728429"><span class="hs-identifier hs-type">batchSize</span></a></span><span>
</span><span id="line-772"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728428"><span class="hs-identifier hs-type">seqLen</span></a></span><span>
</span><span id="line-773"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728427"><span class="hs-identifier hs-type">directionality</span></a></span><span>
</span><span id="line-774"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728426"><span class="hs-identifier hs-type">initialization</span></a></span><span>
</span><span id="line-775"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728425"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-776"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728424"><span class="hs-identifier hs-type">inputSize</span></a></span><span>
</span><span id="line-777"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728423"><span class="hs-identifier hs-type">outputSize</span></a></span><span>
</span><span id="line-778"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728422"><span class="hs-identifier hs-type">hiddenSize</span></a></span><span>
</span><span id="line-779"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728421"><span class="hs-identifier hs-type">inputShape</span></a></span><span>
</span><span id="line-780"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728420"><span class="hs-identifier hs-type">outputShape</span></a></span><span>
</span><span id="line-781"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728419"><span class="hs-identifier hs-type">hxShape</span></a></span><span>
</span><span id="line-782"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728418"><span class="hs-identifier hs-type">parameters</span></a></span><span>
</span><span id="line-783"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728417"><span class="hs-identifier hs-type">tensorParameters</span></a></span><span>
</span><span id="line-784"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728416"><span class="hs-identifier hs-type">dtype</span></a></span><span>
</span><span id="line-785"></span><span>    </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679728415"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-786"></span><span>    </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-787"></span></pre></body></html>