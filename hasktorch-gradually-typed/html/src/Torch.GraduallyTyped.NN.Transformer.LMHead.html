<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-17"></span><span>
</span><span id="line-18"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.LMHead</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Activation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier">Gelu</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Linear</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#Linear"><span class="hs-identifier">Linear</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#LinearSpec"><span class="hs-identifier">LinearSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier">sGeneratorToDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier">sZeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar"><span class="hs-identifier">divScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span>
</span><span id="line-46"></span><span class="hs-keyword">data</span><span>
</span><span id="line-47"></span><span>  </span><span id="GLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span></span><span>
</span><span id="line-48"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806779"><span class="annot"><a href="#local-6989586621679806779"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806778"><span class="annot"><a href="#local-6989586621679806778"><span class="hs-identifier hs-type">dense</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806777"><span class="annot"><a href="#local-6989586621679806777"><span class="hs-identifier hs-type">activation</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806776"><span class="annot"><a href="#local-6989586621679806776"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806775"><span class="annot"><a href="#local-6989586621679806775"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806774"><span class="annot"><a href="#local-6989586621679806774"><span class="hs-identifier hs-type">bias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-55"></span><span>  </span><span id="GLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-56"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679806924"><span class="annot"><a href="#local-6989586621679806924"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806923"><span class="annot"><a href="#local-6989586621679806923"><span class="hs-identifier hs-type">dense</span></a></span></span><span> </span><span id="local-6989586621679806922"><span class="annot"><a href="#local-6989586621679806922"><span class="hs-identifier hs-type">activation</span></a></span></span><span> </span><span id="local-6989586621679806921"><span class="annot"><a href="#local-6989586621679806921"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679806920"><span class="annot"><a href="#local-6989586621679806920"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span id="local-6989586621679806919"><span class="annot"><a href="#local-6989586621679806919"><span class="hs-identifier hs-type">bias</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-57"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="lmHeadInputEmbedDim"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#lmHeadInputEmbedDim"><span class="hs-identifier hs-var hs-var">lmHeadInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806924"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-58"></span><span>      </span><span id="lmHeadDense"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#lmHeadDense"><span class="hs-identifier hs-var hs-var">lmHeadDense</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806923"><span class="hs-identifier hs-type">dense</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-59"></span><span>      </span><span id="lmHeadActivation"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#lmHeadActivation"><span class="hs-identifier hs-var hs-var">lmHeadActivation</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806922"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-60"></span><span>      </span><span id="lmHeadLayerNorm"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#lmHeadLayerNorm"><span class="hs-identifier hs-var hs-var">lmHeadLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806921"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-61"></span><span>      </span><span id="lmHeadDecoder"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#lmHeadDecoder"><span class="hs-identifier hs-var hs-var">lmHeadDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806920"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-62"></span><span>      </span><span id="lmHeadBias"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#lmHeadBias"><span class="hs-identifier hs-var hs-var">lmHeadBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806919"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-63"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-64"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806924"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806923"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806922"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806921"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806920"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806919"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-65"></span><span>
</span><span id="line-66"></span><span class="hs-comment">-- | Language modelling head for transformer encoders and decoders.</span><span>
</span><span id="line-67"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-68"></span><span>  </span><span id="LMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-var">LMHead</span></a></span></span><span>
</span><span id="line-69"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806766"><span class="annot"><a href="#local-6989586621679806766"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806765"><span class="annot"><a href="#local-6989586621679806765"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-71"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806764"><span class="annot"><a href="#local-6989586621679806764"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-72"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806763"><span class="annot"><a href="#local-6989586621679806763"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806762"><span class="annot"><a href="#local-6989586621679806762"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806761"><span class="annot"><a href="#local-6989586621679806761"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-76"></span><span>  </span><span id="LMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-var">LMHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679806893"><span class="annot"><a href="#local-6989586621679806893"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679806892"><span class="annot"><a href="#local-6989586621679806892"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806891"><span class="annot"><a href="#local-6989586621679806891"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806890"><span class="annot"><a href="#local-6989586621679806890"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806894"><span class="annot"><a href="#local-6989586621679806894"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806889"><span class="annot"><a href="#local-6989586621679806889"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-78"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span>
</span><span id="line-79"></span><span>      </span><span class="annot"><a href="#local-6989586621679806894"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-80"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806893"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806894"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-81"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806893"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806893"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806894"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806893"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806894"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806889"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806893"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806889"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-85"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806893"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806894"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806889"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-86"></span><span>
</span><span id="line-87"></span><span class="hs-keyword">data</span><span>
</span><span id="line-88"></span><span>  </span><span id="LMHeadSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-var">LMHeadSpec</span></a></span></span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806758"><span class="annot"><a href="#local-6989586621679806758"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806757"><span class="annot"><a href="#local-6989586621679806757"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-91"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806756"><span class="annot"><a href="#local-6989586621679806756"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-92"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806755"><span class="annot"><a href="#local-6989586621679806755"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806754"><span class="annot"><a href="#local-6989586621679806754"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806753"><span class="annot"><a href="#local-6989586621679806753"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-96"></span><span>  </span><span id="LMHeadSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-var">LMHeadSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679806751"><span class="annot"><a href="#local-6989586621679806751"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679806750"><span class="annot"><a href="#local-6989586621679806750"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806749"><span class="annot"><a href="#local-6989586621679806749"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806748"><span class="annot"><a href="#local-6989586621679806748"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806747"><span class="annot"><a href="#local-6989586621679806747"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806746"><span class="annot"><a href="#local-6989586621679806746"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-98"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806751"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-99"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806750"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-100"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806749"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-101"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806748"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-102"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806747"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-103"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806746"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-104"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-105"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-type">LMHeadSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806751"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806750"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806749"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806748"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806747"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806746"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-106"></span><span>
</span><span id="line-107"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span id="local-6989586621679806745"><span class="annot"><a href="#local-6989586621679806745"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679806744"><span class="annot"><a href="#local-6989586621679806744"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806743"><span class="annot"><a href="#local-6989586621679806743"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806742"><span class="annot"><a href="#local-6989586621679806742"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806741"><span class="annot"><a href="#local-6989586621679806741"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806740"><span class="annot"><a href="#local-6989586621679806740"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-type">LMHeadSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806745"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806744"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806743"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806742"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806741"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806740"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-108"></span><span>
</span><span id="line-109"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-110"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806739"><span class="annot"><a href="#local-6989586621679806739"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806738"><span class="annot"><a href="#local-6989586621679806738"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806737"><span class="annot"><a href="#local-6989586621679806737"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806736"><span class="annot"><a href="#local-6989586621679806736"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806735"><span class="annot"><a href="#local-6989586621679806735"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-116"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-117"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-118"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679806732"><span class="annot"><a href="#local-6989586621679806732"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806731"><span class="annot"><a href="#local-6989586621679806731"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806730"><span class="annot"><a href="#local-6989586621679806730"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806729"><span class="annot"><a href="#local-6989586621679806729"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806732"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806731"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806730"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806729"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-120"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679806726"><span class="annot"><a href="#local-6989586621679806726"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806725"><span class="annot"><a href="#local-6989586621679806725"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806724"><span class="annot"><a href="#local-6989586621679806724"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806723"><span class="annot"><a href="#local-6989586621679806723"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806726"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806725"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806724"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806723"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-122"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679806721"><span class="annot"><a href="#local-6989586621679806721"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806720"><span class="annot"><a href="#local-6989586621679806720"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806719"><span class="annot"><a href="#local-6989586621679806719"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806718"><span class="annot"><a href="#local-6989586621679806718"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806721"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806720"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806719"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806718"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-123"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679806716"><span class="annot"><a href="#local-6989586621679806716"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806715"><span class="annot"><a href="#local-6989586621679806715"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806714"><span class="annot"><a href="#local-6989586621679806714"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806713"><span class="annot"><a href="#local-6989586621679806713"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806716"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806715"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806714"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806713"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806713"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-124"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679806711"><span class="annot"><a href="#local-6989586621679806711"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806710"><span class="annot"><a href="#local-6989586621679806710"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806709"><span class="annot"><a href="#local-6989586621679806709"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806708"><span class="annot"><a href="#local-6989586621679806708"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806711"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806710"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806709"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806708"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-125"></span><span>
</span><span id="line-126"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-127"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span>
</span><span id="line-128"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806707"><span class="annot"><a href="#local-6989586621679806707"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-130"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-131"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-132"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span>
</span><span id="line-133"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span>
</span><span id="line-135"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span>
</span><span id="line-136"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-137"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span>
</span><span id="line-138"></span><span>
</span><span id="line-139"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-140"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span>
</span><span id="line-141"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806706"><span class="annot"><a href="#local-6989586621679806706"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806705"><span class="annot"><a href="#local-6989586621679806705"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806704"><span class="annot"><a href="#local-6989586621679806704"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806703"><span class="annot"><a href="#local-6989586621679806703"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806702"><span class="annot"><a href="#local-6989586621679806702"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-146"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-147"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-148"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679806701"><span class="annot"><a href="#local-6989586621679806701"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806700"><span class="annot"><a href="#local-6989586621679806700"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806699"><span class="annot"><a href="#local-6989586621679806699"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806698"><span class="annot"><a href="#local-6989586621679806698"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806701"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806700"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806699"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806698"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-150"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679806697"><span class="annot"><a href="#local-6989586621679806697"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806696"><span class="annot"><a href="#local-6989586621679806696"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806695"><span class="annot"><a href="#local-6989586621679806695"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806694"><span class="annot"><a href="#local-6989586621679806694"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806697"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806696"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806695"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806694"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-152"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679806693"><span class="annot"><a href="#local-6989586621679806693"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806692"><span class="annot"><a href="#local-6989586621679806692"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806691"><span class="annot"><a href="#local-6989586621679806691"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806690"><span class="annot"><a href="#local-6989586621679806690"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806693"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806692"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806691"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806690"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-153"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679806689"><span class="annot"><a href="#local-6989586621679806689"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806688"><span class="annot"><a href="#local-6989586621679806688"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806687"><span class="annot"><a href="#local-6989586621679806687"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806686"><span class="annot"><a href="#local-6989586621679806686"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806689"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806688"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806687"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679806686"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-154"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679806685"><span class="annot"><a href="#local-6989586621679806685"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806684"><span class="annot"><a href="#local-6989586621679806684"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806683"><span class="annot"><a href="#local-6989586621679806683"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806682"><span class="annot"><a href="#local-6989586621679806682"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806685"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806684"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806683"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806682"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-157"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span>
</span><span id="line-158"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806681"><span class="annot"><a href="#local-6989586621679806681"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-159"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806680"><span class="annot"><a href="#local-6989586621679806680"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806679"><span class="annot"><a href="#local-6989586621679806679"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806678"><span class="annot"><a href="#local-6989586621679806678"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806677"><span class="annot"><a href="#local-6989586621679806677"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806676"><span class="annot"><a href="#local-6989586621679806676"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-164"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-165"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-166"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679806675"><span class="annot"><a href="#local-6989586621679806675"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806674"><span class="annot"><a href="#local-6989586621679806674"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806673"><span class="annot"><a href="#local-6989586621679806673"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806672"><span class="annot"><a href="#local-6989586621679806672"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806671"><span class="annot"><a href="#local-6989586621679806671"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806675"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806674"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806673"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806672"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806671"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-167"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679806670"><span class="annot"><a href="#local-6989586621679806670"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806669"><span class="annot"><a href="#local-6989586621679806669"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806668"><span class="annot"><a href="#local-6989586621679806668"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806667"><span class="annot"><a href="#local-6989586621679806667"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806666"><span class="annot"><a href="#local-6989586621679806666"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806670"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806669"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806668"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806667"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806666"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-168"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679806665"><span class="annot"><a href="#local-6989586621679806665"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806664"><span class="annot"><a href="#local-6989586621679806664"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806663"><span class="annot"><a href="#local-6989586621679806663"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806662"><span class="annot"><a href="#local-6989586621679806662"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806661"><span class="annot"><a href="#local-6989586621679806661"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806665"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806663"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806662"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806661"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-169"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679806660"><span class="annot"><a href="#local-6989586621679806660"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806659"><span class="annot"><a href="#local-6989586621679806659"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806658"><span class="annot"><a href="#local-6989586621679806658"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806657"><span class="annot"><a href="#local-6989586621679806657"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806656"><span class="annot"><a href="#local-6989586621679806656"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806660"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806659"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806658"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806657"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806656"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-170"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679806655"><span class="annot"><a href="#local-6989586621679806655"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806654"><span class="annot"><a href="#local-6989586621679806654"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806653"><span class="annot"><a href="#local-6989586621679806653"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806652"><span class="annot"><a href="#local-6989586621679806652"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806651"><span class="annot"><a href="#local-6989586621679806651"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806655"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806654"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806653"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806652"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806651"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-171"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679806650"><span class="annot"><a href="#local-6989586621679806650"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806649"><span class="annot"><a href="#local-6989586621679806649"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806648"><span class="annot"><a href="#local-6989586621679806648"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806647"><span class="annot"><a href="#local-6989586621679806647"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806646"><span class="annot"><a href="#local-6989586621679806646"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#Linear"><span class="hs-identifier hs-type">Linear</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806650"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806649"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806648"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806647"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806646"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-172"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679806645"><span class="annot"><a href="#local-6989586621679806645"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806644"><span class="annot"><a href="#local-6989586621679806644"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806643"><span class="annot"><a href="#local-6989586621679806643"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806642"><span class="annot"><a href="#local-6989586621679806642"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806641"><span class="annot"><a href="#local-6989586621679806641"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806645"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806644"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806643"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806642"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806641"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-173"></span><span>
</span><span id="line-174"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-175"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span>
</span><span id="line-176"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806640"><span class="annot"><a href="#local-6989586621679806640"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806639"><span class="annot"><a href="#local-6989586621679806639"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806638"><span class="annot"><a href="#local-6989586621679806638"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806637"><span class="annot"><a href="#local-6989586621679806637"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806636"><span class="annot"><a href="#local-6989586621679806636"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-181"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-182"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-183"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-184"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679806635"><span class="annot"><a href="#local-6989586621679806635"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806634"><span class="annot"><a href="#local-6989586621679806634"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806633"><span class="annot"><a href="#local-6989586621679806633"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806632"><span class="annot"><a href="#local-6989586621679806632"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806635"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806634"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806633"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806632"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-185"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679806631"><span class="annot"><a href="#local-6989586621679806631"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806630"><span class="annot"><a href="#local-6989586621679806630"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806629"><span class="annot"><a href="#local-6989586621679806629"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806628"><span class="annot"><a href="#local-6989586621679806628"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806631"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679806630"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806629"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806628"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679806627"><span class="annot"><a href="#local-6989586621679806627"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806626"><span class="annot"><a href="#local-6989586621679806626"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806625"><span class="annot"><a href="#local-6989586621679806625"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806624"><span class="annot"><a href="#local-6989586621679806624"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806627"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806626"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806625"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806624"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-187"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679806623"><span class="annot"><a href="#local-6989586621679806623"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806622"><span class="annot"><a href="#local-6989586621679806622"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806621"><span class="annot"><a href="#local-6989586621679806621"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806620"><span class="annot"><a href="#local-6989586621679806620"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806623"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806622"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806621"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806620"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-188"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679806619"><span class="annot"><a href="#local-6989586621679806619"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806618"><span class="annot"><a href="#local-6989586621679806618"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806617"><span class="annot"><a href="#local-6989586621679806617"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806616"><span class="annot"><a href="#local-6989586621679806616"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806619"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806618"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806617"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806616"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-190"></span><span>
</span><span id="line-191"></span><span id="local-6989586621679806604"><span id="local-6989586621679806605"><span id="local-6989586621679806606"><span id="local-6989586621679806607"><span id="local-6989586621679806608"><span id="local-6989586621679806609"><span id="local-6989586621679806610"><span id="local-6989586621679806611"><span id="local-6989586621679806612"><span id="local-6989586621679806613"><span id="local-6989586621679806614"><span id="local-6989586621679806615"><span class="hs-keyword">instance</span><span>
</span><span id="line-192"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679806615"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806614"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806613"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806611"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806610"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806615"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806615"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-194"></span><span>    </span><span class="annot"><a href="#local-6989586621679806609"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806614"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-195"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806609"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806609"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-196"></span><span>    </span><span class="annot"><a href="#local-6989586621679806608"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806614"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806613"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806611"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806610"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-197"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806608"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806608"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-198"></span><span>    </span><span class="annot"><a href="#local-6989586621679806607"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806614"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806613"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806611"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806610"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806606"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-199"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806607"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806607"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-200"></span><span>    </span><span class="annot"><a href="#local-6989586621679806605"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806614"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806613"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806611"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806606"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-201"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-202"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-203"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806614"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806613"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806611"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806610"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806606"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>    </span><span class="annot"><a href="#local-6989586621679806604"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-205"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806614"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806613"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806611"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806610"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806606"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-206"></span><span>    </span><span class="annot"><a href="#local-6989586621679806612"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-207"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-208"></span><span>  </span><span id="local-6989586621679806601"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (LMHead style gradient device dataType inputEmbedDim vocabDim)
-&gt; Generator generatorDevice
-&gt; m (LMHead style gradient device dataType inputEmbedDim vocabDim,
      Generator device)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-type">LMHeadSpec</span></a></span><span> </span><span id="local-6989586621679806599"><span class="annot"><a href="#local-6989586621679806599"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679806598"><span class="annot"><a href="#local-6989586621679806598"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679806597"><span class="annot"><a href="#local-6989586621679806597"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679806596"><span class="annot"><a href="#local-6989586621679806596"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679806595"><span class="annot"><a href="#local-6989586621679806595"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806594"><span class="annot"><a href="#local-6989586621679806594"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679806593"><span class="annot"><a href="#local-6989586621679806593"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679806592"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679806592"><span class="hs-identifier hs-var">generator</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-209"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806591"><span class="annot"><span class="annottext">generator' :: Generator device
</span><a href="#local-6989586621679806591"><span class="hs-identifier hs-var hs-var">generator'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; Generator generatorDevice -&gt; Generator device
forall (generatorDevice' :: Device (DeviceType Nat))
       (generatorDevice :: Device (DeviceType Nat)).
SDevice generatorDevice'
-&gt; Generator generatorDevice -&gt; Generator generatorDevice'
</span><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier hs-var">sGeneratorToDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806597"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679806592"><span class="hs-identifier hs-var">generator</span></a></span><span>
</span><span id="line-210"></span><span>        </span><span id="local-6989586621679806590"><span class="annot"><span class="annottext">denseSpec :: LinearSpec
  'WithBias gradient device dataType inputEmbedDim inputEmbedDim
</span><a href="#local-6989586621679806590"><span class="hs-identifier hs-var hs-var">denseSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim inputEmbedDim
-&gt; LinearSpec
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; LinearSpec hasBias gradient device dataType inputDim outputDim
</span><a href="Torch.GraduallyTyped.NN.Linear.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806598"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806597"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806596"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806595"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806595"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-211"></span><span>        </span><span id="local-6989586621679806587"><span class="annot"><span class="annottext">dense :: IxStateT m (Generator device) (Generator device) dense
</span><a href="#local-6989586621679806587"><span class="hs-identifier hs-var hs-var">dense</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (dense, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) dense
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (dense, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) dense)
-&gt; (ModelSpec dense
    -&gt; Generator device -&gt; m (dense, Generator device))
-&gt; ModelSpec dense
-&gt; IxStateT m (Generator device) (Generator device) dense
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize dense generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec dense
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806615"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec dense
 -&gt; IxStateT m (Generator device) (Generator device) dense)
-&gt; ModelSpec dense
-&gt; IxStateT m (Generator device) (Generator device) dense
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-212"></span><span>          </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806599"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-213"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-215"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-216"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-218"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec dense
LinearSpec
  'WithBias gradient device dataType inputEmbedDim inputEmbedDim
</span><a href="#local-6989586621679806590"><span class="hs-identifier hs-var">denseSpec</span></a></span><span>
</span><span id="line-219"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec dense
LinearSpec
  'WithBias gradient device dataType inputEmbedDim inputEmbedDim
</span><a href="#local-6989586621679806590"><span class="hs-identifier hs-var">denseSpec</span></a></span><span>
</span><span id="line-220"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec dense
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-221"></span><span>        </span><span id="local-6989586621679806575"><span class="annot"><span class="annottext">activation :: IxStateT m (Generator device) (Generator device) activation
</span><a href="#local-6989586621679806575"><span class="hs-identifier hs-var hs-var">activation</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (activation, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) activation
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (activation, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) activation)
-&gt; (ModelSpec activation
    -&gt; Generator device -&gt; m (activation, Generator device))
-&gt; ModelSpec activation
-&gt; IxStateT m (Generator device) (Generator device) activation
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   activation generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec activation
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806609"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec activation
 -&gt; IxStateT m (Generator device) (Generator device) activation)
-&gt; ModelSpec activation
-&gt; IxStateT m (Generator device) (Generator device) activation
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-222"></span><span>          </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806599"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-223"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-228"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec activation
Gelu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-229"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec activation
Gelu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-230"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec activation
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-231"></span><span>        </span><span id="local-6989586621679806573"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679806573"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806598"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806597"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806596"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806595"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806593"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-232"></span><span>        </span><span id="local-6989586621679806570"><span class="annot"><span class="annottext">layerNorm :: IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679806570"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (layerNorm, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (layerNorm, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; (ModelSpec layerNorm
    -&gt; Generator device -&gt; m (layerNorm, Generator device))
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   layerNorm generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec layerNorm
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806608"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec layerNorm
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-233"></span><span>          </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806599"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-234"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-235"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-236"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-237"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-238"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-239"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679806573"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-240"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679806573"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-241"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-242"></span><span>        </span><span id="local-6989586621679806569"><span class="annot"><span class="annottext">decoderWithoutBiasSpec :: LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806569"><span class="hs-identifier hs-var hs-var">decoderWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; LinearSpec
     'WithoutBias gradient device dataType inputEmbedDim vocabDim
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; LinearSpec hasBias gradient device dataType inputDim outputDim
</span><a href="Torch.GraduallyTyped.NN.Linear.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806598"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806597"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806596"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806595"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679806594"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-243"></span><span>        </span><span id="local-6989586621679806567"><span class="annot"><span class="annottext">decoderWithBiasSpec :: LinearSpec
  'WithBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806567"><span class="hs-identifier hs-var hs-var">decoderWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; LinearSpec
     'WithBias gradient device dataType inputEmbedDim vocabDim
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; LinearSpec hasBias gradient device dataType inputDim outputDim
</span><a href="Torch.GraduallyTyped.NN.Linear.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806598"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806597"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806596"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806595"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679806594"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-244"></span><span>        </span><span id="local-6989586621679806566"><span class="annot"><span class="annottext">decoder :: IxStateT m (Generator device) (Generator device) decoder
</span><a href="#local-6989586621679806566"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (decoder, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) decoder
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (decoder, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) decoder)
-&gt; (ModelSpec decoder
    -&gt; Generator device -&gt; m (decoder, Generator device))
-&gt; ModelSpec decoder
-&gt; IxStateT m (Generator device) (Generator device) decoder
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   decoder generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec decoder
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806607"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec decoder
 -&gt; IxStateT m (Generator device) (Generator device) decoder)
-&gt; ModelSpec decoder
-&gt; IxStateT m (Generator device) (Generator device) decoder
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-245"></span><span>          </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806599"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-246"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806569"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span>
</span><span id="line-247"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806569"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span>
</span><span id="line-248"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806569"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span>
</span><span id="line-249"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806569"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span>
</span><span id="line-250"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806569"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span>
</span><span id="line-251"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
LinearSpec
  'WithBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806567"><span class="hs-identifier hs-var">decoderWithBiasSpec</span></a></span><span>
</span><span id="line-252"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
LinearSpec
  'WithBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806567"><span class="hs-identifier hs-var">decoderWithBiasSpec</span></a></span><span>
</span><span id="line-253"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-254"></span><span>        </span><span id="local-6989586621679806565"><span class="annot"><span class="annottext">biasSpec :: TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679806565"><span class="hs-identifier hs-var hs-var">biasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806598"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806597"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806596"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[vocabDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679806594"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim -&gt; SList '[] -&gt; SList '[vocabDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>        </span><span id="local-6989586621679806559"><span class="annot"><span class="annottext">bias :: IxStateT m (Generator device) (Generator device) bias
</span><a href="#local-6989586621679806559"><span class="hs-identifier hs-var hs-var">bias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">bias -&gt; IxStateT m (Generator device) (Generator device) bias
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(bias -&gt; IxStateT m (Generator device) (Generator device) bias)
-&gt; bias -&gt; IxStateT m (Generator device) (Generator device) bias
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-256"></span><span>          </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806599"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-257"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679806565"><span class="hs-identifier hs-var">biasSpec</span></a></span><span>
</span><span id="line-260"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679806565"><span class="hs-identifier hs-var">biasSpec</span></a></span><span>
</span><span id="line-261"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679806565"><span class="hs-identifier hs-var">biasSpec</span></a></span><span>
</span><span id="line-262"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-264"></span><span>            </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">bias
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-265"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (LMHead style gradient device dataType inputEmbedDim vocabDim)
-&gt; Generator device
-&gt; m (LMHead style gradient device dataType inputEmbedDim vocabDim,
      Generator device)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span>
</span><span id="line-266"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim
 -&gt; dense
 -&gt; activation
 -&gt; layerNorm
 -&gt; decoder
 -&gt; bias
 -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT
     m (Generator device) (Generator device) (SDim inputEmbedDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (dense
      -&gt; activation
      -&gt; layerNorm
      -&gt; decoder
      -&gt; bias
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; IxStateT
     m (Generator device) (Generator device) (SDim inputEmbedDim)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806595"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (dense
   -&gt; activation
   -&gt; layerNorm
   -&gt; decoder
   -&gt; bias
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT m (Generator device) (Generator device) dense
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (activation
      -&gt; layerNorm
      -&gt; decoder
      -&gt; bias
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) dense
</span><a href="#local-6989586621679806587"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (activation
   -&gt; layerNorm
   -&gt; decoder
   -&gt; bias
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT m (Generator device) (Generator device) activation
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (layerNorm
      -&gt; decoder
      -&gt; bias
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) activation
</span><a href="#local-6989586621679806575"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (layerNorm
   -&gt; decoder
   -&gt; bias
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (decoder
      -&gt; bias
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679806570"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (decoder
   -&gt; bias
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT m (Generator device) (Generator device) decoder
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (bias
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) decoder
</span><a href="#local-6989586621679806566"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (bias
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT m (Generator device) (Generator device) bias
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) bias
</span><a href="#local-6989586621679806559"><span class="hs-identifier hs-var">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-267"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; (GLMHead inputEmbedDim dense activation layerNorm decoder bias
    -&gt; IxStateT
         m
         (Generator device)
         (Generator device)
         (LMHead style gradient device dataType inputEmbedDim vocabDim))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (LMHead style gradient device dataType inputEmbedDim vocabDim)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">LMHead style gradient device dataType inputEmbedDim vocabDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (LMHead style gradient device dataType inputEmbedDim vocabDim)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(LMHead style gradient device dataType inputEmbedDim vocabDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (LMHead style gradient device dataType inputEmbedDim vocabDim))
-&gt; (GLMHead inputEmbedDim dense activation layerNorm decoder bias
    -&gt; LMHead style gradient device dataType inputEmbedDim vocabDim)
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (LMHead style gradient device dataType inputEmbedDim vocabDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; LMHead style gradient device dataType inputEmbedDim vocabDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
GLMHead
  inputEmbedDim
  (LMHeadDenseF style gradient device dataType inputEmbedDim)
  (LMHeadActivationF style)
  (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
  (LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim)
  (LMHeadBiasF style gradient device dataType vocabDim)
-&gt; LMHead style gradient device dataType inputEmbedDim vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-var">LMHead</span></a></span><span>
</span><span id="line-268"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-269"></span><span>          </span><span class="annot"><span class="annottext">Generator device
</span><a href="#local-6989586621679806591"><span class="hs-identifier hs-var">generator'</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-270"></span><span>
</span><span id="line-271"></span><span id="local-6989586621679806551"><span id="local-6989586621679806552"><span id="local-6989586621679806553"><span id="local-6989586621679806554"><span id="local-6989586621679806555"><span id="local-6989586621679806556"><span class="hs-keyword">instance</span><span>
</span><span id="line-272"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-273"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-274"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806555"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806554"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806553"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806552"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806551"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-275"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-276"></span><span>  </span><span id="local-6989586621679806547"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (LMHead style gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (LMHead style gradient device dataType inputEmbedDim vocabDim)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-type">LMHeadSpec</span></a></span><span> </span><span id="local-6989586621679806545"><span class="annot"><a href="#local-6989586621679806545"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679806544"><span class="annot"><a href="#local-6989586621679806544"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679806543"><span class="annot"><a href="#local-6989586621679806543"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679806542"><span class="annot"><a href="#local-6989586621679806542"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679806541"><span class="annot"><a href="#local-6989586621679806541"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806540"><span class="annot"><a href="#local-6989586621679806540"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679806539"><span class="annot"><a href="#local-6989586621679806539"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679806538"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-277"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806537"><span class="annot"><span class="annottext">denseSpec :: LinearSpec
  'WithBias gradient device dataType inputEmbedDim inputEmbedDim
</span><a href="#local-6989586621679806537"><span class="hs-identifier hs-var hs-var">denseSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim inputEmbedDim
-&gt; LinearSpec
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; LinearSpec hasBias gradient device dataType inputDim outputDim
</span><a href="Torch.GraduallyTyped.NN.Linear.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806544"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806543"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806542"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806541"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806541"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-278"></span><span>        </span><span id="local-6989586621679806536"><span class="annot"><span class="annottext">dense :: STransformerStyle style
-&gt; m (LMHeadDenseF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679806536"><span class="hs-identifier hs-var hs-var">dense</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-279"></span><span>        </span><span class="annot"><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-280"></span><span>        </span><span class="annot"><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span>        </span><span class="annot"><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>        </span><span class="annot"><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-283"></span><span>        </span><span class="annot"><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
LinearSpec
  'WithBias gradient device dataType inputEmbedDim inputEmbedDim
</span><a href="#local-6989586621679806537"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;transform.dense.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-284"></span><span>        </span><span class="annot"><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
LinearSpec
  'WithBias gradient device dataType inputEmbedDim inputEmbedDim
</span><a href="#local-6989586621679806537"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;dense.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>        </span><span class="annot"><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (LMHeadDenseF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-286"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span>
</span><span id="line-287"></span><span>        </span><span id="local-6989586621679806535"><span class="annot"><span class="annottext">activation :: STransformerStyle style -&gt; LMHeadActivationF style
</span><a href="#local-6989586621679806535"><span class="hs-identifier hs-var hs-var">activation</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-291"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Gelu
LMHeadActivationF style
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-293"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Gelu
LMHeadActivationF style
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-294"></span><span>        </span><span class="annot"><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadActivationF style
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-295"></span><span>        </span><span id="local-6989586621679806534"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679806534"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806544"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806543"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806542"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806541"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806539"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-296"></span><span>        </span><span id="local-6989586621679806533"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (LMHeadLayerNormF
        style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679806533"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-297"></span><span>        </span><span class="annot"><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span>        </span><span class="annot"><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-299"></span><span>        </span><span class="annot"><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679806534"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;transform.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-302"></span><span>        </span><span class="annot"><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679806534"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>        </span><span class="annot"><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-304"></span><span>        </span><span id="local-6989586621679806532"><span class="annot"><span class="annottext">decoderWithoutBiasSpec :: LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806532"><span class="hs-identifier hs-var hs-var">decoderWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; LinearSpec
     'WithoutBias gradient device dataType inputEmbedDim vocabDim
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; LinearSpec hasBias gradient device dataType inputDim outputDim
</span><a href="Torch.GraduallyTyped.NN.Linear.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806544"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806543"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806542"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806541"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679806540"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-305"></span><span>        </span><span id="local-6989586621679806531"><span class="annot"><span class="annottext">decoderWithBiasSpec :: LinearSpec
  'WithBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806531"><span class="hs-identifier hs-var hs-var">decoderWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; LinearSpec
     'WithBias gradient device dataType inputEmbedDim vocabDim
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; LinearSpec hasBias gradient device dataType inputDim outputDim
</span><a href="Torch.GraduallyTyped.NN.Linear.html#LinearSpec"><span class="hs-identifier hs-var">LinearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806544"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806543"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806542"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806541"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679806540"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-306"></span><span>        </span><span id="local-6989586621679806530"><span class="annot"><span class="annottext">decoder :: STransformerStyle style
-&gt; m (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679806530"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithoutBias gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806532"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-307"></span><span>        </span><span class="annot"><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithoutBias gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806532"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-308"></span><span>        </span><span class="annot"><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithoutBias gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806532"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-309"></span><span>        </span><span class="annot"><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithoutBias gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806532"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-310"></span><span>        </span><span class="annot"><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithoutBias gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
LinearSpec
  'WithoutBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806532"><span class="hs-identifier hs-var">decoderWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>        </span><span class="annot"><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear 'WithBias gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithBias gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear 'WithBias gradient device dataType inputEmbedDim vocabDim)
LinearSpec
  'WithBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806531"><span class="hs-identifier hs-var">decoderWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>        </span><span class="annot"><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear 'WithBias gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (Linear
        'WithBias gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Linear 'WithBias gradient device dataType inputEmbedDim vocabDim)
LinearSpec
  'WithBias gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806531"><span class="hs-identifier hs-var">decoderWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>        </span><span class="annot"><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-314"></span><span>        </span><span id="local-6989586621679806529"><span class="annot"><span class="annottext">biasSpec :: TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679806529"><span class="hs-identifier hs-var hs-var">biasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806544"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806543"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806542"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[vocabDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679806540"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim -&gt; SList '[] -&gt; SList '[vocabDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>        </span><span id="local-6989586621679806528"><span class="annot"><span class="annottext">bias :: STransformerStyle style
-&gt; m (LMHeadBiasF style gradient device dataType vocabDim)
</span><a href="#local-6989586621679806528"><span class="hs-identifier hs-var hs-var">bias</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>        </span><span class="annot"><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>        </span><span class="annot"><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; StateDictKey
-&gt; m (Tensor
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
ModelSpec
  (Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
</span><a href="#local-6989586621679806529"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>        </span><span class="annot"><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; StateDictKey
-&gt; m (Tensor
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
ModelSpec
  (Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
</span><a href="#local-6989586621679806529"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>        </span><span class="annot"><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; StateDictKey
-&gt; m (Tensor
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
ModelSpec
  (Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
</span><a href="#local-6989586621679806529"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806538"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>        </span><span class="annot"><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-321"></span><span>        </span><span class="annot"><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>        </span><span class="annot"><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (LMHeadBiasF style gradient device dataType vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-323"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GLMHead
  inputEmbedDim
  (LMHeadDenseF style gradient device dataType inputEmbedDim)
  (LMHeadActivationF style)
  (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
  (LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim)
  (LMHeadBiasF style gradient device dataType vocabDim)
-&gt; LMHead style gradient device dataType inputEmbedDim vocabDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
GLMHead
  inputEmbedDim
  (LMHeadDenseF style gradient device dataType inputEmbedDim)
  (LMHeadActivationF style)
  (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
  (LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim)
  (LMHeadBiasF style gradient device dataType vocabDim)
-&gt; LMHead style gradient device dataType inputEmbedDim vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-var">LMHead</span></a></span><span>
</span><span id="line-324"></span><span>          </span><span class="annot"><span class="annottext">(GLMHead
   inputEmbedDim
   (LMHeadDenseF style gradient device dataType inputEmbedDim)
   (LMHeadActivationF style)
   (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
   (LMHeadDecoderF
      style gradient device dataType inputEmbedDim vocabDim)
   (LMHeadBiasF style gradient device dataType vocabDim)
 -&gt; LMHead style gradient device dataType inputEmbedDim vocabDim)
-&gt; m (GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
-&gt; m (LMHead style gradient device dataType inputEmbedDim vocabDim)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; LMHeadDenseF style gradient device dataType inputEmbedDim
-&gt; LMHeadActivationF style
-&gt; LMHeadLayerNormF style gradient device dataType inputEmbedDim
-&gt; LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim
-&gt; LMHeadBiasF style gradient device dataType vocabDim
-&gt; GLMHead
     inputEmbedDim
     (LMHeadDenseF style gradient device dataType inputEmbedDim)
     (LMHeadActivationF style)
     (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
     (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
     (LMHeadBiasF style gradient device dataType vocabDim)
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806541"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-325"></span><span>                  </span><span class="annot"><span class="annottext">(LMHeadDenseF style gradient device dataType inputEmbedDim
 -&gt; LMHeadActivationF style
 -&gt; LMHeadLayerNormF style gradient device dataType inputEmbedDim
 -&gt; LMHeadDecoderF
      style gradient device dataType inputEmbedDim vocabDim
 -&gt; LMHeadBiasF style gradient device dataType vocabDim
 -&gt; GLMHead
      inputEmbedDim
      (LMHeadDenseF style gradient device dataType inputEmbedDim)
      (LMHeadActivationF style)
      (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
      (LMHeadDecoderF
         style gradient device dataType inputEmbedDim vocabDim)
      (LMHeadBiasF style gradient device dataType vocabDim))
-&gt; m (LMHeadDenseF style gradient device dataType inputEmbedDim)
-&gt; m (LMHeadActivationF style
      -&gt; LMHeadLayerNormF style gradient device dataType inputEmbedDim
      -&gt; LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim
      -&gt; LMHeadBiasF style gradient device dataType vocabDim
      -&gt; GLMHead
           inputEmbedDim
           (LMHeadDenseF style gradient device dataType inputEmbedDim)
           (LMHeadActivationF style)
           (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
           (LMHeadDecoderF
              style gradient device dataType inputEmbedDim vocabDim)
           (LMHeadBiasF style gradient device dataType vocabDim))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (LMHeadDenseF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679806536"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806545"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-326"></span><span>                  </span><span class="annot"><span class="annottext">m (LMHeadActivationF style
   -&gt; LMHeadLayerNormF style gradient device dataType inputEmbedDim
   -&gt; LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim
   -&gt; LMHeadBiasF style gradient device dataType vocabDim
   -&gt; GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
-&gt; m (LMHeadActivationF style)
-&gt; m (LMHeadLayerNormF style gradient device dataType inputEmbedDim
      -&gt; LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim
      -&gt; LMHeadBiasF style gradient device dataType vocabDim
      -&gt; GLMHead
           inputEmbedDim
           (LMHeadDenseF style gradient device dataType inputEmbedDim)
           (LMHeadActivationF style)
           (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
           (LMHeadDecoderF
              style gradient device dataType inputEmbedDim vocabDim)
           (LMHeadBiasF style gradient device dataType vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">LMHeadActivationF style -&gt; m (LMHeadActivationF style)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; LMHeadActivationF style
</span><a href="#local-6989586621679806535"><span class="hs-identifier hs-var">activation</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806545"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-327"></span><span>                  </span><span class="annot"><span class="annottext">m (LMHeadLayerNormF style gradient device dataType inputEmbedDim
   -&gt; LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim
   -&gt; LMHeadBiasF style gradient device dataType vocabDim
   -&gt; GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
-&gt; m (LMHeadLayerNormF
        style gradient device dataType inputEmbedDim)
-&gt; m (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim
      -&gt; LMHeadBiasF style gradient device dataType vocabDim
      -&gt; GLMHead
           inputEmbedDim
           (LMHeadDenseF style gradient device dataType inputEmbedDim)
           (LMHeadActivationF style)
           (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
           (LMHeadDecoderF
              style gradient device dataType inputEmbedDim vocabDim)
           (LMHeadBiasF style gradient device dataType vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (LMHeadLayerNormF
        style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679806533"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806545"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-328"></span><span>                  </span><span class="annot"><span class="annottext">m (LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim
   -&gt; LMHeadBiasF style gradient device dataType vocabDim
   -&gt; GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
-&gt; m (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
-&gt; m (LMHeadBiasF style gradient device dataType vocabDim
      -&gt; GLMHead
           inputEmbedDim
           (LMHeadDenseF style gradient device dataType inputEmbedDim)
           (LMHeadActivationF style)
           (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
           (LMHeadDecoderF
              style gradient device dataType inputEmbedDim vocabDim)
           (LMHeadBiasF style gradient device dataType vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679806530"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806545"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-329"></span><span>                  </span><span class="annot"><span class="annottext">m (LMHeadBiasF style gradient device dataType vocabDim
   -&gt; GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
-&gt; m (LMHeadBiasF style gradient device dataType vocabDim)
-&gt; m (GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (LMHeadBiasF style gradient device dataType vocabDim)
</span><a href="#local-6989586621679806528"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806545"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-330"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-331"></span><span>  </span><span id="local-6989586621679806526"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; LMHead style gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679806524"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679806518"><span id="local-6989586621679806519"><span id="local-6989586621679806520"><span id="local-6989586621679806521"><span id="local-6989586621679806522"><span id="local-6989586621679806523"><span class="annot"><span class="annottext">SDim inputEmbedDim
LMHeadBiasF style gradient device dataType vocabDim
LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
LMHeadLayerNormF style gradient device dataType inputEmbedDim
LMHeadActivationF style
LMHeadDenseF style gradient device dataType inputEmbedDim
lmHeadBias :: LMHeadBiasF style gradient device dataType vocabDim
lmHeadDecoder :: LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
lmHeadLayerNorm :: LMHeadLayerNormF style gradient device dataType inputEmbedDim
lmHeadActivation :: LMHeadActivationF style
lmHeadDense :: LMHeadDenseF style gradient device dataType inputEmbedDim
lmHeadInputEmbedDim :: SDim inputEmbedDim
lmHeadBias :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
lmHeadDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
lmHeadLayerNorm :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
lmHeadActivation :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
lmHeadDense :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
lmHeadInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679806518"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-332"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806517"><span class="annot"><span class="annottext">dense :: STransformerStyle style
-&gt; LMHeadDenseF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806517"><span class="hs-identifier hs-var hs-var">dense</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>        </span><span class="annot"><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-334"></span><span>        </span><span class="annot"><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-335"></span><span>        </span><span class="annot"><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-336"></span><span>        </span><span class="annot"><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-337"></span><span>        </span><span class="annot"><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;transform.dense.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-338"></span><span>        </span><span class="annot"><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;dense.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-339"></span><span>        </span><span class="annot"><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadDenseF style gradient device dataType inputEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-340"></span><span>        </span><span id="local-6989586621679806515"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; LMHeadLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806515"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-341"></span><span>        </span><span class="annot"><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-342"></span><span>        </span><span class="annot"><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-343"></span><span>        </span><span class="annot"><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-344"></span><span>        </span><span class="annot"><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-345"></span><span>        </span><span class="annot"><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;transform.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-346"></span><span>        </span><span class="annot"><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-347"></span><span>        </span><span class="annot"><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-348"></span><span>        </span><span id="local-6989586621679806514"><span class="annot"><span class="annottext">decoder :: STransformerStyle style
-&gt; LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
</span><a href="#local-6989586621679806514"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-349"></span><span>        </span><span class="annot"><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-350"></span><span>        </span><span class="annot"><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-351"></span><span>        </span><span class="annot"><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span>        </span><span class="annot"><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear
     'WithoutBias gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-353"></span><span>        </span><span class="annot"><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear 'WithBias gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-354"></span><span>        </span><span class="annot"><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Linear 'WithBias gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-355"></span><span>        </span><span class="annot"><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-356"></span><span>        </span><span id="local-6989586621679806513"><span class="annot"><span class="annottext">bias :: STransformerStyle style
-&gt; LMHeadBiasF style gradient device dataType vocabDim -&gt; m ()
</span><a href="#local-6989586621679806513"><span class="hs-identifier hs-var hs-var">bias</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>        </span><span class="annot"><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-358"></span><span>        </span><span class="annot"><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-359"></span><span>        </span><span class="annot"><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-360"></span><span>        </span><span class="annot"><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806524"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-361"></span><span>        </span><span class="annot"><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>        </span><span class="annot"><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m () -&gt; () -&gt; m ()
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m () -&gt; () -&gt; m ()) -&gt; m () -&gt; () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-363"></span><span>        </span><span class="annot"><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadBiasF style gradient device dataType vocabDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-364"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-365"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; LMHeadDenseF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806517"><span class="hs-identifier hs-var">dense</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">LMHeadDenseF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679806522"><span class="hs-identifier hs-var">lmHeadDense</span></a></span><span>
</span><span id="line-366"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; LMHeadLayerNormF style gradient device dataType inputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806515"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">LMHeadLayerNormF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679806520"><span class="hs-identifier hs-var">lmHeadLayerNorm</span></a></span><span>
</span><span id="line-367"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
</span><a href="#local-6989586621679806514"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806519"><span class="hs-identifier hs-var">lmHeadDecoder</span></a></span><span>
</span><span id="line-368"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; LMHeadBiasF style gradient device dataType vocabDim -&gt; m ()
</span><a href="#local-6989586621679806513"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806556"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">LMHeadBiasF style gradient device dataType vocabDim
</span><a href="#local-6989586621679806518"><span class="hs-identifier hs-var">lmHeadBias</span></a></span><span>
</span><span id="line-369"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-370"></span><span>
</span><span id="line-371"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-372"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span>
</span><span id="line-373"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806511"><span class="annot"><a href="#local-6989586621679806511"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-374"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806510"><span class="annot"><a href="#local-6989586621679806510"><span class="hs-identifier hs-type">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-375"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806509"><span class="annot"><a href="#local-6989586621679806509"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-376"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806508"><span class="annot"><a href="#local-6989586621679806508"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-377"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806507"><span class="annot"><a href="#local-6989586621679806507"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-378"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806506"><span class="annot"><a href="#local-6989586621679806506"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-379"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-380"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-381"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679806505"><span class="annot"><a href="#local-6989586621679806505"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679806505"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-382"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679806504"><span class="annot"><a href="#local-6989586621679806504"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679806503"><span class="annot"><a href="#local-6989586621679806503"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806502"><span class="annot"><a href="#local-6989586621679806502"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806501"><span class="annot"><a href="#local-6989586621679806501"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806500"><span class="annot"><a href="#local-6989586621679806500"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806504"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806503"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806502"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806501"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806500"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-383"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679806499"><span class="annot"><a href="#local-6989586621679806499"><span class="hs-identifier hs-type hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679806498"><span class="annot"><a href="#local-6989586621679806498"><span class="hs-identifier hs-type hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679806497"><span class="annot"><a href="#local-6989586621679806497"><span class="hs-identifier hs-type hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679806496"><span class="annot"><a href="#local-6989586621679806496"><span class="hs-identifier hs-type hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679806495"><span class="annot"><a href="#local-6989586621679806495"><span class="hs-identifier hs-type hs-type">shape'</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679806494"><span class="annot"><a href="#local-6989586621679806494"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806493"><span class="annot"><a href="#local-6989586621679806493"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806492"><span class="annot"><a href="#local-6989586621679806492"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806491"><span class="annot"><a href="#local-6989586621679806491"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-384"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-385"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806499"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806494"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-386"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806498"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-387"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806497"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806493"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-388"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806496"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806492"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-389"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806495"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806491"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-390"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679806490"><span class="annot"><a href="#local-6989586621679806490"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679806489"><span class="annot"><a href="#local-6989586621679806489"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806488"><span class="annot"><a href="#local-6989586621679806488"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806487"><span class="annot"><a href="#local-6989586621679806487"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806486"><span class="annot"><a href="#local-6989586621679806486"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806490"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806489"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806488"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806487"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806486"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-391"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679806485"><span class="annot"><a href="#local-6989586621679806485"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679806484"><span class="annot"><a href="#local-6989586621679806484"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806483"><span class="annot"><a href="#local-6989586621679806483"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806482"><span class="annot"><a href="#local-6989586621679806482"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806481"><span class="annot"><a href="#local-6989586621679806481"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806485"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806484"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806483"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806482"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806481"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-392"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679806480"><span class="annot"><a href="#local-6989586621679806480"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679806480"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-393"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679806479"><span class="annot"><a href="#local-6989586621679806479"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679806479"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-394"></span><span>
</span><span id="line-395"></span><span class="hs-comment">-- | 'HasForward' instance for 'LMHead'.</span><span>
</span><span id="line-396"></span><span class="hs-comment">--</span><span>
</span><span id="line-397"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-398"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-399"></span><span class="hs-comment">--     &#9474; input &#9474;</span><span>
</span><span id="line-400"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-401"></span><span class="hs-comment">--         &#9474;</span><span>
</span><span id="line-402"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-403"></span><span class="hs-comment">--   (lmHeadDense)</span><span>
</span><span id="line-404"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-405"></span><span class="hs-comment">-- (lmHeadActivation)</span><span>
</span><span id="line-406"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-407"></span><span class="hs-comment">-- (lmHeadLayerNorm)</span><span>
</span><span id="line-408"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-409"></span><span class="hs-comment">--   lmHeadDecoder</span><span>
</span><span id="line-410"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-411"></span><span class="hs-comment">--     (scaling)</span><span>
</span><span id="line-412"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-413"></span><span class="hs-comment">--    (lmHeadBias)</span><span>
</span><span id="line-414"></span><span class="hs-comment">--         &#9474;</span><span>
</span><span id="line-415"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-416"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-417"></span><span class="hs-comment">-- &#9474; decoderOutput &#9474;</span><span>
</span><span id="line-418"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-419"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-420"></span><span id="local-6989586621679806457"><span id="local-6989586621679806458"><span id="local-6989586621679806459"><span id="local-6989586621679806460"><span id="local-6989586621679806461"><span id="local-6989586621679806462"><span id="local-6989586621679806463"><span id="local-6989586621679806464"><span id="local-6989586621679806465"><span id="local-6989586621679806466"><span id="local-6989586621679806467"><span id="local-6989586621679806468"><span id="local-6989586621679806469"><span id="local-6989586621679806470"><span id="local-6989586621679806471"><span id="local-6989586621679806472"><span id="local-6989586621679806473"><span id="local-6989586621679806474"><span id="local-6989586621679806475"><span id="local-6989586621679806476"><span id="local-6989586621679806477"><span id="local-6989586621679806478"><span class="hs-keyword">instance</span><span>
</span><span id="line-421"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-422"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-423"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806475"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806474"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-424"></span><span>      </span><span class="annot"><a href="#local-6989586621679806473"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-425"></span><span>      </span><span class="annot"><a href="#local-6989586621679806472"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-426"></span><span>      </span><span class="annot"><a href="#local-6989586621679806471"><span class="hs-identifier hs-type">denseOutput</span></a></span><span>
</span><span id="line-427"></span><span>      </span><span class="annot"><a href="#local-6989586621679806470"><span class="hs-identifier hs-type">denseGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-428"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-429"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-430"></span><span>      </span><span class="annot"><a href="#local-6989586621679806471"><span class="hs-identifier hs-type">denseOutput</span></a></span><span>
</span><span id="line-431"></span><span>      </span><span class="annot"><a href="#local-6989586621679806470"><span class="hs-identifier hs-type">denseGeneratorOutputDevice</span></a></span><span>
</span><span id="line-432"></span><span>      </span><span class="annot"><a href="#local-6989586621679806469"><span class="hs-identifier hs-type">activationOutput</span></a></span><span>
</span><span id="line-433"></span><span>      </span><span class="annot"><a href="#local-6989586621679806468"><span class="hs-identifier hs-type">activationGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-434"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-435"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806475"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806474"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-436"></span><span>      </span><span class="annot"><a href="#local-6989586621679806469"><span class="hs-identifier hs-type">activationOutput</span></a></span><span>
</span><span id="line-437"></span><span>      </span><span class="annot"><a href="#local-6989586621679806468"><span class="hs-identifier hs-type">activationGeneratorOutputDevice</span></a></span><span>
</span><span id="line-438"></span><span>      </span><span class="annot"><a href="#local-6989586621679806467"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-439"></span><span>      </span><span class="annot"><a href="#local-6989586621679806466"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-440"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-441"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806475"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806474"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806465"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-442"></span><span>      </span><span class="annot"><a href="#local-6989586621679806467"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-443"></span><span>      </span><span class="annot"><a href="#local-6989586621679806466"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span>
</span><span id="line-444"></span><span>      </span><span class="annot"><a href="#local-6989586621679806464"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-445"></span><span>      </span><span class="annot"><a href="#local-6989586621679806463"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-446"></span><span>    </span><span class="annot"><a href="#local-6989586621679806464"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806462"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806461"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806460"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806459"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806458"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-447"></span><span>    </span><span class="annot"><a href="#local-6989586621679806457"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806464"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806475"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806465"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-448"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-449"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-450"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806475"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806474"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806465"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-451"></span><span>    </span><span class="annot"><a href="#local-6989586621679806473"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-452"></span><span>    </span><span class="annot"><a href="#local-6989586621679806472"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-453"></span><span>    </span><span class="annot"><a href="#local-6989586621679806457"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-454"></span><span>    </span><span class="annot"><a href="#local-6989586621679806463"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-455"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-456"></span><span>  </span><span id="local-6989586621679806454"><span class="annot"><span class="annottext">forward :: LMHead style gradient device dataType inputEmbedDim vocabDim
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679806447"><span id="local-6989586621679806448"><span id="local-6989586621679806449"><span id="local-6989586621679806450"><span id="local-6989586621679806451"><span id="local-6989586621679806452"><span class="annot"><span class="annottext">SDim inputEmbedDim
LMHeadBiasF style gradient device dataType vocabDim
LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
LMHeadLayerNormF style gradient device dataType inputEmbedDim
LMHeadActivationF style
LMHeadDenseF style gradient device dataType inputEmbedDim
lmHeadBias :: LMHeadBiasF style gradient device dataType vocabDim
lmHeadDecoder :: LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
lmHeadLayerNorm :: LMHeadLayerNormF style gradient device dataType inputEmbedDim
lmHeadActivation :: LMHeadActivationF style
lmHeadDense :: LMHeadDenseF style gradient device dataType inputEmbedDim
lmHeadInputEmbedDim :: SDim inputEmbedDim
lmHeadBias :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
lmHeadDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
lmHeadLayerNorm :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
lmHeadActivation :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
lmHeadDense :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
lmHeadInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679806447"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679806446"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679806446"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-457"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806445"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806445"><span class="hs-identifier hs-var">s</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked StateDictKey) (IsChecked Integer)
-&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked StateDictKey) (IsChecked Integer)
 -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked StateDictKey) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; Dim (IsChecked StateDictKey) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679806452"><span class="hs-identifier hs-var">lmHeadInputEmbedDim</span></a></span><span>
</span><span id="line-458"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-type">scaling</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679806464"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679806464"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-459"></span><span>        </span><span id="local-6989586621679806442"><span class="annot"><span class="annottext">scaling :: STransformerStyle style -&gt; decoderOutput -&gt; decoderOutput
</span><a href="#local-6989586621679806442"><span class="hs-identifier hs-var hs-var">scaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape')
-&gt; Double
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient' layout' device' dataType' shape'
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape'
forall divisor (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar divisor =&gt;
Tensor gradient layout device dataType shape
-&gt; divisor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar"><span class="hs-identifier hs-var">divScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806445"><span class="hs-identifier hs-var">s</span></a></span><span>
</span><span id="line-460"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape')
-&gt; Double
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient' layout' device' dataType' shape'
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape'
forall divisor (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar divisor =&gt;
Tensor gradient layout device dataType shape
-&gt; divisor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar"><span class="hs-identifier hs-var">divScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806445"><span class="hs-identifier hs-var">s</span></a></span><span>
</span><span id="line-461"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; decoderOutput
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-462"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; decoderOutput
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-463"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; decoderOutput
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-464"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; decoderOutput
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-465"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; decoderOutput
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-466"></span><span>        </span><span class="annot"><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; decoderOutput
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-467"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679806464"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679806457"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-468"></span><span>        </span><span id="local-6989586621679806439"><span class="annot"><span class="annottext">bias :: STransformerStyle style -&gt; decoderOutput -&gt; output
</span><a href="#local-6989586621679806439"><span class="hs-identifier hs-var hs-var">bias</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; output
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-469"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; output
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-470"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; Tensor
     (gradient' &lt;|&gt; gradient)
     (layout' &lt;+&gt; 'Layout 'Dense)
     (device' &lt;+&gt; device)
     (dataType' &lt;+&gt; dataType)
     (BroadcastShapesF
        shape' ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
LMHeadBiasF style gradient device dataType vocabDim
</span><a href="#local-6989586621679806447"><span class="hs-identifier hs-var">lmHeadBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; Tensor
     (gradient' &lt;|&gt; gradient)
     (layout' &lt;+&gt; 'Layout 'Dense)
     (device' &lt;+&gt; device)
     (dataType' &lt;+&gt; dataType)
     (BroadcastShapesF
        shape' ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
LMHeadBiasF style gradient device dataType vocabDim
</span><a href="#local-6989586621679806447"><span class="hs-identifier hs-var">lmHeadBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-472"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; Tensor
     (gradient' &lt;|&gt; gradient)
     (layout' &lt;+&gt; 'Layout 'Dense)
     (device' &lt;+&gt; device)
     (dataType' &lt;+&gt; dataType)
     (BroadcastShapesF
        shape' ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
LMHeadBiasF style gradient device dataType vocabDim
</span><a href="#local-6989586621679806447"><span class="hs-identifier hs-var">lmHeadBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-473"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; output
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-474"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; output
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-475"></span><span>        </span><span class="annot"><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">decoderOutput -&gt; output
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-476"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-477"></span><span>          </span><span class="annot"><span class="annottext">input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679806446"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-478"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) input
-&gt; (input
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator denseGeneratorOutputDevice)
         denseOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator denseGeneratorOutputDevice)
     denseOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (denseOutput, Generator denseGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator denseGeneratorOutputDevice)
     denseOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (denseOutput, Generator denseGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator denseGeneratorOutputDevice)
      denseOutput)
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (denseOutput, Generator denseGeneratorOutputDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator denseGeneratorOutputDevice)
     denseOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LMHeadDenseF style gradient device dataType inputEmbedDim
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (denseOutput, Generator denseGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LMHeadDenseF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679806451"><span class="hs-identifier hs-var">lmHeadDense</span></a></span><span>
</span><span id="line-479"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator denseGeneratorOutputDevice)
  denseOutput
-&gt; (denseOutput
    -&gt; IxStateT
         m
         (Generator denseGeneratorOutputDevice)
         (Generator activationGeneratorOutputDevice)
         activationOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator activationGeneratorOutputDevice)
     activationOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator denseGeneratorOutputDevice
 -&gt; m (activationOutput, Generator activationGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator denseGeneratorOutputDevice)
     (Generator activationGeneratorOutputDevice)
     activationOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator denseGeneratorOutputDevice
  -&gt; m (activationOutput, Generator activationGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator denseGeneratorOutputDevice)
      (Generator activationGeneratorOutputDevice)
      activationOutput)
-&gt; (denseOutput
    -&gt; Generator denseGeneratorOutputDevice
    -&gt; m (activationOutput, Generator activationGeneratorOutputDevice))
-&gt; denseOutput
-&gt; IxStateT
     m
     (Generator denseGeneratorOutputDevice)
     (Generator activationGeneratorOutputDevice)
     activationOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LMHeadActivationF style
-&gt; denseOutput
-&gt; Generator denseGeneratorOutputDevice
-&gt; m (activationOutput, Generator activationGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LMHeadActivationF style
</span><a href="#local-6989586621679806450"><span class="hs-identifier hs-var">lmHeadActivation</span></a></span><span>
</span><span id="line-480"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator activationGeneratorOutputDevice)
  activationOutput
-&gt; (activationOutput
    -&gt; IxStateT
         m
         (Generator activationGeneratorOutputDevice)
         (Generator layerNormGeneratorOutputDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator activationGeneratorOutputDevice
 -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator activationGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator activationGeneratorOutputDevice
  -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator activationGeneratorOutputDevice)
      (Generator layerNormGeneratorOutputDevice)
      layerNormOutput)
-&gt; (activationOutput
    -&gt; Generator activationGeneratorOutputDevice
    -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; activationOutput
-&gt; IxStateT
     m
     (Generator activationGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LMHeadLayerNormF style gradient device dataType inputEmbedDim
-&gt; activationOutput
-&gt; Generator activationGeneratorOutputDevice
-&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LMHeadLayerNormF style gradient device dataType inputEmbedDim
</span><a href="#local-6989586621679806449"><span class="hs-identifier hs-var">lmHeadLayerNorm</span></a></span><span>
</span><span id="line-481"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator layerNormGeneratorOutputDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator layerNormGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         decoderOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     decoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator layerNormGeneratorOutputDevice
 -&gt; m (decoderOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     decoderOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator layerNormGeneratorOutputDevice
  -&gt; m (decoderOutput, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator layerNormGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      decoderOutput)
-&gt; (layerNormOutput
    -&gt; Generator layerNormGeneratorOutputDevice
    -&gt; m (decoderOutput, Generator generatorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     decoderOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
-&gt; layerNormOutput
-&gt; Generator layerNormGeneratorOutputDevice
-&gt; m (decoderOutput, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LMHeadDecoderF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679806448"><span class="hs-identifier hs-var">lmHeadDecoder</span></a></span><span>
</span><span id="line-482"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  decoderOutput
-&gt; (decoderOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         decoderOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     decoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">decoderOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     decoderOutput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(decoderOutput
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      decoderOutput)
-&gt; (decoderOutput -&gt; decoderOutput)
-&gt; decoderOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     decoderOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; decoderOutput -&gt; decoderOutput
</span><a href="#local-6989586621679806442"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-483"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  decoderOutput
-&gt; (decoderOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (decoderOutput -&gt; output)
-&gt; decoderOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; decoderOutput -&gt; output
</span><a href="#local-6989586621679806439"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-484"></span></pre></body></html>