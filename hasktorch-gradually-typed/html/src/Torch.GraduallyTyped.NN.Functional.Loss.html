<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-5"></span><span>
</span><span id="line-6"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Loss</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-7"></span><span>
</span><span id="line-8"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-9"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-10"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-11"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.GC</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">unsafeThrowableIO</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-16"></span><span>
</span><span id="line-17"></span><span class="hs-comment">-- | Compute the mean squared error between two tensors.</span><span>
</span><span id="line-18"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Loss.html#mseLoss"><span class="hs-identifier hs-type">mseLoss</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-19"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679674720"><span class="annot"><a href="#local-6989586621679674720"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679674719"><span class="annot"><a href="#local-6989586621679674719"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679674718"><span class="annot"><a href="#local-6989586621679674718"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679674717"><span class="annot"><a href="#local-6989586621679674717"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679674716"><span class="annot"><a href="#local-6989586621679674716"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679674715"><span class="annot"><a href="#local-6989586621679674715"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679674714"><span class="annot"><a href="#local-6989586621679674714"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679674713"><span class="annot"><a href="#local-6989586621679674713"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679674712"><span class="annot"><a href="#local-6989586621679674712"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679674711"><span class="annot"><a href="#local-6989586621679674711"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679674710"><span class="annot"><a href="#local-6989586621679674710"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-20"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674720"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679674715"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674710"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-21"></span><span>  </span><span class="hs-comment">-- | prediction tensor</span><span>
</span><span id="line-22"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674719"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674718"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674717"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674716"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674715"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-23"></span><span>  </span><span class="hs-comment">-- | target tensor</span><span>
</span><span id="line-24"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674714"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674713"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674712"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674711"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674710"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-25"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-26"></span><span>  </span><span class="annot"><a href="#local-6989586621679674720"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-27"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-28"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679674719"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674714"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679674718"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674713"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679674717"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674712"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679674716"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679674711"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span id="local-6989586621679674709"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679674709"><span class="hs-identifier hs-var">prediction</span></a></span></span><span> </span><span id="mseLoss"><span class="annot"><span class="annottext">mseLoss :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        ('Shape '[]))
</span><a href="Torch.GraduallyTyped.NN.Functional.Loss.html#mseLoss"><span class="hs-operator hs-var hs-var">`mseLoss`</span></a></span></span><span> </span><span id="local-6989586621679674708"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679674708"><span class="hs-identifier hs-var">target</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-35"></span><span>  </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     ('Shape '[]))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        ('Shape '[]))
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      ('Shape '[]))
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         ('Shape '[])))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        ('Shape '[]))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        ('Shape '[]))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-36"></span><span>    </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Int
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        ('Shape '[]))
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span>
</span><span id="line-37"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mse_loss_ttl</span></a></span><span>
</span><span id="line-38"></span><span>      </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679674709"><span class="hs-identifier hs-var">prediction</span></a></span><span>
</span><span id="line-39"></span><span>      </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679674708"><span class="hs-identifier hs-var">target</span></a></span><span>
</span><span id="line-40"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span> </span><span class="hs-comment">-- reduce mean</span><span>
</span><span id="line-41"></span></pre></body></html>