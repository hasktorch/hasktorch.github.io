<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE LambdaCase #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE OverloadedStrings #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE StandaloneDeriving #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# OPTIONS_GHC -fno-warn-partial-type-signatures #-}</span><span>
</span><span id="line-15"></span><span>
</span><span id="line-16"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GEncoderOnly</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-17"></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNothing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier">EmbeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GLMHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier">GLMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier">LMHeadActivationF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier">LMHeadBiasF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier">LMHeadDecoderF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier">LMHeadDenseF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier">LMHeadLayerNormF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier">lmHeadSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GTransformer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#GTransformer"><span class="hs-identifier">GTransformer</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEFinalDropoutF"><span class="hs-identifier">TEFinalDropoutF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEFinalLayerNormF"><span class="hs-identifier">TEFinalLayerNormF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEInitialDropoutF"><span class="hs-identifier">TEInitialDropoutF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEInitialLayerNormF"><span class="hs-identifier">TEInitialLayerNormF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEPosEncF"><span class="hs-identifier">TEPosEncF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TERelPosEncF"><span class="hs-identifier">TERelPosEncF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEStackF"><span class="hs-identifier">TEStackF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#transformerEncoderSpec"><span class="hs-identifier">transformerEncoderSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerHead"><span class="hs-identifier">STransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier">TransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">head</span></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span>
</span><span id="line-43"></span><span class="hs-comment">-- | Data type that is used to represent whether the encoder-only transformer model has a scaled embedding.</span><span>
</span><span id="line-44"></span><span class="hs-keyword">data</span><span> </span><span id="EncoderOnlyTransformerHasEmbedScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerHasEmbedScaling</span></a></span></span><span>
</span><span id="line-45"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="EncoderOnlyTransformerWithEmbedScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithEmbedScaling</span></a></span></span><span>
</span><span id="line-46"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="EncoderOnlyTransformerWithoutEmbedScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span></span><span>
</span><span id="line-47"></span><span>
</span><span id="line-48"></span><span class="hs-comment">-- | Generic encoder-only transformer model.</span><span>
</span><span id="line-49"></span><span class="hs-comment">-- This is a transformer model that only encodes the input, e.g. BERT.</span><span>
</span><span id="line-50"></span><span class="hs-comment">--</span><span>
</span><span id="line-51"></span><span class="hs-comment">-- - @inputEmbedDim@: the dimension of the input embedding.</span><span>
</span><span id="line-52"></span><span class="hs-comment">-- - @encoder@: a transformer encoder.</span><span>
</span><span id="line-53"></span><span class="hs-comment">-- - @encoderEmbedding@: an embedding layer for the input.</span><span>
</span><span id="line-54"></span><span class="hs-comment">-- - @encoderTypeEmbedding@: an embedding layer for the type of the input.</span><span>
</span><span id="line-55"></span><span class="hs-comment">-- - @head@: a head layer for the output.</span><span>
</span><span id="line-56"></span><span class="hs-keyword">data</span><span>
</span><span id="line-57"></span><span>  </span><span id="GEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span></span><span>
</span><span id="line-58"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556279"><span class="annot"><a href="#local-6989586621679556279"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556278"><span class="annot"><a href="#local-6989586621679556278"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556277"><span class="annot"><a href="#local-6989586621679556277"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556276"><span class="annot"><a href="#local-6989586621679556276"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556275"><span class="annot"><a href="#local-6989586621679556275"><span class="hs-identifier hs-type">head</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-64"></span><span>  </span><span id="GEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-65"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679556583"><span class="annot"><a href="#local-6989586621679556583"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556582"><span class="annot"><a href="#local-6989586621679556582"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span id="local-6989586621679556581"><span class="annot"><a href="#local-6989586621679556581"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span></span><span> </span><span id="local-6989586621679556580"><span class="annot"><a href="#local-6989586621679556580"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span></span><span> </span><span id="local-6989586621679556579"><span class="annot"><a href="#local-6989586621679556579"><span class="hs-identifier hs-type">head</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-66"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | input embedding dim for scaling</span><span>
</span><span id="line-67"></span><span>      </span><span id="eotInputEmbedDim"><span class="annot"><span class="annottext">GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; SDim inputEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotInputEmbedDim"><span class="hs-identifier hs-var hs-var">eotInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556583"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-68"></span><span>      </span><span class="hs-comment">-- | encoder</span><span>
</span><span id="line-69"></span><span>      </span><span id="eotEncoder"><span class="annot"><span class="annottext">GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotEncoder"><span class="hs-identifier hs-var hs-var">eotEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556582"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-70"></span><span>      </span><span class="hs-comment">-- | encoder embedding</span><span>
</span><span id="line-71"></span><span>      </span><span id="eotEmbedding"><span class="annot"><span class="annottext">GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderEmbedding
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotEmbedding"><span class="hs-identifier hs-var hs-var">eotEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556581"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-72"></span><span>      </span><span class="hs-comment">-- | encoder type embedding</span><span>
</span><span id="line-73"></span><span>      </span><span id="eotTypeEmbedding"><span class="annot"><span class="annottext">GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderTypeEmbedding
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotTypeEmbedding"><span class="hs-identifier hs-var hs-var">eotTypeEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556580"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-74"></span><span>      </span><span class="hs-comment">-- | encoder head</span><span>
</span><span id="line-75"></span><span>      </span><span id="eotHead"><span class="annot"><span class="annottext">GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; head
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotHead"><span class="hs-identifier hs-var hs-var">eotHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556579"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-76"></span><span>      </span><span class="hs-comment">-- | encoder embedding scaling</span><span>
</span><span id="line-77"></span><span>      </span><span id="eotEmbedScaling"><span class="annot"><span class="annottext">GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotEmbedScaling"><span class="hs-identifier hs-var hs-var">eotEmbedScaling</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-79"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556583"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556582"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556581"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556580"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556579"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-80"></span><span>
</span><span id="line-81"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-82"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span id="local-6989586621679556267"><span class="annot"><a href="#local-6989586621679556267"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556266"><span class="annot"><a href="#local-6989586621679556266"><span class="hs-identifier hs-type hs-type">encoder</span></a></span></span><span> </span><span id="local-6989586621679556265"><span class="annot"><a href="#local-6989586621679556265"><span class="hs-identifier hs-type hs-type">encoderEmbedding</span></a></span></span><span> </span><span id="local-6989586621679556264"><span class="annot"><a href="#local-6989586621679556264"><span class="hs-identifier hs-type hs-type">encoderTypeEmbedding</span></a></span></span><span> </span><span id="local-6989586621679556263"><span class="annot"><a href="#local-6989586621679556263"><span class="hs-identifier hs-type hs-type">head</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-83"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556267"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556266"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556265"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556264"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556263"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>
</span><span id="line-85"></span><span class="hs-comment">-- | Specifies the encoder of the encoder-only transformer model.</span><span>
</span><span id="line-86"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-87"></span><span>  </span><span id="EOTEncoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEncoderF"><span class="hs-identifier hs-var">EOTEncoderF</span></a></span></span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556262"><span class="annot"><a href="#local-6989586621679556262"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556261"><span class="annot"><a href="#local-6989586621679556261"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556260"><span class="annot"><a href="#local-6989586621679556260"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-91"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556259"><span class="annot"><a href="#local-6989586621679556259"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-92"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556258"><span class="annot"><a href="#local-6989586621679556258"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556257"><span class="annot"><a href="#local-6989586621679556257"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556256"><span class="annot"><a href="#local-6989586621679556256"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556255"><span class="annot"><a href="#local-6989586621679556255"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556254"><span class="annot"><a href="#local-6989586621679556254"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556253"><span class="annot"><a href="#local-6989586621679556253"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556252"><span class="annot"><a href="#local-6989586621679556252"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-99"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-100"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-101"></span><span>  </span><span id="EOTEncoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEncoderF"><span class="hs-identifier hs-var">EOTEncoderF</span></a></span></span><span> </span><span id="local-6989586621679556251"><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679556250"><span class="annot"><a href="#local-6989586621679556250"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679556249"><span class="annot"><a href="#local-6989586621679556249"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679556248"><span class="annot"><a href="#local-6989586621679556248"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679556247"><span class="annot"><a href="#local-6989586621679556247"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679556246"><span class="annot"><a href="#local-6989586621679556246"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679556245"><span class="annot"><a href="#local-6989586621679556245"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556244"><span class="annot"><a href="#local-6989586621679556244"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679556243"><span class="annot"><a href="#local-6989586621679556243"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556242"><span class="annot"><a href="#local-6989586621679556242"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679556241"><span class="annot"><a href="#local-6989586621679556241"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-102"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span>
</span><span id="line-103"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#GTransformer"><span class="hs-identifier hs-type">GTransformer</span></a></span><span>
</span><span id="line-104"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEPosEncF"><span class="hs-identifier hs-type">TEPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556248"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556247"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556243"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556241"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TERelPosEncF"><span class="hs-identifier hs-type">TERelPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556248"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556247"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556246"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556241"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEInitialLayerNormF"><span class="hs-identifier hs-type">TEInitialLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556248"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556247"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556243"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEInitialDropoutF"><span class="hs-identifier hs-type">TEInitialDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEStackF"><span class="hs-identifier hs-type">TEStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556250"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556248"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556247"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556246"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556245"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556244"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556243"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556242"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEFinalLayerNormF"><span class="hs-identifier hs-type">TEFinalLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556248"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556247"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556243"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TEFinalDropoutF"><span class="hs-identifier hs-type">TEFinalDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556251"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>
</span><span id="line-113"></span><span class="hs-comment">-- | Specifies the embedding layer of the encoder-only transformer model.</span><span>
</span><span id="line-114"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-115"></span><span>  </span><span id="EOTEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEmbeddingF"><span class="hs-identifier hs-var">EOTEmbeddingF</span></a></span></span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556240"><span class="annot"><a href="#local-6989586621679556240"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556239"><span class="annot"><a href="#local-6989586621679556239"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556238"><span class="annot"><a href="#local-6989586621679556238"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556237"><span class="annot"><a href="#local-6989586621679556237"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556236"><span class="annot"><a href="#local-6989586621679556236"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556235"><span class="annot"><a href="#local-6989586621679556235"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-122"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-123"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-124"></span><span>  </span><span id="EOTEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEmbeddingF"><span class="hs-identifier hs-var">EOTEmbeddingF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679556234"><span class="annot"><a href="#local-6989586621679556234"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679556233"><span class="annot"><a href="#local-6989586621679556233"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679556232"><span class="annot"><a href="#local-6989586621679556232"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679556231"><span class="annot"><a href="#local-6989586621679556231"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556230"><span class="annot"><a href="#local-6989586621679556230"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-125"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556234"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679556233"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556232"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556230"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556231"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>
</span><span id="line-127"></span><span class="hs-comment">-- | Specifies the type embedding layer of the encoder-only transformer model.</span><span>
</span><span id="line-128"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-129"></span><span>  </span><span id="EOTTypeEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-var">EOTTypeEmbeddingF</span></a></span></span><span>
</span><span id="line-130"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556229"><span class="annot"><a href="#local-6989586621679556229"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-131"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556228"><span class="annot"><a href="#local-6989586621679556228"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-132"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556227"><span class="annot"><a href="#local-6989586621679556227"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556226"><span class="annot"><a href="#local-6989586621679556226"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556225"><span class="annot"><a href="#local-6989586621679556225"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-135"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556224"><span class="annot"><a href="#local-6989586621679556224"><span class="hs-identifier hs-type">typeVocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-136"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-137"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-138"></span><span>  </span><span id="EOTTypeEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-var">EOTTypeEmbeddingF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679556223"><span class="annot"><a href="#local-6989586621679556223"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679556222"><span class="annot"><a href="#local-6989586621679556222"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679556221"><span class="annot"><a href="#local-6989586621679556221"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679556220"><span class="annot"><a href="#local-6989586621679556220"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556219"><span class="annot"><a href="#local-6989586621679556219"><span class="hs-identifier hs-type hs-type">typeVocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-139"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556223"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679556222"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556221"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556219"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556220"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-140"></span><span>  </span><span id="EOTTypeEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-var">EOTTypeEmbeddingF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679556218"><span class="annot"><a href="#local-6989586621679556218"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679556217"><span class="annot"><a href="#local-6989586621679556217"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679556216"><span class="annot"><a href="#local-6989586621679556216"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679556215"><span class="annot"><a href="#local-6989586621679556215"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556214"><span class="annot"><a href="#local-6989586621679556214"><span class="hs-identifier hs-type hs-type">typeVocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-141"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-type">EOTTypeEmbeddingF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556218"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556216"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556215"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556214"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span>
</span><span id="line-142"></span><span>
</span><span id="line-143"></span><span class="hs-comment">-- | Specifies the head layer of the encoder-only transformer model.</span><span>
</span><span id="line-144"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-145"></span><span>  </span><span id="EOTHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-var">EOTHeadF</span></a></span></span><span>
</span><span id="line-146"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556213"><span class="annot"><a href="#local-6989586621679556213"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556212"><span class="annot"><a href="#local-6989586621679556212"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556211"><span class="annot"><a href="#local-6989586621679556211"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556210"><span class="annot"><a href="#local-6989586621679556210"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556209"><span class="annot"><a href="#local-6989586621679556209"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556208"><span class="annot"><a href="#local-6989586621679556208"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556207"><span class="annot"><a href="#local-6989586621679556207"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-153"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-154"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-155"></span><span>  </span><span id="EOTHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-var">EOTHeadF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-type">WithoutHead</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-156"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-157"></span><span>  </span><span id="EOTHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-var">EOTHeadF</span></a></span></span><span> </span><span id="local-6989586621679556205"><span class="annot"><a href="#local-6989586621679556205"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-type">WithLMHead</span></a></span><span> </span><span id="local-6989586621679556203"><span class="annot"><a href="#local-6989586621679556203"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679556202"><span class="annot"><a href="#local-6989586621679556202"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679556201"><span class="annot"><a href="#local-6989586621679556201"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679556200"><span class="annot"><a href="#local-6989586621679556200"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556199"><span class="annot"><a href="#local-6989586621679556199"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-158"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span>
</span><span id="line-159"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span>
</span><span id="line-160"></span><span>          </span><span class="annot"><a href="#local-6989586621679556200"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-161"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556205"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556203"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556202"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556201"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556200"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556205"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556205"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556203"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556202"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556201"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556200"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556205"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556203"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556202"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556201"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556200"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556199"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556205"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556203"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556202"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556201"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556199"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>
</span><span id="line-168"></span><span class="hs-comment">-- | Specifies the parameters of an encoder-only transformer model.</span><span>
</span><span id="line-169"></span><span class="hs-comment">--</span><span>
</span><span id="line-170"></span><span class="hs-comment">-- - @style@: the style of the encoder-only transformer model, e.g. 'SBERT', 'SRoBERTa', etc.</span><span>
</span><span id="line-171"></span><span class="hs-comment">-- - @transformerHead@: the head of the encoder-only transformer model.</span><span>
</span><span id="line-172"></span><span class="hs-comment">-- - @numLayers@: the number of layers of the encoder-only transformer model.</span><span>
</span><span id="line-173"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the model parameters</span><span>
</span><span id="line-174"></span><span class="hs-comment">-- - @device@: the computational device on which the model is allocated.</span><span>
</span><span id="line-175"></span><span class="hs-comment">-- - @dataType@: the data type of the model parameters.</span><span>
</span><span id="line-176"></span><span class="hs-comment">-- - @headDim@: the dimension of all transformer heads in the encoder-only transformer model.</span><span>
</span><span id="line-177"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the transformer head embeddings.</span><span>
</span><span id="line-178"></span><span class="hs-comment">-- - @embedDim@: the dimension of the transformer embeddings.</span><span>
</span><span id="line-179"></span><span class="hs-comment">-- - @inputEmbedDim@: the dimension of the input embeddings.</span><span>
</span><span id="line-180"></span><span class="hs-comment">-- - @ffnDim@: the dimension of the feed-forward network.</span><span>
</span><span id="line-181"></span><span class="hs-comment">-- - @posEncDim@: the dimension of the positional embeddings.</span><span>
</span><span id="line-182"></span><span class="hs-comment">-- - @vocabDim@: the dimension of the vocabulary.</span><span>
</span><span id="line-183"></span><span class="hs-comment">-- - @typeVocabDim@: the dimension of the type vocabulary.</span><span>
</span><span id="line-184"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-185"></span><span class="hs-comment">-- - @eps@: the epsilon value for numerical stability of the layer normalization.</span><span>
</span><span id="line-186"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#encoderOnlyTransformerSpec"><span class="hs-identifier hs-type">encoderOnlyTransformerSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-187"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679556197"><span class="annot"><a href="#local-6989586621679556197"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679556196"><span class="annot"><a href="#local-6989586621679556196"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679556195"><span class="annot"><a href="#local-6989586621679556195"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679556194"><span class="annot"><a href="#local-6989586621679556194"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679556193"><span class="annot"><a href="#local-6989586621679556193"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679556192"><span class="annot"><a href="#local-6989586621679556192"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679556191"><span class="annot"><a href="#local-6989586621679556191"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679556190"><span class="annot"><a href="#local-6989586621679556190"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556189"><span class="annot"><a href="#local-6989586621679556189"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679556188"><span class="annot"><a href="#local-6989586621679556188"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556187"><span class="annot"><a href="#local-6989586621679556187"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679556186"><span class="annot"><a href="#local-6989586621679556186"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679556185"><span class="annot"><a href="#local-6989586621679556185"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679556184"><span class="annot"><a href="#local-6989586621679556184"><span class="hs-identifier hs-type">typeVocabDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-188"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556197"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-189"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerHead"><span class="hs-identifier hs-type">STransformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556196"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-190"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556195"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-191"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556194"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-192"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556193"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-193"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556192"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-194"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556191"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-195"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556190"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-196"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556189"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-197"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556188"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-198"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556187"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-199"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556186"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-200"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556185"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-201"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556184"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-202"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-203"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-204"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span>
</span><span id="line-205"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span>
</span><span id="line-206"></span><span>        </span><span class="annot"><a href="#local-6989586621679556188"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-207"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEncoderF"><span class="hs-identifier hs-type">EOTEncoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556197"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556195"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556194"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556193"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556192"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556191"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556190"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556189"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556188"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556187"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556186"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEmbeddingF"><span class="hs-identifier hs-type">EOTEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556197"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556194"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556193"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556192"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556188"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556185"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-209"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-type">EOTTypeEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556197"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556194"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556193"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556192"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556188"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556184"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-210"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-type">EOTHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556197"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556196"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556194"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556193"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556192"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556188"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556185"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-211"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span id="encoderOnlyTransformerSpec"><span class="annot"><span class="annottext">encoderOnlyTransformerSpec :: STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; SDim vocabDim
-&gt; SDim typeVocabDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GEncoderOnlyTransformer
        inputEmbedDim
        (EOTEncoderF
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (EOTEmbeddingF
           style gradient device dataType inputEmbedDim vocabDim)
        (EOTTypeEmbeddingF
           style gradient device dataType inputEmbedDim typeVocabDim)
        (EOTHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#encoderOnlyTransformerSpec"><span class="hs-identifier hs-var hs-var">encoderOnlyTransformerSpec</span></a></span></span><span> </span><span id="local-6989586621679556183"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556183"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679556182"><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="#local-6989586621679556182"><span class="hs-identifier hs-var">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679556181"><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679556181"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span> </span><span id="local-6989586621679556180"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679556180"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679556179"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679556179"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679556178"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679556178"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679556177"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679556177"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679556176"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679556176"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556175"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679556175"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679556174"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556174"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556173"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679556173"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679556172"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679556172"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679556171"><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679556171"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679556170"><span class="annot"><span class="annottext">SDim typeVocabDim
</span><a href="#local-6989586621679556170"><span class="hs-identifier hs-var">typeVocabDim</span></a></span></span><span> </span><span id="local-6989586621679556169"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679556169"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679556168"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679556168"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-213"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679556167"><span class="annot"><span class="annottext">encoderSpec :: STransformerStyle style
-&gt; NamedModel
     (GTransformer
        (ModelSpec
           (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
        (ModelSpec
           (TERelPosEncF style gradient device dataType headDim posEncDim))
        (ModelSpec
           (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEInitialDropoutF style))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                Dropout))
                          Dropout
                          (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                          (FFNInputTransformationF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNActivationF style)
                          (FFNActivationDropoutF style)
                          (FFNOutputProjectionF
                             style gradient device dataType inputEmbedDim ffnDim)
                          Dropout
                          (FFNOutputLayerNormF
                             style gradient device dataType inputEmbedDim)))))))
        (ModelSpec
           (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEFinalDropoutF style)))
</span><a href="#local-6989586621679556167"><span class="hs-identifier hs-var hs-var">encoderSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-214"></span><span>      </span><span class="annot"><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-215"></span><span>      </span><span class="annot"><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-216"></span><span>      </span><span class="annot"><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-217"></span><span>      </span><span class="annot"><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-218"></span><span>      </span><span class="annot"><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     Dropout
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             Dropout))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        Dropout
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                Dropout))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;bert.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GTransformer
   (NamedModel
      (EmbeddingSpec
         gradient
         ('Layout 'Dense)
         device
         dataType
         posEncDim
         inputEmbedDim
         'Nothing))
   ()
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   Dropout
   (NamedModel
      (GTransformerStack
         (VectorSpec
            numLayers
            (GTransformerBlock
               (NamedModel
                  (GSelfAttention
                     ()
                     (NamedModel
                        (GMultiHeadAttention
                           headDim
                           headEmbedDim
                           embedDim
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, embedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           Dropout))
                     Dropout
                     (NamedModel
                        (LayerNorm
                           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
               ()
               (NamedModel
                  (GTransformerFeedForwardNetwork
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[ffnDim, inputEmbedDim])))
                           (NamedModel
                              (Tensor
                                 gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                     Gelu
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim, ffnDim])))
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))
                     Dropout
                     (NamedModel
                        (LayerNorm
                           'WithBias
                           gradient
                           device
                           dataType
                           ('Shape '[inputEmbedDim])))))))))
   ()
   ()
 -&gt; NamedModel
      (GTransformer
         (NamedModel
            (EmbeddingSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               posEncDim
               inputEmbedDim
               'Nothing))
         ()
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         Dropout
         (NamedModel
            (GTransformerStack
               (VectorSpec
                  numLayers
                  (GTransformerBlock
                     (NamedModel
                        (GSelfAttention
                           ()
                           (NamedModel
                              (GMultiHeadAttention
                                 headDim
                                 headEmbedDim
                                 embedDim
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim, embedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim])))))
                                 Dropout))
                           Dropout
                           (NamedModel
                              (LayerNorm
                                 'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                     ()
                     (NamedModel
                        (GTransformerFeedForwardNetwork
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim])))))
                           Gelu
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, ffnDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           Dropout
                           (NamedModel
                              (LayerNorm
                                 'WithBias
                                 gradient
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))))))
         ()
         ()))
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     Dropout
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             Dropout))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        Dropout
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                Dropout))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF 'BERT gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF 'BERT gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF 'BERT))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF 'BERT gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF 'BERT gradient device dataType inputEmbedDim embedDim)
                             (KInProjF 'BERT gradient device dataType inputEmbedDim embedDim)
                             (VInProjF 'BERT gradient device dataType inputEmbedDim embedDim)
                             (OutProjF 'BERT gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF 'BERT gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF 'BERT gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          'BERT gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF 'BERT)
                       (FFNActivationDropoutF 'BERT)
                       (FFNOutputProjectionF
                          'BERT gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          'BERT gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF 'BERT))
forall (style :: TransformerStyle).
STransformerStyle style
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style))
</span><a href="#local-6989586621679556158"><span class="hs-identifier hs-var">encoderSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span>
</span><span id="line-219"></span><span>      </span><span class="annot"><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     Dropout
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             Dropout))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        Dropout
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                Dropout))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;roberta.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GTransformer
   (NamedModel
      (EmbeddingSpec
         gradient
         ('Layout 'Dense)
         device
         dataType
         posEncDim
         inputEmbedDim
         'Nothing))
   ()
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   Dropout
   (NamedModel
      (GTransformerStack
         (VectorSpec
            numLayers
            (GTransformerBlock
               (NamedModel
                  (GSelfAttention
                     ()
                     (NamedModel
                        (GMultiHeadAttention
                           headDim
                           headEmbedDim
                           embedDim
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, embedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           Dropout))
                     Dropout
                     (NamedModel
                        (LayerNorm
                           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
               ()
               (NamedModel
                  (GTransformerFeedForwardNetwork
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[ffnDim, inputEmbedDim])))
                           (NamedModel
                              (Tensor
                                 gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                     Gelu
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim, ffnDim])))
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))
                     Dropout
                     (NamedModel
                        (LayerNorm
                           'WithBias
                           gradient
                           device
                           dataType
                           ('Shape '[inputEmbedDim])))))))))
   ()
   ()
 -&gt; NamedModel
      (GTransformer
         (NamedModel
            (EmbeddingSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               posEncDim
               inputEmbedDim
               'Nothing))
         ()
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         Dropout
         (NamedModel
            (GTransformerStack
               (VectorSpec
                  numLayers
                  (GTransformerBlock
                     (NamedModel
                        (GSelfAttention
                           ()
                           (NamedModel
                              (GMultiHeadAttention
                                 headDim
                                 headEmbedDim
                                 embedDim
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim, embedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim])))))
                                 Dropout))
                           Dropout
                           (NamedModel
                              (LayerNorm
                                 'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                     ()
                     (NamedModel
                        (GTransformerFeedForwardNetwork
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim])))))
                           Gelu
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, ffnDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           Dropout
                           (NamedModel
                              (LayerNorm
                                 'WithBias
                                 gradient
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))))))
         ()
         ()))
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     Dropout
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             Dropout))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       Dropout
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        Dropout
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                Dropout))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          Dropout
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF
           'RoBERTa gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF 'RoBERTa gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF
           'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF 'RoBERTa))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF 'RoBERTa gradient device dataType inputEmbedDim embedDim)
                             (KInProjF 'RoBERTa gradient device dataType inputEmbedDim embedDim)
                             (VInProjF 'RoBERTa gradient device dataType inputEmbedDim embedDim)
                             (OutProjF 'RoBERTa gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          'RoBERTa gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF 'RoBERTa)
                       (FFNActivationDropoutF 'RoBERTa)
                       (FFNOutputProjectionF
                          'RoBERTa gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF
           'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF 'RoBERTa))
forall (style :: TransformerStyle).
STransformerStyle style
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style))
</span><a href="#local-6989586621679556158"><span class="hs-identifier hs-var">encoderSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span>
</span><span id="line-220"></span><span>      </span><span class="annot"><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-221"></span><span>      </span><span id="local-6989586621679556155"><span class="annot"><span class="annottext">embeddingSpec :: STransformerStyle style
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679556155"><span class="hs-identifier hs-var hs-var">embeddingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-222"></span><span>      </span><span class="annot"><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-223"></span><span>      </span><span class="annot"><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-224"></span><span>      </span><span class="annot"><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-225"></span><span>      </span><span class="annot"><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-226"></span><span>      </span><span class="annot"><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;bert.embeddings.word_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679556154"><span class="hs-identifier hs-var">embeddingSpec'</span></a></span><span>
</span><span id="line-227"></span><span>      </span><span class="annot"><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;roberta.embeddings.word_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679556154"><span class="hs-identifier hs-var">embeddingSpec'</span></a></span><span>
</span><span id="line-228"></span><span>      </span><span class="annot"><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-229"></span><span>      </span><span id="local-6989586621679556153"><span class="annot"><span class="annottext">typeEmbeddingSpec :: STransformerStyle style
-&gt; ModelSpec
     (EOTTypeEmbeddingF
        style gradient device dataType inputEmbedDim typeVocabDim)
</span><a href="#local-6989586621679556153"><span class="hs-identifier hs-var hs-var">typeEmbeddingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-230"></span><span>      </span><span class="annot"><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-231"></span><span>      </span><span class="annot"><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-232"></span><span>      </span><span class="annot"><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-233"></span><span>      </span><span class="annot"><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-234"></span><span>      </span><span class="annot"><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     typeVocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        typeVocabDim
        inputEmbedDim
        'Nothing)
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;bert.embeddings.token_type_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  typeVocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679556152"><span class="hs-identifier hs-var">typeEmbeddingSpec'</span></a></span><span>
</span><span id="line-235"></span><span>      </span><span class="annot"><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     typeVocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        typeVocabDim
        inputEmbedDim
        'Nothing)
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;roberta.embeddings.token_type_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  typeVocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679556152"><span class="hs-identifier hs-var">typeEmbeddingSpec'</span></a></span><span>
</span><span id="line-236"></span><span>      </span><span class="annot"><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-237"></span><span>      </span><span id="local-6989586621679556151"><span class="annot"><span class="annottext">headSpec :: STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; ModelSpec
     (EOTHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679556151"><span class="hs-identifier hs-var hs-var">headSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-238"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-239"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-240"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-241"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-242"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-243"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;cls.predictions.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GLMHead
   inputEmbedDim
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim])))))
   Gelu
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[vocabDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
   (GBias ())
 -&gt; NamedModel
      (GLMHead
         inputEmbedDim
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim])))))
         Gelu
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[vocabDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
         (GBias ())))
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF 'BERT))
     (ModelSpec
        (LMHeadLayerNormF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           'BERT gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF 'BERT gradient device dataType vocabDim))
forall (style :: TransformerStyle).
STransformerStyle style
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="#local-6989586621679556148"><span class="hs-identifier hs-var">headSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span>
</span><span id="line-244"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-245"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GLMHead
   inputEmbedDim
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim])))))
   Gelu
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[vocabDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
   (GBias ())
 -&gt; NamedModel
      (GLMHead
         inputEmbedDim
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim])))))
         Gelu
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[vocabDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
         (GBias ())))
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF 'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF 'RoBERTa))
     (ModelSpec
        (LMHeadLayerNormF 'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           'RoBERTa gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec
        (LMHeadBiasF 'RoBERTa gradient device dataType vocabDim))
forall (style :: TransformerStyle).
STransformerStyle style
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="#local-6989586621679556148"><span class="hs-identifier hs-var">headSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span>
</span><span id="line-246"></span><span>      </span><span class="annot"><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-247"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-type">embedScalingSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556197"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span>
</span><span id="line-248"></span><span>      </span><span id="local-6989586621679556147"><span class="annot"><span class="annottext">embedScalingSpec :: STransformerStyle style -&gt; EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679556147"><span class="hs-identifier hs-var hs-var">embedScalingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-249"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-250"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-251"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-252"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-253"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span>
</span><span id="line-254"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span>
</span><span id="line-255"></span><span>      </span><span class="annot"><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-256"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; NamedModel
     (GTransformer
        (ModelSpec
           (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
        (ModelSpec
           (TERelPosEncF style gradient device dataType headDim posEncDim))
        (ModelSpec
           (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEInitialDropoutF style))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                Dropout))
                          Dropout
                          (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                          (FFNInputTransformationF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNActivationF style)
                          (FFNActivationDropoutF style)
                          (FFNOutputProjectionF
                             style gradient device dataType inputEmbedDim ffnDim)
                          Dropout
                          (FFNOutputLayerNormF
                             style gradient device dataType inputEmbedDim)))))))
        (ModelSpec
           (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEFinalDropoutF style)))
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
-&gt; ModelSpec
     (EOTTypeEmbeddingF
        style gradient device dataType inputEmbedDim typeVocabDim)
-&gt; ModelSpec
     (EOTHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim
     (NamedModel
        (GTransformer
           (ModelSpec
              (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
           (ModelSpec
              (TERelPosEncF style gradient device dataType headDim posEncDim))
           (ModelSpec
              (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
           (ModelSpec (TEInitialDropoutF style))
           (NamedModel
              (GTransformerStack
                 (VectorSpec
                    numLayers
                    (GTransformerBlock
                       (NamedModel
                          (GSelfAttention
                             (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                             (NamedModel
                                (GMultiHeadAttention
                                   headDim
                                   headEmbedDim
                                   embedDim
                                   (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                   (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                   (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                   (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                   Dropout))
                             Dropout
                             (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                       ()
                       (NamedModel
                          (GTransformerFeedForwardNetwork
                             (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                             (FFNInputTransformationF
                                style gradient device dataType inputEmbedDim ffnDim)
                             (FFNActivationF style)
                             (FFNActivationDropoutF style)
                             (FFNOutputProjectionF
                                style gradient device dataType inputEmbedDim ffnDim)
                             Dropout
                             (FFNOutputLayerNormF
                                style gradient device dataType inputEmbedDim)))))))
           (ModelSpec
              (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
           (ModelSpec (TEFinalDropoutF style))))
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing))
     (ModelSpec
        (EOTTypeEmbeddingF
           style gradient device dataType inputEmbedDim typeVocabDim))
     (ModelSpec
        (EOTHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; encoderEmbedding
-&gt; encoderTypeEmbedding
-&gt; head
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556174"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; NamedModel
     (GTransformer
        (ModelSpec
           (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
        (ModelSpec
           (TERelPosEncF style gradient device dataType headDim posEncDim))
        (ModelSpec
           (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEInitialDropoutF style))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                Dropout))
                          Dropout
                          (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                          (FFNInputTransformationF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNActivationF style)
                          (FFNActivationDropoutF style)
                          (FFNOutputProjectionF
                             style gradient device dataType inputEmbedDim ffnDim)
                          Dropout
                          (FFNOutputLayerNormF
                             style gradient device dataType inputEmbedDim)))))))
        (ModelSpec
           (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEFinalDropoutF style)))
</span><a href="#local-6989586621679556167"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556183"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679556155"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556183"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (EOTTypeEmbeddingF
        style gradient device dataType inputEmbedDim typeVocabDim)
</span><a href="#local-6989586621679556153"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556183"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; ModelSpec
     (EOTHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679556151"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556183"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="#local-6989586621679556182"><span class="hs-identifier hs-var">transformerHead</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679556147"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556183"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-258"></span><span>    </span><span class="annot"><a href="#local-6989586621679556158"><span class="hs-identifier hs-type">encoderSpec'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-259"></span><span>    </span><span id="local-6989586621679556158"><span class="annot"><span class="annottext">encoderSpec' :: STransformerStyle style
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             Dropout))
                       Dropout
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       Dropout
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style))
</span><a href="#local-6989586621679556158"><span class="hs-identifier hs-var hs-var">encoderSpec'</span></a></span></span><span> </span><span id="local-6989586621679556146"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556146"><span class="hs-identifier hs-var">style'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformer
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim)
        (TERelPosEncF style gradient device dataType headDim posEncDim)
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim)
        (TEInitialDropoutF style)
        (TEStackF
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim)
        (TEFinalDropoutF style))
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformer
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim)
        (TERelPosEncF style gradient device dataType headDim posEncDim)
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim)
        (TEInitialDropoutF style)
        (TEStackF
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim)
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim)
        (TEFinalDropoutF style))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#transformerEncoderSpec"><span class="hs-identifier hs-var">transformerEncoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556146"><span class="hs-identifier hs-var">style'</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679556181"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679556180"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679556179"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679556178"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679556177"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679556176"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679556175"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556174"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679556173"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679556172"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679556169"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679556168"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-260"></span><span>    </span><span id="local-6989586621679556154"><span class="annot"><span class="annottext">embeddingSpec' :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679556154"><span class="hs-identifier hs-var hs-var">embeddingSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim vocabDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679556180"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679556179"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679556178"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679556171"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556174"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-261"></span><span>    </span><span id="local-6989586621679556152"><span class="annot"><span class="annottext">typeEmbeddingSpec' :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  typeVocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679556152"><span class="hs-identifier hs-var hs-var">typeEmbeddingSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim typeVocabDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     typeVocabDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679556180"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679556179"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679556178"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim typeVocabDim
</span><a href="#local-6989586621679556170"><span class="hs-identifier hs-var">typeVocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556174"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-262"></span><span>    </span><span class="annot"><a href="#local-6989586621679556148"><span class="hs-identifier hs-type">headSpec'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-263"></span><span>    </span><span id="local-6989586621679556148"><span class="annot"><span class="annottext">headSpec' :: STransformerStyle style
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="#local-6989586621679556148"><span class="hs-identifier hs-var hs-var">headSpec'</span></a></span></span><span> </span><span id="local-6989586621679556142"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556142"><span class="hs-identifier hs-var">style'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; ModelSpec
     (GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; ModelSpec
     (GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier hs-var">lmHeadSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679556142"><span class="hs-identifier hs-var">style'</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679556180"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679556179"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679556178"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556174"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679556171"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679556168"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-264"></span><span>
</span><span id="line-265"></span><span id="local-6989586621679556136"><span id="local-6989586621679556137"><span id="local-6989586621679556138"><span id="local-6989586621679556139"><span id="local-6989586621679556140"><span id="local-6989586621679556141"><span class="hs-keyword">instance</span><span>
</span><span id="line-266"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556141"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556141"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-267"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556139"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556139"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-268"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556138"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556138"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-269"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556137"><span class="hs-identifier hs-type">head</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556137"><span class="hs-identifier hs-type">head</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-270"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-271"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-272"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556136"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556141"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556139"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556138"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556137"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-273"></span><span>    </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-274"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556136"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556141"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556139"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556138"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556137"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-275"></span><span>    </span><span class="annot"><a href="#local-6989586621679556140"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-276"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-277"></span><span>  </span><span id="local-6989586621679556133"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; Generator generatorDevice
-&gt; m (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head,
      Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span id="local-6989586621679556131"><span class="annot"><a href="#local-6989586621679556131"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556130"><span class="annot"><a href="#local-6989586621679556130"><span class="hs-identifier hs-var">encoderSpec</span></a></span></span><span> </span><span id="local-6989586621679556129"><span class="annot"><a href="#local-6989586621679556129"><span class="hs-identifier hs-var">encoderEmbeddingSpec</span></a></span></span><span> </span><span id="local-6989586621679556128"><span class="annot"><a href="#local-6989586621679556128"><span class="hs-identifier hs-var">encoderTypeEmbeddingSpec</span></a></span></span><span> </span><span id="local-6989586621679556127"><span class="annot"><a href="#local-6989586621679556127"><span class="hs-identifier hs-var">headSpec</span></a></span></span><span> </span><span id="local-6989586621679556126"><span class="annot"><a href="#local-6989586621679556126"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-278"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679556125"><span class="annot"><span class="annottext">encoder :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) encoder
</span><a href="#local-6989586621679556125"><span class="hs-identifier hs-var hs-var">encoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (encoder, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) encoder
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (encoder, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) encoder)
-&gt; (ModelSpec encoder
    -&gt; Generator generatorDevice
    -&gt; m (encoder, Generator generatorDevice))
-&gt; ModelSpec encoder
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) encoder
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoder
-&gt; Generator generatorDevice
-&gt; m (encoder, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec encoder
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) encoder)
-&gt; ModelSpec encoder
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) encoder
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoder
</span><a href="#local-6989586621679556130"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span>
</span><span id="line-279"></span><span>        </span><span id="local-6989586621679556122"><span class="annot"><span class="annottext">embedding :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  encoderEmbedding
</span><a href="#local-6989586621679556122"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (encoderEmbedding, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderEmbedding
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (encoderEmbedding, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      encoderEmbedding)
-&gt; (ModelSpec encoderEmbedding
    -&gt; Generator generatorDevice
    -&gt; m (encoderEmbedding, Generator generatorDevice))
-&gt; ModelSpec encoderEmbedding
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderEmbedding
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderEmbedding
-&gt; Generator generatorDevice
-&gt; m (encoderEmbedding, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec encoderEmbedding
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      encoderEmbedding)
-&gt; ModelSpec encoderEmbedding
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderEmbedding
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderEmbedding
</span><a href="#local-6989586621679556129"><span class="hs-identifier hs-var">encoderEmbeddingSpec</span></a></span><span>
</span><span id="line-280"></span><span>        </span><span id="local-6989586621679556121"><span class="annot"><span class="annottext">typeEmbedding :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  encoderTypeEmbedding
</span><a href="#local-6989586621679556121"><span class="hs-identifier hs-var hs-var">typeEmbedding</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (encoderTypeEmbedding, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderTypeEmbedding
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (encoderTypeEmbedding, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      encoderTypeEmbedding)
-&gt; (ModelSpec encoderTypeEmbedding
    -&gt; Generator generatorDevice
    -&gt; m (encoderTypeEmbedding, Generator generatorDevice))
-&gt; ModelSpec encoderTypeEmbedding
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderTypeEmbedding
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderTypeEmbedding
-&gt; Generator generatorDevice
-&gt; m (encoderTypeEmbedding, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec encoderTypeEmbedding
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      encoderTypeEmbedding)
-&gt; ModelSpec encoderTypeEmbedding
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderTypeEmbedding
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderTypeEmbedding
</span><a href="#local-6989586621679556128"><span class="hs-identifier hs-var">encoderTypeEmbeddingSpec</span></a></span><span>
</span><span id="line-281"></span><span>        </span><span id="local-6989586621679556120"><span class="annot"><span class="annottext">head :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) head
</span><a href="#local-6989586621679556120"><span class="hs-identifier hs-var hs-var">head</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice -&gt; m (head, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) head
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice -&gt; m (head, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) head)
-&gt; (ModelSpec head
    -&gt; Generator generatorDevice
    -&gt; m (head, Generator generatorDevice))
-&gt; ModelSpec head
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) head
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec head
-&gt; Generator generatorDevice -&gt; m (head, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec head
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) head)
-&gt; ModelSpec head
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) head
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec head
</span><a href="#local-6989586621679556127"><span class="hs-identifier hs-var">headSpec</span></a></span><span>
</span><span id="line-282"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; Generator generatorDevice
-&gt; m (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head,
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span>
</span><span id="line-283"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; encoder
-&gt; encoderEmbedding
-&gt; encoderTypeEmbedding
-&gt; head
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; encoderEmbedding
-&gt; encoderTypeEmbedding
-&gt; head
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556131"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-284"></span><span>              </span><span class="annot"><span class="annottext">(encoder
 -&gt; encoderEmbedding
 -&gt; encoderTypeEmbedding
 -&gt; head
 -&gt; EncoderOnlyTransformerHasEmbedScaling
 -&gt; GEncoderOnlyTransformer
      inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) encoder
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (encoderEmbedding
      -&gt; encoderTypeEmbedding
      -&gt; head
      -&gt; EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) encoder
</span><a href="#local-6989586621679556125"><span class="hs-identifier hs-var">encoder</span></a></span><span>
</span><span id="line-285"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (encoderEmbedding
   -&gt; encoderTypeEmbedding
   -&gt; head
   -&gt; EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderEmbedding
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (encoderTypeEmbedding
      -&gt; head
      -&gt; EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  encoderEmbedding
</span><a href="#local-6989586621679556122"><span class="hs-identifier hs-var">embedding</span></a></span><span>
</span><span id="line-286"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (encoderTypeEmbedding
   -&gt; head
   -&gt; EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     encoderTypeEmbedding
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (head
      -&gt; EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  encoderTypeEmbedding
</span><a href="#local-6989586621679556121"><span class="hs-identifier hs-var">typeEmbedding</span></a></span><span>
</span><span id="line-287"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (head
   -&gt; EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) head
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) head
</span><a href="#local-6989586621679556120"><span class="hs-identifier hs-var">head</span></a></span><span>
</span><span id="line-288"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     EncoderOnlyTransformerHasEmbedScaling
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     EncoderOnlyTransformerHasEmbedScaling
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679556126"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span>
</span><span id="line-289"></span><span>          </span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-290"></span><span>
</span><span id="line-291"></span><span id="local-6989586621679556114"><span id="local-6989586621679556115"><span id="local-6989586621679556116"><span id="local-6989586621679556117"><span id="local-6989586621679556118"><span class="hs-keyword">instance</span><span>
</span><span id="line-292"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556118"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-293"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556117"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-294"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556116"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-295"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556115"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-296"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-297"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556114"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556118"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556117"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556116"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556115"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-299"></span><span>  </span><span id="local-6989586621679556110"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; Text
-&gt; m (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span id="local-6989586621679556108"><span class="annot"><a href="#local-6989586621679556108"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679556107"><span class="annot"><a href="#local-6989586621679556107"><span class="hs-identifier hs-var">encoderSpec</span></a></span></span><span> </span><span id="local-6989586621679556106"><span class="annot"><a href="#local-6989586621679556106"><span class="hs-identifier hs-var">encoderEmbeddingSpec</span></a></span></span><span> </span><span id="local-6989586621679556105"><span class="annot"><a href="#local-6989586621679556105"><span class="hs-identifier hs-var">encoderTypeEmbeddingSpec</span></a></span></span><span> </span><span id="local-6989586621679556104"><span class="annot"><a href="#local-6989586621679556104"><span class="hs-identifier hs-var">headSpec</span></a></span></span><span> </span><span id="local-6989586621679556103"><span class="annot"><a href="#local-6989586621679556103"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679556102"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556102"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-300"></span><span>    </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; encoder
-&gt; encoderEmbedding
-&gt; encoderTypeEmbedding
-&gt; head
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; encoderEmbedding
-&gt; encoderTypeEmbedding
-&gt; head
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span><span>
</span><span id="line-301"></span><span>      </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679556108"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-302"></span><span>      </span><span class="annot"><span class="annottext">(encoder
 -&gt; encoderEmbedding
 -&gt; encoderTypeEmbedding
 -&gt; head
 -&gt; EncoderOnlyTransformerHasEmbedScaling
 -&gt; GEncoderOnlyTransformer
      inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; m encoder
-&gt; m (encoderEmbedding
      -&gt; encoderTypeEmbedding
      -&gt; head
      -&gt; EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoder -&gt; Text -&gt; m encoder
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoder
</span><a href="#local-6989586621679556107"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556102"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-303"></span><span>      </span><span class="annot"><span class="annottext">m (encoderEmbedding
   -&gt; encoderTypeEmbedding
   -&gt; head
   -&gt; EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; m encoderEmbedding
-&gt; m (encoderTypeEmbedding
      -&gt; head
      -&gt; EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderEmbedding -&gt; Text -&gt; m encoderEmbedding
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderEmbedding
</span><a href="#local-6989586621679556106"><span class="hs-identifier hs-var">encoderEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556102"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-304"></span><span>      </span><span class="annot"><span class="annottext">m (encoderTypeEmbedding
   -&gt; head
   -&gt; EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; m encoderTypeEmbedding
-&gt; m (head
      -&gt; EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderTypeEmbedding -&gt; Text -&gt; m encoderTypeEmbedding
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec encoderTypeEmbedding
</span><a href="#local-6989586621679556105"><span class="hs-identifier hs-var">encoderTypeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556102"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-305"></span><span>      </span><span class="annot"><span class="annottext">m (head
   -&gt; EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; m head
-&gt; m (EncoderOnlyTransformerHasEmbedScaling
      -&gt; GEncoderOnlyTransformer
           inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec head -&gt; Text -&gt; m head
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec head
</span><a href="#local-6989586621679556104"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556102"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-306"></span><span>      </span><span class="annot"><span class="annottext">m (EncoderOnlyTransformerHasEmbedScaling
   -&gt; GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; m EncoderOnlyTransformerHasEmbedScaling
-&gt; m (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
-&gt; m EncoderOnlyTransformerHasEmbedScaling
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679556103"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span>
</span><span id="line-307"></span><span>  </span><span id="local-6989586621679556100"><span class="annot"><span class="annottext">toStateDict :: Text
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679556098"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556098"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679556092"><span id="local-6989586621679556093"><span id="local-6989586621679556094"><span id="local-6989586621679556095"><span id="local-6989586621679556096"><span id="local-6989586621679556097"><span class="annot"><span class="annottext">encoder
encoderEmbedding
encoderTypeEmbedding
head
SDim inputEmbedDim
EncoderOnlyTransformerHasEmbedScaling
eotEmbedScaling :: EncoderOnlyTransformerHasEmbedScaling
eotHead :: head
eotTypeEmbedding :: encoderTypeEmbedding
eotEmbedding :: encoderEmbedding
eotEncoder :: encoder
eotInputEmbedDim :: SDim inputEmbedDim
eotEmbedScaling :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; EncoderOnlyTransformerHasEmbedScaling
eotHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; head
eotTypeEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderTypeEmbedding
eotEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderEmbedding
eotEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoder
eotInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679556092"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-308"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; encoder -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556098"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">encoder
</span><a href="#local-6989586621679556096"><span class="hs-identifier hs-var">eotEncoder</span></a></span><span>
</span><span id="line-309"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; encoderEmbedding -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556098"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">encoderEmbedding
</span><a href="#local-6989586621679556095"><span class="hs-identifier hs-var">eotEmbedding</span></a></span><span>
</span><span id="line-310"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; encoderTypeEmbedding -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556098"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">encoderTypeEmbedding
</span><a href="#local-6989586621679556094"><span class="hs-identifier hs-var">eotTypeEmbedding</span></a></span><span>
</span><span id="line-311"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; head -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556098"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">head
</span><a href="#local-6989586621679556093"><span class="hs-identifier hs-var">eotHead</span></a></span><span>
</span><span id="line-312"></span><span>    </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-313"></span><span>
</span><span id="line-314"></span><span class="hs-keyword">data</span><span>
</span><span id="line-315"></span><span>  </span><span id="GSimplifiedEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-var">GSimplifiedEncoderOnlyTransformer</span></a></span></span><span>
</span><span id="line-316"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556091"><span class="annot"><a href="#local-6989586621679556091"><span class="hs-identifier hs-type">model</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556090"><span class="annot"><a href="#local-6989586621679556090"><span class="hs-identifier hs-type">mkPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556089"><span class="annot"><a href="#local-6989586621679556089"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679556088"><span class="annot"><a href="#local-6989586621679556088"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-321"></span><span>  </span><span id="GSimplifiedEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-var">GSimplifiedEncoderOnlyTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-322"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679556449"><span class="annot"><a href="#local-6989586621679556449"><span class="hs-identifier hs-type">model</span></a></span></span><span> </span><span id="local-6989586621679556448"><span class="annot"><a href="#local-6989586621679556448"><span class="hs-identifier hs-type">mkPos</span></a></span></span><span> </span><span id="local-6989586621679556447"><span class="annot"><a href="#local-6989586621679556447"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679556446"><span class="annot"><a href="#local-6989586621679556446"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-323"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | encoder-only model</span><span>
</span><span id="line-324"></span><span>      </span><span id="seotModel"><span class="annot"><span class="annottext">GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; model
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotModel"><span class="hs-identifier hs-var hs-var">seotModel</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556449"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-325"></span><span>      </span><span class="hs-comment">-- | make input positions</span><span>
</span><span id="line-326"></span><span>      </span><span id="seotMkPos"><span class="annot"><span class="annottext">GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotMkPos"><span class="hs-identifier hs-var hs-var">seotMkPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556448"><span class="hs-identifier hs-type">mkPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-327"></span><span>      </span><span class="hs-comment">-- | make padding mask</span><span>
</span><span id="line-328"></span><span>      </span><span id="seotMkPaddingMask"><span class="annot"><span class="annottext">GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPaddingMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotMkPaddingMask"><span class="hs-identifier hs-var hs-var">seotMkPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556447"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-329"></span><span>      </span><span class="hs-comment">-- | make attention mask</span><span>
</span><span id="line-330"></span><span>      </span><span id="seotMkAttentionMask"><span class="annot"><span class="annottext">GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotMkAttentionMask"><span class="hs-identifier hs-var hs-var">seotMkAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556446"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-331"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-332"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556449"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556448"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556447"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556446"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-333"></span><span>
</span><span id="line-334"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-335"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span id="local-6989586621679556082"><span class="annot"><a href="#local-6989586621679556082"><span class="hs-identifier hs-type hs-type">model</span></a></span></span><span> </span><span id="local-6989586621679556081"><span class="annot"><a href="#local-6989586621679556081"><span class="hs-identifier hs-type hs-type">mkPos</span></a></span></span><span> </span><span id="local-6989586621679556080"><span class="annot"><a href="#local-6989586621679556080"><span class="hs-identifier hs-type hs-type">mkPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679556079"><span class="annot"><a href="#local-6989586621679556079"><span class="hs-identifier hs-type hs-type">mkAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-336"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556082"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556081"><span class="hs-identifier hs-type">mkPos</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556080"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556079"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-337"></span><span>
</span><span id="line-338"></span><span id="local-6989586621679556074"><span id="local-6989586621679556075"><span id="local-6989586621679556076"><span id="local-6989586621679556077"><span id="local-6989586621679556078"><span class="hs-keyword">instance</span><span>
</span><span id="line-339"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-340"></span><span>      </span><span class="annot"><a href="#local-6989586621679556078"><span class="hs-identifier hs-type">model</span></a></span><span>
</span><span id="line-341"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-342"></span><span>      </span><span class="annot"><a href="#local-6989586621679556078"><span class="hs-identifier hs-type">model</span></a></span><span>
</span><span id="line-343"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-344"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-345"></span><span>      </span><span class="annot"><a href="#local-6989586621679556076"><span class="hs-identifier hs-type">mkPos</span></a></span><span>
</span><span id="line-346"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-347"></span><span>      </span><span class="annot"><a href="#local-6989586621679556076"><span class="hs-identifier hs-type">mkPos</span></a></span><span>
</span><span id="line-348"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-349"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-350"></span><span>      </span><span class="annot"><a href="#local-6989586621679556075"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span>
</span><span id="line-351"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-352"></span><span>      </span><span class="annot"><a href="#local-6989586621679556075"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span>
</span><span id="line-353"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-354"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-355"></span><span>      </span><span class="annot"><a href="#local-6989586621679556074"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-356"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-357"></span><span>      </span><span class="annot"><a href="#local-6989586621679556074"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-358"></span><span>      </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-359"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-360"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-361"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556078"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556076"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556075"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556074"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>    </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-363"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556078"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556076"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556075"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556074"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-364"></span><span>    </span><span class="annot"><a href="#local-6989586621679556077"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-365"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-366"></span><span>  </span><span id="local-6989586621679556072"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
-&gt; Generator generatorDevice
-&gt; m (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask,
      Generator generatorDevice)
</span><a href="#local-6989586621679556072"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span id="local-6989586621679556071"><span class="annot"><a href="#local-6989586621679556071"><span class="hs-identifier hs-var">modelSpec</span></a></span></span><span> </span><span id="local-6989586621679556070"><span class="annot"><a href="#local-6989586621679556070"><span class="hs-identifier hs-var">mkPosSpec</span></a></span></span><span> </span><span id="local-6989586621679556069"><span class="annot"><a href="#local-6989586621679556069"><span class="hs-identifier hs-var">mkPaddingMaskSpec</span></a></span></span><span> </span><span id="local-6989586621679556068"><span class="annot"><a href="#local-6989586621679556068"><span class="hs-identifier hs-var">mkAttentionMaskSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-367"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
-&gt; Generator generatorDevice
-&gt; m (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask,
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span>
</span><span id="line-368"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">model
-&gt; mkPos
-&gt; mkPaddingMask
-&gt; mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
forall model mkPos mkPaddingMask mkAttentionMask.
model
-&gt; mkPos
-&gt; mkPaddingMask
-&gt; mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-var">GSimplifiedEncoderOnlyTransformer</span></a></span><span>
</span><span id="line-369"></span><span>          </span><span class="annot"><span class="annottext">(model
 -&gt; mkPos
 -&gt; mkPaddingMask
 -&gt; mkAttentionMask
 -&gt; GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) model
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (mkPos
      -&gt; mkPaddingMask
      -&gt; mkAttentionMask
      -&gt; GSimplifiedEncoderOnlyTransformer
           model mkPos mkPaddingMask mkAttentionMask)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Generator generatorDevice -&gt; m (model, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) model
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (model, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) model)
-&gt; (ModelSpec model
    -&gt; Generator generatorDevice
    -&gt; m (model, Generator generatorDevice))
-&gt; ModelSpec model
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) model
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (model, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec model
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) model)
-&gt; ModelSpec model
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) model
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec model
</span><a href="#local-6989586621679556071"><span class="hs-identifier hs-var">modelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-370"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (mkPos
   -&gt; mkPaddingMask
   -&gt; mkAttentionMask
   -&gt; GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) mkPos
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (mkPaddingMask
      -&gt; mkAttentionMask
      -&gt; GSimplifiedEncoderOnlyTransformer
           model mkPos mkPaddingMask mkAttentionMask)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Generator generatorDevice -&gt; m (mkPos, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) mkPos
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (mkPos, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) mkPos)
-&gt; (ModelSpec mkPos
    -&gt; Generator generatorDevice
    -&gt; m (mkPos, Generator generatorDevice))
-&gt; ModelSpec mkPos
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) mkPos
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPos
-&gt; Generator generatorDevice
-&gt; m (mkPos, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec mkPos
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) mkPos)
-&gt; ModelSpec mkPos
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) mkPos
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPos
</span><a href="#local-6989586621679556070"><span class="hs-identifier hs-var">mkPosSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-371"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (mkPaddingMask
   -&gt; mkAttentionMask
   -&gt; GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkPaddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (mkAttentionMask
      -&gt; GSimplifiedEncoderOnlyTransformer
           model mkPos mkPaddingMask mkAttentionMask)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (mkPaddingMask, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkPaddingMask
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (mkPaddingMask, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      mkPaddingMask)
-&gt; (ModelSpec mkPaddingMask
    -&gt; Generator generatorDevice
    -&gt; m (mkPaddingMask, Generator generatorDevice))
-&gt; ModelSpec mkPaddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkPaddingMask
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPaddingMask
-&gt; Generator generatorDevice
-&gt; m (mkPaddingMask, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec mkPaddingMask
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      mkPaddingMask)
-&gt; ModelSpec mkPaddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkPaddingMask
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPaddingMask
</span><a href="#local-6989586621679556069"><span class="hs-identifier hs-var">mkPaddingMaskSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-372"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (mkAttentionMask
   -&gt; GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkAttentionMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (mkAttentionMask, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkAttentionMask
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (mkAttentionMask, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      mkAttentionMask)
-&gt; (ModelSpec mkAttentionMask
    -&gt; Generator generatorDevice
    -&gt; m (mkAttentionMask, Generator generatorDevice))
-&gt; ModelSpec mkAttentionMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkAttentionMask
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkAttentionMask
-&gt; Generator generatorDevice
-&gt; m (mkAttentionMask, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec mkAttentionMask
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      mkAttentionMask)
-&gt; ModelSpec mkAttentionMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     mkAttentionMask
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkAttentionMask
</span><a href="#local-6989586621679556068"><span class="hs-identifier hs-var">mkAttentionMaskSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-373"></span><span>      </span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-374"></span><span>
</span><span id="line-375"></span><span id="local-6989586621679556064"><span id="local-6989586621679556065"><span id="local-6989586621679556066"><span id="local-6989586621679556067"><span class="hs-keyword">instance</span><span>
</span><span id="line-376"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556067"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-377"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556066"><span class="hs-identifier hs-type">mkPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-378"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556065"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-379"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556064"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-380"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-381"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556067"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556066"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556065"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556064"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-382"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-383"></span><span>  </span><span id="local-6989586621679556061"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
-&gt; Text
-&gt; m (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
</span><a href="#local-6989586621679556061"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span id="local-6989586621679556060"><span class="annot"><a href="#local-6989586621679556060"><span class="hs-identifier hs-var">modelSpec</span></a></span></span><span> </span><span id="local-6989586621679556059"><span class="annot"><a href="#local-6989586621679556059"><span class="hs-identifier hs-var">mkPosSpec</span></a></span></span><span> </span><span id="local-6989586621679556058"><span class="annot"><a href="#local-6989586621679556058"><span class="hs-identifier hs-var">mkPaddingMaskSpec</span></a></span></span><span> </span><span id="local-6989586621679556057"><span class="annot"><a href="#local-6989586621679556057"><span class="hs-identifier hs-var">mkAttentionMaskSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679556056"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556056"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-384"></span><span>    </span><span class="annot"><span class="annottext">model
-&gt; mkPos
-&gt; mkPaddingMask
-&gt; mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
forall model mkPos mkPaddingMask mkAttentionMask.
model
-&gt; mkPos
-&gt; mkPaddingMask
-&gt; mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-var">GSimplifiedEncoderOnlyTransformer</span></a></span><span>
</span><span id="line-385"></span><span>      </span><span class="annot"><span class="annottext">(model
 -&gt; mkPos
 -&gt; mkPaddingMask
 -&gt; mkAttentionMask
 -&gt; GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask)
-&gt; m model
-&gt; m (mkPos
      -&gt; mkPaddingMask
      -&gt; mkAttentionMask
      -&gt; GSimplifiedEncoderOnlyTransformer
           model mkPos mkPaddingMask mkAttentionMask)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec model -&gt; Text -&gt; m model
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec model
</span><a href="#local-6989586621679556060"><span class="hs-identifier hs-var">modelSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556056"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-386"></span><span>      </span><span class="annot"><span class="annottext">m (mkPos
   -&gt; mkPaddingMask
   -&gt; mkAttentionMask
   -&gt; GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
-&gt; m mkPos
-&gt; m (mkPaddingMask
      -&gt; mkAttentionMask
      -&gt; GSimplifiedEncoderOnlyTransformer
           model mkPos mkPaddingMask mkAttentionMask)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPos -&gt; Text -&gt; m mkPos
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPos
</span><a href="#local-6989586621679556059"><span class="hs-identifier hs-var">mkPosSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556056"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-387"></span><span>      </span><span class="annot"><span class="annottext">m (mkPaddingMask
   -&gt; mkAttentionMask
   -&gt; GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
-&gt; m mkPaddingMask
-&gt; m (mkAttentionMask
      -&gt; GSimplifiedEncoderOnlyTransformer
           model mkPos mkPaddingMask mkAttentionMask)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPaddingMask -&gt; Text -&gt; m mkPaddingMask
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkPaddingMask
</span><a href="#local-6989586621679556058"><span class="hs-identifier hs-var">mkPaddingMaskSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556056"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-388"></span><span>      </span><span class="annot"><span class="annottext">m (mkAttentionMask
   -&gt; GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
-&gt; m mkAttentionMask
-&gt; m (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkAttentionMask -&gt; Text -&gt; m mkAttentionMask
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec mkAttentionMask
</span><a href="#local-6989586621679556057"><span class="hs-identifier hs-var">mkAttentionMaskSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556056"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-389"></span><span>  </span><span id="local-6989586621679556055"><span class="annot"><span class="annottext">toStateDict :: Text
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; m ()
</span><a href="#local-6989586621679556055"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679556054"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556054"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679556050"><span id="local-6989586621679556051"><span id="local-6989586621679556052"><span id="local-6989586621679556053"><span class="annot"><span class="annottext">model
mkPos
mkPaddingMask
mkAttentionMask
seotMkAttentionMask :: mkAttentionMask
seotMkPaddingMask :: mkPaddingMask
seotMkPos :: mkPos
seotModel :: model
seotMkAttentionMask :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkAttentionMask
seotMkPaddingMask :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPaddingMask
seotMkPos :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPos
seotModel :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; model
</span><a href="#local-6989586621679556050"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-390"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; model -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556054"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679556053"><span class="hs-identifier hs-var">seotModel</span></a></span><span>
</span><span id="line-391"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; mkPos -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556054"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">mkPos
</span><a href="#local-6989586621679556052"><span class="hs-identifier hs-var">seotMkPos</span></a></span><span>
</span><span id="line-392"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; mkPaddingMask -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556054"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">mkPaddingMask
</span><a href="#local-6989586621679556051"><span class="hs-identifier hs-var">seotMkPaddingMask</span></a></span><span>
</span><span id="line-393"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; mkAttentionMask -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679556054"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">mkAttentionMask
</span><a href="#local-6989586621679556050"><span class="hs-identifier hs-var">seotMkAttentionMask</span></a></span><span>
</span><span id="line-394"></span><span>    </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-395"></span><span>
</span><span id="line-396"></span><span class="hs-comment">-- | Input data type for use with an encoder-only transformer.</span><span>
</span><span id="line-397"></span><span class="hs-keyword">data</span><span> </span><span id="EncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-var">EncoderOnlyTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679556049"><span class="annot"><a href="#local-6989586621679556049"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679556048"><span class="annot"><a href="#local-6989586621679556048"><span class="hs-identifier hs-type">inputType</span></a></span></span><span> </span><span id="local-6989586621679556047"><span class="annot"><a href="#local-6989586621679556047"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679556046"><span class="annot"><a href="#local-6989586621679556046"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-398"></span><span>  </span><span id="EncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-var">EncoderOnlyTransformerInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-399"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679556362"><span class="annot"><a href="#local-6989586621679556362"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679556361"><span class="annot"><a href="#local-6989586621679556361"><span class="hs-identifier hs-type">inputType</span></a></span></span><span> </span><span id="local-6989586621679556360"><span class="annot"><a href="#local-6989586621679556360"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679556359"><span class="annot"><a href="#local-6989586621679556359"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-400"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="eotInput"><span class="annot"><span class="annottext">EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; input
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotInput"><span class="hs-identifier hs-var hs-var">eotInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556362"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-401"></span><span>      </span><span id="eotInputType"><span class="annot"><span class="annottext">EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; inputType
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotInputType"><span class="hs-identifier hs-var hs-var">eotInputType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556361"><span class="hs-identifier hs-type">inputType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-402"></span><span>      </span><span id="eotPos"><span class="annot"><span class="annottext">EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; pos
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotPos"><span class="hs-identifier hs-var hs-var">eotPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556360"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-403"></span><span>      </span><span id="eotAttentionMask"><span class="annot"><span class="annottext">EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; attentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotAttentionMask"><span class="hs-identifier hs-var hs-var">eotAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556359"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-404"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-405"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556362"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556361"><span class="hs-identifier hs-type">inputType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556360"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556359"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-406"></span><span>
</span><span id="line-407"></span><span id="local-6989586621679556031"><span id="local-6989586621679556033"><span id="local-6989586621679556035"><span id="local-6989586621679556037"><span id="local-6989586621679556038"><span id="local-6989586621679556039"><span id="local-6989586621679556040"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-408"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679556040"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-409"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679556039"><span class="hs-identifier hs-type">inputType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-410"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679556038"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-411"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679556037"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-412"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-413"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556040"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556039"><span class="hs-identifier hs-type">inputType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556038"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556037"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span><span>
</span><span id="line-414"></span><span>
</span><span id="line-415"></span><span class="hs-keyword">data</span><span> </span><span id="SimplifiedEncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679556029"><span class="annot"><a href="#local-6989586621679556029"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679556028"><span class="annot"><a href="#local-6989586621679556028"><span class="hs-identifier hs-type">inputType</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-416"></span><span>  </span><span id="SimplifiedEncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-417"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679556301"><span class="annot"><a href="#local-6989586621679556301"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679556300"><span class="annot"><a href="#local-6989586621679556300"><span class="hs-identifier hs-type">inputType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-418"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="seotInput"><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerInput input inputType -&gt; input
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotInput"><span class="hs-identifier hs-var hs-var">seotInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556301"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-419"></span><span>      </span><span id="seotInputType"><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerInput input inputType -&gt; inputType
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotInputType"><span class="hs-identifier hs-var hs-var">seotInputType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556300"><span class="hs-identifier hs-type">inputType</span></a></span><span>
</span><span id="line-420"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-421"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556301"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556300"><span class="hs-identifier hs-type">inputType</span></a></span><span>
</span><span id="line-422"></span><span>
</span><span id="line-423"></span><span class="hs-comment">-- | Output data type for use with an encoder-only transformer.</span><span>
</span><span id="line-424"></span><span class="hs-keyword">data</span><span> </span><span id="EncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">EncoderOnlyTransformerOutput</span></a></span></span><span> </span><span id="local-6989586621679556024"><span class="annot"><a href="#local-6989586621679556024"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-425"></span><span>  </span><span id="EncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">EncoderOnlyTransformerOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-426"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679556315"><span class="annot"><a href="#local-6989586621679556315"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-427"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="eotOutput"><span class="annot"><span class="annottext">EncoderOnlyTransformerOutput output -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotOutput"><span class="hs-identifier hs-var hs-var">eotOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556315"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-428"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-429"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556315"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-430"></span><span>
</span><span id="line-431"></span><span id="local-6989586621679556015"><span id="local-6989586621679556017"><span id="local-6989586621679556019"><span id="local-6989586621679556021"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-432"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679556021"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-433"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-434"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556021"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-435"></span><span>
</span><span id="line-436"></span><span class="hs-keyword">data</span><span> </span><span id="SimplifiedEncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerOutput</span></a></span></span><span> </span><span id="local-6989586621679556014"><span class="annot"><a href="#local-6989586621679556014"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span id="local-6989586621679556013"><span class="annot"><a href="#local-6989586621679556013"><span class="hs-identifier hs-type">paddingMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-437"></span><span>  </span><span id="SimplifiedEncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-438"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679556297"><span class="annot"><a href="#local-6989586621679556297"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span id="local-6989586621679556296"><span class="annot"><a href="#local-6989586621679556296"><span class="hs-identifier hs-type">paddingMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-439"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="seotOutput"><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerOutput output paddingMask -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotOutput"><span class="hs-identifier hs-var hs-var">seotOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556297"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-440"></span><span>      </span><span id="sedtPaddingMask"><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; paddingMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#sedtPaddingMask"><span class="hs-identifier hs-var hs-var">sedtPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679556296"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-441"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-442"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556297"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556296"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-443"></span><span>
</span><span id="line-444"></span><span class="hs-comment">-- | 'HasForward' instance for encoder-only transformers with optional scaling and head.</span><span>
</span><span id="line-445"></span><span class="hs-comment">--</span><span>
</span><span id="line-446"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-447"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-448"></span><span class="hs-comment">--    &#9474; input &#9474;    &#9474; inputType &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-449"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-450"></span><span class="hs-comment">--        &#9474;              &#9474;           &#9474;            &#9474;</span><span>
</span><span id="line-451"></span><span class="hs-comment">--        &#9660;              &#9660;           &#9474;            &#9474;</span><span>
</span><span id="line-452"></span><span class="hs-comment">--  eotEmbedding  eotTypeEmbedding   &#9474;            &#9474;</span><span>
</span><span id="line-453"></span><span class="hs-comment">--        &#9660;              &#9660;           &#9474;            &#9474;</span><span>
</span><span id="line-454"></span><span class="hs-comment">-- (embedScaling)  (embedScaling)    &#9474;            &#9474;</span><span>
</span><span id="line-455"></span><span class="hs-comment">--        &#9474;              &#9474;           &#9474;            &#9474;</span><span>
</span><span id="line-456"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;           &#9474;            &#9474;</span><span>
</span><span id="line-457"></span><span class="hs-comment">--               &#9474;                   &#9474;            &#9474;</span><span>
</span><span id="line-458"></span><span class="hs-comment">--               &#9660;                   &#9474;            &#9474;</span><span>
</span><span id="line-459"></span><span class="hs-comment">--          eotEncoder&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-460"></span><span class="hs-comment">--               &#9660;</span><span>
</span><span id="line-461"></span><span class="hs-comment">--           (eotHead)</span><span>
</span><span id="line-462"></span><span class="hs-comment">--               &#9474;</span><span>
</span><span id="line-463"></span><span class="hs-comment">--               &#9660;</span><span>
</span><span id="line-464"></span><span class="hs-comment">--          &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-465"></span><span class="hs-comment">--          &#9474; output &#9474;</span><span>
</span><span id="line-466"></span><span class="hs-comment">--          &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-467"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-468"></span><span id="local-6989586621679555982"><span id="local-6989586621679555983"><span id="local-6989586621679555984"><span id="local-6989586621679555985"><span id="local-6989586621679555986"><span id="local-6989586621679555987"><span id="local-6989586621679555988"><span id="local-6989586621679555989"><span id="local-6989586621679555990"><span id="local-6989586621679555991"><span id="local-6989586621679555992"><span id="local-6989586621679555993"><span id="local-6989586621679555994"><span id="local-6989586621679555995"><span id="local-6989586621679555996"><span id="local-6989586621679555997"><span id="local-6989586621679555998"><span id="local-6989586621679555999"><span id="local-6989586621679556000"><span id="local-6989586621679556001"><span id="local-6989586621679556002"><span id="local-6989586621679556003"><span id="local-6989586621679556004"><span id="local-6989586621679556005"><span id="local-6989586621679556006"><span id="local-6989586621679556007"><span id="local-6989586621679556008"><span id="local-6989586621679556009"><span class="hs-keyword">instance</span><span>
</span><span id="line-469"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-470"></span><span>      </span><span class="annot"><a href="#local-6989586621679556009"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span>
</span><span id="line-471"></span><span>      </span><span class="annot"><a href="#local-6989586621679556008"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-472"></span><span>      </span><span class="annot"><a href="#local-6989586621679556007"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-473"></span><span>      </span><span class="annot"><a href="#local-6989586621679556006"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span>
</span><span id="line-474"></span><span>      </span><span class="annot"><a href="#local-6989586621679556005"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-475"></span><span>    </span><span class="annot"><a href="#local-6989586621679556006"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556004"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556003"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556002"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556001"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556000"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-477"></span><span>      </span><span class="annot"><a href="#local-6989586621679555999"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span>
</span><span id="line-478"></span><span>      </span><span class="annot"><a href="#local-6989586621679555998"><span class="hs-identifier hs-type">inputType</span></a></span><span>
</span><span id="line-479"></span><span>      </span><span class="annot"><a href="#local-6989586621679556005"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice</span></a></span><span>
</span><span id="line-480"></span><span>      </span><span class="annot"><a href="#local-6989586621679555997"><span class="hs-identifier hs-type">typeEmbeddingOutput</span></a></span><span>
</span><span id="line-481"></span><span>      </span><span class="annot"><a href="#local-6989586621679555996"><span class="hs-identifier hs-type">typeEmbeddingGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-482"></span><span>    </span><span class="annot"><a href="#local-6989586621679555997"><span class="hs-identifier hs-type">typeEmbeddingOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555995"><span class="hs-identifier hs-type">gradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555994"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555993"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555992"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555991"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-483"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-484"></span><span>      </span><span class="annot"><a href="#local-6989586621679555990"><span class="hs-identifier hs-type">encoder</span></a></span><span>
</span><span id="line-485"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-486"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679556004"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555995"><span class="hs-identifier hs-type">gradient''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679556003"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555994"><span class="hs-identifier hs-type">layout''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-488"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679556002"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555993"><span class="hs-identifier hs-type">device''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-489"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679556001"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555992"><span class="hs-identifier hs-type">dataType''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-490"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556000"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555991"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-491"></span><span>        </span><span class="annot"><a href="#local-6989586621679555989"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-492"></span><span>        </span><span class="annot"><a href="#local-6989586621679555988"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-493"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-494"></span><span>      </span><span class="annot"><a href="#local-6989586621679555996"><span class="hs-identifier hs-type">typeEmbeddingGeneratorOutputDevice</span></a></span><span>
</span><span id="line-495"></span><span>      </span><span class="annot"><a href="#local-6989586621679555987"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-496"></span><span>      </span><span class="annot"><a href="#local-6989586621679555986"><span class="hs-identifier hs-type">encoderGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-497"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-498"></span><span>      </span><span class="annot"><a href="#local-6989586621679555985"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-499"></span><span>      </span><span class="annot"><a href="#local-6989586621679555987"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-500"></span><span>      </span><span class="annot"><a href="#local-6989586621679555986"><span class="hs-identifier hs-type">encoderGeneratorOutputDevice</span></a></span><span>
</span><span id="line-501"></span><span>      </span><span class="annot"><a href="#local-6989586621679555984"><span class="hs-identifier hs-type">headOutput</span></a></span><span>
</span><span id="line-502"></span><span>      </span><span class="annot"><a href="#local-6989586621679555983"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-503"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-504"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-505"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555982"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555990"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556009"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555999"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555985"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-506"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679556008"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555998"><span class="hs-identifier hs-type">inputType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555989"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555988"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-507"></span><span>    </span><span class="annot"><a href="#local-6989586621679556007"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-508"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555984"><span class="hs-identifier hs-type">headOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-509"></span><span>    </span><span class="annot"><a href="#local-6989586621679555983"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-510"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-511"></span><span>  </span><span id="local-6989586621679555979"><span class="annot"><span class="annottext">forward :: GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput headOutput,
      Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679555972"><span id="local-6989586621679555973"><span id="local-6989586621679555974"><span id="local-6989586621679555975"><span id="local-6989586621679555976"><span id="local-6989586621679555977"><span class="annot"><span class="annottext">encoderEmbedding
encoderTypeEmbedding
encoder
head
SDim inputEmbedDim
EncoderOnlyTransformerHasEmbedScaling
eotEmbedScaling :: EncoderOnlyTransformerHasEmbedScaling
eotHead :: head
eotTypeEmbedding :: encoderTypeEmbedding
eotEmbedding :: encoderEmbedding
eotEncoder :: encoder
eotInputEmbedDim :: SDim inputEmbedDim
eotEmbedScaling :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; EncoderOnlyTransformerHasEmbedScaling
eotHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; head
eotTypeEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderTypeEmbedding
eotEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderEmbedding
eotEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoder
eotInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679555972"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679555968"><span id="local-6989586621679555969"><span id="local-6989586621679555970"><span id="local-6989586621679555971"><span class="annot"><span class="annottext">input
inputType
pos
attentionMask
eotAttentionMask :: attentionMask
eotPos :: pos
eotInputType :: inputType
eotInput :: input
eotAttentionMask :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; attentionMask
eotPos :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; pos
eotInputType :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; inputType
eotInput :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; input
</span><a href="#local-6989586621679555968"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-512"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679555967"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679555967"><span class="hs-identifier hs-var">scaling</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679555977"><span class="hs-identifier hs-var">eotInputEmbedDim</span></a></span><span>
</span><span id="line-513"></span><span>        </span><span id="local-6989586621679555964"><span class="annot"><span class="annottext">embeddedInput :: IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient' layout' device' dataType' shape')
</span><a href="#local-6989586621679555964"><span class="hs-identifier hs-var hs-var">embeddedInput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-514"></span><span>          </span><span class="annot"><span class="annottext">input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679555971"><span class="hs-identifier hs-var">eotInput</span></a></span><span>
</span><span id="line-515"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) input
-&gt; (input
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator embeddingGeneratorOutputDevice)
         (Tensor gradient' layout' device' dataType' shape'))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor gradient' layout' device' dataType' shape',
       Generator embeddingGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor gradient' layout' device' dataType' shape',
        Generator embeddingGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator embeddingGeneratorOutputDevice)
      (Tensor gradient' layout' device' dataType' shape'))
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (Tensor gradient' layout' device' dataType' shape',
          Generator embeddingGeneratorOutputDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">encoderEmbedding
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient' layout' device' dataType' shape',
      Generator embeddingGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">encoderEmbedding
</span><a href="#local-6989586621679555975"><span class="hs-identifier hs-var">eotEmbedding</span></a></span><span>
</span><span id="line-516"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient' layout' device' dataType' shape')
-&gt; (Tensor gradient' layout' device' dataType' shape'
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice)
         (Generator embeddingGeneratorOutputDevice)
         (Tensor gradient' layout' device' dataType' shape'))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span>
</span><span id="line-517"></span><span>              </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice)
      (Generator embeddingGeneratorOutputDevice)
      (Tensor gradient' layout' device' dataType' shape'))
-&gt; (Tensor gradient' layout' device' dataType' shape'
    -&gt; Tensor gradient' layout' device' dataType' shape')
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-518"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient' layout' device' dataType' shape'
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-519"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape')
-&gt; Double
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient' layout' device' dataType' shape'
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape'
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679555967"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-520"></span><span>                </span><span class="hs-special">)</span><span>
</span><span id="line-521"></span><span>                </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679555972"><span class="hs-identifier hs-var">eotEmbedScaling</span></a></span><span>
</span><span id="line-522"></span><span>        </span><span id="local-6989586621679555961"><span class="annot"><span class="annottext">embeddedInputType :: IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape'')
</span><a href="#local-6989586621679555961"><span class="hs-identifier hs-var hs-var">embeddedInputType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-523"></span><span>          </span><span class="annot"><span class="annottext">inputType
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     inputType
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">inputType
</span><a href="#local-6989586621679555970"><span class="hs-identifier hs-var">eotInputType</span></a></span><span>
</span><span id="line-524"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator embeddingGeneratorOutputDevice)
  inputType
-&gt; (inputType
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice)
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator embeddingGeneratorOutputDevice
 -&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
       Generator typeEmbeddingGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator embeddingGeneratorOutputDevice
  -&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
        Generator typeEmbeddingGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice)
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; (inputType
    -&gt; Generator embeddingGeneratorOutputDevice
    -&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
          Generator typeEmbeddingGeneratorOutputDevice))
-&gt; inputType
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">encoderTypeEmbedding
-&gt; inputType
-&gt; Generator embeddingGeneratorOutputDevice
-&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
      Generator typeEmbeddingGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">encoderTypeEmbedding
</span><a href="#local-6989586621679555974"><span class="hs-identifier hs-var">eotTypeEmbedding</span></a></span><span>
</span><span id="line-525"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor gradient'' layout'' device'' dataType'' shape''
    -&gt; IxStateT
         m
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span>
</span><span id="line-526"></span><span>              </span><span class="annot"><span class="annottext">(Tensor gradient'' layout'' device'' dataType'' shape''
 -&gt; IxStateT
      m
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; (Tensor gradient'' layout'' device'' dataType'' shape''
    -&gt; Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-527"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-528"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient'' layout'' device'' dataType'' shape''
 -&gt; Double
 -&gt; Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; Double
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Double -&gt; Tensor gradient'' layout'' device'' dataType'' shape''
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679555967"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-529"></span><span>                </span><span class="hs-special">)</span><span>
</span><span id="line-530"></span><span>                </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679555972"><span class="hs-identifier hs-var">eotEmbedScaling</span></a></span><span>
</span><span id="line-531"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (EncoderOnlyTransformerOutput headOutput)
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput headOutput,
      Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   (EncoderOnlyTransformerOutput headOutput)
 -&gt; Generator generatorDevice
 -&gt; m (EncoderOnlyTransformerOutput headOutput,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput headOutput,
      Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-532"></span><span>          </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient' gradient'')
     (Unify (Layout LayoutType) layout' layout'')
     (Unify (Device (DeviceType Nat)) device' device'')
     (Unify (DataType DType) dataType' dataType'')
     (BroadcastShapesF shape' shape'')
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier hs-var">add</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; Tensor gradient'' layout'' device'' dataType'' shape''
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient' gradient'')
      (Unify (Layout LayoutType) layout' layout'')
      (Unify (Device (DeviceType Nat)) device' device'')
      (Unify (DataType DType) dataType' dataType'')
      (BroadcastShapesF shape' shape''))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape''
      -&gt; Tensor
           (Or (Gradient RequiresGradient) gradient' gradient'')
           (Unify (Layout LayoutType) layout' layout'')
           (Unify (Device (DeviceType Nat)) device' device'')
           (Unify (DataType DType) dataType' dataType'')
           (BroadcastShapesF shape' shape''))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient' layout' device' dataType' shape')
</span><a href="#local-6989586621679555964"><span class="hs-identifier hs-var">embeddedInput</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape''
   -&gt; Tensor
        (Or (Gradient RequiresGradient) gradient' gradient'')
        (Unify (Layout LayoutType) layout' layout'')
        (Unify (Device (DeviceType Nat)) device' device'')
        (Unify (DataType DType) dataType' dataType'')
        (BroadcastShapesF shape' shape''))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient' gradient'')
        (Unify (Layout LayoutType) layout' layout'')
        (Unify (Device (DeviceType Nat)) device' device'')
        (Unify (DataType DType) dataType' dataType'')
        (BroadcastShapesF shape' shape''))
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape'')
</span><a href="#local-6989586621679555961"><span class="hs-identifier hs-var">embeddedInputType</span></a></span><span>
</span><span id="line-533"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient' gradient'')
     (Unify (Layout LayoutType) layout' layout'')
     (Unify (Device (DeviceType Nat)) device' device'')
     (Unify (DataType DType) dataType' dataType'')
     (BroadcastShapesF shape' shape''))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient' gradient'')
      (Unify (Layout LayoutType) layout' layout'')
      (Unify (Device (DeviceType Nat)) device' device'')
      (Unify (DataType DType) dataType' dataType'')
      (BroadcastShapesF shape' shape'')
    -&gt; IxStateT
         m
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Generator encoderGeneratorOutputDevice)
         encoderOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679555960"><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient' gradient'')
  (Unify (Layout LayoutType) layout' layout'')
  (Unify (Device (DeviceType Nat)) device' device'')
  (Unify (DataType DType) dataType' dataType'')
  (BroadcastShapesF shape' shape'')
</span><a href="#local-6989586621679555960"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator typeEmbeddingGeneratorOutputDevice
 -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator typeEmbeddingGeneratorOutputDevice
  -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Generator encoderGeneratorOutputDevice)
      encoderOutput)
-&gt; (Generator typeEmbeddingGeneratorOutputDevice
    -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">encoder
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient' gradient'')
      (Unify (Layout LayoutType) layout' layout'')
      (Unify (Device (DeviceType Nat)) device' device'')
      (Unify (DataType DType) dataType' dataType'')
      (BroadcastShapesF shape' shape''),
    pos, attentionMask)
-&gt; Generator typeEmbeddingGeneratorOutputDevice
-&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">encoder
</span><a href="#local-6989586621679555976"><span class="hs-identifier hs-var">eotEncoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient' gradient'')
  (Unify (Layout LayoutType) layout' layout'')
  (Unify (Device (DeviceType Nat)) device' device'')
  (Unify (DataType DType) dataType' dataType'')
  (BroadcastShapesF shape' shape'')
</span><a href="#local-6989586621679555960"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679555969"><span class="hs-identifier hs-var">eotPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionMask
</span><a href="#local-6989586621679555968"><span class="hs-identifier hs-var">eotAttentionMask</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-534"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator encoderGeneratorOutputDevice)
  encoderOutput
-&gt; (encoderOutput
    -&gt; IxStateT
         m
         (Generator encoderGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         headOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     headOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator encoderGeneratorOutputDevice
 -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator encoderGeneratorOutputDevice
  -&gt; m (headOutput, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator encoderGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      headOutput)
-&gt; (encoderOutput
    -&gt; Generator encoderGeneratorOutputDevice
    -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; encoderOutput
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">head
-&gt; encoderOutput
-&gt; Generator encoderGeneratorOutputDevice
-&gt; m (headOutput, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">head
</span><a href="#local-6989586621679555973"><span class="hs-identifier hs-var">eotHead</span></a></span><span>
</span><span id="line-535"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  headOutput
-&gt; (headOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (EncoderOnlyTransformerOutput headOutput))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerOutput headOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(EncoderOnlyTransformerOutput headOutput
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (EncoderOnlyTransformerOutput headOutput))
-&gt; (headOutput -&gt; EncoderOnlyTransformerOutput headOutput)
-&gt; headOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">headOutput -&gt; EncoderOnlyTransformerOutput headOutput
forall output. output -&gt; EncoderOnlyTransformerOutput output
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">EncoderOnlyTransformerOutput</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-536"></span><span>
</span><span id="line-537"></span><span id="local-6989586621679555948"><span id="local-6989586621679555949"><span id="local-6989586621679555950"><span id="local-6989586621679555951"><span id="local-6989586621679555952"><span id="local-6989586621679555953"><span id="local-6989586621679555954"><span id="local-6989586621679555955"><span id="local-6989586621679555956"><span id="local-6989586621679555957"><span id="local-6989586621679555958"><span id="local-6989586621679555959"><span class="hs-keyword">instance</span><span>
</span><span id="line-538"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-539"></span><span>      </span><span class="annot"><a href="#local-6989586621679555959"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span>
</span><span id="line-540"></span><span>      </span><span class="annot"><a href="#local-6989586621679555958"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-541"></span><span>      </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-542"></span><span>      </span><span class="annot"><a href="#local-6989586621679555956"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-543"></span><span>      </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-544"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-545"></span><span>      </span><span class="annot"><a href="#local-6989586621679555955"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-546"></span><span>      </span><span class="annot"><a href="#local-6989586621679555956"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-547"></span><span>      </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-548"></span><span>      </span><span class="annot"><a href="#local-6989586621679555954"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-549"></span><span>      </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-550"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-551"></span><span>      </span><span class="annot"><a href="#local-6989586621679555953"><span class="hs-identifier hs-type">mkPos</span></a></span><span>
</span><span id="line-552"></span><span>      </span><span class="annot"><a href="#local-6989586621679555958"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-553"></span><span>      </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-554"></span><span>      </span><span class="annot"><a href="#local-6989586621679555952"><span class="hs-identifier hs-type">pos</span></a></span><span>
</span><span id="line-555"></span><span>      </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-556"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-557"></span><span>      </span><span class="annot"><a href="#local-6989586621679555951"><span class="hs-identifier hs-type">model</span></a></span><span>
</span><span id="line-558"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555958"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555950"><span class="hs-identifier hs-type">inputType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555952"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555954"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-559"></span><span>      </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-560"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555949"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-561"></span><span>      </span><span class="annot"><a href="#local-6989586621679555948"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-562"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-563"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-564"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555951"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555953"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555959"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555955"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-565"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555958"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555950"><span class="hs-identifier hs-type">inputType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-566"></span><span>    </span><span class="annot"><a href="#local-6989586621679555957"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-567"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555949"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679555956"><span class="hs-identifier hs-type">paddingMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-568"></span><span>    </span><span class="annot"><a href="#local-6989586621679555948"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-569"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-570"></span><span>  </span><span id="local-6989586621679555946"><span class="annot"><span class="annottext">forward :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Generator generatorDevice
-&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
      Generator generatorOutputDevice)
</span><a href="#local-6989586621679555946"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679555942"><span id="local-6989586621679555943"><span id="local-6989586621679555944"><span id="local-6989586621679555945"><span class="annot"><span class="annottext">mkPaddingMask
mkAttentionMask
mkPos
model
seotMkAttentionMask :: mkAttentionMask
seotMkPaddingMask :: mkPaddingMask
seotMkPos :: mkPos
seotModel :: model
seotMkAttentionMask :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkAttentionMask
seotMkPaddingMask :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPaddingMask
seotMkPos :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPos
seotModel :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; model
</span><a href="#local-6989586621679555942"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679555940"><span id="local-6989586621679555941"><span class="annot"><span class="annottext">input
inputType
seotInputType :: inputType
seotInput :: input
seotInputType :: forall input inputType.
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; inputType
seotInput :: forall input inputType.
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; input
</span><a href="#local-6989586621679555940"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-571"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; Generator generatorDevice
-&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
      Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
 -&gt; Generator generatorDevice
 -&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; Generator generatorDevice
-&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
      Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-572"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679555939"><span class="annot"><span class="annottext">paddingMask :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  paddingMask
</span><a href="#local-6989586621679555939"><span class="hs-identifier hs-var hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (paddingMask, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (paddingMask, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      paddingMask)
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (paddingMask, Generator generatorDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">mkPaddingMask
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (paddingMask, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">mkPaddingMask
</span><a href="#local-6989586621679555943"><span class="hs-identifier hs-var">seotMkPaddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">(input
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      paddingMask)
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679555941"><span class="hs-identifier hs-var">seotInput</span></a></span><span>
</span><span id="line-573"></span><span>            </span><span id="local-6989586621679555938"><span class="annot"><span class="annottext">pos :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) pos
</span><a href="#local-6989586621679555938"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice -&gt; m (pos, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice -&gt; m (pos, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) pos)
-&gt; (input
    -&gt; Generator generatorDevice -&gt; m (pos, Generator generatorDevice))
-&gt; input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">mkPos
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (pos, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">mkPos
</span><a href="#local-6989586621679555944"><span class="hs-identifier hs-var">seotMkPos</span></a></span><span> </span><span class="annot"><span class="annottext">(input
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) pos)
-&gt; input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679555941"><span class="hs-identifier hs-var">seotInput</span></a></span><span>
</span><span id="line-574"></span><span>         </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(paddingMask -&gt; pos -&gt; (paddingMask, pos))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (pos -&gt; (paddingMask, pos))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  paddingMask
</span><a href="#local-6989586621679555939"><span class="hs-identifier hs-var">paddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (pos -&gt; (paddingMask, pos))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (paddingMask, pos)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) pos
</span><a href="#local-6989586621679555938"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-575"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-576"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (paddingMask, pos)
-&gt; ((paddingMask, pos)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (SimplifiedEncoderOnlyTransformerOutput output paddingMask))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679555937"><span class="annot"><span class="annottext">paddingMask
</span><a href="#local-6989586621679555937"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679555936"><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679555936"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-577"></span><span>                 </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679555935"><span class="annot"><span class="annottext">attentionMask :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  attentionMask
</span><a href="#local-6989586621679555935"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (attentionMask, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (attentionMask, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      attentionMask)
-&gt; (paddingMask
    -&gt; Generator generatorDevice
    -&gt; m (attentionMask, Generator generatorDevice))
-&gt; paddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">mkAttentionMask
-&gt; paddingMask
-&gt; Generator generatorDevice
-&gt; m (attentionMask, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">mkAttentionMask
</span><a href="#local-6989586621679555942"><span class="hs-identifier hs-var">seotMkAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">(paddingMask
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      attentionMask)
-&gt; paddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">paddingMask
</span><a href="#local-6989586621679555937"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-578"></span><span>                  </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">input
-&gt; inputType
-&gt; pos
-&gt; attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
forall input inputType pos attentionMask.
input
-&gt; inputType
-&gt; pos
-&gt; attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-var">EncoderOnlyTransformerInput</span></a></span><span>
</span><span id="line-579"></span><span>                         </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679555941"><span class="hs-identifier hs-var">seotInput</span></a></span><span>
</span><span id="line-580"></span><span>                         </span><span class="annot"><span class="annottext">inputType
</span><a href="#local-6989586621679555940"><span class="hs-identifier hs-var">seotInputType</span></a></span><span>
</span><span id="line-581"></span><span>                         </span><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679555936"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-582"></span><span>                         </span><span class="annot"><span class="annottext">(attentionMask
 -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (EncoderOnlyTransformerInput input inputType pos attentionMask)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  attentionMask
</span><a href="#local-6989586621679555935"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-583"></span><span>                     </span><span class="hs-special">)</span><span>
</span><span id="line-584"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (EncoderOnlyTransformerOutput output))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput output)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (EncoderOnlyTransformerOutput output,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput output)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (EncoderOnlyTransformerOutput output,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (EncoderOnlyTransformerOutput output))
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Generator generatorDevice
    -&gt; m (EncoderOnlyTransformerOutput output,
          Generator generatorOutputDevice))
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput output)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">model
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput output,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679555945"><span class="hs-identifier hs-var">seotModel</span></a></span><span>
</span><span id="line-585"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (EncoderOnlyTransformerOutput output)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (SimplifiedEncoderOnlyTransformerOutput output paddingMask))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span id="local-6989586621679555934"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679555934"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-586"></span><span>                                </span><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(SimplifiedEncoderOnlyTransformerOutput output paddingMask
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (SimplifiedEncoderOnlyTransformerOutput output paddingMask))
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">output
-&gt; paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
forall output paddingMask.
output
-&gt; paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679555934"><span class="hs-identifier hs-var">output</span></a></span><span> </span><span class="annot"><span class="annottext">paddingMask
</span><a href="#local-6989586621679555937"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-587"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-588"></span><span>             </span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></pre></body></html>