<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span id="local-6989586621679700743"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE LambdaCase #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE OverloadedStrings #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE StandaloneDeriving #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# OPTIONS_GHC -fno-warn-partial-type-signatures #-}</span><span>
</span><span id="line-17"></span><span>
</span><span id="line-18"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GEncoderOnly</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/mlp091qaldwnxnk1kz11fzh8naz8by0p-singletons-lib-singletons-3.0-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/mlp091qaldwnxnk1kz11fzh8naz8by0p-singletons-lib-singletons-3.0-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/mlp091qaldwnxnk1kz11fzh8naz8by0p-singletons-lib-singletons-3.0-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier">EmbeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GLMHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHeadF"><span class="hs-identifier">GLMHeadF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier">lmHeadSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GTransformer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TransformerEncoderF"><span class="hs-identifier">TransformerEncoderF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#transformerEncoderSpec"><span class="hs-identifier">transformerEncoderSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerHead"><span class="hs-identifier">STransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier">TransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier">HasDropout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier">SHasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.Maybe.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SNothing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.TypeLits.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SNat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">head</span></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span>
</span><span id="line-48"></span><span class="hs-comment">-- | Data type that is used to represent whether the encoder-only transformer model has a scaled embedding.</span><span>
</span><span id="line-49"></span><span id="local-6989586621679700727"><span id="local-6989586621679700728"></span></span><span class="hs-keyword">data</span><span> </span><span id="EncoderOnlyTransformerHasEmbedScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerHasEmbedScaling</span></a></span></span><span>
</span><span id="line-50"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="EncoderOnlyTransformerWithEmbedScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithEmbedScaling</span></a></span></span><span>
</span><span id="line-51"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="EncoderOnlyTransformerWithoutEmbedScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span></span><span>
</span><span id="line-52"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700721"><span id="local-6989586621679700723"><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
(EncoderOnlyTransformerHasEmbedScaling
 -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool)
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool)
-&gt; Eq EncoderOnlyTransformerHasEmbedScaling
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
$c/= :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
== :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
$c== :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700701"><span id="local-6989586621679700703"><span id="local-6989586621679700706"><span id="local-6989586621679700709"><span id="local-6989586621679700712"><span id="local-6989586621679700714"><span id="local-6989586621679700716"><span class="annot"><span class="annottext">Eq EncoderOnlyTransformerHasEmbedScaling
Eq EncoderOnlyTransformerHasEmbedScaling
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Ordering)
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool)
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool)
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool)
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool)
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling)
-&gt; (EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling
    -&gt; EncoderOnlyTransformerHasEmbedScaling)
-&gt; Ord EncoderOnlyTransformerHasEmbedScaling
EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Ordering
EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
$cmin :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
max :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
$cmax :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling
&gt;= :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
$c&gt;= :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
&gt; :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
$c&gt; :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
&lt;= :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
$c&lt;= :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
&lt; :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
$c&lt; :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Bool
compare :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Ordering
$ccompare :: EncoderOnlyTransformerHasEmbedScaling
-&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; Ordering
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700694"><span id="local-6989586621679700696"><span id="local-6989586621679700698"><span class="annot"><span class="annottext">Int -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; ShowS
[EncoderOnlyTransformerHasEmbedScaling] -&gt; ShowS
EncoderOnlyTransformerHasEmbedScaling -&gt; String
(Int -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; ShowS)
-&gt; (EncoderOnlyTransformerHasEmbedScaling -&gt; String)
-&gt; ([EncoderOnlyTransformerHasEmbedScaling] -&gt; ShowS)
-&gt; Show EncoderOnlyTransformerHasEmbedScaling
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [EncoderOnlyTransformerHasEmbedScaling] -&gt; ShowS
$cshowList :: [EncoderOnlyTransformerHasEmbedScaling] -&gt; ShowS
show :: EncoderOnlyTransformerHasEmbedScaling -&gt; String
$cshow :: EncoderOnlyTransformerHasEmbedScaling -&gt; String
showsPrec :: Int -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; ShowS
$cshowsPrec :: Int -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 EncoderOnlyTransformerHasEmbedScaling
 -&gt; Rep EncoderOnlyTransformerHasEmbedScaling x)
-&gt; (forall x.
    Rep EncoderOnlyTransformerHasEmbedScaling x
    -&gt; EncoderOnlyTransformerHasEmbedScaling)
-&gt; Generic EncoderOnlyTransformerHasEmbedScaling
forall x.
Rep EncoderOnlyTransformerHasEmbedScaling x
-&gt; EncoderOnlyTransformerHasEmbedScaling
forall x.
EncoderOnlyTransformerHasEmbedScaling
-&gt; Rep EncoderOnlyTransformerHasEmbedScaling x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x.
Rep EncoderOnlyTransformerHasEmbedScaling x
-&gt; EncoderOnlyTransformerHasEmbedScaling
$cfrom :: forall x.
EncoderOnlyTransformerHasEmbedScaling
-&gt; Rep EncoderOnlyTransformerHasEmbedScaling x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span>
</span><span id="line-54"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span>
</span><span id="line-55"></span><span>
</span><span id="line-56"></span><span id="local-6989586621679701623"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701623"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701623"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-57"></span><span>  </span><span id="local-6989586621679700680"><span class="annot"><span class="annottext">initialize :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
ModelSpec EncoderOnlyTransformerHasEmbedScaling
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerHasEmbedScaling,
      Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679700678"><span class="annot"><span class="annottext">ModelSpec EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700678"><span class="hs-identifier hs-var">hasEmbedScaling</span></a></span></span><span> </span><span id="local-6989586621679700677"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679700677"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(EncoderOnlyTransformerHasEmbedScaling, Generator generatorDevice)
-&gt; m (EncoderOnlyTransformerHasEmbedScaling,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec EncoderOnlyTransformerHasEmbedScaling
EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700678"><span class="hs-identifier hs-var">hasEmbedScaling</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679700677"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-58"></span><span>
</span><span id="line-59"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-60"></span><span>  </span><span id="local-6989586621679700666"><span class="annot"><span class="annottext">fromStateDict :: forall (m :: * -&gt; *).
(MonadIO m, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec EncoderOnlyTransformerHasEmbedScaling
-&gt; StateDictKey -&gt; m EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679700664"><span class="annot"><span class="annottext">ModelSpec EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700664"><span class="hs-identifier hs-var">hasEmbedScaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
-&gt; m EncoderOnlyTransformerHasEmbedScaling
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec EncoderOnlyTransformerHasEmbedScaling
EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700664"><span class="hs-identifier hs-var">hasEmbedScaling</span></a></span><span>
</span><span id="line-61"></span><span>  </span><span id="local-6989586621679700658"><span class="annot"><span class="annottext">toStateDict :: forall (m :: * -&gt; *).
(MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; EncoderOnlyTransformerHasEmbedScaling -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>
</span><span id="line-63"></span><span class="hs-comment">-- | Generic encoder-only transformer model.</span><span>
</span><span id="line-64"></span><span class="hs-comment">-- This is a transformer model that only encodes the input, e.g. BERT.</span><span>
</span><span id="line-65"></span><span class="hs-comment">--</span><span>
</span><span id="line-66"></span><span class="hs-comment">-- - @inputEmbedDim@: the dimension of the input embedding.</span><span>
</span><span id="line-67"></span><span class="hs-comment">-- - @encoder@: a transformer encoder.</span><span>
</span><span id="line-68"></span><span class="hs-comment">-- - @encoderEmbedding@: an embedding layer for the input.</span><span>
</span><span id="line-69"></span><span class="hs-comment">-- - @encoderTypeEmbedding@: an embedding layer for the type of the input.</span><span>
</span><span id="line-70"></span><span class="hs-comment">-- - @head@: a head layer for the output.</span><span>
</span><span id="line-71"></span><span id="local-6989586621679700655"><span id="local-6989586621679700656"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-72"></span><span>  </span><span id="GEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span></span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701562"><span class="annot"><a href="#local-6989586621679701562"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701566"><span class="annot"><a href="#local-6989586621679701566"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701565"><span class="annot"><a href="#local-6989586621679701565"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701564"><span class="annot"><a href="#local-6989586621679701564"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701563"><span class="annot"><a href="#local-6989586621679701563"><span class="hs-identifier hs-type">head</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-78"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-79"></span><span>  </span><span id="GEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-80"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679701602"><span class="annot"><a href="#local-6989586621679701602"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679701601"><span class="annot"><a href="#local-6989586621679701601"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span id="local-6989586621679701600"><span class="annot"><a href="#local-6989586621679701600"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span></span><span> </span><span id="local-6989586621679701599"><span class="annot"><a href="#local-6989586621679701599"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span></span><span> </span><span id="local-6989586621679701598"><span class="annot"><a href="#local-6989586621679701598"><span class="hs-identifier hs-type">head</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | input embedding dim for scaling</span><span>
</span><span id="line-82"></span><span>      </span><span id="eotInputEmbedDim"><span class="annot"><span class="annottext">forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; SDim inputEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotInputEmbedDim"><span class="hs-identifier hs-var hs-var">eotInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701602"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-83"></span><span>      </span><span class="hs-comment">-- | encoder</span><span>
</span><span id="line-84"></span><span>      </span><span id="eotEncoder"><span class="annot"><span class="annottext">forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotEncoder"><span class="hs-identifier hs-var hs-var">eotEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701601"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-85"></span><span>      </span><span class="hs-comment">-- | encoder embedding</span><span>
</span><span id="line-86"></span><span>      </span><span id="eotEmbedding"><span class="annot"><span class="annottext">forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderEmbedding
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotEmbedding"><span class="hs-identifier hs-var hs-var">eotEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701600"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-87"></span><span>      </span><span class="hs-comment">-- | encoder type embedding</span><span>
</span><span id="line-88"></span><span>      </span><span id="eotTypeEmbedding"><span class="annot"><span class="annottext">forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderTypeEmbedding
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotTypeEmbedding"><span class="hs-identifier hs-var hs-var">eotTypeEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701599"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-89"></span><span>      </span><span class="hs-comment">-- | encoder head</span><span>
</span><span id="line-90"></span><span>      </span><span id="eotHead"><span class="annot"><span class="annottext">forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; head
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotHead"><span class="hs-identifier hs-var hs-var">eotHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701598"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-91"></span><span>      </span><span class="hs-comment">-- | encoder embedding scaling</span><span>
</span><span id="line-92"></span><span>      </span><span id="eotEmbedScaling"><span class="annot"><span class="annottext">forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotEmbedScaling"><span class="hs-identifier hs-var hs-var">eotEmbedScaling</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-94"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701602"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701601"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701600"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701599"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701598"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-95"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700633"><span id="local-6989586621679700635"><span id="local-6989586621679700646"><span class="annot"><span class="annottext">Int
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; ShowS
[GEncoderOnlyTransformer
   inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head]
-&gt; ShowS
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; String
(Int
 -&gt; GEncoderOnlyTransformer
      inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
 -&gt; ShowS)
-&gt; (GEncoderOnlyTransformer
      inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
    -&gt; String)
-&gt; ([GEncoderOnlyTransformer
       inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head]
    -&gt; ShowS)
-&gt; Show
     (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
(Show encoder, Show encoderEmbedding, Show encoderTypeEmbedding,
 Show head) =&gt;
Int
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; ShowS
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
(Show encoder, Show encoderEmbedding, Show encoderTypeEmbedding,
 Show head) =&gt;
[GEncoderOnlyTransformer
   inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head]
-&gt; ShowS
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
(Show encoder, Show encoderEmbedding, Show encoderTypeEmbedding,
 Show head) =&gt;
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; String
showList :: [GEncoderOnlyTransformer
   inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head]
-&gt; ShowS
$cshowList :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
(Show encoder, Show encoderEmbedding, Show encoderTypeEmbedding,
 Show head) =&gt;
[GEncoderOnlyTransformer
   inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head]
-&gt; ShowS
show :: GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; String
$cshow :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
(Show encoder, Show encoderEmbedding, Show encoderTypeEmbedding,
 Show head) =&gt;
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; String
showsPrec :: Int
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; ShowS
$cshowsPrec :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
(Show encoder, Show encoderEmbedding, Show encoderTypeEmbedding,
 Show head) =&gt;
Int
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 GEncoderOnlyTransformer
   inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
 -&gt; Rep
      (GEncoderOnlyTransformer
         inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
      x)
-&gt; (forall x.
    Rep
      (GEncoderOnlyTransformer
         inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
      x
    -&gt; GEncoderOnlyTransformer
         inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
-&gt; Generic
     (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
forall x.
Rep
  (GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
  x
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
forall x.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; Rep
     (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
     x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head x.
Rep
  (GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
  x
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head x.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; Rep
     (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
     x
$cto :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head x.
Rep
  (GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
  x
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
$cfrom :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head x.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; Rep
     (GEncoderOnlyTransformer
        inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head)
     x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>
</span><span id="line-97"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-98"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span id="local-6989586621679700626"><span id="local-6989586621679700627"><span id="local-6989586621679700628"><span id="local-6989586621679700629"><span id="local-6989586621679700630"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700630"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700629"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700628"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700627"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700626"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-99"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700630"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700629"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700628"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700627"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700626"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>
</span><span id="line-101"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-102"></span><span>  </span><span id="GEncoderOnlyTransformerF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformerF"><span class="hs-identifier hs-var">GEncoderOnlyTransformerF</span></a></span></span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700625"><span class="annot"><a href="#local-6989586621679700625"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700624"><span class="annot"><a href="#local-6989586621679700624"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700623"><span class="annot"><a href="#local-6989586621679700623"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700622"><span class="annot"><a href="#local-6989586621679700622"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700621"><span class="annot"><a href="#local-6989586621679700621"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700620"><span class="annot"><a href="#local-6989586621679700620"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700619"><span class="annot"><a href="#local-6989586621679700619"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700618"><span class="annot"><a href="#local-6989586621679700618"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700617"><span class="annot"><a href="#local-6989586621679700617"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700616"><span class="annot"><a href="#local-6989586621679700616"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700615"><span class="annot"><a href="#local-6989586621679700615"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700614"><span class="annot"><a href="#local-6989586621679700614"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700613"><span class="annot"><a href="#local-6989586621679700613"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700612"><span class="annot"><a href="#local-6989586621679700612"><span class="hs-identifier hs-type">typeVocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700611"><span class="annot"><a href="#local-6989586621679700611"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-118"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-119"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-120"></span><span>  </span><span id="GEncoderOnlyTransformerF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformerF"><span class="hs-identifier hs-var">GEncoderOnlyTransformerF</span></a></span></span><span> </span><span id="local-6989586621679700596"><span id="local-6989586621679700597"><span id="local-6989586621679700598"><span id="local-6989586621679700599"><span id="local-6989586621679700600"><span id="local-6989586621679700601"><span id="local-6989586621679700602"><span id="local-6989586621679700603"><span id="local-6989586621679700604"><span id="local-6989586621679700605"><span id="local-6989586621679700606"><span id="local-6989586621679700607"><span id="local-6989586621679700608"><span id="local-6989586621679700609"><span id="local-6989586621679700610"><span class="annot"><a href="#local-6989586621679700610"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700609"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700608"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700607"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700606"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700605"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700604"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700603"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700602"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700601"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700600"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700599"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700598"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700597"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700596"><span class="hs-identifier hs-type">hasDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-121"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span>
</span><span id="line-122"></span><span>      </span><span class="annot"><a href="#local-6989586621679700601"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-123"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#TransformerEncoderF"><span class="hs-identifier hs-type">TransformerEncoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700610"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700608"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700607"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700606"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700605"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700604"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700603"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700602"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700601"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700600"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700599"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700596"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEmbeddingF"><span class="hs-identifier hs-type">EOTEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700610"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700607"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700606"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700605"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700601"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700598"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-type">EOTTypeEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700610"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700607"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700606"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700605"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700601"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700597"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-type">EOTHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700610"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700609"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700607"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700606"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700605"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700601"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700598"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>
</span><span id="line-128"></span><span class="hs-comment">-- | Specifies the embedding layer of the encoder-only transformer model.</span><span>
</span><span id="line-129"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-130"></span><span>  </span><span id="EOTEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEmbeddingF"><span class="hs-identifier hs-var">EOTEmbeddingF</span></a></span></span><span>
</span><span id="line-131"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700594"><span class="annot"><a href="#local-6989586621679700594"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-132"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700593"><span class="annot"><a href="#local-6989586621679700593"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700592"><span class="annot"><a href="#local-6989586621679700592"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700591"><span class="annot"><a href="#local-6989586621679700591"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-135"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700590"><span class="annot"><a href="#local-6989586621679700590"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700589"><span class="annot"><a href="#local-6989586621679700589"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-137"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-138"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-139"></span><span>  </span><span id="EOTEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTEmbeddingF"><span class="hs-identifier hs-var">EOTEmbeddingF</span></a></span></span><span> </span><span id="local-6989586621679700584"><span id="local-6989586621679700585"><span id="local-6989586621679700586"><span id="local-6989586621679700587"><span id="local-6989586621679700588"><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><a href="#local-6989586621679700588"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700587"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700586"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700585"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700584"><span class="hs-identifier hs-type">vocabDim</span></a></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-140"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700588"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700587"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700586"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700584"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700585"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>
</span><span id="line-142"></span><span class="hs-comment">-- | Specifies the type embedding layer of the encoder-only transformer model.</span><span>
</span><span id="line-143"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-144"></span><span>  </span><span id="EOTTypeEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-var">EOTTypeEmbeddingF</span></a></span></span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700583"><span class="annot"><a href="#local-6989586621679700583"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700582"><span class="annot"><a href="#local-6989586621679700582"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700581"><span class="annot"><a href="#local-6989586621679700581"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700580"><span class="annot"><a href="#local-6989586621679700580"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700579"><span class="annot"><a href="#local-6989586621679700579"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700578"><span class="annot"><a href="#local-6989586621679700578"><span class="hs-identifier hs-type">typeVocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-151"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-152"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-153"></span><span>  </span><span id="EOTTypeEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-var">EOTTypeEmbeddingF</span></a></span></span><span> </span><span id="local-6989586621679700573"><span id="local-6989586621679700574"><span id="local-6989586621679700575"><span id="local-6989586621679700576"><span id="local-6989586621679700577"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700577"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700576"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700575"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700574"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700573"><span class="hs-identifier hs-type">typeVocabDim</span></a></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-154"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700577"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679700576"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700575"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700573"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700574"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-155"></span><span>  </span><span id="EOTTypeEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-var">EOTTypeEmbeddingF</span></a></span></span><span> </span><span id="local-6989586621679700568"><span id="local-6989586621679700569"><span id="local-6989586621679700570"><span id="local-6989586621679700571"><span id="local-6989586621679700572"><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700571"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700570"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700569"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700568"><span class="hs-identifier hs-type">typeVocabDim</span></a></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-156"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTTypeEmbeddingF"><span class="hs-identifier hs-type">EOTTypeEmbeddingF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700572"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700571"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700570"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700569"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700568"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span>
</span><span id="line-157"></span><span>
</span><span id="line-158"></span><span class="hs-comment">-- | Specifies the head layer of the encoder-only transformer model.</span><span>
</span><span id="line-159"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-160"></span><span>  </span><span id="EOTHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-var">EOTHeadF</span></a></span></span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700567"><span class="annot"><a href="#local-6989586621679700567"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700566"><span class="annot"><a href="#local-6989586621679700566"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700565"><span class="annot"><a href="#local-6989586621679700565"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700564"><span class="annot"><a href="#local-6989586621679700564"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700563"><span class="annot"><a href="#local-6989586621679700563"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700562"><span class="annot"><a href="#local-6989586621679700562"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679700561"><span class="annot"><a href="#local-6989586621679700561"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-168"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-169"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-170"></span><span>  </span><span id="EOTHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-var">EOTHeadF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-type">WithoutHead</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-171"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-172"></span><span>  </span><span id="EOTHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EOTHeadF"><span class="hs-identifier hs-var">EOTHeadF</span></a></span></span><span> </span><span id="local-6989586621679700555"><span id="local-6989586621679700556"><span id="local-6989586621679700557"><span id="local-6989586621679700558"><span id="local-6989586621679700559"><span id="local-6989586621679700560"><span class="annot"><a href="#local-6989586621679700560"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-type">WithLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700559"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700558"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700557"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700556"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700555"><span class="hs-identifier hs-type">vocabDim</span></a></span></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-173"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHeadF"><span class="hs-identifier hs-type">GLMHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700560"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700559"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700558"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700557"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700556"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700555"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-174"></span><span>
</span><span id="line-175"></span><span class="hs-comment">-- | Specifies the parameters of an encoder-only transformer model.</span><span>
</span><span id="line-176"></span><span class="hs-comment">--</span><span>
</span><span id="line-177"></span><span class="hs-comment">-- - @style@: the style of the encoder-only transformer model, e.g. 'SBERT', 'SRoBERTa', etc.</span><span>
</span><span id="line-178"></span><span class="hs-comment">-- - @transformerHead@: the head of the encoder-only transformer model.</span><span>
</span><span id="line-179"></span><span class="hs-comment">-- - @numLayers@: the number of layers of the encoder-only transformer model.</span><span>
</span><span id="line-180"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the model parameters</span><span>
</span><span id="line-181"></span><span class="hs-comment">-- - @device@: the computational device on which the model is allocated.</span><span>
</span><span id="line-182"></span><span class="hs-comment">-- - @dataType@: the data type of the model parameters.</span><span>
</span><span id="line-183"></span><span class="hs-comment">-- - @headDim@: the dimension of all transformer heads in the encoder-only transformer model.</span><span>
</span><span id="line-184"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the transformer head embeddings.</span><span>
</span><span id="line-185"></span><span class="hs-comment">-- - @embedDim@: the dimension of the transformer embeddings.</span><span>
</span><span id="line-186"></span><span class="hs-comment">-- - @inputEmbedDim@: the dimension of the input embeddings.</span><span>
</span><span id="line-187"></span><span class="hs-comment">-- - @ffnDim@: the dimension of the feed-forward network.</span><span>
</span><span id="line-188"></span><span class="hs-comment">-- - @posEncDim@: the dimension of the positional embeddings.</span><span>
</span><span id="line-189"></span><span class="hs-comment">-- - @vocabDim@: the dimension of the vocabulary.</span><span>
</span><span id="line-190"></span><span class="hs-comment">-- - @typeVocabDim@: the dimension of the type vocabulary.</span><span>
</span><span id="line-191"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-192"></span><span class="hs-comment">-- - @eps@: the epsilon value for numerical stability of the layer normalization.</span><span>
</span><span id="line-193"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#encoderOnlyTransformerSpec"><span class="hs-identifier hs-type">encoderOnlyTransformerSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-194"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679701554"><span class="annot"><a href="#local-6989586621679701554"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679701552"><span class="annot"><a href="#local-6989586621679701552"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679701550"><span class="annot"><a href="#local-6989586621679701550"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679701548"><span class="annot"><a href="#local-6989586621679701548"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679701546"><span class="annot"><a href="#local-6989586621679701546"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679701544"><span class="annot"><a href="#local-6989586621679701544"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679701542"><span class="annot"><a href="#local-6989586621679701542"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679701541"><span class="annot"><a href="#local-6989586621679701541"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679701540"><span class="annot"><a href="#local-6989586621679701540"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679701539"><span class="annot"><a href="#local-6989586621679701539"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679701538"><span class="annot"><a href="#local-6989586621679701538"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679701537"><span class="annot"><a href="#local-6989586621679701537"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679701536"><span class="annot"><a href="#local-6989586621679701536"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679701535"><span class="annot"><a href="#local-6989586621679701535"><span class="hs-identifier hs-type">typeVocabDim</span></a></span></span><span> </span><span id="local-6989586621679701534"><span class="annot"><a href="#local-6989586621679701534"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-195"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701554"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-196"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerHead"><span class="hs-identifier hs-type">STransformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701552"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-197"></span><span>  </span><span class="annot"><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701550"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-198"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701548"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-199"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701546"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-200"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701544"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-201"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701542"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-202"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701541"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-203"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701540"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-204"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701539"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-205"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701538"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-206"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701537"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-207"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701536"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-208"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701535"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-209"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier hs-type">SHasDropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701534"><span class="hs-identifier hs-type">hasDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-210"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-211"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-212"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformerF"><span class="hs-identifier hs-type">GEncoderOnlyTransformerF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701554"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701552"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701550"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701548"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701546"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701544"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701542"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701541"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701540"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701539"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701538"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701537"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701536"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701535"><span class="hs-identifier hs-type">typeVocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701534"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-213"></span><span id="encoderOnlyTransformerSpec"><span class="annot"><span class="annottext">encoderOnlyTransformerSpec :: forall (style :: TransformerStyle)
       (transformerHead :: TransformerHead) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat))
       (typeVocabDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; SDim vocabDim
-&gt; SDim typeVocabDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GEncoderOnlyTransformerF
        style
        transformerHead
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim
        typeVocabDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#encoderOnlyTransformerSpec"><span class="hs-identifier hs-var hs-var">encoderOnlyTransformerSpec</span></a></span></span><span> </span><span id="local-6989586621679700553"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700553"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679700552"><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="#local-6989586621679700552"><span class="hs-identifier hs-var">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679700551"><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679700551"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span> </span><span id="local-6989586621679700550"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679700550"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679700549"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679700549"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679700548"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679700548"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679700547"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679700547"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679700546"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679700546"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679700545"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679700545"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679700544"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679700544"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679700543"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679700543"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679700542"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679700542"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679700541"><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679700541"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679700540"><span class="annot"><span class="annottext">SDim typeVocabDim
</span><a href="#local-6989586621679700540"><span class="hs-identifier hs-var">typeVocabDim</span></a></span></span><span> </span><span id="local-6989586621679700539"><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679700539"><span class="hs-identifier hs-var">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679700538"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700538"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679700537"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700537"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-214"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700536"><span class="annot"><span class="annottext">encoderSpec :: STransformerStyle style
-&gt; NamedModel
     (GTransformer
        (ModelSpec
           (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
        (ModelSpec
           (TERelPosEncF style gradient device dataType headDim posEncDim))
        (ModelSpec
           (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEInitialDropoutF style hasDropout))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                (DropoutF style hasDropout)))
                          (SADropoutF style hasDropout)
                          (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                          (FFNInputTransformationF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNActivationF style)
                          (FFNActivationDropoutF style)
                          (FFNOutputProjectionF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNOutputDropoutF style hasDropout)
                          (FFNOutputLayerNormF
                             style gradient device dataType inputEmbedDim)))))))
        (ModelSpec
           (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEFinalDropoutF style hasDropout)))
</span><a href="#local-6989586621679700536"><span class="hs-identifier hs-var hs-var">encoderSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-215"></span><span>      </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-216"></span><span>      </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-217"></span><span>      </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-218"></span><span>      </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-219"></span><span>      </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (ModelSpec (TEInitialDropoutF 'BERT hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             (DropoutF 'BERT hasDropout)))
                       (SADropoutF 'BERT hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       (FFNOutputDropoutF 'BERT hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (ModelSpec (TEInitialDropoutF 'BERT hasDropout))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                (DropoutF 'BERT hasDropout)))
                          (SADropoutF 'BERT hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          (FFNOutputDropoutF 'BERT hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;bert.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GTransformer
   (NamedModel
      (EmbeddingSpec
         gradient
         ('Layout 'Dense)
         device
         dataType
         posEncDim
         inputEmbedDim
         'Nothing))
   ()
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   (ModelSpec (TEInitialDropoutF 'BERT hasDropout))
   (NamedModel
      (GTransformerStack
         (VectorSpec
            numLayers
            (GTransformerBlock
               (NamedModel
                  (GSelfAttention
                     ()
                     (NamedModel
                        (GMultiHeadAttention
                           headDim
                           headEmbedDim
                           embedDim
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, embedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           (DropoutF 'BERT hasDropout)))
                     (SADropoutF 'BERT hasDropout)
                     (NamedModel
                        (LayerNorm
                           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
               ()
               (NamedModel
                  (GTransformerFeedForwardNetwork
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[ffnDim, inputEmbedDim])))
                           (NamedModel
                              (Tensor
                                 gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                     Gelu
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim, ffnDim])))
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))
                     (FFNOutputDropoutF 'BERT hasDropout)
                     (NamedModel
                        (LayerNorm
                           'WithBias
                           gradient
                           device
                           dataType
                           ('Shape '[inputEmbedDim])))))))))
   ()
   ()
 -&gt; NamedModel
      (GTransformer
         (NamedModel
            (EmbeddingSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               posEncDim
               inputEmbedDim
               'Nothing))
         ()
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         (ModelSpec (TEInitialDropoutF 'BERT hasDropout))
         (NamedModel
            (GTransformerStack
               (VectorSpec
                  numLayers
                  (GTransformerBlock
                     (NamedModel
                        (GSelfAttention
                           ()
                           (NamedModel
                              (GMultiHeadAttention
                                 headDim
                                 headEmbedDim
                                 embedDim
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim, embedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim])))))
                                 (DropoutF 'BERT hasDropout)))
                           (SADropoutF 'BERT hasDropout)
                           (NamedModel
                              (LayerNorm
                                 'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                     ()
                     (NamedModel
                        (GTransformerFeedForwardNetwork
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim])))))
                           Gelu
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, ffnDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           (FFNOutputDropoutF 'BERT hasDropout)
                           (NamedModel
                              (LayerNorm
                                 'WithBias
                                 gradient
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))))))
         ()
         ()))
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (ModelSpec (TEInitialDropoutF 'BERT hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             (DropoutF 'BERT hasDropout)))
                       (SADropoutF 'BERT hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       (FFNOutputDropoutF 'BERT hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (ModelSpec (TEInitialDropoutF 'BERT hasDropout))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                (DropoutF 'BERT hasDropout)))
                          (SADropoutF 'BERT hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          (FFNOutputDropoutF 'BERT hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF 'BERT gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF 'BERT gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF 'BERT hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF 'BERT gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF 'BERT gradient device dataType inputEmbedDim embedDim)
                             (KInProjF 'BERT gradient device dataType inputEmbedDim embedDim)
                             (VInProjF 'BERT gradient device dataType inputEmbedDim embedDim)
                             (OutProjF 'BERT gradient device dataType embedDim inputEmbedDim)
                             (DropoutF 'BERT hasDropout)))
                       (SADropoutF 'BERT hasDropout)
                       (SAFinalLayerNormF 'BERT gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF 'BERT gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          'BERT gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF 'BERT)
                       (FFNActivationDropoutF 'BERT)
                       (FFNOutputProjectionF
                          'BERT gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF 'BERT hasDropout)
                       (FFNOutputLayerNormF
                          'BERT gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF 'BERT hasDropout))
forall {style :: TransformerStyle}.
STransformerStyle style
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout))
</span><a href="#local-6989586621679700509"><span class="hs-identifier hs-var">encoderSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span>
</span><span id="line-220"></span><span>      </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (ModelSpec (TEInitialDropoutF 'RoBERTa hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             (DropoutF 'RoBERTa hasDropout)))
                       (SADropoutF 'RoBERTa hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       (FFNOutputDropoutF 'RoBERTa hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (ModelSpec (TEInitialDropoutF 'RoBERTa hasDropout))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                (DropoutF 'RoBERTa hasDropout)))
                          (SADropoutF 'RoBERTa hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          (FFNOutputDropoutF 'RoBERTa hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;roberta.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GTransformer
   (NamedModel
      (EmbeddingSpec
         gradient
         ('Layout 'Dense)
         device
         dataType
         posEncDim
         inputEmbedDim
         'Nothing))
   ()
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   (ModelSpec (TEInitialDropoutF 'RoBERTa hasDropout))
   (NamedModel
      (GTransformerStack
         (VectorSpec
            numLayers
            (GTransformerBlock
               (NamedModel
                  (GSelfAttention
                     ()
                     (NamedModel
                        (GMultiHeadAttention
                           headDim
                           headEmbedDim
                           embedDim
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[embedDim])))))
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, embedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           (DropoutF 'RoBERTa hasDropout)))
                     (SADropoutF 'RoBERTa hasDropout)
                     (NamedModel
                        (LayerNorm
                           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
               ()
               (NamedModel
                  (GTransformerFeedForwardNetwork
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[ffnDim, inputEmbedDim])))
                           (NamedModel
                              (Tensor
                                 gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                     Gelu
                     ()
                     (NamedModel
                        (GLinear
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim, ffnDim])))
                           (NamedModel
                              (Tensor
                                 gradient
                                 ('Layout 'Dense)
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))
                     (FFNOutputDropoutF 'RoBERTa hasDropout)
                     (NamedModel
                        (LayerNorm
                           'WithBias
                           gradient
                           device
                           dataType
                           ('Shape '[inputEmbedDim])))))))))
   ()
   ()
 -&gt; NamedModel
      (GTransformer
         (NamedModel
            (EmbeddingSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               posEncDim
               inputEmbedDim
               'Nothing))
         ()
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         (ModelSpec (TEInitialDropoutF 'RoBERTa hasDropout))
         (NamedModel
            (GTransformerStack
               (VectorSpec
                  numLayers
                  (GTransformerBlock
                     (NamedModel
                        (GSelfAttention
                           ()
                           (NamedModel
                              (GMultiHeadAttention
                                 headDim
                                 headEmbedDim
                                 embedDim
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim, inputEmbedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[embedDim])))))
                                 (NamedModel
                                    (GLinear
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim, embedDim])))
                                       (NamedModel
                                          (Tensor
                                             gradient
                                             ('Layout 'Dense)
                                             device
                                             dataType
                                             ('Shape '[inputEmbedDim])))))
                                 (DropoutF 'RoBERTa hasDropout)))
                           (SADropoutF 'RoBERTa hasDropout)
                           (NamedModel
                              (LayerNorm
                                 'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                     ()
                     (NamedModel
                        (GTransformerFeedForwardNetwork
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim, inputEmbedDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[ffnDim])))))
                           Gelu
                           ()
                           (NamedModel
                              (GLinear
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim, ffnDim])))
                                 (NamedModel
                                    (Tensor
                                       gradient
                                       ('Layout 'Dense)
                                       device
                                       dataType
                                       ('Shape '[inputEmbedDim])))))
                           (FFNOutputDropoutF 'RoBERTa hasDropout)
                           (NamedModel
                              (LayerNorm
                                 'WithBias
                                 gradient
                                 device
                                 dataType
                                 ('Shape '[inputEmbedDim])))))))))
         ()
         ()))
-&gt; GTransformer
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           posEncDim
           inputEmbedDim
           'Nothing))
     ()
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (ModelSpec (TEInitialDropoutF 'RoBERTa hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       ()
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim, inputEmbedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[embedDim])))))
                             (NamedModel
                                (GLinear
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim, embedDim])))
                                   (NamedModel
                                      (Tensor
                                         gradient
                                         ('Layout 'Dense)
                                         device
                                         dataType
                                         ('Shape '[inputEmbedDim])))))
                             (DropoutF 'RoBERTa hasDropout)))
                       (SADropoutF 'RoBERTa hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[ffnDim, inputEmbedDim])))
                             (NamedModel
                                (Tensor
                                   gradient ('Layout 'Dense) device dataType ('Shape '[ffnDim])))))
                       Gelu
                       ()
                       (NamedModel
                          (GLinear
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim, ffnDim])))
                             (NamedModel
                                (Tensor
                                   gradient
                                   ('Layout 'Dense)
                                   device
                                   dataType
                                   ('Shape '[inputEmbedDim])))))
                       (FFNOutputDropoutF 'RoBERTa hasDropout)
                       (NamedModel
                          (LayerNorm
                             'WithBias
                             gradient
                             device
                             dataType
                             ('Shape '[inputEmbedDim])))))))))
     ()
     ()
-&gt; NamedModel
     (GTransformer
        (NamedModel
           (EmbeddingSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              posEncDim
              inputEmbedDim
              'Nothing))
        ()
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (ModelSpec (TEInitialDropoutF 'RoBERTa hasDropout))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          ()
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim, inputEmbedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[embedDim])))))
                                (NamedModel
                                   (GLinear
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim, embedDim])))
                                      (NamedModel
                                         (Tensor
                                            gradient
                                            ('Layout 'Dense)
                                            device
                                            dataType
                                            ('Shape '[inputEmbedDim])))))
                                (DropoutF 'RoBERTa hasDropout)))
                          (SADropoutF 'RoBERTa hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias gradient device dataType ('Shape '[inputEmbedDim])))))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim, inputEmbedDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[ffnDim])))))
                          Gelu
                          ()
                          (NamedModel
                             (GLinear
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim, ffnDim])))
                                (NamedModel
                                   (Tensor
                                      gradient
                                      ('Layout 'Dense)
                                      device
                                      dataType
                                      ('Shape '[inputEmbedDim])))))
                          (FFNOutputDropoutF 'RoBERTa hasDropout)
                          (NamedModel
                             (LayerNorm
                                'WithBias
                                gradient
                                device
                                dataType
                                ('Shape '[inputEmbedDim])))))))))
        ()
        ())
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF
           'RoBERTa gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF 'RoBERTa gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF
           'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF 'RoBERTa hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF 'RoBERTa gradient device dataType inputEmbedDim embedDim)
                             (KInProjF 'RoBERTa gradient device dataType inputEmbedDim embedDim)
                             (VInProjF 'RoBERTa gradient device dataType inputEmbedDim embedDim)
                             (OutProjF 'RoBERTa gradient device dataType embedDim inputEmbedDim)
                             (DropoutF 'RoBERTa hasDropout)))
                       (SADropoutF 'RoBERTa hasDropout)
                       (SAFinalLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          'RoBERTa gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF 'RoBERTa)
                       (FFNActivationDropoutF 'RoBERTa)
                       (FFNOutputProjectionF
                          'RoBERTa gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF 'RoBERTa hasDropout)
                       (FFNOutputLayerNormF
                          'RoBERTa gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF
           'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF 'RoBERTa hasDropout))
forall {style :: TransformerStyle}.
STransformerStyle style
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout))
</span><a href="#local-6989586621679700509"><span class="hs-identifier hs-var">encoderSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span>
</span><span id="line-221"></span><span>      </span><span class="annot"><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout)))
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-222"></span><span>      </span><span id="local-6989586621679700501"><span class="annot"><span class="annottext">embeddingSpec :: STransformerStyle style
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679700501"><span class="hs-identifier hs-var hs-var">embeddingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-223"></span><span>      </span><span class="annot"><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-224"></span><span>      </span><span class="annot"><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-225"></span><span>      </span><span class="annot"><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-226"></span><span>      </span><span class="annot"><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-227"></span><span>      </span><span class="annot"><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;bert.embeddings.word_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679700483"><span class="hs-identifier hs-var">embeddingSpec'</span></a></span><span>
</span><span id="line-228"></span><span>      </span><span class="annot"><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;roberta.embeddings.word_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679700483"><span class="hs-identifier hs-var">embeddingSpec'</span></a></span><span>
</span><span id="line-229"></span><span>      </span><span class="annot"><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-230"></span><span>      </span><span id="local-6989586621679700477"><span class="annot"><span class="annottext">typeEmbeddingSpec :: STransformerStyle style
-&gt; ModelSpec
     (EOTTypeEmbeddingF
        style gradient device dataType inputEmbedDim typeVocabDim)
</span><a href="#local-6989586621679700477"><span class="hs-identifier hs-var hs-var">typeEmbeddingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-231"></span><span>      </span><span class="annot"><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-232"></span><span>      </span><span class="annot"><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-233"></span><span>      </span><span class="annot"><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-234"></span><span>      </span><span class="annot"><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-235"></span><span>      </span><span class="annot"><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     typeVocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        typeVocabDim
        inputEmbedDim
        'Nothing)
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;bert.embeddings.token_type_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  typeVocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679700459"><span class="hs-identifier hs-var">typeEmbeddingSpec'</span></a></span><span>
</span><span id="line-236"></span><span>      </span><span class="annot"><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     typeVocabDim
     inputEmbedDim
     'Nothing
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        typeVocabDim
        inputEmbedDim
        'Nothing)
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;roberta.embeddings.token_type_embeddings.&quot;</span></span><span> </span><span class="annot"><span class="annottext">EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  typeVocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679700459"><span class="hs-identifier hs-var">typeEmbeddingSpec'</span></a></span><span>
</span><span id="line-237"></span><span>      </span><span class="annot"><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTTypeEmbeddingF
     style gradient device dataType inputEmbedDim typeVocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-238"></span><span>      </span><span id="local-6989586621679700453"><span class="annot"><span class="annottext">headSpec :: STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; ModelSpec
     (EOTHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679700453"><span class="hs-identifier hs-var hs-var">headSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-239"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-240"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-241"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-242"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-243"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-244"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;cls.predictions.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GLMHead
   inputEmbedDim
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim])))))
   Gelu
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[vocabDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
   (GBias ())
 -&gt; NamedModel
      (GLMHead
         inputEmbedDim
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim])))))
         Gelu
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[vocabDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
         (GBias ())))
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF 'BERT))
     (ModelSpec
        (LMHeadLayerNormF 'BERT gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           'BERT gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF 'BERT gradient device dataType vocabDim))
forall {style :: TransformerStyle}.
STransformerStyle style
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="#local-6989586621679700430"><span class="hs-identifier hs-var">headSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span>
</span><span id="line-245"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-246"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">(GLMHead
   inputEmbedDim
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[inputEmbedDim])))))
   Gelu
   (NamedModel
      (LayerNormSpec
         'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
   (NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[vocabDim, inputEmbedDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
   (GBias ())
 -&gt; NamedModel
      (GLMHead
         inputEmbedDim
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[inputEmbedDim])))))
         Gelu
         (NamedModel
            (LayerNormSpec
               'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
         (NamedModel
            (GLinear
               (NamedModel
                  (TensorSpec
                     gradient
                     ('Layout 'Dense)
                     device
                     dataType
                     ('Shape '[vocabDim, inputEmbedDim])))
               (NamedModel
                  (TensorSpec
                     gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
         (GBias ())))
-&gt; GLMHead
     inputEmbedDim
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[inputEmbedDim])))))
     Gelu
     (NamedModel
        (LayerNormSpec
           'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[vocabDim, inputEmbedDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
     (GBias ())
-&gt; NamedModel
     (GLMHead
        inputEmbedDim
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[inputEmbedDim])))))
        Gelu
        (NamedModel
           (LayerNormSpec
              'WithBias gradient device dataType ('Shape '[inputEmbedDim])))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[vocabDim, inputEmbedDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))))
        (GBias ()))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF 'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF 'RoBERTa))
     (ModelSpec
        (LMHeadLayerNormF 'RoBERTa gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           'RoBERTa gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec
        (LMHeadBiasF 'RoBERTa gradient device dataType vocabDim))
forall {style :: TransformerStyle}.
STransformerStyle style
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="#local-6989586621679700430"><span class="hs-identifier hs-var">headSpec'</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span>
</span><span id="line-247"></span><span>      </span><span class="annot"><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EOTHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-248"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-type">embedScalingSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701554"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerHasEmbedScaling"><span class="hs-identifier hs-type">EncoderOnlyTransformerHasEmbedScaling</span></a></span><span>
</span><span id="line-249"></span><span>      </span><span id="local-6989586621679700421"><span class="annot"><span class="annottext">embedScalingSpec :: STransformerStyle style -&gt; EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700421"><span class="hs-identifier hs-var hs-var">embedScalingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-250"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-251"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-252"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-253"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-254"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span>
</span><span id="line-255"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span>
</span><span id="line-256"></span><span>      </span><span class="annot"><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-257"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; NamedModel
     (GTransformer
        (ModelSpec
           (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
        (ModelSpec
           (TERelPosEncF style gradient device dataType headDim posEncDim))
        (ModelSpec
           (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEInitialDropoutF style hasDropout))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                (DropoutF style hasDropout)))
                          (SADropoutF style hasDropout)
                          (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                          (FFNInputTransformationF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNActivationF style)
                          (FFNActivationDropoutF style)
                          (FFNOutputProjectionF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNOutputDropoutF style hasDropout)
                          (FFNOutputLayerNormF
                             style gradient device dataType inputEmbedDim)))))))
        (ModelSpec
           (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEFinalDropoutF style hasDropout)))
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
-&gt; ModelSpec
     (EOTTypeEmbeddingF
        style gradient device dataType inputEmbedDim typeVocabDim)
-&gt; ModelSpec
     (EOTHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim
     (NamedModel
        (GTransformer
           (ModelSpec
              (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
           (ModelSpec
              (TERelPosEncF style gradient device dataType headDim posEncDim))
           (ModelSpec
              (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
           (ModelSpec (TEInitialDropoutF style hasDropout))
           (NamedModel
              (GTransformerStack
                 (VectorSpec
                    numLayers
                    (GTransformerBlock
                       (NamedModel
                          (GSelfAttention
                             (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                             (NamedModel
                                (GMultiHeadAttention
                                   headDim
                                   headEmbedDim
                                   embedDim
                                   (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                   (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                   (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                   (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                   (DropoutF style hasDropout)))
                             (SADropoutF style hasDropout)
                             (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                       ()
                       (NamedModel
                          (GTransformerFeedForwardNetwork
                             (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                             (FFNInputTransformationF
                                style gradient device dataType inputEmbedDim ffnDim)
                             (FFNActivationF style)
                             (FFNActivationDropoutF style)
                             (FFNOutputProjectionF
                                style gradient device dataType inputEmbedDim ffnDim)
                             (FFNOutputDropoutF style hasDropout)
                             (FFNOutputLayerNormF
                                style gradient device dataType inputEmbedDim)))))))
           (ModelSpec
              (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
           (ModelSpec (TEFinalDropoutF style hasDropout))))
     (NamedModel
        (EmbeddingSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing))
     (ModelSpec
        (EOTTypeEmbeddingF
           style gradient device dataType inputEmbedDim typeVocabDim))
     (ModelSpec
        (EOTHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; encoderEmbedding
-&gt; encoderTypeEmbedding
-&gt; head
-&gt; EncoderOnlyTransformerHasEmbedScaling
-&gt; GEncoderOnlyTransformer
     inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-var">GEncoderOnlyTransformer</span></a></span><span>
</span><span id="line-258"></span><span>        </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679700544"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-259"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; NamedModel
     (GTransformer
        (ModelSpec
           (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
        (ModelSpec
           (TERelPosEncF style gradient device dataType headDim posEncDim))
        (ModelSpec
           (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEInitialDropoutF style hasDropout))
        (NamedModel
           (GTransformerStack
              (VectorSpec
                 numLayers
                 (GTransformerBlock
                    (NamedModel
                       (GSelfAttention
                          (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                          (NamedModel
                             (GMultiHeadAttention
                                headDim
                                headEmbedDim
                                embedDim
                                (QInProjF style gradient device dataType inputEmbedDim embedDim)
                                (KInProjF style gradient device dataType inputEmbedDim embedDim)
                                (VInProjF style gradient device dataType inputEmbedDim embedDim)
                                (OutProjF style gradient device dataType embedDim inputEmbedDim)
                                (DropoutF style hasDropout)))
                          (SADropoutF style hasDropout)
                          (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                    ()
                    (NamedModel
                       (GTransformerFeedForwardNetwork
                          (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                          (FFNInputTransformationF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNActivationF style)
                          (FFNActivationDropoutF style)
                          (FFNOutputProjectionF
                             style gradient device dataType inputEmbedDim ffnDim)
                          (FFNOutputDropoutF style hasDropout)
                          (FFNOutputLayerNormF
                             style gradient device dataType inputEmbedDim)))))))
        (ModelSpec
           (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
        (ModelSpec (TEFinalDropoutF style hasDropout)))
</span><a href="#local-6989586621679700536"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700553"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-260"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; NamedModel
     (EmbeddingSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679700501"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700553"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (EOTTypeEmbeddingF
        style gradient device dataType inputEmbedDim typeVocabDim)
</span><a href="#local-6989586621679700477"><span class="hs-identifier hs-var">typeEmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700553"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; ModelSpec
     (EOTHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679700453"><span class="hs-identifier hs-var">headSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700553"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="#local-6989586621679700552"><span class="hs-identifier hs-var">transformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700421"><span class="hs-identifier hs-var">embedScalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700553"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-264"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-265"></span><span>    </span><span class="annot"><a href="#local-6989586621679700509"><span class="hs-identifier hs-type">encoderSpec'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-266"></span><span>    </span><span id="local-6989586621679700509"><span class="annot"><span class="annottext">encoderSpec' :: STransformerStyle style
-&gt; GTransformer
     (ModelSpec
        (TEPosEncF style gradient device dataType inputEmbedDim posEncDim))
     (ModelSpec
        (TERelPosEncF style gradient device dataType headDim posEncDim))
     (ModelSpec
        (TEInitialLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEInitialDropoutF style hasDropout))
     (NamedModel
        (GTransformerStack
           (VectorSpec
              numLayers
              (GTransformerBlock
                 (NamedModel
                    (GSelfAttention
                       (SAInitialLayerNormF style gradient device dataType inputEmbedDim)
                       (NamedModel
                          (GMultiHeadAttention
                             headDim
                             headEmbedDim
                             embedDim
                             (QInProjF style gradient device dataType inputEmbedDim embedDim)
                             (KInProjF style gradient device dataType inputEmbedDim embedDim)
                             (VInProjF style gradient device dataType inputEmbedDim embedDim)
                             (OutProjF style gradient device dataType embedDim inputEmbedDim)
                             (DropoutF style hasDropout)))
                       (SADropoutF style hasDropout)
                       (SAFinalLayerNormF style gradient device dataType inputEmbedDim)))
                 ()
                 (NamedModel
                    (GTransformerFeedForwardNetwork
                       (FFNInputLayerNormF style gradient device dataType inputEmbedDim)
                       (FFNInputTransformationF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNActivationF style)
                       (FFNActivationDropoutF style)
                       (FFNOutputProjectionF
                          style gradient device dataType inputEmbedDim ffnDim)
                       (FFNOutputDropoutF style hasDropout)
                       (FFNOutputLayerNormF
                          style gradient device dataType inputEmbedDim)))))))
     (ModelSpec
        (TEFinalLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec (TEFinalDropoutF style hasDropout))
</span><a href="#local-6989586621679700509"><span class="hs-identifier hs-var hs-var">encoderSpec'</span></a></span></span><span> </span><span id="local-6989586621679700400"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700400"><span class="hs-identifier hs-var">style'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (TransformerEncoderF
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        hasDropout)
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (TransformerEncoderF
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GTransformer.html#transformerEncoderSpec"><span class="hs-identifier hs-var">transformerEncoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700400"><span class="hs-identifier hs-var">style'</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679700551"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679700550"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679700549"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679700548"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679700547"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679700546"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679700545"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679700544"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679700543"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679700542"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679700539"><span class="hs-identifier hs-var">hasDropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700538"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700537"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-267"></span><span>    </span><span id="local-6989586621679700483"><span class="annot"><span class="annottext">embeddingSpec' :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679700483"><span class="hs-identifier hs-var hs-var">embeddingSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim vocabDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679700550"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679700549"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679700548"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679700541"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679700544"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-268"></span><span>    </span><span id="local-6989586621679700459"><span class="annot"><span class="annottext">typeEmbeddingSpec' :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  typeVocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679700459"><span class="hs-identifier hs-var hs-var">typeEmbeddingSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim typeVocabDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     typeVocabDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679700550"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679700549"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679700548"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim typeVocabDim
</span><a href="#local-6989586621679700540"><span class="hs-identifier hs-var">typeVocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679700544"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-269"></span><span>    </span><span class="annot"><a href="#local-6989586621679700430"><span class="hs-identifier hs-type">headSpec'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-270"></span><span>    </span><span id="local-6989586621679700430"><span class="annot"><span class="annottext">headSpec' :: STransformerStyle style
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="#local-6989586621679700430"><span class="hs-identifier hs-var hs-var">headSpec'</span></a></span></span><span> </span><span id="local-6989586621679700396"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700396"><span class="hs-identifier hs-var">style'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; ModelSpec
     (GLMHeadF style gradient device dataType inputEmbedDim vocabDim)
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; ModelSpec
     (GLMHeadF style gradient device dataType inputEmbedDim vocabDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier hs-var">lmHeadSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679700396"><span class="hs-identifier hs-var">style'</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679700550"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679700549"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679700548"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679700544"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679700541"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700537"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-271"></span><span>
</span><span id="line-272"></span><span id="local-6989586621679701401"><span id="local-6989586621679701402"><span id="local-6989586621679701403"><span id="local-6989586621679701404"><span id="local-6989586621679701405"><span id="local-6989586621679701406"><span id="local-6989586621679701407"><span id="local-6989586621679701408"><span id="local-6989586621679701409"><span id="local-6989586621679701410"><span id="local-6989586621679701411"><span id="local-6989586621679701412"><span id="local-6989586621679701413"><span id="local-6989586621679701414"><span class="hs-keyword">instance</span><span>
</span><span id="line-273"></span><span>  </span><span id="local-6989586621679700394"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701414"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701413"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701412"><span class="hs-identifier hs-type">encoder'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701411"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-274"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701410"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701411"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701409"><span class="hs-identifier hs-type">encoderEmbedding'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701408"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-275"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701407"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701408"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701406"><span class="hs-identifier hs-type">encoderTypeEmbedding'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701405"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-276"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701404"><span class="hs-identifier hs-type">head</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701405"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701403"><span class="hs-identifier hs-type">head'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701402"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-277"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-278"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-279"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701401"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701414"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701410"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701407"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701404"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-280"></span><span>    </span><span class="annot"><a href="#local-6989586621679701413"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-281"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701401"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701412"><span class="hs-identifier hs-type">encoder'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701409"><span class="hs-identifier hs-type">encoderEmbedding'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701406"><span class="hs-identifier hs-type">encoderTypeEmbedding'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701403"><span class="hs-identifier hs-type">head'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>    </span><span class="annot"><a href="#local-6989586621679701402"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-283"></span><span>
</span><span id="line-284"></span><span id="local-6989586621679701396"><span id="local-6989586621679701397"><span id="local-6989586621679701398"><span id="local-6989586621679701399"><span id="local-6989586621679701400"><span class="hs-keyword">instance</span><span>
</span><span id="line-285"></span><span>  </span><span id="local-6989586621679700390"><span id="local-6989586621679700392"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701400"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701399"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701398"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701397"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-286"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701396"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701400"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701399"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701398"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701397"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span><span>
</span><span id="line-287"></span><span>
</span><span id="line-288"></span><span id="local-6989586621679700388"><span id="local-6989586621679700389"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-289"></span><span>  </span><span id="GSimplifiedEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-var">GSimplifiedEncoderOnlyTransformer</span></a></span></span><span>
</span><span id="line-290"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701371"><span class="annot"><a href="#local-6989586621679701371"><span class="hs-identifier hs-type">model</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-291"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701370"><span class="annot"><a href="#local-6989586621679701370"><span class="hs-identifier hs-type">mkPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701369"><span class="annot"><a href="#local-6989586621679701369"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-293"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679701368"><span class="annot"><a href="#local-6989586621679701368"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-294"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-295"></span><span>  </span><span id="GSimplifiedEncoderOnlyTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-var">GSimplifiedEncoderOnlyTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-296"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679701391"><span class="annot"><a href="#local-6989586621679701391"><span class="hs-identifier hs-type">model</span></a></span></span><span> </span><span id="local-6989586621679701390"><span class="annot"><a href="#local-6989586621679701390"><span class="hs-identifier hs-type">mkPos</span></a></span></span><span> </span><span id="local-6989586621679701389"><span class="annot"><a href="#local-6989586621679701389"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679701388"><span class="annot"><a href="#local-6989586621679701388"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-297"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | encoder-only model</span><span>
</span><span id="line-298"></span><span>      </span><span id="seotModel"><span class="annot"><span class="annottext">forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; model
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotModel"><span class="hs-identifier hs-var hs-var">seotModel</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701391"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-299"></span><span>      </span><span class="hs-comment">-- | make input positions</span><span>
</span><span id="line-300"></span><span>      </span><span id="seotMkPos"><span class="annot"><span class="annottext">forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotMkPos"><span class="hs-identifier hs-var hs-var">seotMkPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701390"><span class="hs-identifier hs-type">mkPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-301"></span><span>      </span><span class="hs-comment">-- | make padding mask</span><span>
</span><span id="line-302"></span><span>      </span><span id="seotMkPaddingMask"><span class="annot"><span class="annottext">forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPaddingMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotMkPaddingMask"><span class="hs-identifier hs-var hs-var">seotMkPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701389"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-303"></span><span>      </span><span class="hs-comment">-- | make attention mask</span><span>
</span><span id="line-304"></span><span>      </span><span id="seotMkAttentionMask"><span class="annot"><span class="annottext">forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotMkAttentionMask"><span class="hs-identifier hs-var hs-var">seotMkAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701388"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-305"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-306"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701391"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701390"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701389"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701388"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-307"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700375"><span id="local-6989586621679700381"><span class="annot"><span class="annottext">GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
(GSimplifiedEncoderOnlyTransformer
   model mkPos mkPaddingMask mkAttentionMask
 -&gt; GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
 -&gt; Bool)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; Bool)
-&gt; Eq
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall model mkPos mkPaddingMask mkAttentionMask.
(Eq model, Eq mkPos, Eq mkPaddingMask, Eq mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
/= :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
$c/= :: forall model mkPos mkPaddingMask mkAttentionMask.
(Eq model, Eq mkPos, Eq mkPaddingMask, Eq mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
== :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
$c== :: forall model mkPos mkPaddingMask mkAttentionMask.
(Eq model, Eq mkPos, Eq mkPaddingMask, Eq mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700348"><span id="local-6989586621679700350"><span id="local-6989586621679700353"><span id="local-6989586621679700356"><span id="local-6989586621679700359"><span id="local-6989586621679700365"><span id="local-6989586621679700371"><span class="annot"><span class="annottext">Eq
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
Eq
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; Ordering)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; Bool)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; Bool)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; Bool)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; Bool)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask)
-&gt; Ord
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Ordering
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall {model} {mkPos} {mkPaddingMask} {mkAttentionMask}.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
Eq
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Ordering
forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
min :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
$cmin :: forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
max :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
$cmax :: forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
&gt;= :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
$c&gt;= :: forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
&gt; :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
$c&gt; :: forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
&lt;= :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
$c&lt;= :: forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
&lt; :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
$c&lt; :: forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Bool
compare :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Ordering
$ccompare :: forall model mkPos mkPaddingMask mkAttentionMask.
(Ord model, Ord mkPos, Ord mkPaddingMask, Ord mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; Ordering
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700337"><span id="local-6989586621679700339"><span id="local-6989586621679700346"><span class="annot"><span class="annottext">Int
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; ShowS
[GSimplifiedEncoderOnlyTransformer
   model mkPos mkPaddingMask mkAttentionMask]
-&gt; ShowS
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; String
(Int
 -&gt; GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
 -&gt; ShowS)
-&gt; (GSimplifiedEncoderOnlyTransformer
      model mkPos mkPaddingMask mkAttentionMask
    -&gt; String)
-&gt; ([GSimplifiedEncoderOnlyTransformer
       model mkPos mkPaddingMask mkAttentionMask]
    -&gt; ShowS)
-&gt; Show
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall model mkPos mkPaddingMask mkAttentionMask.
(Show model, Show mkPos, Show mkPaddingMask,
 Show mkAttentionMask) =&gt;
Int
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; ShowS
forall model mkPos mkPaddingMask mkAttentionMask.
(Show model, Show mkPos, Show mkPaddingMask,
 Show mkAttentionMask) =&gt;
[GSimplifiedEncoderOnlyTransformer
   model mkPos mkPaddingMask mkAttentionMask]
-&gt; ShowS
forall model mkPos mkPaddingMask mkAttentionMask.
(Show model, Show mkPos, Show mkPaddingMask,
 Show mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; String
showList :: [GSimplifiedEncoderOnlyTransformer
   model mkPos mkPaddingMask mkAttentionMask]
-&gt; ShowS
$cshowList :: forall model mkPos mkPaddingMask mkAttentionMask.
(Show model, Show mkPos, Show mkPaddingMask,
 Show mkAttentionMask) =&gt;
[GSimplifiedEncoderOnlyTransformer
   model mkPos mkPaddingMask mkAttentionMask]
-&gt; ShowS
show :: GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; String
$cshow :: forall model mkPos mkPaddingMask mkAttentionMask.
(Show model, Show mkPos, Show mkPaddingMask,
 Show mkAttentionMask) =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; String
showsPrec :: Int
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; ShowS
$cshowsPrec :: forall model mkPos mkPaddingMask mkAttentionMask.
(Show model, Show mkPos, Show mkPaddingMask,
 Show mkAttentionMask) =&gt;
Int
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 GSimplifiedEncoderOnlyTransformer
   model mkPos mkPaddingMask mkAttentionMask
 -&gt; Rep
      (GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask)
      x)
-&gt; (forall x.
    Rep
      (GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask)
      x
    -&gt; GSimplifiedEncoderOnlyTransformer
         model mkPos mkPaddingMask mkAttentionMask)
-&gt; Generic
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
forall x.
Rep
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
  x
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
forall x.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; Rep
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
     x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall model mkPos mkPaddingMask mkAttentionMask x.
Rep
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
  x
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
forall model mkPos mkPaddingMask mkAttentionMask x.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; Rep
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
     x
$cto :: forall model mkPos mkPaddingMask mkAttentionMask x.
Rep
  (GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask)
  x
-&gt; GSimplifiedEncoderOnlyTransformer
     model mkPos mkPaddingMask mkAttentionMask
$cfrom :: forall model mkPos mkPaddingMask mkAttentionMask x.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; Rep
     (GSimplifiedEncoderOnlyTransformer
        model mkPos mkPaddingMask mkAttentionMask)
     x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-308"></span><span>
</span><span id="line-309"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-310"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span id="local-6989586621679700331"><span id="local-6989586621679700332"><span id="local-6989586621679700333"><span id="local-6989586621679700334"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700334"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700333"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700332"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700331"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-311"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700334"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700333"><span class="hs-identifier hs-type">mkPos</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700332"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679700331"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>
</span><span id="line-313"></span><span id="local-6989586621679701355"><span id="local-6989586621679701356"><span id="local-6989586621679701357"><span id="local-6989586621679701358"><span id="local-6989586621679701359"><span id="local-6989586621679701360"><span id="local-6989586621679701361"><span id="local-6989586621679701362"><span id="local-6989586621679701363"><span id="local-6989586621679701364"><span id="local-6989586621679701365"><span id="local-6989586621679701366"><span id="local-6989586621679701367"><span class="hs-keyword">instance</span><span>
</span><span id="line-314"></span><span>  </span><span id="local-6989586621679700329"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701367"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701366"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701365"><span class="hs-identifier hs-type">model'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701364"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-315"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701363"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701364"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701362"><span class="hs-identifier hs-type">mkPos'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701361"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-316"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701360"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701361"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701359"><span class="hs-identifier hs-type">mkPaddingMask'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701358"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-317"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701357"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701358"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701356"><span class="hs-identifier hs-type">mkAttentionMask'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701355"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-318"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-319"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-320"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701367"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701363"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701360"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701357"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-321"></span><span>    </span><span class="annot"><a href="#local-6989586621679701366"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-322"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701365"><span class="hs-identifier hs-type">model'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701362"><span class="hs-identifier hs-type">mkPos'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701359"><span class="hs-identifier hs-type">mkPaddingMask'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701356"><span class="hs-identifier hs-type">mkAttentionMask'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-323"></span><span>    </span><span class="annot"><a href="#local-6989586621679701355"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-324"></span><span>
</span><span id="line-325"></span><span id="local-6989586621679701351"><span id="local-6989586621679701352"><span id="local-6989586621679701353"><span id="local-6989586621679701354"><span class="hs-keyword">instance</span><span>
</span><span id="line-326"></span><span>  </span><span id="local-6989586621679700325"><span id="local-6989586621679700327"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701354"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701353"><span class="hs-identifier hs-type">mkPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701352"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701351"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-327"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701354"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701353"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701352"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701351"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-328"></span><span>
</span><span id="line-329"></span><span class="hs-comment">-- | Input data type for use with an encoder-only transformer.</span><span>
</span><span id="line-330"></span><span id="local-6989586621679700323"><span id="local-6989586621679700324"></span></span><span class="hs-keyword">data</span><span> </span><span id="EncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-var">EncoderOnlyTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679701326"><span class="annot"><a href="#local-6989586621679701326"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679701325"><span class="annot"><a href="#local-6989586621679701325"><span class="hs-identifier hs-type">inputType</span></a></span></span><span> </span><span id="local-6989586621679701324"><span class="annot"><a href="#local-6989586621679701324"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679701323"><span class="annot"><a href="#local-6989586621679701323"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-331"></span><span>  </span><span id="EncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-var">EncoderOnlyTransformerInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-332"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679701346"><span class="annot"><a href="#local-6989586621679701346"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679701345"><span class="annot"><a href="#local-6989586621679701345"><span class="hs-identifier hs-type">inputType</span></a></span></span><span> </span><span id="local-6989586621679701344"><span class="annot"><a href="#local-6989586621679701344"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679701343"><span class="annot"><a href="#local-6989586621679701343"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-333"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="eotInput"><span class="annot"><span class="annottext">forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; input
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotInput"><span class="hs-identifier hs-var hs-var">eotInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701346"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-334"></span><span>      </span><span id="eotInputType"><span class="annot"><span class="annottext">forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; inputType
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotInputType"><span class="hs-identifier hs-var hs-var">eotInputType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701345"><span class="hs-identifier hs-type">inputType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-335"></span><span>      </span><span id="eotPos"><span class="annot"><span class="annottext">forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; pos
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotPos"><span class="hs-identifier hs-var hs-var">eotPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701344"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-336"></span><span>      </span><span id="eotAttentionMask"><span class="annot"><span class="annottext">forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; attentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotAttentionMask"><span class="hs-identifier hs-var hs-var">eotAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701343"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-337"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-338"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701346"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701345"><span class="hs-identifier hs-type">inputType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701344"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701343"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-339"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700310"><span id="local-6989586621679700316"><span class="annot"><span class="annottext">EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
(EncoderOnlyTransformerInput input inputType pos attentionMask
 -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
 -&gt; Bool)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Bool)
-&gt; Eq
     (EncoderOnlyTransformerInput input inputType pos attentionMask)
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall input inputType pos attentionMask.
(Eq input, Eq inputType, Eq pos, Eq attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
/= :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
$c/= :: forall input inputType pos attentionMask.
(Eq input, Eq inputType, Eq pos, Eq attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
== :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
$c== :: forall input inputType pos attentionMask.
(Eq input, Eq inputType, Eq pos, Eq attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700283"><span id="local-6989586621679700285"><span id="local-6989586621679700288"><span id="local-6989586621679700291"><span id="local-6989586621679700294"><span id="local-6989586621679700300"><span id="local-6989586621679700306"><span class="annot"><span class="annottext">Eq (EncoderOnlyTransformerInput input inputType pos attentionMask)
Eq (EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Ordering)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Bool)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Bool)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Bool)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Bool)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; Ord
     (EncoderOnlyTransformerInput input inputType pos attentionMask)
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Ordering
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall {input} {inputType} {pos} {attentionMask}.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
Eq (EncoderOnlyTransformerInput input inputType pos attentionMask)
forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Ordering
forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
min :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
$cmin :: forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
max :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
$cmax :: forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
&gt;= :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
$c&gt;= :: forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
&gt; :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
$c&gt; :: forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
&lt;= :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
$c&lt;= :: forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
&lt; :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
$c&lt; :: forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Bool
compare :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Ordering
$ccompare :: forall input inputType pos attentionMask.
(Ord input, Ord inputType, Ord pos, Ord attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Ordering
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700272"><span id="local-6989586621679700274"><span id="local-6989586621679700281"><span class="annot"><span class="annottext">Int
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; ShowS
[EncoderOnlyTransformerInput input inputType pos attentionMask]
-&gt; ShowS
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; String
(Int
 -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
 -&gt; ShowS)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; String)
-&gt; ([EncoderOnlyTransformerInput input inputType pos attentionMask]
    -&gt; ShowS)
-&gt; Show
     (EncoderOnlyTransformerInput input inputType pos attentionMask)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall input inputType pos attentionMask.
(Show input, Show inputType, Show pos, Show attentionMask) =&gt;
Int
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; ShowS
forall input inputType pos attentionMask.
(Show input, Show inputType, Show pos, Show attentionMask) =&gt;
[EncoderOnlyTransformerInput input inputType pos attentionMask]
-&gt; ShowS
forall input inputType pos attentionMask.
(Show input, Show inputType, Show pos, Show attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; String
showList :: [EncoderOnlyTransformerInput input inputType pos attentionMask]
-&gt; ShowS
$cshowList :: forall input inputType pos attentionMask.
(Show input, Show inputType, Show pos, Show attentionMask) =&gt;
[EncoderOnlyTransformerInput input inputType pos attentionMask]
-&gt; ShowS
show :: EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; String
$cshow :: forall input inputType pos attentionMask.
(Show input, Show inputType, Show pos, Show attentionMask) =&gt;
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; String
showsPrec :: Int
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; ShowS
$cshowsPrec :: forall input inputType pos attentionMask.
(Show input, Show inputType, Show pos, Show attentionMask) =&gt;
Int
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 EncoderOnlyTransformerInput input inputType pos attentionMask
 -&gt; Rep
      (EncoderOnlyTransformerInput input inputType pos attentionMask) x)
-&gt; (forall x.
    Rep
      (EncoderOnlyTransformerInput input inputType pos attentionMask) x
    -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; Generic
     (EncoderOnlyTransformerInput input inputType pos attentionMask)
forall x.
Rep
  (EncoderOnlyTransformerInput input inputType pos attentionMask) x
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
forall x.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Rep
     (EncoderOnlyTransformerInput input inputType pos attentionMask) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall input inputType pos attentionMask x.
Rep
  (EncoderOnlyTransformerInput input inputType pos attentionMask) x
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
forall input inputType pos attentionMask x.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Rep
     (EncoderOnlyTransformerInput input inputType pos attentionMask) x
$cto :: forall input inputType pos attentionMask x.
Rep
  (EncoderOnlyTransformerInput input inputType pos attentionMask) x
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
$cfrom :: forall input inputType pos attentionMask x.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Rep
     (EncoderOnlyTransformerInput input inputType pos attentionMask) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-340"></span><span>
</span><span id="line-341"></span><span id="local-6989586621679700267"><span id="local-6989586621679700268"></span></span><span class="hs-keyword">data</span><span> </span><span id="SimplifiedEncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679701314"><span class="annot"><a href="#local-6989586621679701314"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679701313"><span class="annot"><a href="#local-6989586621679701313"><span class="hs-identifier hs-type">inputType</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-342"></span><span>  </span><span id="SimplifiedEncoderOnlyTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-343"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679701320"><span class="annot"><a href="#local-6989586621679701320"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679701319"><span class="annot"><a href="#local-6989586621679701319"><span class="hs-identifier hs-type">inputType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-344"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="seotInput"><span class="annot"><span class="annottext">forall input inputType.
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; input
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotInput"><span class="hs-identifier hs-var hs-var">seotInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701320"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-345"></span><span>      </span><span id="seotInputType"><span class="annot"><span class="annottext">forall input inputType.
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; inputType
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotInputType"><span class="hs-identifier hs-var hs-var">seotInputType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701319"><span class="hs-identifier hs-type">inputType</span></a></span><span>
</span><span id="line-346"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-347"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701320"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701319"><span class="hs-identifier hs-type">inputType</span></a></span><span>
</span><span id="line-348"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700258"><span id="local-6989586621679700262"><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
(SimplifiedEncoderOnlyTransformerInput input inputType
 -&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool)
-&gt; Eq (SimplifiedEncoderOnlyTransformerInput input inputType)
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall input inputType.
(Eq input, Eq inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
/= :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
$c/= :: forall input inputType.
(Eq input, Eq inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
== :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
$c== :: forall input inputType.
(Eq input, Eq inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700235"><span id="local-6989586621679700237"><span id="local-6989586621679700240"><span id="local-6989586621679700243"><span id="local-6989586621679700246"><span id="local-6989586621679700250"><span id="local-6989586621679700254"><span class="annot"><span class="annottext">Eq (SimplifiedEncoderOnlyTransformerInput input inputType)
Eq (SimplifiedEncoderOnlyTransformerInput input inputType)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; Ordering)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType)
-&gt; Ord (SimplifiedEncoderOnlyTransformerInput input inputType)
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Ordering
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall {input} {inputType}.
(Ord input, Ord inputType) =&gt;
Eq (SimplifiedEncoderOnlyTransformerInput input inputType)
forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Ordering
forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
min :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
$cmin :: forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
max :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
$cmax :: forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
&gt;= :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
$c&gt;= :: forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
&gt; :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
$c&gt; :: forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
&lt;= :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
$c&lt;= :: forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
&lt; :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
$c&lt; :: forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; Bool
compare :: SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Ordering
$ccompare :: forall input inputType.
(Ord input, Ord inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Ordering
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700226"><span id="local-6989586621679700228"><span id="local-6989586621679700233"><span class="annot"><span class="annottext">Int
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; ShowS
[SimplifiedEncoderOnlyTransformerInput input inputType] -&gt; ShowS
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; String
(Int
 -&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; ShowS)
-&gt; (SimplifiedEncoderOnlyTransformerInput input inputType
    -&gt; String)
-&gt; ([SimplifiedEncoderOnlyTransformerInput input inputType]
    -&gt; ShowS)
-&gt; Show (SimplifiedEncoderOnlyTransformerInput input inputType)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall input inputType.
(Show input, Show inputType) =&gt;
Int
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; ShowS
forall input inputType.
(Show input, Show inputType) =&gt;
[SimplifiedEncoderOnlyTransformerInput input inputType] -&gt; ShowS
forall input inputType.
(Show input, Show inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; String
showList :: [SimplifiedEncoderOnlyTransformerInput input inputType] -&gt; ShowS
$cshowList :: forall input inputType.
(Show input, Show inputType) =&gt;
[SimplifiedEncoderOnlyTransformerInput input inputType] -&gt; ShowS
show :: SimplifiedEncoderOnlyTransformerInput input inputType -&gt; String
$cshow :: forall input inputType.
(Show input, Show inputType) =&gt;
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; String
showsPrec :: Int
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; ShowS
$cshowsPrec :: forall input inputType.
(Show input, Show inputType) =&gt;
Int
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 SimplifiedEncoderOnlyTransformerInput input inputType
 -&gt; Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x)
-&gt; (forall x.
    Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x
    -&gt; SimplifiedEncoderOnlyTransformerInput input inputType)
-&gt; Generic (SimplifiedEncoderOnlyTransformerInput input inputType)
forall x.
Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
forall x.
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall input inputType x.
Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
forall input inputType x.
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x
$cto :: forall input inputType x.
Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
$cfrom :: forall input inputType x.
SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Rep (SimplifiedEncoderOnlyTransformerInput input inputType) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-349"></span><span>
</span><span id="line-350"></span><span class="hs-comment">-- | Output data type for use with an encoder-only transformer.</span><span>
</span><span id="line-351"></span><span id="local-6989586621679700221"><span id="local-6989586621679700222"></span></span><span class="hs-keyword">data</span><span> </span><span id="EncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">EncoderOnlyTransformerOutput</span></a></span></span><span> </span><span id="local-6989586621679701309"><span class="annot"><a href="#local-6989586621679701309"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-352"></span><span>  </span><span id="EncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">EncoderOnlyTransformerOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-353"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679701311"><span class="annot"><a href="#local-6989586621679701311"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-354"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="eotOutput"><span class="annot"><span class="annottext">forall output. EncoderOnlyTransformerOutput output -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#eotOutput"><span class="hs-identifier hs-var hs-var">eotOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701311"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-355"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-356"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701311"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-357"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700214"><span id="local-6989586621679700217"><span class="annot"><span class="annottext">EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
(EncoderOnlyTransformerOutput output
 -&gt; EncoderOnlyTransformerOutput output -&gt; Bool)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output -&gt; Bool)
-&gt; Eq (EncoderOnlyTransformerOutput output)
forall output.
Eq output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
$c/= :: forall output.
Eq output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
== :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
$c== :: forall output.
Eq output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700193"><span id="local-6989586621679700195"><span id="local-6989586621679700198"><span id="local-6989586621679700201"><span id="local-6989586621679700204"><span id="local-6989586621679700207"><span id="local-6989586621679700210"><span class="annot"><span class="annottext">Eq (EncoderOnlyTransformerOutput output)
Eq (EncoderOnlyTransformerOutput output)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output -&gt; Ordering)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output -&gt; Bool)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output -&gt; Bool)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output -&gt; Bool)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output -&gt; Bool)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output
    -&gt; EncoderOnlyTransformerOutput output)
-&gt; Ord (EncoderOnlyTransformerOutput output)
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Ordering
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall {output}.
Ord output =&gt;
Eq (EncoderOnlyTransformerOutput output)
forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Ordering
forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
min :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
$cmin :: forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
max :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
$cmax :: forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output
&gt;= :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
$c&gt;= :: forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
&gt; :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
$c&gt; :: forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
&lt;= :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
$c&lt;= :: forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
&lt; :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
$c&lt; :: forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Bool
compare :: EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Ordering
$ccompare :: forall output.
Ord output =&gt;
EncoderOnlyTransformerOutput output
-&gt; EncoderOnlyTransformerOutput output -&gt; Ordering
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700185"><span id="local-6989586621679700187"><span id="local-6989586621679700191"><span class="annot"><span class="annottext">Int -&gt; EncoderOnlyTransformerOutput output -&gt; ShowS
[EncoderOnlyTransformerOutput output] -&gt; ShowS
EncoderOnlyTransformerOutput output -&gt; String
(Int -&gt; EncoderOnlyTransformerOutput output -&gt; ShowS)
-&gt; (EncoderOnlyTransformerOutput output -&gt; String)
-&gt; ([EncoderOnlyTransformerOutput output] -&gt; ShowS)
-&gt; Show (EncoderOnlyTransformerOutput output)
forall output.
Show output =&gt;
Int -&gt; EncoderOnlyTransformerOutput output -&gt; ShowS
forall output.
Show output =&gt;
[EncoderOnlyTransformerOutput output] -&gt; ShowS
forall output.
Show output =&gt;
EncoderOnlyTransformerOutput output -&gt; String
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [EncoderOnlyTransformerOutput output] -&gt; ShowS
$cshowList :: forall output.
Show output =&gt;
[EncoderOnlyTransformerOutput output] -&gt; ShowS
show :: EncoderOnlyTransformerOutput output -&gt; String
$cshow :: forall output.
Show output =&gt;
EncoderOnlyTransformerOutput output -&gt; String
showsPrec :: Int -&gt; EncoderOnlyTransformerOutput output -&gt; ShowS
$cshowsPrec :: forall output.
Show output =&gt;
Int -&gt; EncoderOnlyTransformerOutput output -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 EncoderOnlyTransformerOutput output
 -&gt; Rep (EncoderOnlyTransformerOutput output) x)
-&gt; (forall x.
    Rep (EncoderOnlyTransformerOutput output) x
    -&gt; EncoderOnlyTransformerOutput output)
-&gt; Generic (EncoderOnlyTransformerOutput output)
forall x.
Rep (EncoderOnlyTransformerOutput output) x
-&gt; EncoderOnlyTransformerOutput output
forall x.
EncoderOnlyTransformerOutput output
-&gt; Rep (EncoderOnlyTransformerOutput output) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall output x.
Rep (EncoderOnlyTransformerOutput output) x
-&gt; EncoderOnlyTransformerOutput output
forall output x.
EncoderOnlyTransformerOutput output
-&gt; Rep (EncoderOnlyTransformerOutput output) x
$cto :: forall output x.
Rep (EncoderOnlyTransformerOutput output) x
-&gt; EncoderOnlyTransformerOutput output
$cfrom :: forall output x.
EncoderOnlyTransformerOutput output
-&gt; Rep (EncoderOnlyTransformerOutput output) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-358"></span><span>
</span><span id="line-359"></span><span id="local-6989586621679700180"><span id="local-6989586621679700181"></span></span><span class="hs-keyword">data</span><span> </span><span id="SimplifiedEncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerOutput</span></a></span></span><span> </span><span id="local-6989586621679701300"><span class="annot"><a href="#local-6989586621679701300"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span id="local-6989586621679701299"><span class="annot"><a href="#local-6989586621679701299"><span class="hs-identifier hs-type">paddingMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-360"></span><span>  </span><span id="SimplifiedEncoderOnlyTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-361"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679701306"><span class="annot"><a href="#local-6989586621679701306"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span id="local-6989586621679701305"><span class="annot"><a href="#local-6989586621679701305"><span class="hs-identifier hs-type">paddingMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-362"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="seotOutput"><span class="annot"><span class="annottext">forall output paddingMask.
SimplifiedEncoderOnlyTransformerOutput output paddingMask -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#seotOutput"><span class="hs-identifier hs-var hs-var">seotOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701306"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-363"></span><span>      </span><span id="sedtPaddingMask"><span class="annot"><span class="annottext">forall output paddingMask.
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; paddingMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#sedtPaddingMask"><span class="hs-identifier hs-var hs-var">sedtPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679701305"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-364"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-365"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701306"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701305"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-366"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679700171"><span id="local-6989586621679700175"><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
(SimplifiedEncoderOnlyTransformerOutput output paddingMask
 -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
 -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; Bool)
-&gt; Eq (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
forall output paddingMask.
(Eq output, Eq paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
/= :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
$c/= :: forall output paddingMask.
(Eq output, Eq paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
== :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
$c== :: forall output paddingMask.
(Eq output, Eq paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700148"><span id="local-6989586621679700150"><span id="local-6989586621679700153"><span id="local-6989586621679700156"><span id="local-6989586621679700159"><span id="local-6989586621679700163"><span id="local-6989586621679700167"><span class="annot"><span class="annottext">Eq (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
Eq (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; Ordering)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; Bool)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; Ord (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Ordering
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall {output} {paddingMask}.
(Ord output, Ord paddingMask) =&gt;
Eq (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Ordering
forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
min :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
$cmin :: forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
max :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
$cmax :: forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
&gt;= :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
$c&gt;= :: forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
&gt; :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
$c&gt; :: forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
&lt;= :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
$c&lt;= :: forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
&lt; :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
$c&lt; :: forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Bool
compare :: SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Ordering
$ccompare :: forall output paddingMask.
(Ord output, Ord paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Ordering
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700139"><span id="local-6989586621679700141"><span id="local-6989586621679700146"><span class="annot"><span class="annottext">Int
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; ShowS
[SimplifiedEncoderOnlyTransformerOutput output paddingMask]
-&gt; ShowS
SimplifiedEncoderOnlyTransformerOutput output paddingMask -&gt; String
(Int
 -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
 -&gt; ShowS)
-&gt; (SimplifiedEncoderOnlyTransformerOutput output paddingMask
    -&gt; String)
-&gt; ([SimplifiedEncoderOnlyTransformerOutput output paddingMask]
    -&gt; ShowS)
-&gt; Show (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall output paddingMask.
(Show output, Show paddingMask) =&gt;
Int
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; ShowS
forall output paddingMask.
(Show output, Show paddingMask) =&gt;
[SimplifiedEncoderOnlyTransformerOutput output paddingMask]
-&gt; ShowS
forall output paddingMask.
(Show output, Show paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask -&gt; String
showList :: [SimplifiedEncoderOnlyTransformerOutput output paddingMask]
-&gt; ShowS
$cshowList :: forall output paddingMask.
(Show output, Show paddingMask) =&gt;
[SimplifiedEncoderOnlyTransformerOutput output paddingMask]
-&gt; ShowS
show :: SimplifiedEncoderOnlyTransformerOutput output paddingMask -&gt; String
$cshow :: forall output paddingMask.
(Show output, Show paddingMask) =&gt;
SimplifiedEncoderOnlyTransformerOutput output paddingMask -&gt; String
showsPrec :: Int
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; ShowS
$cshowsPrec :: forall output paddingMask.
(Show output, Show paddingMask) =&gt;
Int
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 SimplifiedEncoderOnlyTransformerOutput output paddingMask
 -&gt; Rep
      (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x)
-&gt; (forall x.
    Rep (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x
    -&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; Generic
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall x.
Rep (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
forall x.
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Rep
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall output paddingMask x.
Rep (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
forall output paddingMask x.
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Rep
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x
$cto :: forall output paddingMask x.
Rep (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
$cfrom :: forall output paddingMask x.
SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; Rep
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-367"></span><span>
</span><span id="line-368"></span><span class="hs-comment">-- | 'HasForward' instance for encoder-only transformers with optional scaling and head.</span><span>
</span><span id="line-369"></span><span class="hs-comment">--</span><span>
</span><span id="line-370"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-371"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-372"></span><span class="hs-comment">--    &#9474; input &#9474;    &#9474; inputType &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;</span><span>
</span><span id="line-373"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-374"></span><span class="hs-comment">--        &#9474;              &#9474;           &#9474;            &#9474;</span><span>
</span><span id="line-375"></span><span class="hs-comment">--        &#9660;              &#9660;           &#9474;            &#9474;</span><span>
</span><span id="line-376"></span><span class="hs-comment">--  eotEmbedding  eotTypeEmbedding   &#9474;            &#9474;</span><span>
</span><span id="line-377"></span><span class="hs-comment">--        &#9660;              &#9660;           &#9474;            &#9474;</span><span>
</span><span id="line-378"></span><span class="hs-comment">-- (embedScaling)  (embedScaling)    &#9474;            &#9474;</span><span>
</span><span id="line-379"></span><span class="hs-comment">--        &#9474;              &#9474;           &#9474;            &#9474;</span><span>
</span><span id="line-380"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;           &#9474;            &#9474;</span><span>
</span><span id="line-381"></span><span class="hs-comment">--               &#9474;                   &#9474;            &#9474;</span><span>
</span><span id="line-382"></span><span class="hs-comment">--               &#9660;                   &#9474;            &#9474;</span><span>
</span><span id="line-383"></span><span class="hs-comment">--          eotEncoder&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-384"></span><span class="hs-comment">--               &#9660;</span><span>
</span><span id="line-385"></span><span class="hs-comment">--           (eotHead)</span><span>
</span><span id="line-386"></span><span class="hs-comment">--               &#9474;</span><span>
</span><span id="line-387"></span><span class="hs-comment">--               &#9660;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--          &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--          &#9474; output &#9474;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--          &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-391"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-392"></span><span id="local-6989586621679701231"><span id="local-6989586621679701232"><span id="local-6989586621679701233"><span id="local-6989586621679701234"><span id="local-6989586621679701235"><span id="local-6989586621679701236"><span id="local-6989586621679701237"><span id="local-6989586621679701238"><span id="local-6989586621679701239"><span id="local-6989586621679701240"><span id="local-6989586621679701241"><span id="local-6989586621679701242"><span id="local-6989586621679701243"><span id="local-6989586621679701244"><span id="local-6989586621679701245"><span id="local-6989586621679701246"><span id="local-6989586621679701247"><span id="local-6989586621679701248"><span id="local-6989586621679701249"><span id="local-6989586621679701250"><span id="local-6989586621679701251"><span id="local-6989586621679701252"><span id="local-6989586621679701253"><span id="local-6989586621679701254"><span id="local-6989586621679701255"><span id="local-6989586621679701256"><span id="local-6989586621679701257"><span id="local-6989586621679701258"><span class="hs-keyword">instance</span><span>
</span><span id="line-393"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-394"></span><span>      </span><span class="annot"><a href="#local-6989586621679701258"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span>
</span><span id="line-395"></span><span>      </span><span class="annot"><a href="#local-6989586621679701257"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-396"></span><span>      </span><span class="annot"><a href="#local-6989586621679701256"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-397"></span><span>      </span><span class="annot"><a href="#local-6989586621679701255"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span>
</span><span id="line-398"></span><span>      </span><span class="annot"><a href="#local-6989586621679701254"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-399"></span><span>    </span><span class="annot"><a href="#local-6989586621679701255"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701253"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701252"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701251"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701250"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701249"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-400"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-401"></span><span>      </span><span class="annot"><a href="#local-6989586621679701248"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span>
</span><span id="line-402"></span><span>      </span><span class="annot"><a href="#local-6989586621679701247"><span class="hs-identifier hs-type">inputType</span></a></span><span>
</span><span id="line-403"></span><span>      </span><span class="annot"><a href="#local-6989586621679701254"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice</span></a></span><span>
</span><span id="line-404"></span><span>      </span><span class="annot"><a href="#local-6989586621679701246"><span class="hs-identifier hs-type">typeEmbeddingOutput</span></a></span><span>
</span><span id="line-405"></span><span>      </span><span class="annot"><a href="#local-6989586621679701245"><span class="hs-identifier hs-type">typeEmbeddingGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-406"></span><span>    </span><span class="annot"><a href="#local-6989586621679701246"><span class="hs-identifier hs-type">typeEmbeddingOutput</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701244"><span class="hs-identifier hs-type">gradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701243"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701242"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701241"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701240"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-407"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-408"></span><span>      </span><span class="annot"><a href="#local-6989586621679701239"><span class="hs-identifier hs-type">encoder</span></a></span><span>
</span><span id="line-409"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-410"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679701253"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701244"><span class="hs-identifier hs-type">gradient''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-411"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679701252"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701243"><span class="hs-identifier hs-type">layout''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-412"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679701251"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701242"><span class="hs-identifier hs-type">device''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-413"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679701250"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701241"><span class="hs-identifier hs-type">dataType''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701249"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701240"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-415"></span><span>        </span><span class="annot"><a href="#local-6989586621679701238"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-416"></span><span>        </span><span class="annot"><a href="#local-6989586621679701237"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-417"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-418"></span><span>      </span><span class="annot"><a href="#local-6989586621679701245"><span class="hs-identifier hs-type">typeEmbeddingGeneratorOutputDevice</span></a></span><span>
</span><span id="line-419"></span><span>      </span><span class="annot"><a href="#local-6989586621679701236"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-420"></span><span>      </span><span class="annot"><a href="#local-6989586621679701235"><span class="hs-identifier hs-type">encoderGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-421"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701249"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701240"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-422"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-423"></span><span>      </span><span class="annot"><a href="#local-6989586621679701234"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-424"></span><span>      </span><span class="annot"><a href="#local-6989586621679701236"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-425"></span><span>      </span><span class="annot"><a href="#local-6989586621679701235"><span class="hs-identifier hs-type">encoderGeneratorOutputDevice</span></a></span><span>
</span><span id="line-426"></span><span>      </span><span class="annot"><a href="#local-6989586621679701233"><span class="hs-identifier hs-type">headOutput</span></a></span><span>
</span><span id="line-427"></span><span>      </span><span class="annot"><a href="#local-6989586621679701232"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-428"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-429"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-430"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701231"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701239"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701258"><span class="hs-identifier hs-type">encoderEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701248"><span class="hs-identifier hs-type">encoderTypeEmbedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701234"><span class="hs-identifier hs-type">head</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-431"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701257"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701247"><span class="hs-identifier hs-type">inputType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701238"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701237"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-432"></span><span>    </span><span class="annot"><a href="#local-6989586621679701256"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-433"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701233"><span class="hs-identifier hs-type">headOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-434"></span><span>    </span><span class="annot"><a href="#local-6989586621679701232"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-435"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-436"></span><span>  </span><span id="local-6989586621679700065"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput headOutput,
      Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GEncoderOnlyTransformer"><span class="hs-identifier hs-type">GEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679700058"><span id="local-6989586621679700059"><span id="local-6989586621679700060"><span id="local-6989586621679700061"><span id="local-6989586621679700062"><span id="local-6989586621679700063"><span class="annot"><span class="annottext">encoderEmbedding
encoderTypeEmbedding
encoder
head
SDim inputEmbedDim
EncoderOnlyTransformerHasEmbedScaling
eotEmbedScaling :: EncoderOnlyTransformerHasEmbedScaling
eotHead :: head
eotTypeEmbedding :: encoderTypeEmbedding
eotEmbedding :: encoderEmbedding
eotEncoder :: encoder
eotInputEmbedDim :: SDim inputEmbedDim
eotEmbedScaling :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; EncoderOnlyTransformerHasEmbedScaling
eotHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; head
eotTypeEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderTypeEmbedding
eotEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoderEmbedding
eotEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; encoder
eotInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       encoderEmbedding encoderTypeEmbedding head.
GEncoderOnlyTransformer
  inputEmbedDim encoder encoderEmbedding encoderTypeEmbedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679700058"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679700054"><span id="local-6989586621679700055"><span id="local-6989586621679700056"><span id="local-6989586621679700057"><span class="annot"><span class="annottext">input
inputType
pos
attentionMask
eotAttentionMask :: attentionMask
eotPos :: pos
eotInputType :: inputType
eotInput :: input
eotAttentionMask :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; attentionMask
eotPos :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; pos
eotInputType :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; inputType
eotInput :: forall input inputType pos attentionMask.
EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; input
</span><a href="#local-6989586621679700054"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-437"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700053"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700053"><span class="hs-identifier hs-var">scaling</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/mlp091qaldwnxnk1kz11fzh8naz8by0p-singletons-lib-singletons-3.0-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679700063"><span class="hs-identifier hs-var">eotInputEmbedDim</span></a></span><span>
</span><span id="line-438"></span><span>        </span><span id="local-6989586621679700049"><span class="annot"><span class="annottext">embeddedInput :: IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient' layout' device' dataType' shape')
</span><a href="#local-6989586621679700049"><span class="hs-identifier hs-var hs-var">embeddedInput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-439"></span><span>          </span><span class="annot"><span class="annottext">input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) input
forall {k} (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679700057"><span class="hs-identifier hs-var">eotInput</span></a></span><span>
</span><span id="line-440"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) input
-&gt; (input
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator embeddingGeneratorOutputDevice)
         (Tensor gradient' layout' device' dataType' shape'))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor gradient' layout' device' dataType' shape',
       Generator embeddingGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor gradient' layout' device' dataType' shape',
        Generator embeddingGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator embeddingGeneratorOutputDevice)
      (Tensor gradient' layout' device' dataType' shape'))
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (Tensor gradient' layout' device' dataType' shape',
          Generator embeddingGeneratorOutputDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">encoderEmbedding
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient' layout' device' dataType' shape',
      Generator embeddingGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">encoderEmbedding
</span><a href="#local-6989586621679700061"><span class="hs-identifier hs-var">eotEmbedding</span></a></span><span>
</span><span id="line-441"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient' layout' device' dataType' shape')
-&gt; (Tensor gradient' layout' device' dataType' shape'
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice)
         (Generator embeddingGeneratorOutputDevice)
         (Tensor gradient' layout' device' dataType' shape'))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall {k} (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span>
</span><span id="line-442"></span><span>              </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice)
      (Generator embeddingGeneratorOutputDevice)
      (Tensor gradient' layout' device' dataType' shape'))
-&gt; (Tensor gradient' layout' device' dataType' shape'
    -&gt; Tensor gradient' layout' device' dataType' shape')
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-443"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient' layout' device' dataType' shape'
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-444"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape')
-&gt; Double
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient' layout' device' dataType' shape'
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Double -&gt; Tensor gradient' layout' device' dataType' shape'
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700053"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-445"></span><span>                </span><span class="hs-special">)</span><span>
</span><span id="line-446"></span><span>                </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700058"><span class="hs-identifier hs-var">eotEmbedScaling</span></a></span><span>
</span><span id="line-447"></span><span>        </span><span id="local-6989586621679700045"><span class="annot"><span class="annottext">embeddedInputType :: IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape'')
</span><a href="#local-6989586621679700045"><span class="hs-identifier hs-var hs-var">embeddedInputType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-448"></span><span>          </span><span class="annot"><span class="annottext">inputType
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     inputType
forall {k} (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">inputType
</span><a href="#local-6989586621679700056"><span class="hs-identifier hs-var">eotInputType</span></a></span><span>
</span><span id="line-449"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator embeddingGeneratorOutputDevice)
  inputType
-&gt; (inputType
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice)
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator embeddingGeneratorOutputDevice
 -&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
       Generator typeEmbeddingGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator embeddingGeneratorOutputDevice
  -&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
        Generator typeEmbeddingGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice)
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; (inputType
    -&gt; Generator embeddingGeneratorOutputDevice
    -&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
          Generator typeEmbeddingGeneratorOutputDevice))
-&gt; inputType
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">encoderTypeEmbedding
-&gt; inputType
-&gt; Generator embeddingGeneratorOutputDevice
-&gt; m (Tensor gradient'' layout'' device'' dataType'' shape'',
      Generator typeEmbeddingGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">encoderTypeEmbedding
</span><a href="#local-6989586621679700060"><span class="hs-identifier hs-var">eotTypeEmbedding</span></a></span><span>
</span><span id="line-450"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor gradient'' layout'' device'' dataType'' shape''
    -&gt; IxStateT
         m
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall {k} (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span>
</span><span id="line-451"></span><span>              </span><span class="annot"><span class="annottext">(Tensor gradient'' layout'' device'' dataType'' shape''
 -&gt; IxStateT
      m
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; (Tensor gradient'' layout'' device'' dataType'' shape''
    -&gt; Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-452"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithoutEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithoutEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-453"></span><span>                    </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerWithEmbedScaling"><span class="hs-identifier hs-var">EncoderOnlyTransformerWithEmbedScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient'' layout'' device'' dataType'' shape''
 -&gt; Double
 -&gt; Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; Double
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Double -&gt; Tensor gradient'' layout'' device'' dataType'' shape''
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679700053"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-454"></span><span>                </span><span class="hs-special">)</span><span>
</span><span id="line-455"></span><span>                </span><span class="annot"><span class="annottext">EncoderOnlyTransformerHasEmbedScaling
</span><a href="#local-6989586621679700058"><span class="hs-identifier hs-var">eotEmbedScaling</span></a></span><span>
</span><span id="line-456"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (EncoderOnlyTransformerOutput headOutput)
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput headOutput,
      Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   (EncoderOnlyTransformerOutput headOutput)
 -&gt; Generator generatorDevice
 -&gt; m (EncoderOnlyTransformerOutput headOutput,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput headOutput,
      Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-457"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; Tensor gradient'' layout'' device'' dataType'' shape''
 -&gt; (Tensor gradient' layout' device' dataType' shape',
     Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape')
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape''
      -&gt; (Tensor gradient' layout' device' dataType' shape',
          Tensor gradient'' layout'' device'' dataType'' shape''))
forall {k1} {k2} (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1)
       (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient' layout' device' dataType' shape')
</span><a href="#local-6989586621679700049"><span class="hs-identifier hs-var">embeddedInput</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape''
   -&gt; (Tensor gradient' layout' device' dataType' shape',
       Tensor gradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor gradient' layout' device' dataType' shape',
      Tensor gradient'' layout'' device'' dataType'' shape'')
forall {k1} (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator embeddingGeneratorOutputDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor gradient'' layout'' device'' dataType'' shape'')
</span><a href="#local-6989586621679700045"><span class="hs-identifier hs-var">embeddedInputType</span></a></span><span>
</span><span id="line-458"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor gradient' layout' device' dataType' shape',
   Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; ((Tensor gradient' layout' device' dataType' shape',
     Tensor gradient'' layout'' device'' dataType'' shape'')
    -&gt; IxStateT
         m
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient' gradient'')
            (Unify (Layout LayoutType) layout' layout'')
            (Unify (Device (DeviceType Nat)) device' device'')
            (Unify (DataType DType) dataType' dataType'')
            (BroadcastShapesF shape' shape'')))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient' gradient'')
        (Unify (Layout LayoutType) layout' layout'')
        (Unify (Device (DeviceType Nat)) device' device'')
        (Unify (DataType DType) dataType' dataType'')
        (BroadcastShapesF shape' shape''))
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient' gradient'')
     (Unify (Layout LayoutType) layout' layout'')
     (Unify (Device (DeviceType Nat)) device' device'')
     (Unify (DataType DType) dataType' dataType'')
     (BroadcastShapesF shape' shape''))
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient' gradient'')
        (Unify (Layout LayoutType) layout' layout'')
        (Unify (Device (DeviceType Nat)) device' device'')
        (Unify (DataType DType) dataType' dataType'')
        (BroadcastShapesF shape' shape''))
forall {k} (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient' gradient'')
      (Unify (Layout LayoutType) layout' layout'')
      (Unify (Device (DeviceType Nat)) device' device'')
      (Unify (DataType DType) dataType' dataType'')
      (BroadcastShapesF shape' shape''))
 -&gt; IxStateT
      m
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient' gradient'')
         (Unify (Layout LayoutType) layout' layout'')
         (Unify (Device (DeviceType Nat)) device' device'')
         (Unify (DataType DType) dataType' dataType'')
         (BroadcastShapesF shape' shape'')))
-&gt; ((Tensor gradient' layout' device' dataType' shape',
     Tensor gradient'' layout'' device'' dataType'' shape'')
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient' gradient'')
            (Unify (Layout LayoutType) layout' layout'')
            (Unify (Device (DeviceType Nat)) device' device'')
            (Unify (DataType DType) dataType' dataType'')
            (BroadcastShapesF shape' shape'')))
-&gt; (Tensor gradient' layout' device' dataType' shape',
    Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient' gradient'')
        (Unify (Layout LayoutType) layout' layout'')
        (Unify (Device (DeviceType Nat)) device' device'')
        (Unify (DataType DType) dataType' dataType'')
        (BroadcastShapesF shape' shape''))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient' layout' device' dataType' shape'
 -&gt; Tensor gradient'' layout'' device'' dataType'' shape''
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient' gradient'')
         (Unify (Layout LayoutType) layout' layout'')
         (Unify (Device (DeviceType Nat)) device' device'')
         (Unify (DataType DType) dataType' dataType'')
         (BroadcastShapesF shape' shape'')))
-&gt; (Tensor gradient' layout' device' dataType' shape',
    Tensor gradient'' layout'' device'' dataType'' shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient' gradient'')
        (Unify (Layout LayoutType) layout' layout'')
        (Unify (Device (DeviceType Nat)) device' device'')
        (Unify (DataType DType) dataType' dataType'')
        (BroadcastShapesF shape' shape''))
forall a b c. (a -&gt; b -&gt; c) -&gt; (a, b) -&gt; c
</span><span class="hs-identifier hs-var">uncurry</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient' gradient'')
        (Unify (Layout LayoutType) layout' layout'')
        (Unify (Device (DeviceType Nat)) device' device'')
        (Unify (DataType DType) dataType' dataType'')
        (BroadcastShapesF shape' shape''))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier hs-var">add</span></a></span><span>
</span><span id="line-459"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator typeEmbeddingGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient' gradient'')
     (Unify (Layout LayoutType) layout' layout'')
     (Unify (Device (DeviceType Nat)) device' device'')
     (Unify (DataType DType) dataType' dataType'')
     (BroadcastShapesF shape' shape''))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient' gradient'')
      (Unify (Layout LayoutType) layout' layout'')
      (Unify (Device (DeviceType Nat)) device' device'')
      (Unify (DataType DType) dataType' dataType'')
      (BroadcastShapesF shape' shape'')
    -&gt; IxStateT
         m
         (Generator typeEmbeddingGeneratorOutputDevice)
         (Generator encoderGeneratorOutputDevice)
         encoderOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679700042"><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient' gradient'')
  (Unify (Layout LayoutType) layout' layout'')
  (Unify (Device (DeviceType Nat)) device' device'')
  (Unify (DataType DType) dataType' dataType'')
  (BroadcastShapesF shape' shape'')
</span><a href="#local-6989586621679700042"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator typeEmbeddingGeneratorOutputDevice
 -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator typeEmbeddingGeneratorOutputDevice
  -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator typeEmbeddingGeneratorOutputDevice)
      (Generator encoderGeneratorOutputDevice)
      encoderOutput)
-&gt; (Generator typeEmbeddingGeneratorOutputDevice
    -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator typeEmbeddingGeneratorOutputDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">encoder
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient' gradient'')
      (Unify (Layout LayoutType) layout' layout'')
      (Unify (Device (DeviceType Nat)) device' device'')
      (Unify (DataType DType) dataType' dataType'')
      (BroadcastShapesF shape' shape''),
    pos, attentionMask)
-&gt; Generator typeEmbeddingGeneratorOutputDevice
-&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">encoder
</span><a href="#local-6989586621679700062"><span class="hs-identifier hs-var">eotEncoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient' gradient'')
  (Unify (Layout LayoutType) layout' layout'')
  (Unify (Device (DeviceType Nat)) device' device'')
  (Unify (DataType DType) dataType' dataType'')
  (BroadcastShapesF shape' shape'')
</span><a href="#local-6989586621679700042"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679700055"><span class="hs-identifier hs-var">eotPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionMask
</span><a href="#local-6989586621679700054"><span class="hs-identifier hs-var">eotAttentionMask</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-460"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator encoderGeneratorOutputDevice)
  encoderOutput
-&gt; (encoderOutput
    -&gt; IxStateT
         m
         (Generator encoderGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         headOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     headOutput
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator encoderGeneratorOutputDevice
 -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator encoderGeneratorOutputDevice
  -&gt; m (headOutput, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator encoderGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      headOutput)
-&gt; (encoderOutput
    -&gt; Generator encoderGeneratorOutputDevice
    -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; encoderOutput
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">head
-&gt; encoderOutput
-&gt; Generator encoderGeneratorOutputDevice
-&gt; m (headOutput, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">head
</span><a href="#local-6989586621679700059"><span class="hs-identifier hs-var">eotHead</span></a></span><span>
</span><span id="line-461"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  headOutput
-&gt; (headOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (EncoderOnlyTransformerOutput headOutput))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">EncoderOnlyTransformerOutput headOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
forall {k} (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(EncoderOnlyTransformerOutput headOutput
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (EncoderOnlyTransformerOutput headOutput))
-&gt; (headOutput -&gt; EncoderOnlyTransformerOutput headOutput)
-&gt; headOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput headOutput)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">headOutput -&gt; EncoderOnlyTransformerOutput headOutput
forall output. output -&gt; EncoderOnlyTransformerOutput output
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">EncoderOnlyTransformerOutput</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-462"></span><span>
</span><span id="line-463"></span><span id="local-6989586621679701113"><span id="local-6989586621679701114"><span id="local-6989586621679701115"><span id="local-6989586621679701116"><span id="local-6989586621679701117"><span id="local-6989586621679701118"><span id="local-6989586621679701119"><span id="local-6989586621679701120"><span id="local-6989586621679701121"><span id="local-6989586621679701122"><span id="local-6989586621679701123"><span id="local-6989586621679701124"><span class="hs-keyword">instance</span><span>
</span><span id="line-464"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-465"></span><span>      </span><span class="annot"><a href="#local-6989586621679701124"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span>
</span><span id="line-466"></span><span>      </span><span class="annot"><a href="#local-6989586621679701123"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-467"></span><span>      </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-468"></span><span>      </span><span class="annot"><a href="#local-6989586621679701121"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-469"></span><span>      </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-470"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-471"></span><span>      </span><span class="annot"><a href="#local-6989586621679701120"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span>
</span><span id="line-472"></span><span>      </span><span class="annot"><a href="#local-6989586621679701121"><span class="hs-identifier hs-type">paddingMask</span></a></span><span>
</span><span id="line-473"></span><span>      </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-474"></span><span>      </span><span class="annot"><a href="#local-6989586621679701119"><span class="hs-identifier hs-type">attentionMask</span></a></span><span>
</span><span id="line-475"></span><span>      </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-477"></span><span>      </span><span class="annot"><a href="#local-6989586621679701118"><span class="hs-identifier hs-type">mkPos</span></a></span><span>
</span><span id="line-478"></span><span>      </span><span class="annot"><a href="#local-6989586621679701123"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-479"></span><span>      </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-480"></span><span>      </span><span class="annot"><a href="#local-6989586621679701117"><span class="hs-identifier hs-type">pos</span></a></span><span>
</span><span id="line-481"></span><span>      </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-482"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-483"></span><span>      </span><span class="annot"><a href="#local-6989586621679701116"><span class="hs-identifier hs-type">model</span></a></span><span>
</span><span id="line-484"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-type">EncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701123"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701115"><span class="hs-identifier hs-type">inputType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701117"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701119"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-485"></span><span>      </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-486"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701114"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>      </span><span class="annot"><a href="#local-6989586621679701113"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-488"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-489"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-490"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701116"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701118"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701124"><span class="hs-identifier hs-type">mkPaddingMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701120"><span class="hs-identifier hs-type">mkAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-491"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701123"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701115"><span class="hs-identifier hs-type">inputType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-492"></span><span>    </span><span class="annot"><a href="#local-6989586621679701122"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-493"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701114"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679701121"><span class="hs-identifier hs-type">paddingMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-494"></span><span>    </span><span class="annot"><a href="#local-6989586621679701113"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-495"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-496"></span><span>  </span><span id="local-6989586621679700018"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; SimplifiedEncoderOnlyTransformerInput input inputType
-&gt; Generator generatorDevice
-&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
      Generator generatorOutputDevice)
</span><a href="#local-6989586621679700018"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#GSimplifiedEncoderOnlyTransformer"><span class="hs-identifier hs-type">GSimplifiedEncoderOnlyTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679700014"><span id="local-6989586621679700015"><span id="local-6989586621679700016"><span id="local-6989586621679700017"><span class="annot"><span class="annottext">mkPaddingMask
mkAttentionMask
mkPos
model
seotMkAttentionMask :: mkAttentionMask
seotMkPaddingMask :: mkPaddingMask
seotMkPos :: mkPos
seotModel :: model
seotMkAttentionMask :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkAttentionMask
seotMkPaddingMask :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPaddingMask
seotMkPos :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; mkPos
seotModel :: forall model mkPos mkPaddingMask mkAttentionMask.
GSimplifiedEncoderOnlyTransformer
  model mkPos mkPaddingMask mkAttentionMask
-&gt; model
</span><a href="#local-6989586621679700014"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerInput"><span class="hs-identifier hs-type">SimplifiedEncoderOnlyTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679700012"><span id="local-6989586621679700013"><span class="annot"><span class="annottext">input
inputType
seotInputType :: inputType
seotInput :: input
seotInputType :: forall input inputType.
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; inputType
seotInput :: forall input inputType.
SimplifiedEncoderOnlyTransformerInput input inputType -&gt; input
</span><a href="#local-6989586621679700012"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-497"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; Generator generatorDevice
-&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
      Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
 -&gt; Generator generatorDevice
 -&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
-&gt; Generator generatorDevice
-&gt; m (SimplifiedEncoderOnlyTransformerOutput output paddingMask,
      Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-498"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700011"><span class="annot"><span class="annottext">paddingMask :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  paddingMask
</span><a href="#local-6989586621679700011"><span class="hs-identifier hs-var hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (paddingMask, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (paddingMask, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      paddingMask)
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (paddingMask, Generator generatorDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">mkPaddingMask
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (paddingMask, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">mkPaddingMask
</span><a href="#local-6989586621679700015"><span class="hs-identifier hs-var">seotMkPaddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">(input
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      paddingMask)
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679700013"><span class="hs-identifier hs-var">seotInput</span></a></span><span>
</span><span id="line-499"></span><span>            </span><span id="local-6989586621679700010"><span class="annot"><span class="annottext">pos :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) pos
</span><a href="#local-6989586621679700010"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice -&gt; m (pos, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice -&gt; m (pos, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) pos)
-&gt; (input
    -&gt; Generator generatorDevice -&gt; m (pos, Generator generatorDevice))
-&gt; input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">mkPos
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (pos, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">mkPos
</span><a href="#local-6989586621679700016"><span class="hs-identifier hs-var">seotMkPos</span></a></span><span> </span><span class="annot"><span class="annottext">(input
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) pos)
-&gt; input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679700013"><span class="hs-identifier hs-var">seotInput</span></a></span><span>
</span><span id="line-500"></span><span>         </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(paddingMask -&gt; pos -&gt; (paddingMask, pos))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     paddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (pos -&gt; (paddingMask, pos))
forall {k1} {k2} (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1)
       (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  paddingMask
</span><a href="#local-6989586621679700011"><span class="hs-identifier hs-var">paddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (pos -&gt; (paddingMask, pos))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) pos
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (paddingMask, pos)
forall {k1} (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) pos
</span><a href="#local-6989586621679700010"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-501"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-502"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (paddingMask, pos)
-&gt; ((paddingMask, pos)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (SimplifiedEncoderOnlyTransformerOutput output paddingMask))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679700009"><span class="annot"><span class="annottext">paddingMask
</span><a href="#local-6989586621679700009"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679700008"><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679700008"><span class="hs-identifier hs-var">pos</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-503"></span><span>                 </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679700007"><span class="annot"><span class="annottext">attentionMask :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  attentionMask
</span><a href="#local-6989586621679700007"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (attentionMask, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (attentionMask, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      attentionMask)
-&gt; (paddingMask
    -&gt; Generator generatorDevice
    -&gt; m (attentionMask, Generator generatorDevice))
-&gt; paddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">mkAttentionMask
-&gt; paddingMask
-&gt; Generator generatorDevice
-&gt; m (attentionMask, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">mkAttentionMask
</span><a href="#local-6989586621679700014"><span class="hs-identifier hs-var">seotMkAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">(paddingMask
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      attentionMask)
-&gt; paddingMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">paddingMask
</span><a href="#local-6989586621679700009"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-504"></span><span>                  </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">input
-&gt; inputType
-&gt; pos
-&gt; attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
forall input inputType pos attentionMask.
input
-&gt; inputType
-&gt; pos
-&gt; attentionMask
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerInput"><span class="hs-identifier hs-var">EncoderOnlyTransformerInput</span></a></span><span>
</span><span id="line-505"></span><span>                         </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679700013"><span class="hs-identifier hs-var">seotInput</span></a></span><span>
</span><span id="line-506"></span><span>                         </span><span class="annot"><span class="annottext">inputType
</span><a href="#local-6989586621679700012"><span class="hs-identifier hs-var">seotInputType</span></a></span><span>
</span><span id="line-507"></span><span>                         </span><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679700008"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-508"></span><span>                         </span><span class="annot"><span class="annottext">(attentionMask
 -&gt; EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     attentionMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (EncoderOnlyTransformerInput input inputType pos attentionMask)
forall {k1} {k2} (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1)
       (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  attentionMask
</span><a href="#local-6989586621679700007"><span class="hs-identifier hs-var">attentionMask</span></a></span><span>
</span><span id="line-509"></span><span>                     </span><span class="hs-special">)</span><span>
</span><span id="line-510"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (EncoderOnlyTransformerInput input inputType pos attentionMask)
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (EncoderOnlyTransformerOutput output))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput output)
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (EncoderOnlyTransformerOutput output,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput output)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (EncoderOnlyTransformerOutput output,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (EncoderOnlyTransformerOutput output))
-&gt; (EncoderOnlyTransformerInput input inputType pos attentionMask
    -&gt; Generator generatorDevice
    -&gt; m (EncoderOnlyTransformerOutput output,
          Generator generatorOutputDevice))
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (EncoderOnlyTransformerOutput output)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">model
-&gt; EncoderOnlyTransformerInput input inputType pos attentionMask
-&gt; Generator generatorDevice
-&gt; m (EncoderOnlyTransformerOutput output,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679700017"><span class="hs-identifier hs-var">seotModel</span></a></span><span>
</span><span id="line-511"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (EncoderOnlyTransformerOutput output)
-&gt; (EncoderOnlyTransformerOutput output
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (SimplifiedEncoderOnlyTransformerOutput output paddingMask))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall {k1} (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#EncoderOnlyTransformerOutput"><span class="hs-identifier hs-type">EncoderOnlyTransformerOutput</span></a></span><span> </span><span id="local-6989586621679700006"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679700006"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-512"></span><span>                                </span><span class="annot"><span class="annottext">SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall {k} (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(SimplifiedEncoderOnlyTransformerOutput output paddingMask
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (SimplifiedEncoderOnlyTransformerOutput output paddingMask))
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (SimplifiedEncoderOnlyTransformerOutput output paddingMask)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">output
-&gt; paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
forall output paddingMask.
output
-&gt; paddingMask
-&gt; SimplifiedEncoderOnlyTransformerOutput output paddingMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderOnly.html#SimplifiedEncoderOnlyTransformerOutput"><span class="hs-identifier hs-var">SimplifiedEncoderOnlyTransformerOutput</span></a></span><span> </span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679700006"><span class="hs-identifier hs-var">output</span></a></span><span> </span><span class="annot"><span class="annottext">paddingMask
</span><a href="#local-6989586621679700009"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-513"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-514"></span><span>             </span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-515"></span></pre></body></html>