<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span id="%24con2tag_GOLp2vAcHy78EOISD5ngQ8"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FunctionalDependencies #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE LambdaCase #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE OverloadedStrings #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL #-}</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.Catch</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadThrow</span></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.NonLinearActivation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier">SoftmaxF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#softmax"><span class="hs-identifier">softmax</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Linear</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinear"><span class="hs-identifier">GLinear</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier">GLinearF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier">linearSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier">HasDropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier">SHasDropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.List.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier">sGetDimFromShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#sUnifyDim"><span class="hs-identifier">sUnifyDim</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">!</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SBy"><span class="hs-identifier">SBy</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#ReshapeF"><span class="hs-identifier">ReshapeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier">TransposeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sReshape"><span class="hs-identifier">sReshape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sTranspose"><span class="hs-identifier">sTranspose</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier">MatmulF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#matmul"><span class="hs-identifier">matmul</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span>
</span><span id="line-51"></span><span class="hs-comment">-- | Data type for representing whether or not (and, if so, where) scaling is applied in the multi-headed attention layer.</span><span>
</span><span id="line-52"></span><span id="local-6989586621679698075"><span id="local-6989586621679698076"></span></span><span class="hs-keyword">data</span><span> </span><span id="MultiHeadAttentionHasScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-var">MultiHeadAttentionHasScaling</span></a></span></span><span>
</span><span id="line-53"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="hs-comment">-- | Scaling is not done.</span><span>
</span><span id="line-54"></span><span>    </span><span id="MultiHeadAttentionWithoutScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithoutScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithoutScaling</span></a></span></span><span>
</span><span id="line-55"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | Scaling is applied to the query after in the in-projection.</span><span>
</span><span id="line-56"></span><span>    </span><span id="MultiHeadAttentionWithQueryScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithQueryScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithQueryScaling</span></a></span></span><span>
</span><span id="line-57"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | Scaling is applied to the attention weights.</span><span>
</span><span id="line-58"></span><span>    </span><span id="MultiHeadAttentionWithWeightScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithWeightScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithWeightScaling</span></a></span></span><span>
</span><span id="line-59"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679698068"><span id="local-6989586621679698070"><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
(MultiHeadAttentionHasScaling
 -&gt; MultiHeadAttentionHasScaling -&gt; Bool)
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; Bool)
-&gt; Eq MultiHeadAttentionHasScaling
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
$c/= :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
== :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
$c== :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679698052"><span id="local-6989586621679698054"><span id="local-6989586621679698056"><span id="local-6989586621679698058"><span id="local-6989586621679698060"><span id="local-6989586621679698062"><span id="local-6989586621679698064"><span class="annot"><span class="annottext">Eq MultiHeadAttentionHasScaling
Eq MultiHeadAttentionHasScaling
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; Ordering)
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; Bool)
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; Bool)
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; Bool)
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; Bool)
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; MultiHeadAttentionHasScaling)
-&gt; (MultiHeadAttentionHasScaling
    -&gt; MultiHeadAttentionHasScaling -&gt; MultiHeadAttentionHasScaling)
-&gt; Ord MultiHeadAttentionHasScaling
MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Ordering
MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; MultiHeadAttentionHasScaling
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; MultiHeadAttentionHasScaling
$cmin :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; MultiHeadAttentionHasScaling
max :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; MultiHeadAttentionHasScaling
$cmax :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; MultiHeadAttentionHasScaling
&gt;= :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
$c&gt;= :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
&gt; :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
$c&gt; :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
&lt;= :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
$c&lt;= :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
&lt; :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
$c&lt; :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Bool
compare :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Ordering
$ccompare :: MultiHeadAttentionHasScaling
-&gt; MultiHeadAttentionHasScaling -&gt; Ordering
$cp1Ord :: Eq MultiHeadAttentionHasScaling
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679698045"><span id="local-6989586621679698047"><span id="local-6989586621679698049"><span class="annot"><span class="annottext">Int -&gt; MultiHeadAttentionHasScaling -&gt; ShowS
[MultiHeadAttentionHasScaling] -&gt; ShowS
MultiHeadAttentionHasScaling -&gt; String
(Int -&gt; MultiHeadAttentionHasScaling -&gt; ShowS)
-&gt; (MultiHeadAttentionHasScaling -&gt; String)
-&gt; ([MultiHeadAttentionHasScaling] -&gt; ShowS)
-&gt; Show MultiHeadAttentionHasScaling
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [MultiHeadAttentionHasScaling] -&gt; ShowS
$cshowList :: [MultiHeadAttentionHasScaling] -&gt; ShowS
show :: MultiHeadAttentionHasScaling -&gt; String
$cshow :: MultiHeadAttentionHasScaling -&gt; String
showsPrec :: Int -&gt; MultiHeadAttentionHasScaling -&gt; ShowS
$cshowsPrec :: Int -&gt; MultiHeadAttentionHasScaling -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 MultiHeadAttentionHasScaling -&gt; Rep MultiHeadAttentionHasScaling x)
-&gt; (forall x.
    Rep MultiHeadAttentionHasScaling x -&gt; MultiHeadAttentionHasScaling)
-&gt; Generic MultiHeadAttentionHasScaling
forall x.
Rep MultiHeadAttentionHasScaling x -&gt; MultiHeadAttentionHasScaling
forall x.
MultiHeadAttentionHasScaling -&gt; Rep MultiHeadAttentionHasScaling x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x.
Rep MultiHeadAttentionHasScaling x -&gt; MultiHeadAttentionHasScaling
$cfrom :: forall x.
MultiHeadAttentionHasScaling -&gt; Rep MultiHeadAttentionHasScaling x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span>
</span><span id="line-61"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-type">MultiHeadAttentionHasScaling</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-type">MultiHeadAttentionHasScaling</span></a></span><span>
</span><span id="line-62"></span><span>
</span><span id="line-63"></span><span id="local-6989586621679698040"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-type">MultiHeadAttentionHasScaling</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698040"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-type">MultiHeadAttentionHasScaling</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698040"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-64"></span><span>  </span><span id="local-6989586621679698037"><span class="annot"><span class="annottext">initialize :: ModelSpec MultiHeadAttentionHasScaling
-&gt; Generator generatorDevice
-&gt; m (MultiHeadAttentionHasScaling, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679698035"><span class="annot"><span class="annottext">ModelSpec MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679698035"><span class="hs-identifier hs-var">hasScaling</span></a></span></span><span> </span><span id="local-6989586621679698034"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679698034"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MultiHeadAttentionHasScaling, Generator generatorDevice)
-&gt; m (MultiHeadAttentionHasScaling, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec MultiHeadAttentionHasScaling
MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679698035"><span class="hs-identifier hs-var">hasScaling</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679698034"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-65"></span><span>
</span><span id="line-66"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-type">MultiHeadAttentionHasScaling</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-67"></span><span>  </span><span id="local-6989586621679698030"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec MultiHeadAttentionHasScaling
-&gt; StateDictKey -&gt; m MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679698028"><span class="annot"><span class="annottext">ModelSpec MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679698028"><span class="hs-identifier hs-var">hasScaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling -&gt; m MultiHeadAttentionHasScaling
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec MultiHeadAttentionHasScaling
MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679698028"><span class="hs-identifier hs-var">hasScaling</span></a></span><span>
</span><span id="line-68"></span><span>  </span><span id="local-6989586621679698027"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MultiHeadAttentionHasScaling -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-69"></span><span>
</span><span id="line-70"></span><span class="hs-comment">-- | Generic multi-headed attention layer.</span><span>
</span><span id="line-71"></span><span class="hs-comment">--</span><span>
</span><span id="line-72"></span><span class="hs-comment">-- - @headDim@ is the dimension of the attention heads.</span><span>
</span><span id="line-73"></span><span class="hs-comment">-- - @headEmbedDim@ is the dimension of the attention head embedding.</span><span>
</span><span id="line-74"></span><span class="hs-comment">-- - @embedDim@ is the dimension of the embedding.</span><span>
</span><span id="line-75"></span><span class="hs-comment">-- - @qInProj@ is the type of the query projection.</span><span>
</span><span id="line-76"></span><span class="hs-comment">-- - @kInProj@ is the type of the key projection.</span><span>
</span><span id="line-77"></span><span class="hs-comment">-- - @vInProj@ is the type of the value projection.</span><span>
</span><span id="line-78"></span><span class="hs-comment">-- - @outProj@ is the type of the output projection.</span><span>
</span><span id="line-79"></span><span class="hs-comment">-- - @dropout@ is the type of the dropout layer.</span><span>
</span><span id="line-80"></span><span id="local-6989586621679698024"><span id="local-6989586621679698025"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-81"></span><span>  </span><span id="GMultiHeadAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-var">GMultiHeadAttention</span></a></span></span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698023"><span class="annot"><a href="#local-6989586621679698023"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698022"><span class="annot"><a href="#local-6989586621679698022"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698021"><span class="annot"><a href="#local-6989586621679698021"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698020"><span class="annot"><a href="#local-6989586621679698020"><span class="hs-identifier hs-type">qInProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698019"><span class="annot"><a href="#local-6989586621679698019"><span class="hs-identifier hs-type">kInProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698018"><span class="annot"><a href="#local-6989586621679698018"><span class="hs-identifier hs-type">vInProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698017"><span class="annot"><a href="#local-6989586621679698017"><span class="hs-identifier hs-type">outProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679698016"><span class="annot"><a href="#local-6989586621679698016"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-91"></span><span>  </span><span id="GMultiHeadAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-var">GMultiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-92"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679698429"><span class="annot"><a href="#local-6989586621679698429"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679698428"><span class="annot"><a href="#local-6989586621679698428"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679698427"><span class="annot"><a href="#local-6989586621679698427"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679698426"><span class="annot"><a href="#local-6989586621679698426"><span class="hs-identifier hs-type">qInProj</span></a></span></span><span> </span><span id="local-6989586621679698425"><span class="annot"><a href="#local-6989586621679698425"><span class="hs-identifier hs-type">kInProj</span></a></span></span><span> </span><span id="local-6989586621679698424"><span class="annot"><a href="#local-6989586621679698424"><span class="hs-identifier hs-type">vInProj</span></a></span></span><span> </span><span id="local-6989586621679698423"><span class="annot"><a href="#local-6989586621679698423"><span class="hs-identifier hs-type">outProj</span></a></span></span><span> </span><span id="local-6989586621679698422"><span class="annot"><a href="#local-6989586621679698422"><span class="hs-identifier hs-type">dropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | head dim</span><span>
</span><span id="line-94"></span><span>      </span><span id="mhaHeadDim"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; SDim headDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaHeadDim"><span class="hs-identifier hs-var hs-var">mhaHeadDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698429"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-95"></span><span>      </span><span class="hs-comment">-- | head embed dim</span><span>
</span><span id="line-96"></span><span>      </span><span id="mhaHeadEmbedDim"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; SDim headEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaHeadEmbedDim"><span class="hs-identifier hs-var hs-var">mhaHeadEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698428"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-97"></span><span>      </span><span class="hs-comment">-- | embed dim</span><span>
</span><span id="line-98"></span><span>      </span><span id="mhaEmbedDim"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; SDim embedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaEmbedDim"><span class="hs-identifier hs-var hs-var">mhaEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698427"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-99"></span><span>      </span><span class="hs-comment">-- | in-projection for query</span><span>
</span><span id="line-100"></span><span>      </span><span id="mhaQInProj"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; qInProj
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaQInProj"><span class="hs-identifier hs-var hs-var">mhaQInProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679698426"><span class="hs-identifier hs-type">qInProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-101"></span><span>      </span><span class="hs-comment">-- | in-projection for key</span><span>
</span><span id="line-102"></span><span>      </span><span id="mhaKInProj"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; kInProj
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaKInProj"><span class="hs-identifier hs-var hs-var">mhaKInProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679698425"><span class="hs-identifier hs-type">kInProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-103"></span><span>      </span><span class="hs-comment">-- | in-projection for value</span><span>
</span><span id="line-104"></span><span>      </span><span id="mhaVInProj"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; vInProj
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaVInProj"><span class="hs-identifier hs-var hs-var">mhaVInProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679698424"><span class="hs-identifier hs-type">vInProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-105"></span><span>      </span><span class="hs-comment">-- | out-projection</span><span>
</span><span id="line-106"></span><span>      </span><span id="mhaOutProj"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; outProj
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaOutProj"><span class="hs-identifier hs-var hs-var">mhaOutProj</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679698423"><span class="hs-identifier hs-type">outProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-107"></span><span>      </span><span class="hs-comment">-- | dropout</span><span>
</span><span id="line-108"></span><span>      </span><span id="mhaDropout"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaDropout"><span class="hs-identifier hs-var hs-var">mhaDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679698422"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-109"></span><span>      </span><span class="hs-comment">-- | scaling</span><span>
</span><span id="line-110"></span><span>      </span><span id="mhaScaling"><span class="annot"><span class="annottext">GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#mhaScaling"><span class="hs-identifier hs-var hs-var">mhaScaling</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-type">MultiHeadAttentionHasScaling</span></a></span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-112"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698429"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698428"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698427"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698426"><span class="hs-identifier hs-type">qInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698425"><span class="hs-identifier hs-type">kInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698424"><span class="hs-identifier hs-type">vInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698423"><span class="hs-identifier hs-type">outProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698422"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-113"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679698000"><span id="local-6989586621679698002"><span id="local-6989586621679698004"><span class="annot"><span class="annottext">Int
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
-&gt; ShowS
[GMultiHeadAttention
   headDim
   headEmbedDim
   embedDim
   qInProj
   kInProj
   vInProj
   outProj
   dropout]
-&gt; ShowS
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; String
(Int
 -&gt; GMultiHeadAttention
      headDim
      headEmbedDim
      embedDim
      qInProj
      kInProj
      vInProj
      outProj
      dropout
 -&gt; ShowS)
-&gt; (GMultiHeadAttention
      headDim
      headEmbedDim
      embedDim
      qInProj
      kInProj
      vInProj
      outProj
      dropout
    -&gt; String)
-&gt; ([GMultiHeadAttention
       headDim
       headEmbedDim
       embedDim
       qInProj
       kInProj
       vInProj
       outProj
       dropout]
    -&gt; ShowS)
-&gt; Show
     (GMultiHeadAttention
        headDim
        headEmbedDim
        embedDim
        qInProj
        kInProj
        vInProj
        outProj
        dropout)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
(Show qInProj, Show kInProj, Show vInProj, Show outProj,
 Show dropout) =&gt;
Int
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
-&gt; ShowS
forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
(Show qInProj, Show kInProj, Show vInProj, Show outProj,
 Show dropout) =&gt;
[GMultiHeadAttention
   headDim
   headEmbedDim
   embedDim
   qInProj
   kInProj
   vInProj
   outProj
   dropout]
-&gt; ShowS
forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
(Show qInProj, Show kInProj, Show vInProj, Show outProj,
 Show dropout) =&gt;
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; String
showList :: [GMultiHeadAttention
   headDim
   headEmbedDim
   embedDim
   qInProj
   kInProj
   vInProj
   outProj
   dropout]
-&gt; ShowS
$cshowList :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
(Show qInProj, Show kInProj, Show vInProj, Show outProj,
 Show dropout) =&gt;
[GMultiHeadAttention
   headDim
   headEmbedDim
   embedDim
   qInProj
   kInProj
   vInProj
   outProj
   dropout]
-&gt; ShowS
show :: GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; String
$cshow :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
(Show qInProj, Show kInProj, Show vInProj, Show outProj,
 Show dropout) =&gt;
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; String
showsPrec :: Int
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
-&gt; ShowS
$cshowsPrec :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
(Show qInProj, Show kInProj, Show vInProj, Show outProj,
 Show dropout) =&gt;
Int
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 GMultiHeadAttention
   headDim
   headEmbedDim
   embedDim
   qInProj
   kInProj
   vInProj
   outProj
   dropout
 -&gt; Rep
      (GMultiHeadAttention
         headDim
         headEmbedDim
         embedDim
         qInProj
         kInProj
         vInProj
         outProj
         dropout)
      x)
-&gt; (forall x.
    Rep
      (GMultiHeadAttention
         headDim
         headEmbedDim
         embedDim
         qInProj
         kInProj
         vInProj
         outProj
         dropout)
      x
    -&gt; GMultiHeadAttention
         headDim
         headEmbedDim
         embedDim
         qInProj
         kInProj
         vInProj
         outProj
         dropout)
-&gt; Generic
     (GMultiHeadAttention
        headDim
        headEmbedDim
        embedDim
        qInProj
        kInProj
        vInProj
        outProj
        dropout)
forall x.
Rep
  (GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout)
  x
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
forall x.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; Rep
     (GMultiHeadAttention
        headDim
        headEmbedDim
        embedDim
        qInProj
        kInProj
        vInProj
        outProj
        dropout)
     x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout x.
Rep
  (GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout)
  x
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout x.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; Rep
     (GMultiHeadAttention
        headDim
        headEmbedDim
        embedDim
        qInProj
        kInProj
        vInProj
        outProj
        dropout)
     x
$cto :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout x.
Rep
  (GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout)
  x
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
$cfrom :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout x.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; Rep
     (GMultiHeadAttention
        headDim
        headEmbedDim
        embedDim
        qInProj
        kInProj
        vInProj
        outProj
        dropout)
     x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>
</span><span id="line-115"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-116"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span id="local-6989586621679697997"><span class="annot"><a href="#local-6989586621679697997"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679697996"><span class="annot"><a href="#local-6989586621679697996"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697995"><span class="annot"><a href="#local-6989586621679697995"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697994"><span class="annot"><a href="#local-6989586621679697994"><span class="hs-identifier hs-type hs-type">qInProj</span></a></span></span><span> </span><span id="local-6989586621679697993"><span class="annot"><a href="#local-6989586621679697993"><span class="hs-identifier hs-type hs-type">kInProj</span></a></span></span><span> </span><span id="local-6989586621679697992"><span class="annot"><a href="#local-6989586621679697992"><span class="hs-identifier hs-type hs-type">vInProj</span></a></span></span><span> </span><span id="local-6989586621679697991"><span class="annot"><a href="#local-6989586621679697991"><span class="hs-identifier hs-type hs-type">outProj</span></a></span></span><span> </span><span id="local-6989586621679697990"><span class="annot"><a href="#local-6989586621679697990"><span class="hs-identifier hs-type hs-type">dropout</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-117"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697997"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697996"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697995"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697994"><span class="hs-identifier hs-type">qInProj</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697993"><span class="hs-identifier hs-type">kInProj</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697992"><span class="hs-identifier hs-type">vInProj</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697991"><span class="hs-identifier hs-type">outProj</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697990"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>
</span><span id="line-119"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-120"></span><span>  </span><span id="GMultiHeadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttentionF"><span class="hs-identifier hs-var">GMultiHeadAttentionF</span></a></span></span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697989"><span class="annot"><a href="#local-6989586621679697989"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697988"><span class="annot"><a href="#local-6989586621679697988"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697987"><span class="annot"><a href="#local-6989586621679697987"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697986"><span class="annot"><a href="#local-6989586621679697986"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697985"><span class="annot"><a href="#local-6989586621679697985"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697984"><span class="annot"><a href="#local-6989586621679697984"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697983"><span class="annot"><a href="#local-6989586621679697983"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697982"><span class="annot"><a href="#local-6989586621679697982"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-129"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697981"><span class="annot"><a href="#local-6989586621679697981"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697980"><span class="annot"><a href="#local-6989586621679697980"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-131"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697979"><span class="annot"><a href="#local-6989586621679697979"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-133"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-134"></span><span>  </span><span id="GMultiHeadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttentionF"><span class="hs-identifier hs-var">GMultiHeadAttentionF</span></a></span></span><span> </span><span id="local-6989586621679697978"><span class="annot"><a href="#local-6989586621679697978"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679697977"><span class="annot"><a href="#local-6989586621679697977"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697976"><span class="annot"><a href="#local-6989586621679697976"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697975"><span class="annot"><a href="#local-6989586621679697975"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697974"><span class="annot"><a href="#local-6989586621679697974"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679697973"><span class="annot"><a href="#local-6989586621679697973"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697972"><span class="annot"><a href="#local-6989586621679697972"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697971"><span class="annot"><a href="#local-6989586621679697971"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697970"><span class="annot"><a href="#local-6989586621679697970"><span class="hs-identifier hs-type hs-type">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697969"><span class="annot"><a href="#local-6989586621679697969"><span class="hs-identifier hs-type hs-type">valueEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697968"><span class="annot"><a href="#local-6989586621679697968"><span class="hs-identifier hs-type hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-135"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span>
</span><span id="line-136"></span><span>      </span><span class="annot"><a href="#local-6989586621679697974"><span class="hs-identifier hs-type">headDim</span></a></span><span>
</span><span id="line-137"></span><span>      </span><span class="annot"><a href="#local-6989586621679697973"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span>
</span><span id="line-138"></span><span>      </span><span class="annot"><a href="#local-6989586621679697972"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-139"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QInProjF"><span class="hs-identifier hs-type">QInProjF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697978"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697975"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697971"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697972"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-140"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KInProjF"><span class="hs-identifier hs-type">KInProjF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697978"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697975"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697970"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697972"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#VInProjF"><span class="hs-identifier hs-type">VInProjF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697978"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697975"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697969"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697972"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#OutProjF"><span class="hs-identifier hs-type">OutProjF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697978"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697976"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697975"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697972"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697971"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#DropoutF"><span class="hs-identifier hs-type">DropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697978"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697968"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>
</span><span id="line-145"></span><span class="hs-comment">-- | Specifies the linear transformation of the query.</span><span>
</span><span id="line-146"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-147"></span><span>  </span><span id="QInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QInProjF"><span class="hs-identifier hs-var">QInProjF</span></a></span></span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697967"><span class="annot"><a href="#local-6989586621679697967"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697966"><span class="annot"><a href="#local-6989586621679697966"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697965"><span class="annot"><a href="#local-6989586621679697965"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697964"><span class="annot"><a href="#local-6989586621679697964"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697963"><span class="annot"><a href="#local-6989586621679697963"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-153"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697962"><span class="annot"><a href="#local-6989586621679697962"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-154"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-155"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-156"></span><span>  </span><span id="QInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QInProjF"><span class="hs-identifier hs-var">QInProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679697960"><span class="annot"><a href="#local-6989586621679697960"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697959"><span class="annot"><a href="#local-6989586621679697959"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697958"><span class="annot"><a href="#local-6989586621679697958"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697957"><span class="annot"><a href="#local-6989586621679697957"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697956"><span class="annot"><a href="#local-6989586621679697956"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-157"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697960"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697958"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697957"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697956"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-158"></span><span>  </span><span id="QInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QInProjF"><span class="hs-identifier hs-var">QInProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679697954"><span class="annot"><a href="#local-6989586621679697954"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697953"><span class="annot"><a href="#local-6989586621679697953"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697952"><span class="annot"><a href="#local-6989586621679697952"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697951"><span class="annot"><a href="#local-6989586621679697951"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697950"><span class="annot"><a href="#local-6989586621679697950"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-159"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QInProjF"><span class="hs-identifier hs-type">QInProjF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697954"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697953"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697952"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697951"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697950"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-160"></span><span>  </span><span id="QInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QInProjF"><span class="hs-identifier hs-var">QInProjF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679697949"><span class="annot"><a href="#local-6989586621679697949"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697948"><span class="annot"><a href="#local-6989586621679697948"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697947"><span class="annot"><a href="#local-6989586621679697947"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697946"><span class="annot"><a href="#local-6989586621679697946"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697945"><span class="annot"><a href="#local-6989586621679697945"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-161"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697949"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697948"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697947"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697946"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697945"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>
</span><span id="line-163"></span><span class="hs-comment">-- | Specifies the linear transformation of the key.</span><span>
</span><span id="line-164"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-165"></span><span>  </span><span id="KInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KInProjF"><span class="hs-identifier hs-var">KInProjF</span></a></span></span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697944"><span class="annot"><a href="#local-6989586621679697944"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697943"><span class="annot"><a href="#local-6989586621679697943"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-168"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697942"><span class="annot"><a href="#local-6989586621679697942"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697941"><span class="annot"><a href="#local-6989586621679697941"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-170"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697940"><span class="annot"><a href="#local-6989586621679697940"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-171"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697939"><span class="annot"><a href="#local-6989586621679697939"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-172"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-173"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-174"></span><span>  </span><span id="KInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KInProjF"><span class="hs-identifier hs-var">KInProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679697938"><span class="annot"><a href="#local-6989586621679697938"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697937"><span class="annot"><a href="#local-6989586621679697937"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697936"><span class="annot"><a href="#local-6989586621679697936"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697935"><span class="annot"><a href="#local-6989586621679697935"><span class="hs-identifier hs-type hs-type">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697934"><span class="annot"><a href="#local-6989586621679697934"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-175"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697938"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697937"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697936"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697935"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697934"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-176"></span><span>  </span><span id="KInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KInProjF"><span class="hs-identifier hs-var">KInProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679697933"><span class="annot"><a href="#local-6989586621679697933"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697932"><span class="annot"><a href="#local-6989586621679697932"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697931"><span class="annot"><a href="#local-6989586621679697931"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697930"><span class="annot"><a href="#local-6989586621679697930"><span class="hs-identifier hs-type hs-type">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697929"><span class="annot"><a href="#local-6989586621679697929"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-177"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KInProjF"><span class="hs-identifier hs-type">KInProjF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697933"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697932"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697931"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697930"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697929"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-178"></span><span>  </span><span id="KInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KInProjF"><span class="hs-identifier hs-var">KInProjF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679697928"><span class="annot"><a href="#local-6989586621679697928"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697927"><span class="annot"><a href="#local-6989586621679697927"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697926"><span class="annot"><a href="#local-6989586621679697926"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697925"><span class="annot"><a href="#local-6989586621679697925"><span class="hs-identifier hs-type hs-type">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697924"><span class="annot"><a href="#local-6989586621679697924"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-179"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697928"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697927"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697926"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697925"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697924"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>
</span><span id="line-181"></span><span class="hs-comment">-- | Specifies the linear transformation of the value.</span><span>
</span><span id="line-182"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-183"></span><span>  </span><span id="VInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#VInProjF"><span class="hs-identifier hs-var">VInProjF</span></a></span></span><span>
</span><span id="line-184"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697923"><span class="annot"><a href="#local-6989586621679697923"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697922"><span class="annot"><a href="#local-6989586621679697922"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697921"><span class="annot"><a href="#local-6989586621679697921"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697920"><span class="annot"><a href="#local-6989586621679697920"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697919"><span class="annot"><a href="#local-6989586621679697919"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697918"><span class="annot"><a href="#local-6989586621679697918"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-190"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-191"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-192"></span><span>  </span><span id="VInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#VInProjF"><span class="hs-identifier hs-var">VInProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679697917"><span class="annot"><a href="#local-6989586621679697917"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697916"><span class="annot"><a href="#local-6989586621679697916"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697915"><span class="annot"><a href="#local-6989586621679697915"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697914"><span class="annot"><a href="#local-6989586621679697914"><span class="hs-identifier hs-type hs-type">valueEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697913"><span class="annot"><a href="#local-6989586621679697913"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697917"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697916"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697915"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697914"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697913"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-194"></span><span>  </span><span id="VInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#VInProjF"><span class="hs-identifier hs-var">VInProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679697912"><span class="annot"><a href="#local-6989586621679697912"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697911"><span class="annot"><a href="#local-6989586621679697911"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697910"><span class="annot"><a href="#local-6989586621679697910"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697909"><span class="annot"><a href="#local-6989586621679697909"><span class="hs-identifier hs-type hs-type">valueEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697908"><span class="annot"><a href="#local-6989586621679697908"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-195"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#VInProjF"><span class="hs-identifier hs-type">VInProjF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697912"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697911"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697910"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697909"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697908"><span class="hs-identifier hs-type">embedDim</span></a></span><span>
</span><span id="line-196"></span><span>  </span><span id="VInProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#VInProjF"><span class="hs-identifier hs-var">VInProjF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679697907"><span class="annot"><a href="#local-6989586621679697907"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697906"><span class="annot"><a href="#local-6989586621679697906"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697905"><span class="annot"><a href="#local-6989586621679697905"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697904"><span class="annot"><a href="#local-6989586621679697904"><span class="hs-identifier hs-type hs-type">valueEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697903"><span class="annot"><a href="#local-6989586621679697903"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-197"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697907"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697906"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697905"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697904"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697903"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-198"></span><span>
</span><span id="line-199"></span><span class="hs-comment">-- | Specifies the type of the out-projection layer.</span><span>
</span><span id="line-200"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-201"></span><span>  </span><span id="OutProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#OutProjF"><span class="hs-identifier hs-var">OutProjF</span></a></span></span><span>
</span><span id="line-202"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697902"><span class="annot"><a href="#local-6989586621679697902"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-203"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697901"><span class="annot"><a href="#local-6989586621679697901"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697900"><span class="annot"><a href="#local-6989586621679697900"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-205"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697899"><span class="annot"><a href="#local-6989586621679697899"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-206"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697898"><span class="annot"><a href="#local-6989586621679697898"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-207"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697897"><span class="annot"><a href="#local-6989586621679697897"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-208"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-209"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-210"></span><span>  </span><span id="OutProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#OutProjF"><span class="hs-identifier hs-var">OutProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679697896"><span class="annot"><a href="#local-6989586621679697896"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697895"><span class="annot"><a href="#local-6989586621679697895"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697894"><span class="annot"><a href="#local-6989586621679697894"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697893"><span class="annot"><a href="#local-6989586621679697893"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697892"><span class="annot"><a href="#local-6989586621679697892"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-211"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697896"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697895"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697894"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697893"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697892"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span>  </span><span id="OutProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#OutProjF"><span class="hs-identifier hs-var">OutProjF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679697891"><span class="annot"><a href="#local-6989586621679697891"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697890"><span class="annot"><a href="#local-6989586621679697890"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697889"><span class="annot"><a href="#local-6989586621679697889"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697888"><span class="annot"><a href="#local-6989586621679697888"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697887"><span class="annot"><a href="#local-6989586621679697887"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-213"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#OutProjF"><span class="hs-identifier hs-type">OutProjF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697891"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697890"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697889"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697888"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697887"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-214"></span><span>  </span><span id="OutProjF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#OutProjF"><span class="hs-identifier hs-var">OutProjF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679697886"><span class="annot"><a href="#local-6989586621679697886"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697885"><span class="annot"><a href="#local-6989586621679697885"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697884"><span class="annot"><a href="#local-6989586621679697884"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697883"><span class="annot"><a href="#local-6989586621679697883"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697882"><span class="annot"><a href="#local-6989586621679697882"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-215"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697886"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697885"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697884"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697883"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697882"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-216"></span><span>
</span><span id="line-217"></span><span class="hs-comment">-- | Specifies the type of the dropout layer.</span><span>
</span><span id="line-218"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-219"></span><span>  </span><span id="DropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#DropoutF"><span class="hs-identifier hs-var">DropoutF</span></a></span></span><span>
</span><span id="line-220"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697881"><span class="annot"><a href="#local-6989586621679697881"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697880"><span class="annot"><a href="#local-6989586621679697880"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-222"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-223"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-224"></span><span>  </span><span id="DropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#DropoutF"><span class="hs-identifier hs-var">DropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithDropout"><span class="hs-identifier hs-type">WithDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-225"></span><span>  </span><span id="DropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#DropoutF"><span class="hs-identifier hs-var">DropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutDropout"><span class="hs-identifier hs-type">WithoutDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>
</span><span id="line-227"></span><span class="hs-comment">-- | Specifies the parameters of a multi-headed attention layer.</span><span>
</span><span id="line-228"></span><span class="hs-comment">--</span><span>
</span><span id="line-229"></span><span class="hs-comment">-- - @style@: the style of the attention layer, e.g. 'ST5', 'ByT5', etc.</span><span>
</span><span id="line-230"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the attention layer.</span><span>
</span><span id="line-231"></span><span class="hs-comment">-- - @device@: the computational device on which to allocate the attention layer.</span><span>
</span><span id="line-232"></span><span class="hs-comment">-- - @dataType@: the data type of the attention layer.</span><span>
</span><span id="line-233"></span><span class="hs-comment">-- - @headDim@: the dimension of the attention heads.</span><span>
</span><span id="line-234"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the attention head embeddings.</span><span>
</span><span id="line-235"></span><span class="hs-comment">-- - @embedDim@: the dimension of the input embeddings.</span><span>
</span><span id="line-236"></span><span class="hs-comment">-- - @queryEmbedDim@: the dimension of the query embeddings.</span><span>
</span><span id="line-237"></span><span class="hs-comment">-- - @keyEmbedDim@: the dimension of the key embeddings.</span><span>
</span><span id="line-238"></span><span class="hs-comment">-- - @valueEmbedDim@: the dimension of the value embeddings.</span><span>
</span><span id="line-239"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-240"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#multiHeadAttentionSpec"><span class="hs-identifier hs-type">multiHeadAttentionSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-241"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679697876"><span class="annot"><a href="#local-6989586621679697876"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679697875"><span class="annot"><a href="#local-6989586621679697875"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697874"><span class="annot"><a href="#local-6989586621679697874"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697873"><span class="annot"><a href="#local-6989586621679697873"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697872"><span class="annot"><a href="#local-6989586621679697872"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679697871"><span class="annot"><a href="#local-6989586621679697871"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697870"><span class="annot"><a href="#local-6989586621679697870"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697869"><span class="annot"><a href="#local-6989586621679697869"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697868"><span class="annot"><a href="#local-6989586621679697868"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697867"><span class="annot"><a href="#local-6989586621679697867"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697866"><span class="annot"><a href="#local-6989586621679697866"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-242"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697876"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-243"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697875"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-244"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697874"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-245"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697873"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-246"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697872"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-247"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697871"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-248"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697870"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-249"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697869"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-250"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697868"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-251"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697867"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-252"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier hs-type">SHasDropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697866"><span class="hs-identifier hs-type">hasDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-253"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-254"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttentionF"><span class="hs-identifier hs-type">GMultiHeadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697876"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697875"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697874"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697873"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697872"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697871"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697870"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697869"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697868"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697867"><span class="hs-identifier hs-type">valueEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697866"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span id="multiHeadAttentionSpec"><span class="annot"><span class="annottext">multiHeadAttentionSpec :: STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; ModelSpec
     (GMultiHeadAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        valueEmbedDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#multiHeadAttentionSpec"><span class="hs-identifier hs-var hs-var">multiHeadAttentionSpec</span></a></span></span><span> </span><span id="local-6989586621679697865"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697865"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679697864"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679697864"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679697863"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679697863"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679697862"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679697862"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679697861"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679697861"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679697860"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679697860"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697859"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697858"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697857"><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697856"><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697855"><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679697855"><span class="hs-identifier hs-var">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679697854"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697854"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-256"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697853"><span class="annot"><span class="annottext">qInProjSpec :: STransformerStyle style
-&gt; ModelSpec
     (QInProjF style gradient device dataType queryEmbedDim embedDim)
</span><a href="#local-6989586621679697853"><span class="hs-identifier hs-var hs-var">qInProjSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, queryEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;q.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim queryEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>      </span><span class="annot"><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, queryEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;q.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim queryEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>      </span><span class="annot"><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, queryEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;q_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim queryEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>      </span><span class="annot"><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, queryEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;q_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim queryEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-260"></span><span>      </span><span class="annot"><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, queryEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;q_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim queryEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>      </span><span class="annot"><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, queryEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self.query.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim queryEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>      </span><span class="annot"><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, queryEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self.query.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim queryEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, queryEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>      </span><span class="annot"><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (QInProjF style gradient device dataType queryEmbedDim embedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-264"></span><span>      </span><span id="local-6989586621679697840"><span class="annot"><span class="annottext">kInProjSpec :: STransformerStyle style
-&gt; ModelSpec
     (KInProjF style gradient device dataType keyEmbedDim embedDim)
</span><a href="#local-6989586621679697840"><span class="hs-identifier hs-var hs-var">kInProjSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, keyEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;k.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim keyEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-265"></span><span>      </span><span class="annot"><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, keyEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;k.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim keyEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-266"></span><span>      </span><span class="annot"><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, keyEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;k_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim keyEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-267"></span><span>      </span><span class="annot"><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, keyEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;k_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim keyEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-268"></span><span>      </span><span class="annot"><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, keyEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;k_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim keyEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-269"></span><span>      </span><span class="annot"><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, keyEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self.key.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim keyEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-270"></span><span>      </span><span class="annot"><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, keyEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self.key.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim keyEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, keyEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697857"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-271"></span><span>      </span><span class="annot"><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (KInProjF style gradient device dataType keyEmbedDim embedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-272"></span><span>      </span><span id="local-6989586621679697839"><span class="annot"><span class="annottext">vInProjSpec :: STransformerStyle style
-&gt; ModelSpec
     (VInProjF style gradient device dataType valueEmbedDim embedDim)
</span><a href="#local-6989586621679697839"><span class="hs-identifier hs-var hs-var">vInProjSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, valueEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;v.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim valueEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-273"></span><span>      </span><span class="annot"><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, valueEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;v.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim valueEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-274"></span><span>      </span><span class="annot"><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, valueEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;v_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim valueEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-275"></span><span>      </span><span class="annot"><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, valueEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;v_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim valueEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-276"></span><span>      </span><span class="annot"><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, valueEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;v_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim valueEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-277"></span><span>      </span><span class="annot"><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, valueEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self.value.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim valueEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-278"></span><span>      </span><span class="annot"><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[embedDim, valueEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[embedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self.value.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim valueEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[embedDim, valueEmbedDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[embedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim valueEmbedDim
</span><a href="#local-6989586621679697856"><span class="hs-identifier hs-var">valueEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-279"></span><span>      </span><span class="annot"><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (VInProjF style gradient device dataType valueEmbedDim embedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-280"></span><span>      </span><span id="local-6989586621679697838"><span class="annot"><span class="annottext">outProjSpec :: STransformerStyle style
-&gt; ModelSpec
     (OutProjF style gradient device dataType embedDim queryEmbedDim)
</span><a href="#local-6989586621679697838"><span class="hs-identifier hs-var hs-var">outProjSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim, embedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;o.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span>      </span><span class="annot"><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim, embedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;o.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel ()))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var">projSpecWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>      </span><span class="annot"><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim, embedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;out_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-283"></span><span>      </span><span class="annot"><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim, embedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;out_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-284"></span><span>      </span><span class="annot"><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim, embedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;out_proj.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>      </span><span class="annot"><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim, embedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.dense.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-286"></span><span>      </span><span class="annot"><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim, embedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[queryEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.dense.&quot;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim, embedDim])))
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[queryEmbedDim]))))
forall (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var">projSpecWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697858"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-287"></span><span>      </span><span class="annot"><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (OutProjF style gradient device dataType embedDim queryEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-288"></span><span>      </span><span id="local-6989586621679697837"><span class="annot"><span class="annottext">dropoutSpec :: STransformerStyle style
-&gt; SHasDropout hasDropout -&gt; ModelSpec (DropoutF style hasDropout)
</span><a href="#local-6989586621679697837"><span class="hs-identifier hs-var hs-var">dropoutSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithDropout"><span class="hs-identifier hs-var">SWithDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697854"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-289"></span><span>      </span><span class="annot"><a href="#local-6989586621679697837"><span class="hs-identifier hs-var">dropoutSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutDropout"><span class="hs-identifier hs-var">SWithoutDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-type">scaling</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697876"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionHasScaling"><span class="hs-identifier hs-type">MultiHeadAttentionHasScaling</span></a></span><span>
</span><span id="line-291"></span><span>      </span><span id="local-6989586621679697833"><span class="annot"><span class="annottext">scaling :: STransformerStyle style -&gt; MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679697833"><span class="hs-identifier hs-var hs-var">scaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithoutScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithoutScaling</span></a></span><span>
</span><span id="line-292"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithoutScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithoutScaling</span></a></span><span>
</span><span id="line-293"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithQueryScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithQueryScaling</span></a></span><span>
</span><span id="line-294"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithQueryScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithQueryScaling</span></a></span><span>
</span><span id="line-295"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithQueryScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithQueryScaling</span></a></span><span>
</span><span id="line-296"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithWeightScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithWeightScaling</span></a></span><span>
</span><span id="line-297"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithWeightScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithWeightScaling</span></a></span><span>
</span><span id="line-298"></span><span>      </span><span class="annot"><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-299"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; ModelSpec
     (QInProjF style gradient device dataType queryEmbedDim embedDim)
-&gt; ModelSpec
     (KInProjF style gradient device dataType keyEmbedDim embedDim)
-&gt; ModelSpec
     (VInProjF style gradient device dataType valueEmbedDim embedDim)
-&gt; ModelSpec
     (OutProjF style gradient device dataType embedDim queryEmbedDim)
-&gt; ModelSpec (DropoutF style hasDropout)
-&gt; MultiHeadAttentionHasScaling
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     (ModelSpec
        (QInProjF style gradient device dataType queryEmbedDim embedDim))
     (ModelSpec
        (KInProjF style gradient device dataType keyEmbedDim embedDim))
     (ModelSpec
        (VInProjF style gradient device dataType valueEmbedDim embedDim))
     (ModelSpec
        (OutProjF style gradient device dataType embedDim queryEmbedDim))
     (ModelSpec (DropoutF style hasDropout))
forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; qInProj
-&gt; kInProj
-&gt; vInProj
-&gt; outProj
-&gt; dropout
-&gt; MultiHeadAttentionHasScaling
-&gt; GMultiHeadAttention
     headDim
     headEmbedDim
     embedDim
     qInProj
     kInProj
     vInProj
     outProj
     dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-var">GMultiHeadAttention</span></a></span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679697861"><span class="hs-identifier hs-var">headDim</span></a></span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679697860"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span>
</span><span id="line-302"></span><span>        </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697859"><span class="hs-identifier hs-var">embedDim</span></a></span><span>
</span><span id="line-303"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (QInProjF style gradient device dataType queryEmbedDim embedDim)
</span><a href="#local-6989586621679697853"><span class="hs-identifier hs-var">qInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697865"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-304"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (KInProjF style gradient device dataType keyEmbedDim embedDim)
</span><a href="#local-6989586621679697840"><span class="hs-identifier hs-var">kInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697865"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-305"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (VInProjF style gradient device dataType valueEmbedDim embedDim)
</span><a href="#local-6989586621679697839"><span class="hs-identifier hs-var">vInProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697865"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (OutProjF style gradient device dataType embedDim queryEmbedDim)
</span><a href="#local-6989586621679697838"><span class="hs-identifier hs-var">outProjSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697865"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-307"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SHasDropout hasDropout -&gt; ModelSpec (DropoutF style hasDropout)
</span><a href="#local-6989586621679697837"><span class="hs-identifier hs-var">dropoutSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697865"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679697855"><span class="hs-identifier hs-var">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-308"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679697833"><span class="hs-identifier hs-var">scaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697865"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-309"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-310"></span><span>    </span><span class="annot"><a href="#local-6989586621679697850"><span class="hs-identifier hs-type">projSpecWithoutBias</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-311"></span><span>      </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679698441"><span class="annot"><a href="#local-6989586621679698441"><span class="hs-identifier hs-type">inputDim</span></a></span></span><span> </span><span id="local-6989586621679698440"><span class="annot"><a href="#local-6989586621679698440"><span class="hs-identifier hs-type">outputDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-312"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698441"><span class="hs-identifier hs-type">inputDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-313"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698440"><span class="hs-identifier hs-type">outputDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-314"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span>
</span><span id="line-315"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinear"><span class="hs-identifier hs-type">GLinear</span></a></span><span>
</span><span id="line-316"></span><span>            </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697875"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697874"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697873"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679698440"><span class="hs-identifier hs-type">outputDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679698441"><span class="hs-identifier hs-type">inputDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>            </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>    </span><span id="local-6989586621679697850"><span class="annot"><span class="annottext">projSpecWithoutBias :: SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel ()))
</span><a href="#local-6989586621679697850"><span class="hs-identifier hs-var hs-var">projSpecWithoutBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF 'WithoutBias gradient device dataType inputDim outputDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679697864"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679697863"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679697862"><span class="hs-identifier hs-var">dataType</span></a></span><span>
</span><span id="line-320"></span><span>    </span><span class="annot"><a href="#local-6989586621679697847"><span class="hs-identifier hs-type">projSpecWithBias</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-321"></span><span>      </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679698439"><span class="annot"><a href="#local-6989586621679698439"><span class="hs-identifier hs-type">inputDim</span></a></span></span><span> </span><span id="local-6989586621679698438"><span class="annot"><a href="#local-6989586621679698438"><span class="hs-identifier hs-type">outputDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-322"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698439"><span class="hs-identifier hs-type">inputDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-323"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698438"><span class="hs-identifier hs-type">outputDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-324"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span>
</span><span id="line-325"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinear"><span class="hs-identifier hs-type">GLinear</span></a></span><span>
</span><span id="line-326"></span><span>            </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697875"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697874"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697873"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679698438"><span class="hs-identifier hs-type">outputDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679698439"><span class="hs-identifier hs-type">inputDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-327"></span><span>            </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697875"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697874"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697873"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679698438"><span class="hs-identifier hs-type">outputDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-328"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-329"></span><span>    </span><span id="local-6989586621679697847"><span class="annot"><span class="annottext">projSpecWithBias :: SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinear
        (NamedModel
           (Tensor
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, inputDim])))
        (NamedModel
           (Tensor
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
</span><a href="#local-6989586621679697847"><span class="hs-identifier hs-var hs-var">projSpecWithBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF 'WithBias gradient device dataType inputDim outputDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679697864"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679697863"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679697862"><span class="hs-identifier hs-var">dataType</span></a></span><span>
</span><span id="line-330"></span><span>
</span><span id="line-331"></span><span id="local-6989586621679697812"><span id="local-6989586621679697813"><span id="local-6989586621679697814"><span id="local-6989586621679697815"><span id="local-6989586621679697816"><span id="local-6989586621679697817"><span id="local-6989586621679697818"><span id="local-6989586621679697819"><span id="local-6989586621679697820"><span id="local-6989586621679697821"><span id="local-6989586621679697822"><span id="local-6989586621679697823"><span id="local-6989586621679697824"><span id="local-6989586621679697825"><span id="local-6989586621679697826"><span id="local-6989586621679697827"><span id="local-6989586621679697828"><span id="local-6989586621679697829"><span id="local-6989586621679697830"><span class="hs-keyword">instance</span><span>
</span><span id="line-332"></span><span>  </span><span id="local-6989586621679697810"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697830"><span class="hs-identifier hs-type">qInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697829"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697828"><span class="hs-identifier hs-type">qInProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697827"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-333"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697826"><span class="hs-identifier hs-type">kInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697827"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697825"><span class="hs-identifier hs-type">kInProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697824"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-334"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697823"><span class="hs-identifier hs-type">vInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697824"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697822"><span class="hs-identifier hs-type">vInProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697821"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-335"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697820"><span class="hs-identifier hs-type">outProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697821"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697819"><span class="hs-identifier hs-type">outProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697818"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-336"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697817"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697818"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697816"><span class="hs-identifier hs-type">dropout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697815"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-337"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-338"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-339"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697814"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697813"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697812"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697830"><span class="hs-identifier hs-type">qInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697826"><span class="hs-identifier hs-type">kInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697823"><span class="hs-identifier hs-type">vInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697820"><span class="hs-identifier hs-type">outProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697817"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-340"></span><span>    </span><span class="annot"><a href="#local-6989586621679697829"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-341"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697814"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697813"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697812"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697828"><span class="hs-identifier hs-type">qInProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697825"><span class="hs-identifier hs-type">kInProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697822"><span class="hs-identifier hs-type">vInProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697819"><span class="hs-identifier hs-type">outProj'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697816"><span class="hs-identifier hs-type">dropout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-342"></span><span>    </span><span class="annot"><a href="#local-6989586621679697815"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-343"></span><span>
</span><span id="line-344"></span><span id="local-6989586621679697802"><span id="local-6989586621679697803"><span id="local-6989586621679697804"><span id="local-6989586621679697805"><span id="local-6989586621679697806"><span id="local-6989586621679697807"><span id="local-6989586621679697808"><span id="local-6989586621679697809"><span class="hs-keyword">instance</span><span>
</span><span id="line-345"></span><span>  </span><span id="local-6989586621679697798"><span id="local-6989586621679697800"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697809"><span class="hs-identifier hs-type">qInProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-346"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697808"><span class="hs-identifier hs-type">vInProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-347"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697807"><span class="hs-identifier hs-type">kInProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-348"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697806"><span class="hs-identifier hs-type">outProj</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-349"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697805"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-350"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-351"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697804"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697803"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697802"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697809"><span class="hs-identifier hs-type">qInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697807"><span class="hs-identifier hs-type">kInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697808"><span class="hs-identifier hs-type">vInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697806"><span class="hs-identifier hs-type">outProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697805"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-352"></span><span>
</span><span id="line-353"></span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#BatchDim"><span class="hs-identifier hs-type">BatchDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-354"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-355"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-356"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-357"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-358"></span><span>
</span><span id="line-359"></span><span class="hs-keyword">type</span><span> </span><span id="BatchDim"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#BatchDim"><span class="hs-identifier hs-var">BatchDim</span></a></span></span><span> </span><span id="local-6989586621679697797"><span class="annot"><a href="#local-6989586621679697797"><span class="hs-identifier hs-type">queryShape</span></a></span></span><span> </span><span id="local-6989586621679697796"><span class="annot"><a href="#local-6989586621679697796"><span class="hs-identifier hs-type">keyShape</span></a></span></span><span> </span><span id="local-6989586621679697795"><span class="annot"><a href="#local-6989586621679697795"><span class="hs-identifier hs-type">valueShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-360"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697797"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697796"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697795"><span class="hs-identifier hs-type">valueShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span>
</span><span id="line-361"></span><span>
</span><span id="line-362"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getBatchDim"><span class="hs-identifier hs-type">getBatchDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-363"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679698244"><span class="annot"><a href="#local-6989586621679698244"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679698242"><span class="annot"><a href="#local-6989586621679698242"><span class="hs-identifier hs-type">queryShape</span></a></span></span><span> </span><span id="local-6989586621679698241"><span class="annot"><a href="#local-6989586621679698241"><span class="hs-identifier hs-type">keyShape</span></a></span></span><span> </span><span id="local-6989586621679698240"><span class="annot"><a href="#local-6989586621679698240"><span class="hs-identifier hs-type">valueShape</span></a></span></span><span> </span><span id="local-6989586621679698243"><span class="annot"><a href="#local-6989586621679698243"><span class="hs-identifier hs-type">batchDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-364"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679698244"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679698243"><span class="hs-identifier hs-type">batchDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#BatchDim"><span class="hs-identifier hs-type">BatchDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698242"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698241"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698240"><span class="hs-identifier hs-type">valueShape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-365"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698242"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-366"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698241"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-367"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698240"><span class="hs-identifier hs-type">valueShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-368"></span><span>  </span><span class="annot"><a href="#local-6989586621679698244"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698243"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-369"></span><span id="getBatchDim"><span class="annot"><span class="annottext">getBatchDim :: SShape queryShape
-&gt; SShape keyShape -&gt; SShape valueShape -&gt; m (SDim batchDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getBatchDim"><span class="hs-identifier hs-var hs-var">getBatchDim</span></a></span></span><span> </span><span id="local-6989586621679697793"><span class="annot"><span class="annottext">SShape queryShape
</span><a href="#local-6989586621679697793"><span class="hs-identifier hs-var">queryShape</span></a></span></span><span> </span><span id="local-6989586621679697792"><span class="annot"><span class="annottext">SShape keyShape
</span><a href="#local-6989586621679697792"><span class="hs-identifier hs-var">keyShape</span></a></span></span><span> </span><span id="local-6989586621679697791"><span class="annot"><span class="annottext">SShape valueShape
</span><a href="#local-6989586621679697791"><span class="hs-identifier hs-var">valueShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-370"></span><span>  </span><span id="local-6989586621679697790"><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) queryShape)
</span><a href="#local-6989586621679697790"><span class="hs-identifier hs-var">queryBatchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 0))
-&gt; SShape queryShape
-&gt; m (SDim (GetDimF ('SelectDim ('ByIndex 0)) queryShape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0)))
-&gt; SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 0 =&gt; SBy ('ByIndex 0)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape queryShape
</span><a href="#local-6989586621679697793"><span class="hs-identifier hs-var">queryShape</span></a></span><span>
</span><span id="line-371"></span><span>  </span><span id="local-6989586621679697787"><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) keyShape)
</span><a href="#local-6989586621679697787"><span class="hs-identifier hs-var">keyBatchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 0))
-&gt; SShape keyShape
-&gt; m (SDim (GetDimF ('SelectDim ('ByIndex 0)) keyShape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0)))
-&gt; SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 0 =&gt; SBy ('ByIndex 0)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape keyShape
</span><a href="#local-6989586621679697792"><span class="hs-identifier hs-var">keyShape</span></a></span><span>
</span><span id="line-372"></span><span>  </span><span id="local-6989586621679697786"><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) valueShape)
</span><a href="#local-6989586621679697786"><span class="hs-identifier hs-var">valueBatchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 0))
-&gt; SShape valueShape
-&gt; m (SDim (GetDimF ('SelectDim ('ByIndex 0)) valueShape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0)))
-&gt; SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 0 =&gt; SBy ('ByIndex 0)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape valueShape
</span><a href="#local-6989586621679697791"><span class="hs-identifier hs-var">valueShape</span></a></span><span>
</span><span id="line-373"></span><span>  </span><span id="local-6989586621679697785"><span class="annot"><span class="annottext">SDim
  (Unify
     (Dim (Name Symbol) (Size Nat))
     (GetDimF ('SelectDim ('ByIndex 0)) keyShape)
     (GetDimF ('SelectDim ('ByIndex 0)) valueShape))
</span><a href="#local-6989586621679697785"><span class="hs-identifier hs-var">keyValueBatchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) keyShape)
-&gt; SDim (GetDimF ('SelectDim ('ByIndex 0)) valueShape)
-&gt; m (SDim
        (GetDimF ('SelectDim ('ByIndex 0)) keyShape
         &lt;+&gt; GetDimF ('SelectDim ('ByIndex 0)) valueShape))
forall (m :: * -&gt; *) (dim :: Dim (Name Symbol) (Size Nat))
       (dim' :: Dim (Name Symbol) (Size Nat)).
MonadThrow m =&gt;
SDim dim -&gt; SDim dim' -&gt; m (SDim (dim &lt;+&gt; dim'))
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sUnifyDim"><span class="hs-identifier hs-var">sUnifyDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) keyShape)
</span><a href="#local-6989586621679697787"><span class="hs-identifier hs-var">keyBatchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) valueShape)
</span><a href="#local-6989586621679697786"><span class="hs-identifier hs-var">valueBatchDim</span></a></span><span>
</span><span id="line-374"></span><span>  </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) queryShape)
-&gt; SDim
     (Unify
        (Dim (Name Symbol) (Size Nat))
        (GetDimF ('SelectDim ('ByIndex 0)) keyShape)
        (GetDimF ('SelectDim ('ByIndex 0)) valueShape))
-&gt; m (SDim
        (GetDimF ('SelectDim ('ByIndex 0)) queryShape
         &lt;+&gt; Unify
               (Dim (Name Symbol) (Size Nat))
               (GetDimF ('SelectDim ('ByIndex 0)) keyShape)
               (GetDimF ('SelectDim ('ByIndex 0)) valueShape)))
forall (m :: * -&gt; *) (dim :: Dim (Name Symbol) (Size Nat))
       (dim' :: Dim (Name Symbol) (Size Nat)).
MonadThrow m =&gt;
SDim dim -&gt; SDim dim' -&gt; m (SDim (dim &lt;+&gt; dim'))
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sUnifyDim"><span class="hs-identifier hs-var">sUnifyDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 0)) queryShape)
</span><a href="#local-6989586621679697790"><span class="hs-identifier hs-var">queryBatchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim
  (Unify
     (Dim (Name Symbol) (Size Nat))
     (GetDimF ('SelectDim ('ByIndex 0)) keyShape)
     (GetDimF ('SelectDim ('ByIndex 0)) valueShape))
</span><a href="#local-6989586621679697785"><span class="hs-identifier hs-var">keyValueBatchDim</span></a></span><span>
</span><span id="line-375"></span><span>
</span><span id="line-376"></span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QuerySeqDim"><span class="hs-identifier hs-type">QuerySeqDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-377"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-378"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-379"></span><span>
</span><span id="line-380"></span><span class="hs-keyword">type</span><span> </span><span id="QuerySeqDim"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QuerySeqDim"><span class="hs-identifier hs-var">QuerySeqDim</span></a></span></span><span> </span><span id="local-6989586621679697784"><span class="annot"><a href="#local-6989586621679697784"><span class="hs-identifier hs-type">queryShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-381"></span><span>  </span><span class="annot"><a href="#local-6989586621679697784"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-382"></span><span>
</span><span id="line-383"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getQuerySeqDim"><span class="hs-identifier hs-type">getQuerySeqDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-384"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679698239"><span class="annot"><a href="#local-6989586621679698239"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679698237"><span class="annot"><a href="#local-6989586621679698237"><span class="hs-identifier hs-type">queryShape</span></a></span></span><span> </span><span id="local-6989586621679698238"><span class="annot"><a href="#local-6989586621679698238"><span class="hs-identifier hs-type">querySeqDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-385"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679698239"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679698238"><span class="hs-identifier hs-type">querySeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QuerySeqDim"><span class="hs-identifier hs-type">QuerySeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698237"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-386"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698237"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-387"></span><span>  </span><span class="annot"><a href="#local-6989586621679698239"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698238"><span class="hs-identifier hs-type">querySeqDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-388"></span><span id="getQuerySeqDim"><span class="annot"><span class="annottext">getQuerySeqDim :: SShape queryShape -&gt; m (SDim querySeqDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getQuerySeqDim"><span class="hs-identifier hs-var hs-var">getQuerySeqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape queryShape -&gt; m (SDim querySeqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-389"></span><span>
</span><span id="line-390"></span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KeySeqDim"><span class="hs-identifier hs-type">KeySeqDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-391"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-392"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-393"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-394"></span><span>
</span><span id="line-395"></span><span class="hs-keyword">type</span><span> </span><span id="KeySeqDim"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KeySeqDim"><span class="hs-identifier hs-var">KeySeqDim</span></a></span></span><span> </span><span id="local-6989586621679697782"><span class="annot"><a href="#local-6989586621679697782"><span class="hs-identifier hs-type">keyShape</span></a></span></span><span> </span><span id="local-6989586621679697781"><span class="annot"><a href="#local-6989586621679697781"><span class="hs-identifier hs-type">valueShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-396"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697782"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697781"><span class="hs-identifier hs-type">valueShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-397"></span><span>
</span><span id="line-398"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getKeySeqDim"><span class="hs-identifier hs-type">getKeySeqDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-399"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679698236"><span class="annot"><a href="#local-6989586621679698236"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679698234"><span class="annot"><a href="#local-6989586621679698234"><span class="hs-identifier hs-type">keyShape</span></a></span></span><span> </span><span id="local-6989586621679698233"><span class="annot"><a href="#local-6989586621679698233"><span class="hs-identifier hs-type">valueShape</span></a></span></span><span> </span><span id="local-6989586621679698235"><span class="annot"><a href="#local-6989586621679698235"><span class="hs-identifier hs-type">keySeqDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-400"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679698236"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679698235"><span class="hs-identifier hs-type">keySeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KeySeqDim"><span class="hs-identifier hs-type">KeySeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698234"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698233"><span class="hs-identifier hs-type">valueShape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-401"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698234"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-402"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698233"><span class="hs-identifier hs-type">valueShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-403"></span><span>  </span><span class="annot"><a href="#local-6989586621679698236"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679698235"><span class="hs-identifier hs-type">keySeqDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-404"></span><span id="getKeySeqDim"><span class="annot"><span class="annottext">getKeySeqDim :: SShape keyShape -&gt; SShape valueShape -&gt; m (SDim keySeqDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getKeySeqDim"><span class="hs-identifier hs-var hs-var">getKeySeqDim</span></a></span></span><span> </span><span id="local-6989586621679697779"><span class="annot"><span class="annottext">SShape keyShape
</span><a href="#local-6989586621679697779"><span class="hs-identifier hs-var">keyShape</span></a></span></span><span> </span><span id="local-6989586621679697778"><span class="annot"><span class="annottext">SShape valueShape
</span><a href="#local-6989586621679697778"><span class="hs-identifier hs-var">valueShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-405"></span><span>  </span><span class="hs-keyword">do</span><span>
</span><span id="line-406"></span><span>    </span><span id="local-6989586621679697777"><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 1)) keyShape)
</span><a href="#local-6989586621679697777"><span class="hs-identifier hs-var">keySeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape keyShape
-&gt; m (SDim (GetDimF ('SelectDim ('ByIndex 1)) keyShape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape keyShape
</span><a href="#local-6989586621679697779"><span class="hs-identifier hs-var">keyShape</span></a></span><span>
</span><span id="line-407"></span><span>    </span><span id="local-6989586621679697776"><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 1)) valueShape)
</span><a href="#local-6989586621679697776"><span class="hs-identifier hs-var">valueSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape valueShape
-&gt; m (SDim (GetDimF ('SelectDim ('ByIndex 1)) valueShape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape valueShape
</span><a href="#local-6989586621679697778"><span class="hs-identifier hs-var">valueShape</span></a></span><span>
</span><span id="line-408"></span><span>    </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 1)) keyShape)
-&gt; SDim (GetDimF ('SelectDim ('ByIndex 1)) valueShape)
-&gt; m (SDim
        (GetDimF ('SelectDim ('ByIndex 1)) keyShape
         &lt;+&gt; GetDimF ('SelectDim ('ByIndex 1)) valueShape))
forall (m :: * -&gt; *) (dim :: Dim (Name Symbol) (Size Nat))
       (dim' :: Dim (Name Symbol) (Size Nat)).
MonadThrow m =&gt;
SDim dim -&gt; SDim dim' -&gt; m (SDim (dim &lt;+&gt; dim'))
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sUnifyDim"><span class="hs-identifier hs-var">sUnifyDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 1)) keyShape)
</span><a href="#local-6989586621679697777"><span class="hs-identifier hs-var">keySeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim (GetDimF ('SelectDim ('ByIndex 1)) valueShape)
</span><a href="#local-6989586621679697776"><span class="hs-identifier hs-var">valueSeqDim</span></a></span><span>
</span><span id="line-409"></span><span>
</span><span id="line-410"></span><span class="hs-comment">-- | 'HasForward' instance for 'GMultiHeadAttention'.</span><span>
</span><span id="line-411"></span><span class="hs-comment">--</span><span>
</span><span id="line-412"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-413"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;        &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-414"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;        &#9474; query &#9474;       &#9474; key &#9474;       &#9474; value &#9474;</span><span>
</span><span id="line-415"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;        &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;       &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;       &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-416"></span><span class="hs-comment">--         &#9474;                    &#9474;              &#9474;              &#9474;</span><span>
</span><span id="line-417"></span><span class="hs-comment">--         &#9474;                    &#9660;              &#9660;              &#9660;</span><span>
</span><span id="line-418"></span><span class="hs-comment">--         &#9474;                mhaQInProj     mhaKInProj     mhaVInProj</span><span>
</span><span id="line-419"></span><span class="hs-comment">--         &#9474;                    &#9660;              &#9474;              &#9474;</span><span>
</span><span id="line-420"></span><span class="hs-comment">--         &#9474;                (scaling)          &#9474;              &#9474;</span><span>
</span><span id="line-421"></span><span class="hs-comment">--         &#9474;                    &#9660;              &#9660;              &#9660;</span><span>
</span><span id="line-422"></span><span class="hs-comment">--         &#9474;                 reshape        reshape        reshape</span><span>
</span><span id="line-423"></span><span class="hs-comment">--         &#9474;                    &#9660;              &#9660;              &#9660;</span><span>
</span><span id="line-424"></span><span class="hs-comment">--         &#9474;                transpose      transpose      transpose</span><span>
</span><span id="line-425"></span><span class="hs-comment">--         &#9474;                    &#9474;              &#9660;              &#9474;</span><span>
</span><span id="line-426"></span><span class="hs-comment">--         &#9474;                    &#9474;          transpose          &#9474;</span><span>
</span><span id="line-427"></span><span class="hs-comment">--         &#9474;                    &#9474;              &#9474;              &#9474;</span><span>
</span><span id="line-428"></span><span class="hs-comment">--         &#9474;                    &#9492;&#9472;&#9472;&#9472;&#9658;matmul&#9668;&#9472;&#9472;&#9472;&#9496;              &#9474;</span><span>
</span><span id="line-429"></span><span class="hs-comment">--         &#9474;                           &#9660;                      &#9474;</span><span>
</span><span id="line-430"></span><span class="hs-comment">--         &#9474;                       (scaling)                  &#9474;</span><span>
</span><span id="line-431"></span><span class="hs-comment">--         &#9474;                           &#9474;                      &#9474;</span><span>
</span><span id="line-432"></span><span class="hs-comment">--         &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                      &#9474;</span><span>
</span><span id="line-433"></span><span class="hs-comment">--                      &#9660;                                     &#9474;</span><span>
</span><span id="line-434"></span><span class="hs-comment">--                   softmax                                  &#9474;</span><span>
</span><span id="line-435"></span><span class="hs-comment">--                      &#9660;                                     &#9474;</span><span>
</span><span id="line-436"></span><span class="hs-comment">--                  mhaDropout                                &#9474;</span><span>
</span><span id="line-437"></span><span class="hs-comment">--                      &#9474;                                     &#9474;</span><span>
</span><span id="line-438"></span><span class="hs-comment">--                      &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;matmul&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-439"></span><span class="hs-comment">--                                        &#9660;</span><span>
</span><span id="line-440"></span><span class="hs-comment">--                                    transpose</span><span>
</span><span id="line-441"></span><span class="hs-comment">--                                        &#9660;</span><span>
</span><span id="line-442"></span><span class="hs-comment">--                                     reshape</span><span>
</span><span id="line-443"></span><span class="hs-comment">--                                        &#9660;</span><span>
</span><span id="line-444"></span><span class="hs-comment">--                                    mhaOutProj</span><span>
</span><span id="line-445"></span><span class="hs-comment">--                                        &#9474;</span><span>
</span><span id="line-446"></span><span class="hs-comment">--                                        &#9660;</span><span>
</span><span id="line-447"></span><span class="hs-comment">--                                    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-448"></span><span class="hs-comment">--                                    &#9474; query &#9474;</span><span>
</span><span id="line-449"></span><span class="hs-comment">--                                    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-450"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-451"></span><span id="local-6989586621679697708"><span id="local-6989586621679697709"><span id="local-6989586621679697710"><span id="local-6989586621679697711"><span id="local-6989586621679697712"><span id="local-6989586621679697713"><span id="local-6989586621679697714"><span id="local-6989586621679697715"><span id="local-6989586621679697716"><span id="local-6989586621679697717"><span id="local-6989586621679697718"><span id="local-6989586621679697719"><span id="local-6989586621679697720"><span id="local-6989586621679697721"><span id="local-6989586621679697722"><span id="local-6989586621679697723"><span id="local-6989586621679697724"><span id="local-6989586621679697725"><span id="local-6989586621679697726"><span id="local-6989586621679697727"><span id="local-6989586621679697728"><span id="local-6989586621679697729"><span id="local-6989586621679697730"><span id="local-6989586621679697731"><span id="local-6989586621679697732"><span id="local-6989586621679697733"><span id="local-6989586621679697734"><span id="local-6989586621679697735"><span id="local-6989586621679697736"><span id="local-6989586621679697737"><span id="local-6989586621679697738"><span id="local-6989586621679697739"><span id="local-6989586621679697740"><span id="local-6989586621679697741"><span id="local-6989586621679697742"><span id="local-6989586621679697743"><span id="local-6989586621679697744"><span id="local-6989586621679697745"><span id="local-6989586621679697746"><span id="local-6989586621679697747"><span id="local-6989586621679697748"><span id="local-6989586621679697749"><span id="local-6989586621679697750"><span id="local-6989586621679697751"><span id="local-6989586621679697752"><span id="local-6989586621679697753"><span id="local-6989586621679697754"><span id="local-6989586621679697755"><span id="local-6989586621679697756"><span id="local-6989586621679697757"><span id="local-6989586621679697758"><span id="local-6989586621679697759"><span id="local-6989586621679697760"><span id="local-6989586621679697761"><span id="local-6989586621679697762"><span id="local-6989586621679697763"><span id="local-6989586621679697764"><span id="local-6989586621679697765"><span id="local-6989586621679697766"><span id="local-6989586621679697767"><span id="local-6989586621679697768"><span id="local-6989586621679697769"><span id="local-6989586621679697770"><span id="local-6989586621679697771"><span id="local-6989586621679697772"><span id="local-6989586621679697773"><span id="local-6989586621679697774"><span id="local-6989586621679697775"><span class="hs-keyword">instance</span><span>
</span><span id="line-452"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-453"></span><span>      </span><span class="annot"><a href="#local-6989586621679697775"><span class="hs-identifier hs-type">qInProj</span></a></span><span>
</span><span id="line-454"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697774"><span class="hs-identifier hs-type">queryRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697773"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697772"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697771"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697770"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-455"></span><span>      </span><span class="annot"><a href="#local-6989586621679697769"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-456"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697768"><span class="hs-identifier hs-type">qRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697767"><span class="hs-identifier hs-type">qLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697766"><span class="hs-identifier hs-type">qDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697765"><span class="hs-identifier hs-type">qDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697764"><span class="hs-identifier hs-type">qShape0</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-457"></span><span>      </span><span class="annot"><a href="#local-6989586621679697763"><span class="hs-identifier hs-type">qGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-458"></span><span>    </span><span class="annot"><a href="#local-6989586621679697762"><span class="hs-identifier hs-type">reshapedQShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#ReshapeF"><span class="hs-identifier hs-type">ReshapeF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697764"><span class="hs-identifier hs-type">qShape0</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679697761"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697760"><span class="hs-identifier hs-type">querySeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697759"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697758"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-459"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697762"><span class="hs-identifier hs-type">reshapedQShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-460"></span><span>    </span><span class="annot"><a href="#local-6989586621679697757"><span class="hs-identifier hs-type">qShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697762"><span class="hs-identifier hs-type">reshapedQShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-461"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697757"><span class="hs-identifier hs-type">qShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-462"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-463"></span><span>      </span><span class="annot"><a href="#local-6989586621679697756"><span class="hs-identifier hs-type">kInProj</span></a></span><span>
</span><span id="line-464"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697755"><span class="hs-identifier hs-type">keyRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697754"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697753"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697752"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697751"><span class="hs-identifier hs-type">keyShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-465"></span><span>      </span><span class="annot"><a href="#local-6989586621679697763"><span class="hs-identifier hs-type">qGeneratorOutputDevice</span></a></span><span>
</span><span id="line-466"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697768"><span class="hs-identifier hs-type">qRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697750"><span class="hs-identifier hs-type">kLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697749"><span class="hs-identifier hs-type">kDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697748"><span class="hs-identifier hs-type">kDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697747"><span class="hs-identifier hs-type">kShape0</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>      </span><span class="annot"><a href="#local-6989586621679697746"><span class="hs-identifier hs-type">kGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-468"></span><span>    </span><span class="annot"><a href="#local-6989586621679697745"><span class="hs-identifier hs-type">reshapedKShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#ReshapeF"><span class="hs-identifier hs-type">ReshapeF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697747"><span class="hs-identifier hs-type">kShape0</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679697761"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697744"><span class="hs-identifier hs-type">keySeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697759"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697758"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-469"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697745"><span class="hs-identifier hs-type">reshapedKShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-470"></span><span>    </span><span class="annot"><a href="#local-6989586621679697743"><span class="hs-identifier hs-type">transposedReshapedKShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697745"><span class="hs-identifier hs-type">reshapedKShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-471"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697743"><span class="hs-identifier hs-type">transposedReshapedKShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-472"></span><span>    </span><span class="annot"><a href="#local-6989586621679697742"><span class="hs-identifier hs-type">doubleTransposedReshapedKShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697743"><span class="hs-identifier hs-type">transposedReshapedKShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-473"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697742"><span class="hs-identifier hs-type">doubleTransposedReshapedKShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-474"></span><span>    </span><span class="annot"><a href="#local-6989586621679697741"><span class="hs-identifier hs-type">multipliedQDoubleTransposedReshapedKShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-type">MatmulF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697757"><span class="hs-identifier hs-type">qShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697742"><span class="hs-identifier hs-type">doubleTransposedReshapedKShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-475"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697741"><span class="hs-identifier hs-type">multipliedQDoubleTransposedReshapedKShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="#local-6989586621679697740"><span class="hs-identifier hs-type">weightsShape0</span></a></span><span>
</span><span id="line-477"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-type">SoftmaxF</span></a></span><span>
</span><span id="line-478"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-479"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697741"><span class="hs-identifier hs-type">multipliedQDoubleTransposedReshapedKShape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697739"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-480"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697741"><span class="hs-identifier hs-type">multipliedQDoubleTransposedReshapedKShape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697739"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-481"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697740"><span class="hs-identifier hs-type">weightsShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-482"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-483"></span><span>      </span><span class="annot"><a href="#local-6989586621679697738"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-484"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-485"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697768"><span class="hs-identifier hs-type">qRequiresGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697737"><span class="hs-identifier hs-type">attentionBiasRequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-486"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697767"><span class="hs-identifier hs-type">qLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697750"><span class="hs-identifier hs-type">kLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697736"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697766"><span class="hs-identifier hs-type">qDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697749"><span class="hs-identifier hs-type">kDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697735"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-488"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697765"><span class="hs-identifier hs-type">qDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697748"><span class="hs-identifier hs-type">kDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697734"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-489"></span><span>          </span><span class="annot"><a href="#local-6989586621679697740"><span class="hs-identifier hs-type">weightsShape0</span></a></span><span>
</span><span id="line-490"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-491"></span><span>      </span><span class="annot"><a href="#local-6989586621679697746"><span class="hs-identifier hs-type">kGeneratorOutputDevice</span></a></span><span>
</span><span id="line-492"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697733"><span class="hs-identifier hs-type">weightsRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697732"><span class="hs-identifier hs-type">weightsLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697731"><span class="hs-identifier hs-type">weightsDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697730"><span class="hs-identifier hs-type">weightsDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697729"><span class="hs-identifier hs-type">weightsShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-493"></span><span>      </span><span class="annot"><a href="#local-6989586621679697728"><span class="hs-identifier hs-type">weightsGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-494"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-495"></span><span>      </span><span class="annot"><a href="#local-6989586621679697727"><span class="hs-identifier hs-type">vInProj</span></a></span><span>
</span><span id="line-496"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697726"><span class="hs-identifier hs-type">valueRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697725"><span class="hs-identifier hs-type">valueLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697724"><span class="hs-identifier hs-type">valueDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697723"><span class="hs-identifier hs-type">valueDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697722"><span class="hs-identifier hs-type">valueShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-497"></span><span>      </span><span class="annot"><a href="#local-6989586621679697728"><span class="hs-identifier hs-type">weightsGeneratorOutputDevice</span></a></span><span>
</span><span id="line-498"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697733"><span class="hs-identifier hs-type">weightsRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697721"><span class="hs-identifier hs-type">vLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697720"><span class="hs-identifier hs-type">vDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697719"><span class="hs-identifier hs-type">vDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697718"><span class="hs-identifier hs-type">vShape0</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-499"></span><span>      </span><span class="annot"><a href="#local-6989586621679697717"><span class="hs-identifier hs-type">vGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-500"></span><span>    </span><span class="annot"><a href="#local-6989586621679697716"><span class="hs-identifier hs-type">reshapedVShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#ReshapeF"><span class="hs-identifier hs-type">ReshapeF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697718"><span class="hs-identifier hs-type">vShape0</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679697761"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697744"><span class="hs-identifier hs-type">keySeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697759"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697758"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-501"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697716"><span class="hs-identifier hs-type">reshapedVShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-502"></span><span>    </span><span class="annot"><a href="#local-6989586621679697715"><span class="hs-identifier hs-type">transposedReshapedVShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697716"><span class="hs-identifier hs-type">reshapedVShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-503"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697715"><span class="hs-identifier hs-type">transposedReshapedVShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-504"></span><span>    </span><span class="annot"><a href="#local-6989586621679697714"><span class="hs-identifier hs-type">multipliedWeightsTransposedReshapedVShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-type">MatmulF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697729"><span class="hs-identifier hs-type">weightsShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697715"><span class="hs-identifier hs-type">transposedReshapedVShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-505"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697714"><span class="hs-identifier hs-type">multipliedWeightsTransposedReshapedVShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-506"></span><span>    </span><span class="annot"><a href="#local-6989586621679697713"><span class="hs-identifier hs-type">outputQueryShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679697714"><span class="hs-identifier hs-type">multipliedWeightsTransposedReshapedVShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-507"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697713"><span class="hs-identifier hs-type">outputQueryShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-508"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-509"></span><span>      </span><span class="annot"><a href="#local-6989586621679697712"><span class="hs-identifier hs-type">outProj</span></a></span><span>
</span><span id="line-510"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-511"></span><span>          </span><span class="annot"><a href="#local-6989586621679697733"><span class="hs-identifier hs-type">weightsRequiresGradient</span></a></span><span>
</span><span id="line-512"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697732"><span class="hs-identifier hs-type">weightsLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697721"><span class="hs-identifier hs-type">vLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-513"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697731"><span class="hs-identifier hs-type">weightsDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697720"><span class="hs-identifier hs-type">vDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-514"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697730"><span class="hs-identifier hs-type">weightsDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697719"><span class="hs-identifier hs-type">vDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-515"></span><span>          </span><span class="annot"><a href="#local-6989586621679697711"><span class="hs-identifier hs-type">reshapedOutputQueryShape0</span></a></span><span>
</span><span id="line-516"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-517"></span><span>      </span><span class="annot"><a href="#local-6989586621679697717"><span class="hs-identifier hs-type">vGeneratorOutputDevice</span></a></span><span>
</span><span id="line-518"></span><span>      </span><span class="annot"><a href="#local-6989586621679697710"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-519"></span><span>      </span><span class="annot"><a href="#local-6989586621679697709"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-520"></span><span>    </span><span class="annot"><a href="#local-6989586621679697711"><span class="hs-identifier hs-type">reshapedOutputQueryShape0</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#ReshapeF"><span class="hs-identifier hs-type">ReshapeF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697713"><span class="hs-identifier hs-type">outputQueryShape0</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679697761"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697760"><span class="hs-identifier hs-type">querySeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697708"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-521"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697711"><span class="hs-identifier hs-type">reshapedOutputQueryShape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-522"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697770"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-523"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697751"><span class="hs-identifier hs-type">keyShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-524"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697722"><span class="hs-identifier hs-type">valueShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-525"></span><span>    </span><span class="annot"><a href="#local-6989586621679697761"><span class="hs-identifier hs-type">batchDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#BatchDim"><span class="hs-identifier hs-type">BatchDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697770"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697751"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697722"><span class="hs-identifier hs-type">valueShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-526"></span><span>    </span><span class="annot"><a href="#local-6989586621679697760"><span class="hs-identifier hs-type">querySeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#QuerySeqDim"><span class="hs-identifier hs-type">QuerySeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697770"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-527"></span><span>    </span><span class="annot"><a href="#local-6989586621679697744"><span class="hs-identifier hs-type">keySeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#KeySeqDim"><span class="hs-identifier hs-type">KeySeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697751"><span class="hs-identifier hs-type">keyShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697722"><span class="hs-identifier hs-type">valueShape</span></a></span><span>
</span><span id="line-528"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-529"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-530"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697759"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697758"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697708"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697775"><span class="hs-identifier hs-type">qInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697756"><span class="hs-identifier hs-type">kInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697727"><span class="hs-identifier hs-type">vInProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697712"><span class="hs-identifier hs-type">outProj</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697738"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-531"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697774"><span class="hs-identifier hs-type">queryRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697773"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697772"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697771"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697770"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-532"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697755"><span class="hs-identifier hs-type">keyRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697754"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697753"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697752"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697751"><span class="hs-identifier hs-type">keyShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-533"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697726"><span class="hs-identifier hs-type">valueRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697725"><span class="hs-identifier hs-type">valueLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697724"><span class="hs-identifier hs-type">valueDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697723"><span class="hs-identifier hs-type">valueDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697722"><span class="hs-identifier hs-type">valueShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-534"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697737"><span class="hs-identifier hs-type">attentionBiasRequiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697736"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697735"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697734"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697739"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span>
</span><span id="line-535"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-536"></span><span>    </span><span class="annot"><a href="#local-6989586621679697769"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-537"></span><span>    </span><span class="annot"><a href="#local-6989586621679697710"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-538"></span><span>    </span><span class="annot"><a href="#local-6989586621679697709"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-539"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-540"></span><span>  </span><span id="local-6989586621679697705"><span class="annot"><span class="annottext">forward :: GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; (Tensor
      queryRequiresGradient
      queryLayout
      queryDevice
      queryDataType
      queryShape,
    Tensor
      keyRequiresGradient keyLayout keyDevice keyDataType keyShape,
    Tensor
      valueRequiresGradient
      valueLayout
      valueDevice
      valueDataType
      valueShape,
    Tensor
      attentionBiasRequiresGradient
      attentionBiasLayout
      attentionBiasDevice
      attentionBiasDataType
      attentionBiasShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#GMultiHeadAttention"><span class="hs-identifier hs-type">GMultiHeadAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679697695"><span id="local-6989586621679697696"><span id="local-6989586621679697697"><span id="local-6989586621679697698"><span id="local-6989586621679697699"><span id="local-6989586621679697700"><span id="local-6989586621679697701"><span id="local-6989586621679697702"><span id="local-6989586621679697703"><span class="annot"><span class="annottext">qInProj
kInProj
dropout
vInProj
outProj
SDim headDim
SDim headEmbedDim
SDim embedDim
MultiHeadAttentionHasScaling
mhaScaling :: MultiHeadAttentionHasScaling
mhaDropout :: dropout
mhaOutProj :: outProj
mhaVInProj :: vInProj
mhaKInProj :: kInProj
mhaQInProj :: qInProj
mhaEmbedDim :: SDim embedDim
mhaHeadEmbedDim :: SDim headEmbedDim
mhaHeadDim :: SDim headDim
mhaScaling :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; MultiHeadAttentionHasScaling
mhaDropout :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; dropout
mhaOutProj :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; outProj
mhaVInProj :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; vInProj
mhaKInProj :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; kInProj
mhaQInProj :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; qInProj
mhaEmbedDim :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; SDim embedDim
mhaHeadEmbedDim :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; SDim headEmbedDim
mhaHeadDim :: forall (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat)) qInProj kInProj vInProj
       outProj dropout.
GMultiHeadAttention
  headDim
  headEmbedDim
  embedDim
  qInProj
  kInProj
  vInProj
  outProj
  dropout
-&gt; SDim headDim
</span><a href="#local-6989586621679697695"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697694"><span class="annot"><span class="annottext">Tensor
  queryRequiresGradient
  queryLayout
  queryDevice
  queryDataType
  queryShape
</span><a href="#local-6989586621679697694"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697693"><span class="annot"><span class="annottext">Tensor keyRequiresGradient keyLayout keyDevice keyDataType keyShape
</span><a href="#local-6989586621679697693"><span class="hs-identifier hs-var">key</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697692"><span class="annot"><span class="annottext">Tensor
  valueRequiresGradient
  valueLayout
  valueDevice
  valueDataType
  valueShape
</span><a href="#local-6989586621679697692"><span class="hs-identifier hs-var">value</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697691"><span class="annot"><span class="annottext">Tensor
  attentionBiasRequiresGradient
  attentionBiasLayout
  attentionBiasDevice
  attentionBiasDataType
  attentionBiasShape
</span><a href="#local-6989586621679697691"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679697690"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697690"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-541"></span><span>    </span><span id="local-6989586621679697689"><span class="annot"><span class="annottext">SDim batchDim
</span><a href="#local-6989586621679697689"><span class="hs-identifier hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-542"></span><span>      </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697688"><span class="annot"><span class="annottext">queryShape :: SShape queryShape
</span><a href="#local-6989586621679697688"><span class="hs-identifier hs-var hs-var">queryShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  queryRequiresGradient
  queryLayout
  queryDevice
  queryDataType
  queryShape
-&gt; SShape queryShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryRequiresGradient
  queryLayout
  queryDevice
  queryDataType
  queryShape
</span><a href="#local-6989586621679697694"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-543"></span><span>          </span><span id="local-6989586621679697686"><span class="annot"><span class="annottext">keyShape :: SShape keyShape
</span><a href="#local-6989586621679697686"><span class="hs-identifier hs-var hs-var">keyShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor keyRequiresGradient keyLayout keyDevice keyDataType keyShape
-&gt; SShape keyShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor keyRequiresGradient keyLayout keyDevice keyDataType keyShape
</span><a href="#local-6989586621679697693"><span class="hs-identifier hs-var">key</span></a></span><span>
</span><span id="line-544"></span><span>          </span><span id="local-6989586621679697685"><span class="annot"><span class="annottext">valueShape :: SShape valueShape
</span><a href="#local-6989586621679697685"><span class="hs-identifier hs-var hs-var">valueShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  valueRequiresGradient
  valueLayout
  valueDevice
  valueDataType
  valueShape
-&gt; SShape valueShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  valueRequiresGradient
  valueLayout
  valueDevice
  valueDataType
  valueShape
</span><a href="#local-6989586621679697692"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-545"></span><span>       </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SShape queryShape
-&gt; SShape keyShape -&gt; SShape valueShape -&gt; m (SDim batchDim)
forall (m :: * -&gt; *)
       (queryShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (keyShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (valueShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (batchDim :: Dim (Name Symbol) (Size Nat)).
(MonadThrow m,
 batchDim ~ BatchDim queryShape keyShape valueShape) =&gt;
SShape queryShape
-&gt; SShape keyShape -&gt; SShape valueShape -&gt; m (SDim batchDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getBatchDim"><span class="hs-identifier hs-var">getBatchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SShape queryShape
</span><a href="#local-6989586621679697688"><span class="hs-identifier hs-var">queryShape</span></a></span><span> </span><span class="annot"><span class="annottext">SShape keyShape
</span><a href="#local-6989586621679697686"><span class="hs-identifier hs-var">keyShape</span></a></span><span> </span><span class="annot"><span class="annottext">SShape valueShape
</span><a href="#local-6989586621679697685"><span class="hs-identifier hs-var">valueShape</span></a></span><span>
</span><span id="line-546"></span><span>    </span><span id="local-6989586621679697684"><span class="annot"><span class="annottext">SDim querySeqDim
</span><a href="#local-6989586621679697684"><span class="hs-identifier hs-var">querySeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-547"></span><span>      </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697683"><span class="annot"><span class="annottext">queryShape :: SShape queryShape
</span><a href="#local-6989586621679697683"><span class="hs-identifier hs-var hs-var">queryShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  queryRequiresGradient
  queryLayout
  queryDevice
  queryDataType
  queryShape
-&gt; SShape queryShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryRequiresGradient
  queryLayout
  queryDevice
  queryDataType
  queryShape
</span><a href="#local-6989586621679697694"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-548"></span><span>       </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SShape queryShape -&gt; m (SDim querySeqDim)
forall (m :: * -&gt; *)
       (queryShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (querySeqDim :: Dim (Name Symbol) (Size Nat)).
(MonadThrow m, querySeqDim ~ QuerySeqDim queryShape) =&gt;
SShape queryShape -&gt; m (SDim querySeqDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getQuerySeqDim"><span class="hs-identifier hs-var">getQuerySeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SShape queryShape
</span><a href="#local-6989586621679697683"><span class="hs-identifier hs-var">queryShape</span></a></span><span>
</span><span id="line-549"></span><span>    </span><span id="local-6989586621679697682"><span class="annot"><span class="annottext">SDim keySeqDim
</span><a href="#local-6989586621679697682"><span class="hs-identifier hs-var">keySeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-550"></span><span>      </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697681"><span class="annot"><span class="annottext">keyShape :: SShape keyShape
</span><a href="#local-6989586621679697681"><span class="hs-identifier hs-var hs-var">keyShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor keyRequiresGradient keyLayout keyDevice keyDataType keyShape
-&gt; SShape keyShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor keyRequiresGradient keyLayout keyDevice keyDataType keyShape
</span><a href="#local-6989586621679697693"><span class="hs-identifier hs-var">key</span></a></span><span>
</span><span id="line-551"></span><span>          </span><span id="local-6989586621679697680"><span class="annot"><span class="annottext">valueShape :: SShape valueShape
</span><a href="#local-6989586621679697680"><span class="hs-identifier hs-var hs-var">valueShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  valueRequiresGradient
  valueLayout
  valueDevice
  valueDataType
  valueShape
-&gt; SShape valueShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  valueRequiresGradient
  valueLayout
  valueDevice
  valueDataType
  valueShape
</span><a href="#local-6989586621679697692"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-552"></span><span>       </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SShape keyShape -&gt; SShape valueShape -&gt; m (SDim keySeqDim)
forall (m :: * -&gt; *)
       (keyShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (valueShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (keySeqDim :: Dim (Name Symbol) (Size Nat)).
(MonadThrow m, keySeqDim ~ KeySeqDim keyShape valueShape) =&gt;
SShape keyShape -&gt; SShape valueShape -&gt; m (SDim keySeqDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#getKeySeqDim"><span class="hs-identifier hs-var">getKeySeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SShape keyShape
</span><a href="#local-6989586621679697681"><span class="hs-identifier hs-var">keyShape</span></a></span><span> </span><span class="annot"><span class="annottext">SShape valueShape
</span><a href="#local-6989586621679697680"><span class="hs-identifier hs-var">valueShape</span></a></span><span>
</span><span id="line-553"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697679"><span class="annot"><span class="annottext">scaling :: Double
</span><a href="#local-6989586621679697679"><span class="hs-identifier hs-var hs-var">scaling</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim headEmbedDim -&gt; Double) -&gt; SDim headEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim headEmbedDim -&gt; Integer) -&gt; SDim headEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim headEmbedDim -&gt; IsChecked Integer)
-&gt; SDim headEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim headEmbedDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim headEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim -&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim headEmbedDim -&gt; Double) -&gt; SDim headEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679697702"><span class="hs-identifier hs-var">mhaHeadEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-554"></span><span>    </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; Generator generatorDevice
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; m (output, Generator generatorOutputDevice)
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697690"><span class="hs-identifier hs-var">g</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-555"></span><span>      </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697671"><span class="annot"><span class="annottext">q :: IxStateT
  m
  (Generator generatorDevice)
  (Generator qGeneratorOutputDevice)
  (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
</span><a href="#local-6989586621679697671"><span class="hs-identifier hs-var hs-var">q</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-556"></span><span>            </span><span class="annot"><span class="annottext">Tensor
  queryRequiresGradient
  queryLayout
  queryDevice
  queryDataType
  queryShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        queryRequiresGradient
        queryLayout
        queryDevice
        queryDataType
        queryShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryRequiresGradient
  queryLayout
  queryDevice
  queryDataType
  queryShape
</span><a href="#local-6989586621679697694"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-557"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     queryRequiresGradient
     queryLayout
     queryDevice
     queryDataType
     queryShape)
-&gt; (Tensor
      queryRequiresGradient
      queryLayout
      queryDevice
      queryDataType
      queryShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator qGeneratorOutputDevice)
         (Tensor qRequiresGradient qLayout qDevice qDataType qShape0))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0,
       Generator qGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0,
        Generator qGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator qGeneratorOutputDevice)
      (Tensor qRequiresGradient qLayout qDevice qDataType qShape0))
-&gt; (Tensor
      queryRequiresGradient
      queryLayout
      queryDevice
      queryDataType
      queryShape
    -&gt; Generator generatorDevice
    -&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0,
          Generator qGeneratorOutputDevice))
-&gt; Tensor
     queryRequiresGradient
     queryLayout
     queryDevice
     queryDataType
     queryShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">qInProj
-&gt; Tensor
     queryRequiresGradient
     queryLayout
     queryDevice
     queryDataType
     queryShape
-&gt; Generator generatorDevice
-&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0,
      Generator qGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">qInProj
</span><a href="#local-6989586621679697700"><span class="hs-identifier hs-var">mhaQInProj</span></a></span><span>
</span><span id="line-558"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator qGeneratorOutputDevice)
  (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
-&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape0
    -&gt; IxStateT
         m
         (Generator qGeneratorOutputDevice)
         (Generator qGeneratorOutputDevice)
         (Tensor qRequiresGradient qLayout qDevice qDataType qShape0))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span>
</span><span id="line-559"></span><span>                </span><span class="annot"><span class="annottext">(m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
 -&gt; IxStateT
      m
      (Generator qGeneratorOutputDevice)
      (Generator qGeneratorOutputDevice)
      (Tensor qRequiresGradient qLayout qDevice qDataType qShape0))
-&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape0
    -&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0))
-&gt; Tensor qRequiresGradient qLayout qDevice qDataType qShape0
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-560"></span><span>                      </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithoutScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithoutScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor qRequiresGradient qLayout qDevice qDataType qShape0
-&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-561"></span><span>                      </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithQueryScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithQueryScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor qRequiresGradient qLayout qDevice qDataType qShape0
 -&gt; Double
 -&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0))
-&gt; Double
-&gt; Tensor qRequiresGradient qLayout qDevice qDataType qShape0
-&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor qRequiresGradient qLayout qDevice qDataType qShape0
-&gt; Double
-&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar other, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697679"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-562"></span><span>                      </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithWeightScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithWeightScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor qRequiresGradient qLayout qDevice qDataType qShape0
-&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-563"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-564"></span><span>                  </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679697695"><span class="hs-identifier hs-var">mhaScaling</span></a></span><span>
</span><span id="line-565"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator qGeneratorOutputDevice)
  (Tensor qRequiresGradient qLayout qDevice qDataType qShape0)
-&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape0
    -&gt; IxStateT
         m
         (Generator qGeneratorOutputDevice)
         (Generator qGeneratorOutputDevice)
         (Tensor
            qRequiresGradient qLayout qDevice qDataType reshapedQShape0))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor
        qRequiresGradient qLayout qDevice qDataType reshapedQShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     qRequiresGradient qLayout qDevice qDataType reshapedQShape0)
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor
        qRequiresGradient qLayout qDevice qDataType reshapedQShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      qRequiresGradient qLayout qDevice qDataType reshapedQShape0)
 -&gt; IxStateT
      m
      (Generator qGeneratorOutputDevice)
      (Generator qGeneratorOutputDevice)
      (Tensor
         qRequiresGradient qLayout qDevice qDataType reshapedQShape0))
-&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape0
    -&gt; m (Tensor
            qRequiresGradient qLayout qDevice qDataType reshapedQShape0))
-&gt; Tensor qRequiresGradient qLayout qDevice qDataType qShape0
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor
        qRequiresGradient qLayout qDevice qDataType reshapedQShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[batchDim, querySeqDim, headDim, headEmbedDim])
-&gt; Tensor qRequiresGradient qLayout qDevice qDataType qShape0
-&gt; m (Tensor
        qRequiresGradient qLayout qDevice qDataType reshapedQShape0)
forall (m :: * -&gt; *)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, shape'' ~ ReshapeF shape shape', Catch shape'') =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape'')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sReshape"><span class="hs-identifier hs-var">sReshape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[batchDim, querySeqDim, headDim, headEmbedDim]
-&gt; SShape ('Shape '[batchDim, querySeqDim, headDim, headEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[batchDim, querySeqDim, headDim, headEmbedDim]
 -&gt; SShape ('Shape '[batchDim, querySeqDim, headDim, headEmbedDim]))
-&gt; SList '[batchDim, querySeqDim, headDim, headEmbedDim]
-&gt; SShape ('Shape '[batchDim, querySeqDim, headDim, headEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679697689"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
-&gt; SList '[querySeqDim, headDim, headEmbedDim]
-&gt; SList '[batchDim, querySeqDim, headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing querySeqDim
SDim querySeqDim
</span><a href="#local-6989586621679697684"><span class="hs-identifier hs-var">querySeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing querySeqDim
-&gt; SList '[headDim, headEmbedDim]
-&gt; SList '[querySeqDim, headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headDim
SDim headDim
</span><a href="#local-6989586621679697703"><span class="hs-identifier hs-var">mhaHeadDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headDim
-&gt; SList '[headEmbedDim] -&gt; SList '[headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headEmbedDim
SDim headEmbedDim
</span><a href="#local-6989586621679697702"><span class="hs-identifier hs-var">mhaHeadEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headEmbedDim -&gt; SList '[] -&gt; SList '[headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-566"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator qGeneratorOutputDevice)
  (Tensor
     qRequiresGradient qLayout qDevice qDataType reshapedQShape0)
-&gt; (Tensor
      qRequiresGradient qLayout qDevice qDataType reshapedQShape0
    -&gt; IxStateT
         m
         (Generator qGeneratorOutputDevice)
         (Generator qGeneratorOutputDevice)
         (Tensor qRequiresGradient qLayout qDevice qDataType qShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
 -&gt; IxStateT
      m
      (Generator qGeneratorOutputDevice)
      (Generator qGeneratorOutputDevice)
      (Tensor qRequiresGradient qLayout qDevice qDataType qShape))
-&gt; (Tensor
      qRequiresGradient qLayout qDevice qDataType reshapedQShape0
    -&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape))
-&gt; Tensor
     qRequiresGradient qLayout qDevice qDataType reshapedQShape0
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SSelectDim ('SelectDim ('ByIndex 2))
-&gt; Tensor
     qRequiresGradient qLayout qDevice qDataType reshapedQShape0
-&gt; m (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, Catch shape',
 MonadThrow m) =&gt;
SSelectDim selectDim0
-&gt; SSelectDim selectDim1
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sTranspose"><span class="hs-identifier hs-var">sTranspose</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 2) -&gt; SSelectDim ('SelectDim ('ByIndex 2))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 2 =&gt; SBy ('ByIndex 2)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-567"></span><span>          </span><span id="local-6989586621679697667"><span class="annot"><span class="annottext">k :: IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     transposedReshapedKShape0)
</span><a href="#local-6989586621679697667"><span class="hs-identifier hs-var hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-568"></span><span>            </span><span class="annot"><span class="annottext">Tensor keyRequiresGradient keyLayout keyDevice keyDataType keyShape
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor
        keyRequiresGradient keyLayout keyDevice keyDataType keyShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor keyRequiresGradient keyLayout keyDevice keyDataType keyShape
</span><a href="#local-6989586621679697693"><span class="hs-identifier hs-var">key</span></a></span><span>
</span><span id="line-569"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator qGeneratorOutputDevice)
  (Tensor
     keyRequiresGradient keyLayout keyDevice keyDataType keyShape)
-&gt; (Tensor
      keyRequiresGradient keyLayout keyDevice keyDataType keyShape
    -&gt; IxStateT
         m
         (Generator qGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor qRequiresGradient kLayout kDevice kDataType kShape0))
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor qRequiresGradient kLayout kDevice kDataType kShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator qGeneratorOutputDevice
 -&gt; m (Tensor qRequiresGradient kLayout kDevice kDataType kShape0,
       Generator kGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor qRequiresGradient kLayout kDevice kDataType kShape0)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator qGeneratorOutputDevice
  -&gt; m (Tensor qRequiresGradient kLayout kDevice kDataType kShape0,
        Generator kGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator qGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor qRequiresGradient kLayout kDevice kDataType kShape0))
-&gt; (Tensor
      keyRequiresGradient keyLayout keyDevice keyDataType keyShape
    -&gt; Generator qGeneratorOutputDevice
    -&gt; m (Tensor qRequiresGradient kLayout kDevice kDataType kShape0,
          Generator kGeneratorOutputDevice))
-&gt; Tensor
     keyRequiresGradient keyLayout keyDevice keyDataType keyShape
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor qRequiresGradient kLayout kDevice kDataType kShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">kInProj
-&gt; Tensor
     keyRequiresGradient keyLayout keyDevice keyDataType keyShape
-&gt; Generator qGeneratorOutputDevice
-&gt; m (Tensor qRequiresGradient kLayout kDevice kDataType kShape0,
      Generator kGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">kInProj
</span><a href="#local-6989586621679697699"><span class="hs-identifier hs-var">mhaKInProj</span></a></span><span>
</span><span id="line-570"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor qRequiresGradient kLayout kDevice kDataType kShape0)
-&gt; (Tensor qRequiresGradient kLayout kDevice kDataType kShape0
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor
            qRequiresGradient kLayout kDevice kDataType reshapedKShape0))
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient kLayout kDevice kDataType reshapedKShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     qRequiresGradient kLayout kDevice kDataType reshapedKShape0)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient kLayout kDevice kDataType reshapedKShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      qRequiresGradient kLayout kDevice kDataType reshapedKShape0)
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor
         qRequiresGradient kLayout kDevice kDataType reshapedKShape0))
-&gt; (Tensor qRequiresGradient kLayout kDevice kDataType kShape0
    -&gt; m (Tensor
            qRequiresGradient kLayout kDevice kDataType reshapedKShape0))
-&gt; Tensor qRequiresGradient kLayout kDevice kDataType kShape0
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient kLayout kDevice kDataType reshapedKShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])
-&gt; Tensor qRequiresGradient kLayout kDevice kDataType kShape0
-&gt; m (Tensor
        qRequiresGradient kLayout kDevice kDataType reshapedKShape0)
forall (m :: * -&gt; *)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, shape'' ~ ReshapeF shape shape', Catch shape'') =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape'')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sReshape"><span class="hs-identifier hs-var">sReshape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[batchDim, keySeqDim, headDim, headEmbedDim]
-&gt; SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[batchDim, keySeqDim, headDim, headEmbedDim]
 -&gt; SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))
-&gt; SList '[batchDim, keySeqDim, headDim, headEmbedDim]
-&gt; SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679697689"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
-&gt; SList '[keySeqDim, headDim, headEmbedDim]
-&gt; SList '[batchDim, keySeqDim, headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing keySeqDim
SDim keySeqDim
</span><a href="#local-6989586621679697682"><span class="hs-identifier hs-var">keySeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing keySeqDim
-&gt; SList '[headDim, headEmbedDim]
-&gt; SList '[keySeqDim, headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headDim
SDim headDim
</span><a href="#local-6989586621679697703"><span class="hs-identifier hs-var">mhaHeadDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headDim
-&gt; SList '[headEmbedDim] -&gt; SList '[headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headEmbedDim
SDim headEmbedDim
</span><a href="#local-6989586621679697702"><span class="hs-identifier hs-var">mhaHeadEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headEmbedDim -&gt; SList '[] -&gt; SList '[headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-571"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient kLayout kDevice kDataType reshapedKShape0)
-&gt; (Tensor
      qRequiresGradient kLayout kDevice kDataType reshapedKShape0
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor
            qRequiresGradient
            kLayout
            kDevice
            kDataType
            transposedReshapedKShape0))
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        transposedReshapedKShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     transposedReshapedKShape0)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        transposedReshapedKShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      transposedReshapedKShape0)
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor
         qRequiresGradient
         kLayout
         kDevice
         kDataType
         transposedReshapedKShape0))
-&gt; (Tensor
      qRequiresGradient kLayout kDevice kDataType reshapedKShape0
    -&gt; m (Tensor
            qRequiresGradient
            kLayout
            kDevice
            kDataType
            transposedReshapedKShape0))
-&gt; Tensor
     qRequiresGradient kLayout kDevice kDataType reshapedKShape0
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        transposedReshapedKShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SSelectDim ('SelectDim ('ByIndex 2))
-&gt; Tensor
     qRequiresGradient kLayout kDevice kDataType reshapedKShape0
-&gt; m (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        transposedReshapedKShape0)
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, Catch shape',
 MonadThrow m) =&gt;
SSelectDim selectDim0
-&gt; SSelectDim selectDim1
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sTranspose"><span class="hs-identifier hs-var">sTranspose</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 2) -&gt; SSelectDim ('SelectDim ('ByIndex 2))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 2 =&gt; SBy ('ByIndex 2)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-572"></span><span>          </span><span id="local-6989586621679697666"><span class="annot"><span class="annottext">kt :: IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     doubleTransposedReshapedKShape0)
</span><a href="#local-6989586621679697666"><span class="hs-identifier hs-var hs-var">kt</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     transposedReshapedKShape0)
</span><a href="#local-6989586621679697667"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     transposedReshapedKShape0)
-&gt; (Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      transposedReshapedKShape0
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor
            qRequiresGradient
            kLayout
            kDevice
            kDataType
            doubleTransposedReshapedKShape0))
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        doubleTransposedReshapedKShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     doubleTransposedReshapedKShape0)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        doubleTransposedReshapedKShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      doubleTransposedReshapedKShape0)
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor
         qRequiresGradient
         kLayout
         kDevice
         kDataType
         doubleTransposedReshapedKShape0))
-&gt; (Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      transposedReshapedKShape0
    -&gt; m (Tensor
            qRequiresGradient
            kLayout
            kDevice
            kDataType
            doubleTransposedReshapedKShape0))
-&gt; Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     transposedReshapedKShape0
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        doubleTransposedReshapedKShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 2))
-&gt; SSelectDim ('SelectDim ('ByIndex 3))
-&gt; Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     transposedReshapedKShape0
-&gt; m (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        doubleTransposedReshapedKShape0)
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, Catch shape',
 MonadThrow m) =&gt;
SSelectDim selectDim0
-&gt; SSelectDim selectDim1
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sTranspose"><span class="hs-identifier hs-var">sTranspose</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 2) -&gt; SSelectDim ('SelectDim ('ByIndex 2))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 2 =&gt; SBy ('ByIndex 2)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 3) -&gt; SSelectDim ('SelectDim ('ByIndex 3))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SBy ('ByIndex 3)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-573"></span><span>          </span><span id="local-6989586621679697665"><span class="annot"><span class="annottext">weights :: IxStateT
  m
  (Generator generatorDevice)
  (Generator weightsGeneratorOutputDevice)
  (Tensor
     weightsRequiresGradient
     weightsLayout
     weightsDevice
     weightsDataType
     weightsShape)
</span><a href="#local-6989586621679697665"><span class="hs-identifier hs-var hs-var">weights</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-574"></span><span>            </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor qRequiresGradient qLayout qDevice qDataType qShape
 -&gt; Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      doubleTransposedReshapedKShape0
 -&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape,
     Tensor
       qRequiresGradient
       kLayout
       kDevice
       kDataType
       doubleTransposedReshapedKShape0))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator qGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        doubleTransposedReshapedKShape0
      -&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape,
          Tensor
            qRequiresGradient
            kLayout
            kDevice
            kDataType
            doubleTransposedReshapedKShape0))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator qGeneratorOutputDevice)
  (Tensor qRequiresGradient qLayout qDevice qDataType qShape)
</span><a href="#local-6989586621679697671"><span class="hs-identifier hs-var">q</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator qGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     doubleTransposedReshapedKShape0
   -&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape,
       Tensor
         qRequiresGradient
         kLayout
         kDevice
         kDataType
         doubleTransposedReshapedKShape0))
-&gt; IxStateT
     m
     (Generator qGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        doubleTransposedReshapedKShape0)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor qRequiresGradient qLayout qDevice qDataType qShape,
      Tensor
        qRequiresGradient
        kLayout
        kDevice
        kDataType
        doubleTransposedReshapedKShape0)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator qGeneratorOutputDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     doubleTransposedReshapedKShape0)
</span><a href="#local-6989586621679697666"><span class="hs-identifier hs-var">kt</span></a></span><span>
</span><span id="line-575"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor qRequiresGradient qLayout qDevice qDataType qShape,
   Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     doubleTransposedReshapedKShape0)
-&gt; ((Tensor qRequiresGradient qLayout qDevice qDataType qShape,
     Tensor
       qRequiresGradient
       kLayout
       kDevice
       kDataType
       doubleTransposedReshapedKShape0)
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor
            qRequiresGradient
            (Unify (Layout LayoutType) qLayout kLayout)
            (Unify (Device (DeviceType Nat)) qDevice kDevice)
            (Unify (DataType DType) qDataType kDataType)
            multipliedQDoubleTransposedReshapedKShape0))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     qRequiresGradient
     (Unify (Layout LayoutType) qLayout kLayout)
     (Unify (Device (DeviceType Nat)) qDevice kDevice)
     (Unify (DataType DType) qDataType kDataType)
     multipliedQDoubleTransposedReshapedKShape0)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      qRequiresGradient
      (Unify (Layout LayoutType) qLayout kLayout)
      (Unify (Device (DeviceType Nat)) qDevice kDevice)
      (Unify (DataType DType) qDataType kDataType)
      multipliedQDoubleTransposedReshapedKShape0)
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor
         qRequiresGradient
         (Unify (Layout LayoutType) qLayout kLayout)
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         (Unify (DataType DType) qDataType kDataType)
         multipliedQDoubleTransposedReshapedKShape0))
-&gt; ((Tensor qRequiresGradient qLayout qDevice qDataType qShape,
     Tensor
       qRequiresGradient
       kLayout
       kDevice
       kDataType
       doubleTransposedReshapedKShape0)
    -&gt; m (Tensor
            qRequiresGradient
            (Unify (Layout LayoutType) qLayout kLayout)
            (Unify (Device (DeviceType Nat)) qDevice kDevice)
            (Unify (DataType DType) qDataType kDataType)
            multipliedQDoubleTransposedReshapedKShape0))
-&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape,
    Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      doubleTransposedReshapedKShape0)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(Tensor qRequiresGradient qLayout qDevice qDataType qShape
 -&gt; Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      doubleTransposedReshapedKShape0
 -&gt; m (Tensor
         qRequiresGradient
         (Unify (Layout LayoutType) qLayout kLayout)
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         (Unify (DataType DType) qDataType kDataType)
         multipliedQDoubleTransposedReshapedKShape0))
-&gt; (Tensor qRequiresGradient qLayout qDevice qDataType qShape,
    Tensor
      qRequiresGradient
      kLayout
      kDevice
      kDataType
      doubleTransposedReshapedKShape0)
-&gt; m (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall a b c. (a -&gt; b -&gt; c) -&gt; (a, b) -&gt; c
</span><span class="hs-identifier hs-var">uncurry</span></span><span> </span><span class="annot"><span class="annottext">Tensor qRequiresGradient qLayout qDevice qDataType qShape
-&gt; Tensor
     qRequiresGradient
     kLayout
     kDevice
     kDataType
     doubleTransposedReshapedKShape0
-&gt; m (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (gradient' :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (layout' :: Layout LayoutType)
       (device :: Device (DeviceType Nat))
       (device' :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (dataType' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, shape'' ~ MatmulF shape shape', Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#matmul"><span class="hs-identifier hs-var">matmul</span></a></span><span>
</span><span id="line-576"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     (Unify (Layout LayoutType) qLayout kLayout)
     (Unify (Device (DeviceType Nat)) qDevice kDevice)
     (Unify (DataType DType) qDataType kDataType)
     multipliedQDoubleTransposedReshapedKShape0)
-&gt; (Tensor
      qRequiresGradient
      (Unify (Layout LayoutType) qLayout kLayout)
      (Unify (Device (DeviceType Nat)) qDevice kDevice)
      (Unify (DataType DType) qDataType kDataType)
      multipliedQDoubleTransposedReshapedKShape0
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor
            qRequiresGradient
            (Unify (Layout LayoutType) qLayout kLayout)
            (Unify (Device (DeviceType Nat)) qDevice kDevice)
            (Unify (DataType DType) qDataType kDataType)
            multipliedQDoubleTransposedReshapedKShape0))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     qRequiresGradient
     (Unify (Layout LayoutType) qLayout kLayout)
     (Unify (Device (DeviceType Nat)) qDevice kDevice)
     (Unify (DataType DType) qDataType kDataType)
     multipliedQDoubleTransposedReshapedKShape0)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span>
</span><span id="line-577"></span><span>                </span><span class="annot"><span class="annottext">(m (Tensor
      qRequiresGradient
      (Unify (Layout LayoutType) qLayout kLayout)
      (Unify (Device (DeviceType Nat)) qDevice kDevice)
      (Unify (DataType DType) qDataType kDataType)
      multipliedQDoubleTransposedReshapedKShape0)
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor
         qRequiresGradient
         (Unify (Layout LayoutType) qLayout kLayout)
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         (Unify (DataType DType) qDataType kDataType)
         multipliedQDoubleTransposedReshapedKShape0))
-&gt; (Tensor
      qRequiresGradient
      (Unify (Layout LayoutType) qLayout kLayout)
      (Unify (Device (DeviceType Nat)) qDevice kDevice)
      (Unify (DataType DType) qDataType kDataType)
      multipliedQDoubleTransposedReshapedKShape0
    -&gt; m (Tensor
            qRequiresGradient
            (Unify (Layout LayoutType) qLayout kLayout)
            (Unify (Device (DeviceType Nat)) qDevice kDevice)
            (Unify (DataType DType) qDataType kDataType)
            multipliedQDoubleTransposedReshapedKShape0))
-&gt; Tensor
     qRequiresGradient
     (Unify (Layout LayoutType) qLayout kLayout)
     (Unify (Device (DeviceType Nat)) qDevice kDevice)
     (Unify (DataType DType) qDataType kDataType)
     multipliedQDoubleTransposedReshapedKShape0
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-578"></span><span>                      </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithoutScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithoutScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
  qRequiresGradient
  (Unify (Layout LayoutType) qLayout kLayout)
  (Unify (Device (DeviceType Nat)) qDevice kDevice)
  (Unify (DataType DType) qDataType kDataType)
  multipliedQDoubleTransposedReshapedKShape0
-&gt; m (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-579"></span><span>                      </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithQueryScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithQueryScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
  qRequiresGradient
  (Unify (Layout LayoutType) qLayout kLayout)
  (Unify (Device (DeviceType Nat)) qDevice kDevice)
  (Unify (DataType DType) qDataType kDataType)
  multipliedQDoubleTransposedReshapedKShape0
-&gt; m (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-580"></span><span>                      </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GMultiHeadAttention.html#MultiHeadAttentionWithWeightScaling"><span class="hs-identifier hs-var">MultiHeadAttentionWithWeightScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor
   qRequiresGradient
   (Unify (Layout LayoutType) qLayout kLayout)
   (Unify (Device (DeviceType Nat)) qDevice kDevice)
   (Unify (DataType DType) qDataType kDataType)
   multipliedQDoubleTransposedReshapedKShape0
 -&gt; Double
 -&gt; m (Tensor
         qRequiresGradient
         (Unify (Layout LayoutType) qLayout kLayout)
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         (Unify (DataType DType) qDataType kDataType)
         multipliedQDoubleTransposedReshapedKShape0))
-&gt; Double
-&gt; Tensor
     qRequiresGradient
     (Unify (Layout LayoutType) qLayout kLayout)
     (Unify (Device (DeviceType Nat)) qDevice kDevice)
     (Unify (DataType DType) qDataType kDataType)
     multipliedQDoubleTransposedReshapedKShape0
-&gt; m (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  qRequiresGradient
  (Unify (Layout LayoutType) qLayout kLayout)
  (Unify (Device (DeviceType Nat)) qDevice kDevice)
  (Unify (DataType DType) qDataType kDataType)
  multipliedQDoubleTransposedReshapedKShape0
-&gt; Double
-&gt; m (Tensor
        qRequiresGradient
        (Unify (Layout LayoutType) qLayout kLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        (Unify (DataType DType) qDataType kDataType)
        multipliedQDoubleTransposedReshapedKShape0)
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar other, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697679"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-581"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-582"></span><span>                  </span><span class="annot"><span class="annottext">MultiHeadAttentionHasScaling
</span><a href="#local-6989586621679697695"><span class="hs-identifier hs-var">mhaScaling</span></a></span><span>
</span><span id="line-583"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     qRequiresGradient
     (Unify (Layout LayoutType) qLayout kLayout)
     (Unify (Device (DeviceType Nat)) qDevice kDevice)
     (Unify (DataType DType) qDataType kDataType)
     multipliedQDoubleTransposedReshapedKShape0)
-&gt; (Tensor
      qRequiresGradient
      (Unify (Layout LayoutType) qLayout kLayout)
      (Unify (Device (DeviceType Nat)) qDevice kDevice)
      (Unify (DataType DType) qDataType kDataType)
      multipliedQDoubleTransposedReshapedKShape0
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               qRequiresGradient
               attentionBiasRequiresGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) qLayout kLayout)
               attentionBiasLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) qDevice kDevice)
               attentionBiasDevice)
            (Unify
               (DataType DType)
               (Unify (DataType DType) qDataType kDataType)
               attentionBiasDataType)
            (BroadcastShapesF
               multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           qRequiresGradient
           attentionBiasRequiresGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) qLayout kLayout)
           attentionBiasLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) qDevice kDevice)
           attentionBiasDevice)
        (Unify
           (DataType DType)
           (Unify (DataType DType) qDataType kDataType)
           attentionBiasDataType)
        (BroadcastShapesF
           multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     (BroadcastShapesF
        multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape))
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           qRequiresGradient
           attentionBiasRequiresGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) qLayout kLayout)
           attentionBiasLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) qDevice kDevice)
           attentionBiasDevice)
        (Unify
           (DataType DType)
           (Unify (DataType DType) qDataType kDataType)
           attentionBiasDataType)
        (BroadcastShapesF
           multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or
         (Gradient RequiresGradient)
         qRequiresGradient
         attentionBiasRequiresGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) qLayout kLayout)
         attentionBiasLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         attentionBiasDevice)
      (Unify
         (DataType DType)
         (Unify (DataType DType) qDataType kDataType)
         attentionBiasDataType)
      (BroadcastShapesF
         multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape))
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            qRequiresGradient
            attentionBiasRequiresGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) qLayout kLayout)
            attentionBiasLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) qDevice kDevice)
            attentionBiasDevice)
         (Unify
            (DataType DType)
            (Unify (DataType DType) qDataType kDataType)
            attentionBiasDataType)
         (BroadcastShapesF
            multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape)))
-&gt; (Tensor
      qRequiresGradient
      (Unify (Layout LayoutType) qLayout kLayout)
      (Unify (Device (DeviceType Nat)) qDevice kDevice)
      (Unify (DataType DType) qDataType kDataType)
      multipliedQDoubleTransposedReshapedKShape0
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               qRequiresGradient
               attentionBiasRequiresGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) qLayout kLayout)
               attentionBiasLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) qDevice kDevice)
               attentionBiasDevice)
            (Unify
               (DataType DType)
               (Unify (DataType DType) qDataType kDataType)
               attentionBiasDataType)
            (BroadcastShapesF
               multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape)))
-&gt; Tensor
     qRequiresGradient
     (Unify (Layout LayoutType) qLayout kLayout)
     (Unify (Device (DeviceType Nat)) qDevice kDevice)
     (Unify (DataType DType) qDataType kDataType)
     multipliedQDoubleTransposedReshapedKShape0
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           qRequiresGradient
           attentionBiasRequiresGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) qLayout kLayout)
           attentionBiasLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) qDevice kDevice)
           attentionBiasDevice)
        (Unify
           (DataType DType)
           (Unify (DataType DType) qDataType kDataType)
           attentionBiasDataType)
        (BroadcastShapesF
           multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  qRequiresGradient
  (Unify (Layout LayoutType) qLayout kLayout)
  (Unify (Device (DeviceType Nat)) qDevice kDevice)
  (Unify (DataType DType) qDataType kDataType)
  multipliedQDoubleTransposedReshapedKShape0
-&gt; Tensor
     attentionBiasRequiresGradient
     attentionBiasLayout
     attentionBiasDevice
     attentionBiasDataType
     attentionBiasShape
-&gt; m (Tensor
        (qRequiresGradient &lt;|&gt; attentionBiasRequiresGradient)
        (Unify (Layout LayoutType) qLayout kLayout &lt;+&gt; attentionBiasLayout)
        (Unify (Device (DeviceType Nat)) qDevice kDevice
         &lt;+&gt; attentionBiasDevice)
        (Unify (DataType DType) qDataType kDataType
         &lt;+&gt; attentionBiasDataType)
        (BroadcastShapesF
           multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  attentionBiasRequiresGradient
  attentionBiasLayout
  attentionBiasDevice
  attentionBiasDataType
  attentionBiasShape
</span><a href="#local-6989586621679697691"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-584"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     (BroadcastShapesF
        multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         qRequiresGradient
         attentionBiasRequiresGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) qLayout kLayout)
         attentionBiasLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         attentionBiasDevice)
      (Unify
         (DataType DType)
         (Unify (DataType DType) qDataType kDataType)
         attentionBiasDataType)
      (BroadcastShapesF
         multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape)
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator kGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               qRequiresGradient
               attentionBiasRequiresGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) qLayout kLayout)
               attentionBiasLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) qDevice kDevice)
               attentionBiasDevice)
            (Unify
               (DataType DType)
               (Unify (DataType DType) qDataType kDataType)
               attentionBiasDataType)
            weightsShape0))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           qRequiresGradient
           attentionBiasRequiresGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) qLayout kLayout)
           attentionBiasLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) qDevice kDevice)
           attentionBiasDevice)
        (Unify
           (DataType DType)
           (Unify (DataType DType) qDataType kDataType)
           attentionBiasDataType)
        weightsShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     weightsShape0)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           qRequiresGradient
           attentionBiasRequiresGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) qLayout kLayout)
           attentionBiasLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) qDevice kDevice)
           attentionBiasDevice)
        (Unify
           (DataType DType)
           (Unify (DataType DType) qDataType kDataType)
           attentionBiasDataType)
        weightsShape0)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or
         (Gradient RequiresGradient)
         qRequiresGradient
         attentionBiasRequiresGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) qLayout kLayout)
         attentionBiasLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         attentionBiasDevice)
      (Unify
         (DataType DType)
         (Unify (DataType DType) qDataType kDataType)
         attentionBiasDataType)
      weightsShape0)
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator kGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            qRequiresGradient
            attentionBiasRequiresGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) qLayout kLayout)
            attentionBiasLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) qDevice kDevice)
            attentionBiasDevice)
         (Unify
            (DataType DType)
            (Unify (DataType DType) qDataType kDataType)
            attentionBiasDataType)
         weightsShape0))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         qRequiresGradient
         attentionBiasRequiresGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) qLayout kLayout)
         attentionBiasLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         attentionBiasDevice)
      (Unify
         (DataType DType)
         (Unify (DataType DType) qDataType kDataType)
         attentionBiasDataType)
      (BroadcastShapesF
         multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape)
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               qRequiresGradient
               attentionBiasRequiresGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) qLayout kLayout)
               attentionBiasLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) qDevice kDevice)
               attentionBiasDevice)
            (Unify
               (DataType DType)
               (Unify (DataType DType) qDataType kDataType)
               attentionBiasDataType)
            weightsShape0))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     (BroadcastShapesF
        multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape)
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator kGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           qRequiresGradient
           attentionBiasRequiresGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) qLayout kLayout)
           attentionBiasLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) qDevice kDevice)
           attentionBiasDevice)
        (Unify
           (DataType DType)
           (Unify (DataType DType) qDataType kDataType)
           attentionBiasDataType)
        weightsShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 3))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     (BroadcastShapesF
        multipliedQDoubleTransposedReshapedKShape0 attentionBiasShape)
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           qRequiresGradient
           attentionBiasRequiresGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) qLayout kLayout)
           attentionBiasLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) qDevice kDevice)
           attentionBiasDevice)
        (Unify
           (DataType DType)
           (Unify (DataType DType) qDataType kDataType)
           attentionBiasDataType)
        weightsShape0)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape' ~ SoftmaxF selectDim shape, Catch shape') =&gt;
SSelectDim selectDim
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#softmax"><span class="hs-identifier hs-var">softmax</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 3) -&gt; SSelectDim ('SelectDim ('ByIndex 3))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SBy ('ByIndex 3)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator kGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     weightsShape0)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         qRequiresGradient
         attentionBiasRequiresGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) qLayout kLayout)
         attentionBiasLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         attentionBiasDevice)
      (Unify
         (DataType DType)
         (Unify (DataType DType) qDataType kDataType)
         attentionBiasDataType)
      weightsShape0
    -&gt; IxStateT
         m
         (Generator kGeneratorOutputDevice)
         (Generator weightsGeneratorOutputDevice)
         (Tensor
            weightsRequiresGradient
            weightsLayout
            weightsDevice
            weightsDataType
            weightsShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator weightsGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        weightsLayout
        weightsDevice
        weightsDataType
        weightsShape)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator kGeneratorOutputDevice
 -&gt; m (Tensor
         weightsRequiresGradient
         weightsLayout
         weightsDevice
         weightsDataType
         weightsShape,
       Generator weightsGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator weightsGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        weightsLayout
        weightsDevice
        weightsDataType
        weightsShape)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator kGeneratorOutputDevice
  -&gt; m (Tensor
          weightsRequiresGradient
          weightsLayout
          weightsDevice
          weightsDataType
          weightsShape,
        Generator weightsGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator kGeneratorOutputDevice)
      (Generator weightsGeneratorOutputDevice)
      (Tensor
         weightsRequiresGradient
         weightsLayout
         weightsDevice
         weightsDataType
         weightsShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         qRequiresGradient
         attentionBiasRequiresGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) qLayout kLayout)
         attentionBiasLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) qDevice kDevice)
         attentionBiasDevice)
      (Unify
         (DataType DType)
         (Unify (DataType DType) qDataType kDataType)
         attentionBiasDataType)
      weightsShape0
    -&gt; Generator kGeneratorOutputDevice
    -&gt; m (Tensor
            weightsRequiresGradient
            weightsLayout
            weightsDevice
            weightsDataType
            weightsShape,
          Generator weightsGeneratorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     weightsShape0
-&gt; IxStateT
     m
     (Generator kGeneratorOutputDevice)
     (Generator weightsGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        weightsLayout
        weightsDevice
        weightsDataType
        weightsShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        qRequiresGradient
        attentionBiasRequiresGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) qLayout kLayout)
        attentionBiasLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) qDevice kDevice)
        attentionBiasDevice)
     (Unify
        (DataType DType)
        (Unify (DataType DType) qDataType kDataType)
        attentionBiasDataType)
     weightsShape0
-&gt; Generator kGeneratorOutputDevice
-&gt; m (Tensor
        weightsRequiresGradient
        weightsLayout
        weightsDevice
        weightsDataType
        weightsShape,
      Generator weightsGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">dropout
</span><a href="#local-6989586621679697696"><span class="hs-identifier hs-var">mhaDropout</span></a></span><span>
</span><span id="line-586"></span><span>          </span><span id="local-6989586621679697663"><span class="annot"><span class="annottext">v :: IxStateT
  m
  (Generator weightsGeneratorOutputDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
</span><a href="#local-6989586621679697663"><span class="hs-identifier hs-var hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-587"></span><span>            </span><span class="annot"><span class="annottext">Tensor
  valueRequiresGradient
  valueLayout
  valueDevice
  valueDataType
  valueShape
-&gt; IxStateT
     m
     (Generator weightsGeneratorOutputDevice)
     (Generator weightsGeneratorOutputDevice)
     (Tensor
        valueRequiresGradient
        valueLayout
        valueDevice
        valueDataType
        valueShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  valueRequiresGradient
  valueLayout
  valueDevice
  valueDataType
  valueShape
</span><a href="#local-6989586621679697692"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-588"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator weightsGeneratorOutputDevice)
  (Generator weightsGeneratorOutputDevice)
  (Tensor
     valueRequiresGradient
     valueLayout
     valueDevice
     valueDataType
     valueShape)
-&gt; (Tensor
      valueRequiresGradient
      valueLayout
      valueDevice
      valueDataType
      valueShape
    -&gt; IxStateT
         m
         (Generator weightsGeneratorOutputDevice)
         (Generator vGeneratorOutputDevice)
         (Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0))
-&gt; IxStateT
     m
     (Generator weightsGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator weightsGeneratorOutputDevice
 -&gt; m (Tensor
         weightsRequiresGradient vLayout vDevice vDataType vShape0,
       Generator vGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator weightsGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator weightsGeneratorOutputDevice
  -&gt; m (Tensor
          weightsRequiresGradient vLayout vDevice vDataType vShape0,
        Generator vGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator weightsGeneratorOutputDevice)
      (Generator vGeneratorOutputDevice)
      (Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0))
-&gt; (Tensor
      valueRequiresGradient
      valueLayout
      valueDevice
      valueDataType
      valueShape
    -&gt; Generator weightsGeneratorOutputDevice
    -&gt; m (Tensor
            weightsRequiresGradient vLayout vDevice vDataType vShape0,
          Generator vGeneratorOutputDevice))
-&gt; Tensor
     valueRequiresGradient
     valueLayout
     valueDevice
     valueDataType
     valueShape
-&gt; IxStateT
     m
     (Generator weightsGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">vInProj
-&gt; Tensor
     valueRequiresGradient
     valueLayout
     valueDevice
     valueDataType
     valueShape
-&gt; Generator weightsGeneratorOutputDevice
-&gt; m (Tensor
        weightsRequiresGradient vLayout vDevice vDataType vShape0,
      Generator vGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">vInProj
</span><a href="#local-6989586621679697698"><span class="hs-identifier hs-var">mhaVInProj</span></a></span><span>
</span><span id="line-589"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator weightsGeneratorOutputDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0)
-&gt; (Tensor
      weightsRequiresGradient vLayout vDevice vDataType vShape0
    -&gt; IxStateT
         m
         (Generator vGeneratorOutputDevice)
         (Generator vGeneratorOutputDevice)
         (Tensor
            weightsRequiresGradient
            vLayout
            vDevice
            vDataType
            (ReshapeImplF
               (NumelF vShape0)
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF keySeqDim)
                     (LiftTimesMaybe
                        (NumelDimF headDim)
                        (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
               vShape0
               ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; IxStateT
     m
     (Generator weightsGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (ReshapeImplF
        (NumelF vShape0)
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF keySeqDim)
              (LiftTimesMaybe
                 (NumelDimF headDim)
                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
        vShape0
        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (ReshapeImplF
         (NumelF vShape0)
         (LiftTimesMaybe
            (NumelDimF batchDim)
            (LiftTimesMaybe
               (NumelDimF keySeqDim)
               (LiftTimesMaybe
                  (NumelDimF headDim)
                  (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
         vShape0
         ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
 -&gt; IxStateT
      m
      (Generator vGeneratorOutputDevice)
      (Generator vGeneratorOutputDevice)
      (Tensor
         weightsRequiresGradient
         vLayout
         vDevice
         vDataType
         (ReshapeImplF
            (NumelF vShape0)
            (LiftTimesMaybe
               (NumelDimF batchDim)
               (LiftTimesMaybe
                  (NumelDimF keySeqDim)
                  (LiftTimesMaybe
                     (NumelDimF headDim)
                     (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
            vShape0
            ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; (Tensor
      weightsRequiresGradient vLayout vDevice vDataType vShape0
    -&gt; m (Tensor
            weightsRequiresGradient
            vLayout
            vDevice
            vDataType
            (ReshapeImplF
               (NumelF vShape0)
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF keySeqDim)
                     (LiftTimesMaybe
                        (NumelDimF headDim)
                        (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
               vShape0
               ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])
-&gt; Tensor weightsRequiresGradient vLayout vDevice vDataType vShape0
-&gt; m (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
forall (m :: * -&gt; *)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, shape'' ~ ReshapeF shape shape', Catch shape'') =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape'')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sReshape"><span class="hs-identifier hs-var">sReshape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[batchDim, keySeqDim, headDim, headEmbedDim]
-&gt; SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[batchDim, keySeqDim, headDim, headEmbedDim]
 -&gt; SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))
-&gt; SList '[batchDim, keySeqDim, headDim, headEmbedDim]
-&gt; SShape ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679697689"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
-&gt; SList '[keySeqDim, headDim, headEmbedDim]
-&gt; SList '[batchDim, keySeqDim, headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing keySeqDim
SDim keySeqDim
</span><a href="#local-6989586621679697682"><span class="hs-identifier hs-var">keySeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing keySeqDim
-&gt; SList '[headDim, headEmbedDim]
-&gt; SList '[keySeqDim, headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headDim
SDim headDim
</span><a href="#local-6989586621679697703"><span class="hs-identifier hs-var">mhaHeadDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headDim
-&gt; SList '[headEmbedDim] -&gt; SList '[headDim, headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headEmbedDim
SDim headEmbedDim
</span><a href="#local-6989586621679697702"><span class="hs-identifier hs-var">mhaHeadEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing headEmbedDim -&gt; SList '[] -&gt; SList '[headEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-590"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator weightsGeneratorOutputDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (ReshapeImplF
        (NumelF vShape0)
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF keySeqDim)
              (LiftTimesMaybe
                 (NumelDimF headDim)
                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
        vShape0
        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
-&gt; (Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (ReshapeImplF
         (NumelF vShape0)
         (LiftTimesMaybe
            (NumelDimF batchDim)
            (LiftTimesMaybe
               (NumelDimF keySeqDim)
               (LiftTimesMaybe
                  (NumelDimF headDim)
                  (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
         vShape0
         ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))
    -&gt; IxStateT
         m
         (Generator vGeneratorOutputDevice)
         (Generator vGeneratorOutputDevice)
         (Tensor
            weightsRequiresGradient
            vLayout
            vDevice
            vDataType
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; IxStateT
     m
     (Generator weightsGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (ReshapeImplF
            (NumelF vShape0)
            (LiftTimesMaybe
               (NumelDimF batchDim)
               (LiftTimesMaybe
                  (NumelDimF keySeqDim)
                  (LiftTimesMaybe
                     (NumelDimF headDim)
                     (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
            vShape0
            ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
 -&gt; IxStateT
      m
      (Generator vGeneratorOutputDevice)
      (Generator vGeneratorOutputDevice)
      (Tensor
         weightsRequiresGradient
         vLayout
         vDevice
         vDataType
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (ReshapeImplF
               (NumelF vShape0)
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF keySeqDim)
                     (LiftTimesMaybe
                        (NumelDimF headDim)
                        (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
               vShape0
               ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; (Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (ReshapeImplF
         (NumelF vShape0)
         (LiftTimesMaybe
            (NumelDimF batchDim)
            (LiftTimesMaybe
               (NumelDimF keySeqDim)
               (LiftTimesMaybe
                  (NumelDimF headDim)
                  (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
         vShape0
         ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))
    -&gt; m (Tensor
            weightsRequiresGradient
            vLayout
            vDevice
            vDataType
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (ReshapeImplF
        (NumelF vShape0)
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF keySeqDim)
              (LiftTimesMaybe
                 (NumelDimF headDim)
                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
        vShape0
        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SSelectDim ('SelectDim ('ByIndex 2))
-&gt; Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (ReshapeImplF
        (NumelF vShape0)
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF keySeqDim)
              (LiftTimesMaybe
                 (NumelDimF headDim)
                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
        vShape0
        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))
-&gt; m (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, Catch shape',
 MonadThrow m) =&gt;
SSelectDim selectDim0
-&gt; SSelectDim selectDim1
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sTranspose"><span class="hs-identifier hs-var">sTranspose</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 2) -&gt; SSelectDim ('SelectDim ('ByIndex 2))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 2 =&gt; SBy ('ByIndex 2)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-591"></span><span>       </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor
   weightsRequiresGradient
   weightsLayout
   weightsDevice
   weightsDataType
   weightsShape
 -&gt; Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (ReshapeImplF
            (NumelF vShape0)
            (LiftTimesMaybe
               (NumelDimF batchDim)
               (LiftTimesMaybe
                  (NumelDimF keySeqDim)
                  (LiftTimesMaybe
                     (NumelDimF headDim)
                     (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
            vShape0
            ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
 -&gt; (Tensor
       weightsRequiresGradient
       weightsLayout
       weightsDevice
       weightsDataType
       weightsShape,
     Tensor
       weightsRequiresGradient
       vLayout
       vDevice
       vDataType
       (TransposeF
          ('SelectDim ('ByIndex 1))
          ('SelectDim ('ByIndex 2))
          (ReshapeImplF
             (NumelF vShape0)
             (LiftTimesMaybe
                (NumelDimF batchDim)
                (LiftTimesMaybe
                   (NumelDimF keySeqDim)
                   (LiftTimesMaybe
                      (NumelDimF headDim)
                      (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
             vShape0
             ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator weightsGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        weightsLayout
        weightsDevice
        weightsDataType
        weightsShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator weightsGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
      -&gt; (Tensor
            weightsRequiresGradient
            weightsLayout
            weightsDevice
            weightsDataType
            weightsShape,
          Tensor
            weightsRequiresGradient
            vLayout
            vDevice
            vDataType
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator weightsGeneratorOutputDevice)
  (Tensor
     weightsRequiresGradient
     weightsLayout
     weightsDevice
     weightsDataType
     weightsShape)
</span><a href="#local-6989586621679697665"><span class="hs-identifier hs-var">weights</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator weightsGeneratorOutputDevice)
  (Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
   -&gt; (Tensor
         weightsRequiresGradient
         weightsLayout
         weightsDevice
         weightsDataType
         weightsShape,
       Tensor
         weightsRequiresGradient
         vLayout
         vDevice
         vDataType
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (ReshapeImplF
               (NumelF vShape0)
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF keySeqDim)
                     (LiftTimesMaybe
                        (NumelDimF headDim)
                        (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
               vShape0
               ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; IxStateT
     m
     (Generator weightsGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        weightsRequiresGradient
        weightsLayout
        weightsDevice
        weightsDataType
        weightsShape,
      Tensor
        weightsRequiresGradient
        vLayout
        vDevice
        vDataType
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator weightsGeneratorOutputDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
</span><a href="#local-6989586621679697663"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-592"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor
     weightsRequiresGradient
     weightsLayout
     weightsDevice
     weightsDataType
     weightsShape,
   Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; ((Tensor
       weightsRequiresGradient
       weightsLayout
       weightsDevice
       weightsDataType
       weightsShape,
     Tensor
       weightsRequiresGradient
       vLayout
       vDevice
       vDataType
       (TransposeF
          ('SelectDim ('ByIndex 1))
          ('SelectDim ('ByIndex 2))
          (ReshapeImplF
             (NumelF vShape0)
             (LiftTimesMaybe
                (NumelDimF batchDim)
                (LiftTimesMaybe
                   (NumelDimF keySeqDim)
                   (LiftTimesMaybe
                      (NumelDimF headDim)
                      (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
             vShape0
             ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
    -&gt; IxStateT
         m
         (Generator vGeneratorOutputDevice)
         (Generator vGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               weightsRequiresGradient
               weightsRequiresGradient)
            (Unify (Layout LayoutType) weightsLayout vLayout)
            (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
            (Unify (DataType DType) weightsDataType vDataType)
            (MatmulF
               weightsShape
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (ReshapeImplF
                     (NumelF vShape0)
                     (LiftTimesMaybe
                        (NumelDimF batchDim)
                        (LiftTimesMaybe
                           (NumelDimF keySeqDim)
                           (LiftTimesMaybe
                              (NumelDimF headDim)
                              (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                     vShape0
                     ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (MatmulF
        weightsShape
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (MatmulF
         weightsShape
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (ReshapeImplF
               (NumelF vShape0)
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF keySeqDim)
                     (LiftTimesMaybe
                        (NumelDimF headDim)
                        (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
               vShape0
               ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
 -&gt; IxStateT
      m
      (Generator vGeneratorOutputDevice)
      (Generator vGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            weightsRequiresGradient
            weightsRequiresGradient)
         (Unify (Layout LayoutType) weightsLayout vLayout)
         (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
         (Unify (DataType DType) weightsDataType vDataType)
         (MatmulF
            weightsShape
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
-&gt; ((Tensor
       weightsRequiresGradient
       weightsLayout
       weightsDevice
       weightsDataType
       weightsShape,
     Tensor
       weightsRequiresGradient
       vLayout
       vDevice
       vDataType
       (TransposeF
          ('SelectDim ('ByIndex 1))
          ('SelectDim ('ByIndex 2))
          (ReshapeImplF
             (NumelF vShape0)
             (LiftTimesMaybe
                (NumelDimF batchDim)
                (LiftTimesMaybe
                   (NumelDimF keySeqDim)
                   (LiftTimesMaybe
                      (NumelDimF headDim)
                      (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
             vShape0
             ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               weightsRequiresGradient
               weightsRequiresGradient)
            (Unify (Layout LayoutType) weightsLayout vLayout)
            (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
            (Unify (DataType DType) weightsDataType vDataType)
            (MatmulF
               weightsShape
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (ReshapeImplF
                     (NumelF vShape0)
                     (LiftTimesMaybe
                        (NumelDimF batchDim)
                        (LiftTimesMaybe
                           (NumelDimF keySeqDim)
                           (LiftTimesMaybe
                              (NumelDimF headDim)
                              (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                     vShape0
                     ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
-&gt; (Tensor
      weightsRequiresGradient
      weightsLayout
      weightsDevice
      weightsDataType
      weightsShape,
    Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (ReshapeImplF
            (NumelF vShape0)
            (LiftTimesMaybe
               (NumelDimF batchDim)
               (LiftTimesMaybe
                  (NumelDimF keySeqDim)
                  (LiftTimesMaybe
                     (NumelDimF headDim)
                     (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
            vShape0
            ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   weightsRequiresGradient
   weightsLayout
   weightsDevice
   weightsDataType
   weightsShape
 -&gt; Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (ReshapeImplF
            (NumelF vShape0)
            (LiftTimesMaybe
               (NumelDimF batchDim)
               (LiftTimesMaybe
                  (NumelDimF keySeqDim)
                  (LiftTimesMaybe
                     (NumelDimF headDim)
                     (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
            vShape0
            ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            weightsRequiresGradient
            weightsRequiresGradient)
         (Unify (Layout LayoutType) weightsLayout vLayout)
         (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
         (Unify (DataType DType) weightsDataType vDataType)
         (MatmulF
            weightsShape
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
-&gt; (Tensor
      weightsRequiresGradient
      weightsLayout
      weightsDevice
      weightsDataType
      weightsShape,
    Tensor
      weightsRequiresGradient
      vLayout
      vDevice
      vDataType
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (ReshapeImplF
            (NumelF vShape0)
            (LiftTimesMaybe
               (NumelDimF batchDim)
               (LiftTimesMaybe
                  (NumelDimF keySeqDim)
                  (LiftTimesMaybe
                     (NumelDimF headDim)
                     (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
            vShape0
            ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
forall a b c. (a -&gt; b -&gt; c) -&gt; (a, b) -&gt; c
</span><span class="hs-identifier hs-var">uncurry</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  weightsRequiresGradient
  weightsLayout
  weightsDevice
  weightsDataType
  weightsShape
-&gt; Tensor
     weightsRequiresGradient
     vLayout
     vDevice
     vDataType
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (ReshapeImplF
           (NumelF vShape0)
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF keySeqDim)
                 (LiftTimesMaybe
                    (NumelDimF headDim)
                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
           vShape0
           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (gradient' :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (layout' :: Layout LayoutType)
       (device :: Device (DeviceType Nat))
       (device' :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (dataType' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, shape'' ~ MatmulF shape shape', Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#matmul"><span class="hs-identifier hs-var">matmul</span></a></span><span>
</span><span id="line-593"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (MatmulF
        weightsShape
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (MatmulF
         weightsShape
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (ReshapeImplF
               (NumelF vShape0)
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF keySeqDim)
                     (LiftTimesMaybe
                        (NumelDimF headDim)
                        (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
               vShape0
               ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
    -&gt; IxStateT
         m
         (Generator vGeneratorOutputDevice)
         (Generator vGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               weightsRequiresGradient
               weightsRequiresGradient)
            (Unify (Layout LayoutType) weightsLayout vLayout)
            (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
            (Unify (DataType DType) weightsDataType vDataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (MatmulF
                  weightsShape
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (ReshapeImplF
                        (NumelF vShape0)
                        (LiftTimesMaybe
                           (NumelDimF batchDim)
                           (LiftTimesMaybe
                              (NumelDimF keySeqDim)
                              (LiftTimesMaybe
                                 (NumelDimF headDim)
                                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                        vShape0
                        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (MatmulF
            weightsShape
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
 -&gt; IxStateT
      m
      (Generator vGeneratorOutputDevice)
      (Generator vGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            weightsRequiresGradient
            weightsRequiresGradient)
         (Unify (Layout LayoutType) weightsLayout vLayout)
         (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
         (Unify (DataType DType) weightsDataType vDataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (MatmulF
               weightsShape
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (ReshapeImplF
                     (NumelF vShape0)
                     (LiftTimesMaybe
                        (NumelDimF batchDim)
                        (LiftTimesMaybe
                           (NumelDimF keySeqDim)
                           (LiftTimesMaybe
                              (NumelDimF headDim)
                              (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                     vShape0
                     ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (MatmulF
         weightsShape
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (ReshapeImplF
               (NumelF vShape0)
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF keySeqDim)
                     (LiftTimesMaybe
                        (NumelDimF headDim)
                        (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
               vShape0
               ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               weightsRequiresGradient
               weightsRequiresGradient)
            (Unify (Layout LayoutType) weightsLayout vLayout)
            (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
            (Unify (DataType DType) weightsDataType vDataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (MatmulF
                  weightsShape
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (ReshapeImplF
                        (NumelF vShape0)
                        (LiftTimesMaybe
                           (NumelDimF batchDim)
                           (LiftTimesMaybe
                              (NumelDimF keySeqDim)
                              (LiftTimesMaybe
                                 (NumelDimF headDim)
                                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                        vShape0
                        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (MatmulF
        weightsShape
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SSelectDim ('SelectDim ('ByIndex 2))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (MatmulF
        weightsShape
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (ReshapeImplF
              (NumelF vShape0)
              (LiftTimesMaybe
                 (NumelDimF batchDim)
                 (LiftTimesMaybe
                    (NumelDimF keySeqDim)
                    (LiftTimesMaybe
                       (NumelDimF headDim)
                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
              vShape0
              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, Catch shape',
 MonadThrow m) =&gt;
SSelectDim selectDim0
-&gt; SSelectDim selectDim1
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sTranspose"><span class="hs-identifier hs-var">sTranspose</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 2) -&gt; SSelectDim ('SelectDim ('ByIndex 2))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 2 =&gt; SBy ('ByIndex 2)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-594"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (MatmulF
            weightsShape
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
    -&gt; IxStateT
         m
         (Generator vGeneratorOutputDevice)
         (Generator vGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               weightsRequiresGradient
               weightsRequiresGradient)
            (Unify (Layout LayoutType) weightsLayout vLayout)
            (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
            (Unify (DataType DType) weightsDataType vDataType)
            (ReshapeImplF
               (NumelF
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (MatmulF
                        weightsShape
                        (TransposeF
                           ('SelectDim ('ByIndex 1))
                           ('SelectDim ('ByIndex 2))
                           (ReshapeImplF
                              (NumelF vShape0)
                              (LiftTimesMaybe
                                 (NumelDimF batchDim)
                                 (LiftTimesMaybe
                                    (NumelDimF keySeqDim)
                                    (LiftTimesMaybe
                                       (NumelDimF headDim)
                                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                              vShape0
                              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF querySeqDim)
                     (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (MatmulF
                     weightsShape
                     (TransposeF
                        ('SelectDim ('ByIndex 1))
                        ('SelectDim ('ByIndex 2))
                        (ReshapeImplF
                           (NumelF vShape0)
                           (LiftTimesMaybe
                              (NumelDimF batchDim)
                              (LiftTimesMaybe
                                 (NumelDimF keySeqDim)
                                 (LiftTimesMaybe
                                    (NumelDimF headDim)
                                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                           vShape0
                           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
               ('Shape '[batchDim, querySeqDim, embedDim]))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (ReshapeImplF
           (NumelF
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (MatmulF
                    weightsShape
                    (TransposeF
                       ('SelectDim ('ByIndex 1))
                       ('SelectDim ('ByIndex 2))
                       (ReshapeImplF
                          (NumelF vShape0)
                          (LiftTimesMaybe
                             (NumelDimF batchDim)
                             (LiftTimesMaybe
                                (NumelDimF keySeqDim)
                                (LiftTimesMaybe
                                   (NumelDimF headDim)
                                   (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                          vShape0
                          ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF querySeqDim)
                 (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
           ('Shape '[batchDim, querySeqDim, embedDim])))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (ReshapeImplF
        (NumelF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF querySeqDim)
              (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
        ('Shape '[batchDim, querySeqDim, embedDim])))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (ReshapeImplF
           (NumelF
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (MatmulF
                    weightsShape
                    (TransposeF
                       ('SelectDim ('ByIndex 1))
                       ('SelectDim ('ByIndex 2))
                       (ReshapeImplF
                          (NumelF vShape0)
                          (LiftTimesMaybe
                             (NumelDimF batchDim)
                             (LiftTimesMaybe
                                (NumelDimF keySeqDim)
                                (LiftTimesMaybe
                                   (NumelDimF headDim)
                                   (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                          vShape0
                          ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF querySeqDim)
                 (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
           ('Shape '[batchDim, querySeqDim, embedDim])))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (ReshapeImplF
         (NumelF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (MatmulF
                  weightsShape
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (ReshapeImplF
                        (NumelF vShape0)
                        (LiftTimesMaybe
                           (NumelDimF batchDim)
                           (LiftTimesMaybe
                              (NumelDimF keySeqDim)
                              (LiftTimesMaybe
                                 (NumelDimF headDim)
                                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                        vShape0
                        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
         (LiftTimesMaybe
            (NumelDimF batchDim)
            (LiftTimesMaybe
               (NumelDimF querySeqDim)
               (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (MatmulF
               weightsShape
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (ReshapeImplF
                     (NumelF vShape0)
                     (LiftTimesMaybe
                        (NumelDimF batchDim)
                        (LiftTimesMaybe
                           (NumelDimF keySeqDim)
                           (LiftTimesMaybe
                              (NumelDimF headDim)
                              (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                     vShape0
                     ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
         ('Shape '[batchDim, querySeqDim, embedDim])))
 -&gt; IxStateT
      m
      (Generator vGeneratorOutputDevice)
      (Generator vGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            weightsRequiresGradient
            weightsRequiresGradient)
         (Unify (Layout LayoutType) weightsLayout vLayout)
         (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
         (Unify (DataType DType) weightsDataType vDataType)
         (ReshapeImplF
            (NumelF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (MatmulF
                     weightsShape
                     (TransposeF
                        ('SelectDim ('ByIndex 1))
                        ('SelectDim ('ByIndex 2))
                        (ReshapeImplF
                           (NumelF vShape0)
                           (LiftTimesMaybe
                              (NumelDimF batchDim)
                              (LiftTimesMaybe
                                 (NumelDimF keySeqDim)
                                 (LiftTimesMaybe
                                    (NumelDimF headDim)
                                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                           vShape0
                           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
            (LiftTimesMaybe
               (NumelDimF batchDim)
               (LiftTimesMaybe
                  (NumelDimF querySeqDim)
                  (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (MatmulF
                  weightsShape
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (ReshapeImplF
                        (NumelF vShape0)
                        (LiftTimesMaybe
                           (NumelDimF batchDim)
                           (LiftTimesMaybe
                              (NumelDimF keySeqDim)
                              (LiftTimesMaybe
                                 (NumelDimF headDim)
                                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                        vShape0
                        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
            ('Shape '[batchDim, querySeqDim, embedDim]))))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (MatmulF
            weightsShape
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (ReshapeImplF
                  (NumelF vShape0)
                  (LiftTimesMaybe
                     (NumelDimF batchDim)
                     (LiftTimesMaybe
                        (NumelDimF keySeqDim)
                        (LiftTimesMaybe
                           (NumelDimF headDim)
                           (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                  vShape0
                  ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               weightsRequiresGradient
               weightsRequiresGradient)
            (Unify (Layout LayoutType) weightsLayout vLayout)
            (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
            (Unify (DataType DType) weightsDataType vDataType)
            (ReshapeImplF
               (NumelF
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (MatmulF
                        weightsShape
                        (TransposeF
                           ('SelectDim ('ByIndex 1))
                           ('SelectDim ('ByIndex 2))
                           (ReshapeImplF
                              (NumelF vShape0)
                              (LiftTimesMaybe
                                 (NumelDimF batchDim)
                                 (LiftTimesMaybe
                                    (NumelDimF keySeqDim)
                                    (LiftTimesMaybe
                                       (NumelDimF headDim)
                                       (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                              vShape0
                              ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
               (LiftTimesMaybe
                  (NumelDimF batchDim)
                  (LiftTimesMaybe
                     (NumelDimF querySeqDim)
                     (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (MatmulF
                     weightsShape
                     (TransposeF
                        ('SelectDim ('ByIndex 1))
                        ('SelectDim ('ByIndex 2))
                        (ReshapeImplF
                           (NumelF vShape0)
                           (LiftTimesMaybe
                              (NumelDimF batchDim)
                              (LiftTimesMaybe
                                 (NumelDimF keySeqDim)
                                 (LiftTimesMaybe
                                    (NumelDimF headDim)
                                    (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                           vShape0
                           ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
               ('Shape '[batchDim, querySeqDim, embedDim]))))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator vGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (ReshapeImplF
           (NumelF
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (MatmulF
                    weightsShape
                    (TransposeF
                       ('SelectDim ('ByIndex 1))
                       ('SelectDim ('ByIndex 2))
                       (ReshapeImplF
                          (NumelF vShape0)
                          (LiftTimesMaybe
                             (NumelDimF batchDim)
                             (LiftTimesMaybe
                                (NumelDimF keySeqDim)
                                (LiftTimesMaybe
                                   (NumelDimF headDim)
                                   (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                          vShape0
                          ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF querySeqDim)
                 (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
           ('Shape '[batchDim, querySeqDim, embedDim])))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[batchDim, querySeqDim, embedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (MatmulF
           weightsShape
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (ReshapeImplF
                 (NumelF vShape0)
                 (LiftTimesMaybe
                    (NumelDimF batchDim)
                    (LiftTimesMaybe
                       (NumelDimF keySeqDim)
                       (LiftTimesMaybe
                          (NumelDimF headDim)
                          (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                 vShape0
                 ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           weightsRequiresGradient
           weightsRequiresGradient)
        (Unify (Layout LayoutType) weightsLayout vLayout)
        (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
        (Unify (DataType DType) weightsDataType vDataType)
        (ReshapeImplF
           (NumelF
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (MatmulF
                    weightsShape
                    (TransposeF
                       ('SelectDim ('ByIndex 1))
                       ('SelectDim ('ByIndex 2))
                       (ReshapeImplF
                          (NumelF vShape0)
                          (LiftTimesMaybe
                             (NumelDimF batchDim)
                             (LiftTimesMaybe
                                (NumelDimF keySeqDim)
                                (LiftTimesMaybe
                                   (NumelDimF headDim)
                                   (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                          vShape0
                          ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
           (LiftTimesMaybe
              (NumelDimF batchDim)
              (LiftTimesMaybe
                 (NumelDimF querySeqDim)
                 (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
           ('Shape '[batchDim, querySeqDim, embedDim])))
forall (m :: * -&gt; *)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, shape'' ~ ReshapeF shape shape', Catch shape'') =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape'')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sReshape"><span class="hs-identifier hs-var">sReshape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[batchDim, querySeqDim, embedDim]
-&gt; SShape ('Shape '[batchDim, querySeqDim, embedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[batchDim, querySeqDim, embedDim]
 -&gt; SShape ('Shape '[batchDim, querySeqDim, embedDim]))
-&gt; SList '[batchDim, querySeqDim, embedDim]
-&gt; SShape ('Shape '[batchDim, querySeqDim, embedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679697689"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
-&gt; SList '[querySeqDim, embedDim]
-&gt; SList '[batchDim, querySeqDim, embedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing querySeqDim
SDim querySeqDim
</span><a href="#local-6989586621679697684"><span class="hs-identifier hs-var">querySeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing querySeqDim
-&gt; SList '[embedDim] -&gt; SList '[querySeqDim, embedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing embedDim
SDim embedDim
</span><a href="#local-6989586621679697701"><span class="hs-identifier hs-var">mhaEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing embedDim -&gt; SList '[] -&gt; SList '[embedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-595"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator vGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (ReshapeImplF
        (NumelF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF querySeqDim)
              (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
        ('Shape '[batchDim, querySeqDim, embedDim])))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (ReshapeImplF
         (NumelF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (MatmulF
                  weightsShape
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (ReshapeImplF
                        (NumelF vShape0)
                        (LiftTimesMaybe
                           (NumelDimF batchDim)
                           (LiftTimesMaybe
                              (NumelDimF keySeqDim)
                              (LiftTimesMaybe
                                 (NumelDimF headDim)
                                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                        vShape0
                        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
         (LiftTimesMaybe
            (NumelDimF batchDim)
            (LiftTimesMaybe
               (NumelDimF querySeqDim)
               (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (MatmulF
               weightsShape
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (ReshapeImplF
                     (NumelF vShape0)
                     (LiftTimesMaybe
                        (NumelDimF batchDim)
                        (LiftTimesMaybe
                           (NumelDimF keySeqDim)
                           (LiftTimesMaybe
                              (NumelDimF headDim)
                              (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                     vShape0
                     ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
         ('Shape '[batchDim, querySeqDim, embedDim]))
    -&gt; IxStateT
         m
         (Generator vGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator vGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator vGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator vGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         weightsRequiresGradient
         weightsRequiresGradient)
      (Unify (Layout LayoutType) weightsLayout vLayout)
      (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
      (Unify (DataType DType) weightsDataType vDataType)
      (ReshapeImplF
         (NumelF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (MatmulF
                  weightsShape
                  (TransposeF
                     ('SelectDim ('ByIndex 1))
                     ('SelectDim ('ByIndex 2))
                     (ReshapeImplF
                        (NumelF vShape0)
                        (LiftTimesMaybe
                           (NumelDimF batchDim)
                           (LiftTimesMaybe
                              (NumelDimF keySeqDim)
                              (LiftTimesMaybe
                                 (NumelDimF headDim)
                                 (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                        vShape0
                        ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
         (LiftTimesMaybe
            (NumelDimF batchDim)
            (LiftTimesMaybe
               (NumelDimF querySeqDim)
               (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (MatmulF
               weightsShape
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (ReshapeImplF
                     (NumelF vShape0)
                     (LiftTimesMaybe
                        (NumelDimF batchDim)
                        (LiftTimesMaybe
                           (NumelDimF keySeqDim)
                           (LiftTimesMaybe
                              (NumelDimF headDim)
                              (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                     vShape0
                     ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
         ('Shape '[batchDim, querySeqDim, embedDim]))
    -&gt; Generator vGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (ReshapeImplF
        (NumelF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF querySeqDim)
              (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
        ('Shape '[batchDim, querySeqDim, embedDim]))
-&gt; IxStateT
     m
     (Generator vGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">outProj
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        weightsRequiresGradient
        weightsRequiresGradient)
     (Unify (Layout LayoutType) weightsLayout vLayout)
     (Unify (Device (DeviceType Nat)) weightsDevice vDevice)
     (Unify (DataType DType) weightsDataType vDataType)
     (ReshapeImplF
        (NumelF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (MatmulF
                 weightsShape
                 (TransposeF
                    ('SelectDim ('ByIndex 1))
                    ('SelectDim ('ByIndex 2))
                    (ReshapeImplF
                       (NumelF vShape0)
                       (LiftTimesMaybe
                          (NumelDimF batchDim)
                          (LiftTimesMaybe
                             (NumelDimF keySeqDim)
                             (LiftTimesMaybe
                                (NumelDimF headDim)
                                (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                       vShape0
                       ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim]))))))
        (LiftTimesMaybe
           (NumelDimF batchDim)
           (LiftTimesMaybe
              (NumelDimF querySeqDim)
              (LiftTimesMaybe (NumelDimF embedDim) ('Just 1))))
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (MatmulF
              weightsShape
              (TransposeF
                 ('SelectDim ('ByIndex 1))
                 ('SelectDim ('ByIndex 2))
                 (ReshapeImplF
                    (NumelF vShape0)
                    (LiftTimesMaybe
                       (NumelDimF batchDim)
                       (LiftTimesMaybe
                          (NumelDimF keySeqDim)
                          (LiftTimesMaybe
                             (NumelDimF headDim)
                             (LiftTimesMaybe (NumelDimF headEmbedDim) ('Just 1)))))
                    vShape0
                    ('Shape '[batchDim, keySeqDim, headDim, headEmbedDim])))))
        ('Shape '[batchDim, querySeqDim, embedDim]))
-&gt; Generator vGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">outProj
</span><a href="#local-6989586621679697697"><span class="hs-identifier hs-var">mhaOutProj</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-596"></span></pre></body></html>