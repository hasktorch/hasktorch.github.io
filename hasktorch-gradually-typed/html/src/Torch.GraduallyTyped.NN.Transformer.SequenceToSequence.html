<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE StandaloneDeriving #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.SequenceToSequence</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-20"></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxState</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">KnownNat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Decoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier">TransformerDecoder</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier">TransformerEncoder</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.LMHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier">LMHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerHead"><span class="hs-identifier">STransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier">SWithLMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier">SWithMLMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier">SWithoutHead</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier">TransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier">WithLMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier">WithoutHead</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span>
</span><span id="line-46"></span><span class="hs-keyword">data</span><span>
</span><span id="line-47"></span><span>  </span><span id="GSequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span></span><span>
</span><span id="line-48"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760441"><span class="annot"><a href="#local-6989586621679760441"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760440"><span class="annot"><a href="#local-6989586621679760440"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760439"><span class="annot"><a href="#local-6989586621679760439"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760438"><span class="annot"><a href="#local-6989586621679760438"><span class="hs-identifier hs-type">embedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760437"><span class="annot"><a href="#local-6989586621679760437"><span class="hs-identifier hs-type">head</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-54"></span><span>  </span><span id="GSequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-55"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679760825"><span class="annot"><a href="#local-6989586621679760825"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760824"><span class="annot"><a href="#local-6989586621679760824"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span id="local-6989586621679760823"><span class="annot"><a href="#local-6989586621679760823"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span id="local-6989586621679760822"><span class="annot"><a href="#local-6989586621679760822"><span class="hs-identifier hs-type">embedding</span></a></span></span><span> </span><span id="local-6989586621679760821"><span class="annot"><a href="#local-6989586621679760821"><span class="hs-identifier hs-type">head</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-56"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | input embedding dim for scaling</span><span>
</span><span id="line-57"></span><span>      </span><span id="seqToSeqInputEmbedDim"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqInputEmbedDim"><span class="hs-identifier hs-var hs-var">seqToSeqInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760825"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-58"></span><span>      </span><span class="hs-comment">-- | encoder</span><span>
</span><span id="line-59"></span><span>      </span><span id="seqToSeqEncoder"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqEncoder"><span class="hs-identifier hs-var hs-var">seqToSeqEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760824"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-60"></span><span>      </span><span class="hs-comment">-- | decoder</span><span>
</span><span id="line-61"></span><span>      </span><span id="seqToSeqDecoder"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqDecoder"><span class="hs-identifier hs-var hs-var">seqToSeqDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760823"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-62"></span><span>      </span><span class="hs-comment">-- | shared embedding</span><span>
</span><span id="line-63"></span><span>      </span><span id="seqToSeqEmbedding"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqEmbedding"><span class="hs-identifier hs-var hs-var">seqToSeqEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760822"><span class="hs-identifier hs-type">embedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-64"></span><span>      </span><span class="hs-comment">-- | transformer head</span><span>
</span><span id="line-65"></span><span>      </span><span id="seqToSeqHead"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqHead"><span class="hs-identifier hs-var hs-var">seqToSeqHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760821"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-66"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-67"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760825"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760824"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760823"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760822"><span class="hs-identifier hs-type">embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760821"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-68"></span><span>
</span><span id="line-69"></span><span class="hs-comment">-- | Sequence-to-sequence transformer model.</span><span>
</span><span id="line-70"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-71"></span><span>  </span><span id="SequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span></span><span>
</span><span id="line-72"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760430"><span class="annot"><a href="#local-6989586621679760430"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760429"><span class="annot"><a href="#local-6989586621679760429"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760428"><span class="annot"><a href="#local-6989586621679760428"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760427"><span class="annot"><a href="#local-6989586621679760427"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760426"><span class="annot"><a href="#local-6989586621679760426"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760425"><span class="annot"><a href="#local-6989586621679760425"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760424"><span class="annot"><a href="#local-6989586621679760424"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-79"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760423"><span class="annot"><a href="#local-6989586621679760423"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-80"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760422"><span class="annot"><a href="#local-6989586621679760422"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760421"><span class="annot"><a href="#local-6989586621679760421"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760420"><span class="annot"><a href="#local-6989586621679760420"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760419"><span class="annot"><a href="#local-6989586621679760419"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760418"><span class="annot"><a href="#local-6989586621679760418"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760417"><span class="annot"><a href="#local-6989586621679760417"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760416"><span class="annot"><a href="#local-6989586621679760416"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-88"></span><span>  </span><span id="SequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679760790"><span class="annot"><a href="#local-6989586621679760790"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679760774"><span class="annot"><a href="#local-6989586621679760774"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679760789"><span class="annot"><a href="#local-6989586621679760789"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679760778"><span class="annot"><a href="#local-6989586621679760778"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679760788"><span class="annot"><a href="#local-6989586621679760788"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679760787"><span class="annot"><a href="#local-6989586621679760787"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679760786"><span class="annot"><a href="#local-6989586621679760786"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679760785"><span class="annot"><a href="#local-6989586621679760785"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679760784"><span class="annot"><a href="#local-6989586621679760784"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760783"><span class="annot"><a href="#local-6989586621679760783"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679760791"><span class="annot"><a href="#local-6989586621679760791"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760782"><span class="annot"><a href="#local-6989586621679760782"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679760781"><span class="annot"><a href="#local-6989586621679760781"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679760776"><span class="annot"><a href="#local-6989586621679760776"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679760780"><span class="annot"><a href="#local-6989586621679760780"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-90"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-91"></span><span>      </span><span class="annot"><a href="#local-6989586621679760791"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-92"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-type">SequenceToSequenceEncoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760790"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760789"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760788"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760787"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760786"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760785"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760784"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760783"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760791"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760782"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760781"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760780"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-type">SequenceToSequenceDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760790"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760778"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760788"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760787"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760786"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760785"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760784"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760783"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760791"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760782"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760781"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760780"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760790"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760788"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760787"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760786"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760791"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760776"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-type">SequenceToSequenceHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760790"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760774"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760788"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760787"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760786"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760791"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760776"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-96"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760790"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760774"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760789"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760778"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760788"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760787"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760786"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760785"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760784"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760783"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760791"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760782"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760781"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760776"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760780"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-97"></span><span>
</span><span id="line-98"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-99"></span><span>  </span><span id="SequenceToSequenceEncoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-var">SequenceToSequenceEncoderF</span></a></span></span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760414"><span class="annot"><a href="#local-6989586621679760414"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760413"><span class="annot"><a href="#local-6989586621679760413"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760412"><span class="annot"><a href="#local-6989586621679760412"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760411"><span class="annot"><a href="#local-6989586621679760411"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760410"><span class="annot"><a href="#local-6989586621679760410"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760409"><span class="annot"><a href="#local-6989586621679760409"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760408"><span class="annot"><a href="#local-6989586621679760408"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760407"><span class="annot"><a href="#local-6989586621679760407"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760406"><span class="annot"><a href="#local-6989586621679760406"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760405"><span class="annot"><a href="#local-6989586621679760405"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760404"><span class="annot"><a href="#local-6989586621679760404"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760403"><span class="annot"><a href="#local-6989586621679760403"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-113"></span><span>  </span><span id="SequenceToSequenceEncoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-var">SequenceToSequenceEncoderF</span></a></span></span><span> </span><span id="local-6989586621679760402"><span class="annot"><a href="#local-6989586621679760402"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679760401"><span class="annot"><a href="#local-6989586621679760401"><span class="hs-identifier hs-type hs-type">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679760400"><span class="annot"><a href="#local-6989586621679760400"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679760399"><span class="annot"><a href="#local-6989586621679760399"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679760398"><span class="annot"><a href="#local-6989586621679760398"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679760397"><span class="annot"><a href="#local-6989586621679760397"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679760396"><span class="annot"><a href="#local-6989586621679760396"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760395"><span class="annot"><a href="#local-6989586621679760395"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679760394"><span class="annot"><a href="#local-6989586621679760394"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760393"><span class="annot"><a href="#local-6989586621679760393"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679760392"><span class="annot"><a href="#local-6989586621679760392"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679760391"><span class="annot"><a href="#local-6989586621679760391"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-114"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760402"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760401"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760400"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760399"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760398"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760397"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760396"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760395"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760394"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760393"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760392"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760391"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-115"></span><span>
</span><span id="line-116"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-117"></span><span>  </span><span id="SequenceToSequenceDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-var">SequenceToSequenceDecoderF</span></a></span></span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760390"><span class="annot"><a href="#local-6989586621679760390"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760389"><span class="annot"><a href="#local-6989586621679760389"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760388"><span class="annot"><a href="#local-6989586621679760388"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760387"><span class="annot"><a href="#local-6989586621679760387"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760386"><span class="annot"><a href="#local-6989586621679760386"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760385"><span class="annot"><a href="#local-6989586621679760385"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760384"><span class="annot"><a href="#local-6989586621679760384"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760383"><span class="annot"><a href="#local-6989586621679760383"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760382"><span class="annot"><a href="#local-6989586621679760382"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760381"><span class="annot"><a href="#local-6989586621679760381"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760380"><span class="annot"><a href="#local-6989586621679760380"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-129"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760379"><span class="annot"><a href="#local-6989586621679760379"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-131"></span><span>  </span><span id="SequenceToSequenceDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-var">SequenceToSequenceDecoderF</span></a></span></span><span> </span><span id="local-6989586621679760378"><span class="annot"><a href="#local-6989586621679760378"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679760377"><span class="annot"><a href="#local-6989586621679760377"><span class="hs-identifier hs-type hs-type">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679760376"><span class="annot"><a href="#local-6989586621679760376"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679760375"><span class="annot"><a href="#local-6989586621679760375"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679760374"><span class="annot"><a href="#local-6989586621679760374"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679760373"><span class="annot"><a href="#local-6989586621679760373"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679760372"><span class="annot"><a href="#local-6989586621679760372"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760371"><span class="annot"><a href="#local-6989586621679760371"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679760370"><span class="annot"><a href="#local-6989586621679760370"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760369"><span class="annot"><a href="#local-6989586621679760369"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679760368"><span class="annot"><a href="#local-6989586621679760368"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679760367"><span class="annot"><a href="#local-6989586621679760367"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760378"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760377"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760376"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760375"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760374"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760373"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760372"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760371"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760370"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760370"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760369"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760368"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760367"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-133"></span><span>
</span><span id="line-134"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-135"></span><span>  </span><span id="SequenceToSequenceEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-var">SequenceToSequenceEmbeddingF</span></a></span></span><span>
</span><span id="line-136"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760366"><span class="annot"><a href="#local-6989586621679760366"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-137"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760365"><span class="annot"><a href="#local-6989586621679760365"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-138"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760364"><span class="annot"><a href="#local-6989586621679760364"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-139"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760363"><span class="annot"><a href="#local-6989586621679760363"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-140"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760362"><span class="annot"><a href="#local-6989586621679760362"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760361"><span class="annot"><a href="#local-6989586621679760361"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-143"></span><span>  </span><span id="SequenceToSequenceEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-var">SequenceToSequenceEmbeddingF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679760360"><span class="annot"><a href="#local-6989586621679760360"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679760359"><span class="annot"><a href="#local-6989586621679760359"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679760358"><span class="annot"><a href="#local-6989586621679760358"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679760357"><span class="annot"><a href="#local-6989586621679760357"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760356"><span class="annot"><a href="#local-6989586621679760356"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-144"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760360"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679760359"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760358"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760356"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760357"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-145"></span><span>
</span><span id="line-146"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-147"></span><span>  </span><span id="SequenceToSequenceHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-var">SequenceToSequenceHeadF</span></a></span></span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760355"><span class="annot"><a href="#local-6989586621679760355"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760354"><span class="annot"><a href="#local-6989586621679760354"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760353"><span class="annot"><a href="#local-6989586621679760353"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760352"><span class="annot"><a href="#local-6989586621679760352"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760351"><span class="annot"><a href="#local-6989586621679760351"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-153"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760350"><span class="annot"><a href="#local-6989586621679760350"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-154"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760349"><span class="annot"><a href="#local-6989586621679760349"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-155"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-156"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-157"></span><span>  </span><span id="SequenceToSequenceHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-var">SequenceToSequenceHeadF</span></a></span></span><span> </span><span id="local-6989586621679760348"><span class="annot"><a href="#local-6989586621679760348"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-type">WithoutHead</span></a></span><span> </span><span id="local-6989586621679760347"><span class="annot"><a href="#local-6989586621679760347"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679760346"><span class="annot"><a href="#local-6989586621679760346"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679760345"><span class="annot"><a href="#local-6989586621679760345"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679760344"><span class="annot"><a href="#local-6989586621679760344"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760343"><span class="annot"><a href="#local-6989586621679760343"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-158"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-159"></span><span>  </span><span id="SequenceToSequenceHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-var">SequenceToSequenceHeadF</span></a></span></span><span> </span><span id="local-6989586621679760342"><span class="annot"><a href="#local-6989586621679760342"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-type">WithLMHead</span></a></span><span> </span><span id="local-6989586621679760341"><span class="annot"><a href="#local-6989586621679760341"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679760340"><span class="annot"><a href="#local-6989586621679760340"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679760339"><span class="annot"><a href="#local-6989586621679760339"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679760338"><span class="annot"><a href="#local-6989586621679760338"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760337"><span class="annot"><a href="#local-6989586621679760337"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-160"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760342"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760341"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760340"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760339"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760338"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760337"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-161"></span><span>
</span><span id="line-162"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-163"></span><span>  </span><span id="HasInitializeSequenceToSequenceHeadInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#HasInitializeSequenceToSequenceHeadInputF"><span class="hs-identifier hs-var">HasInitializeSequenceToSequenceHeadInputF</span></a></span></span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760336"><span class="annot"><a href="#local-6989586621679760336"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760335"><span class="annot"><a href="#local-6989586621679760335"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760334"><span class="annot"><a href="#local-6989586621679760334"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760333"><span class="annot"><a href="#local-6989586621679760333"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-168"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760332"><span class="annot"><a href="#local-6989586621679760332"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679760331"><span class="annot"><a href="#local-6989586621679760331"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-170"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-171"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-172"></span><span>  </span><span id="HasInitializeSequenceToSequenceHeadInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#HasInitializeSequenceToSequenceHeadInputF"><span class="hs-identifier hs-var">HasInitializeSequenceToSequenceHeadInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-type">WithoutHead</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-173"></span><span>  </span><span id="HasInitializeSequenceToSequenceHeadInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#HasInitializeSequenceToSequenceHeadInputF"><span class="hs-identifier hs-var">HasInitializeSequenceToSequenceHeadInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-type">WithLMHead</span></a></span><span> </span><span id="local-6989586621679760330"><span class="annot"><a href="#local-6989586621679760330"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679760329"><span class="annot"><a href="#local-6989586621679760329"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679760328"><span class="annot"><a href="#local-6989586621679760328"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679760327"><span class="annot"><a href="#local-6989586621679760327"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679760326"><span class="annot"><a href="#local-6989586621679760326"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-174"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760330"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760329"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760328"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760327"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760326"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-175"></span><span>
</span><span id="line-176"></span><span id="local-6989586621679760306"><span id="local-6989586621679760307"><span id="local-6989586621679760308"><span id="local-6989586621679760309"><span id="local-6989586621679760310"><span id="local-6989586621679760311"><span id="local-6989586621679760312"><span id="local-6989586621679760313"><span id="local-6989586621679760314"><span id="local-6989586621679760315"><span id="local-6989586621679760316"><span id="local-6989586621679760317"><span id="local-6989586621679760318"><span id="local-6989586621679760319"><span id="local-6989586621679760320"><span id="local-6989586621679760321"><span id="local-6989586621679760322"><span id="local-6989586621679760323"><span id="local-6989586621679760324"><span id="local-6989586621679760325"><span class="hs-keyword">instance</span><span>
</span><span id="line-177"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760325"><span class="hs-identifier hs-type">transformerHead</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-178"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-179"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760324"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760323"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760319"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760318"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760317"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760314"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760313"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760319"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760318"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760317"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760314"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679760313"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-181"></span><span>      </span><span class="annot"><a href="#local-6989586621679760312"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-182"></span><span>      </span><span class="annot"><a href="#local-6989586621679760311"><span class="hs-identifier hs-type">generator'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-183"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-184"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760324"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760310"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760319"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760318"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760317"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760314"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760313"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760319"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760318"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760317"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760314"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679760313"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>      </span><span class="annot"><a href="#local-6989586621679760311"><span class="hs-identifier hs-type">generator'</span></a></span><span>
</span><span id="line-187"></span><span>      </span><span class="annot"><a href="#local-6989586621679760309"><span class="hs-identifier hs-type">generator''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-188"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-189"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760308"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">)</span><span>
</span><span id="line-190"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760308"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-191"></span><span>      </span><span class="annot"><a href="#local-6989586621679760309"><span class="hs-identifier hs-type">generator''</span></a></span><span>
</span><span id="line-192"></span><span>      </span><span class="annot"><a href="#local-6989586621679760307"><span class="hs-identifier hs-type">generator'''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-194"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-type">SequenceToSequenceHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760324"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760325"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760308"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-195"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#HasInitializeSequenceToSequenceHeadInputF"><span class="hs-identifier hs-type">HasInitializeSequenceToSequenceHeadInputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760325"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760308"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-196"></span><span>      </span><span class="annot"><a href="#local-6989586621679760307"><span class="hs-identifier hs-type">generator'''</span></a></span><span>
</span><span id="line-197"></span><span>      </span><span class="annot"><a href="#local-6989586621679760306"><span class="hs-identifier hs-type">generator''''</span></a></span><span>
</span><span id="line-198"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-199"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-200"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760324"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760325"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760323"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760310"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760319"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760318"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760317"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760314"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760308"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760313"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-201"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760322"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760321"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760320"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760319"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760318"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760317"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760316"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760314"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760308"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679760313"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>    </span><span class="annot"><a href="#local-6989586621679760312"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-203"></span><span>    </span><span class="annot"><a href="#local-6989586621679760306"><span class="hs-identifier hs-type">generator''''</span></a></span><span>
</span><span id="line-204"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-205"></span><span>  </span><span id="local-6989586621679760303"><span class="annot"><span class="annottext">initialize :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, SDim vocabDim, dropoutP, Double)
-&gt; generator
-&gt; (SequenceToSequenceTransformer
      style
      transformerHead
      numEncoderLayers
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      vocabDim
      dropoutP,
    generator'''')
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679760301"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760301"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760300"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760300"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760299"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760299"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760298"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760298"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760297"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760297"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760296"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760296"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760295"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760295"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760294"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760294"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760293"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760293"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760292"><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760292"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760291"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760291"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760290"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760290"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-206"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679760289"><span class="annot"><span class="annottext">encoder :: IxState
  generator
  generator'
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
</span><a href="#local-6989586621679760289"><span class="hs-identifier hs-var hs-var">encoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; (TransformerEncoder
       style
       numEncoderLayers
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       inputEmbedDim
       ffnDim
       posEncDim
       dropoutP,
     generator'))
-&gt; IxState
     generator
     generator'
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP,
      generator'))
 -&gt; IxState
      generator
      generator'
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP))
-&gt; ((SGradient gradient, SDevice device, SDataType dataType,
     SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
     SDim ffnDim, SDim posEncDim, dropoutP, Double)
    -&gt; generator
    -&gt; (TransformerEncoder
          style
          numEncoderLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          inputEmbedDim
          ffnDim
          posEncDim
          dropoutP,
        generator'))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
    SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; IxState
     generator
     generator'
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; generator
-&gt; (TransformerEncoder
      style
      numEncoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">((SGradient gradient, SDevice device, SDataType dataType,
  SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
  SDim ffnDim, SDim posEncDim, dropoutP, Double)
 -&gt; IxState
      generator
      generator'
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
    SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; IxState
     generator
     generator'
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760301"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760300"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760299"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760298"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760297"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760296"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760295"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760294"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760293"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760291"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760290"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-207"></span><span>        </span><span id="local-6989586621679760286"><span class="annot"><span class="annottext">decoder :: IxState
  generator'
  generator''
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
</span><a href="#local-6989586621679760286"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator'
 -&gt; (TransformerDecoder
       style
       numDecoderLayers
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       inputEmbedDim
       inputEmbedDim
       ffnDim
       posEncDim
       dropoutP,
     generator''))
-&gt; IxState
     generator'
     generator''
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator'
  -&gt; (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP,
      generator''))
 -&gt; IxState
      generator'
      generator''
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP))
-&gt; ((SGradient gradient, SDevice device, SDataType dataType,
     SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
     SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
    -&gt; generator'
    -&gt; (TransformerDecoder
          style
          numDecoderLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          inputEmbedDim
          inputEmbedDim
          ffnDim
          posEncDim
          dropoutP,
        generator''))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
    SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; IxState
     generator'
     generator''
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; generator'
-&gt; (TransformerDecoder
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator'')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">((SGradient gradient, SDevice device, SDataType dataType,
  SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
  SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
 -&gt; IxState
      generator'
      generator''
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
    SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; IxState
     generator'
     generator''
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760301"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760300"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760299"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760298"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760297"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760296"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760295"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760295"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760294"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760293"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760291"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760290"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>        </span><span id="local-6989586621679760285"><span class="annot"><span class="annottext">embedding :: IxState
  generator''
  generator'''
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
</span><a href="#local-6989586621679760285"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator''
 -&gt; (Embedding
       gradient
       ('Layout 'Dense)
       device
       dataType
       vocabDim
       inputEmbedDim
       'Nothing,
     generator'''))
-&gt; IxState
     generator''
     generator'''
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator''
  -&gt; (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing,
      generator'''))
 -&gt; IxState
      generator''
      generator'''
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing))
-&gt; ((SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
     SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
    -&gt; generator''
    -&gt; (Embedding
          gradient
          ('Layout 'Dense)
          device
          dataType
          vocabDim
          inputEmbedDim
          'Nothing,
        generator'''))
-&gt; (SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
    SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; IxState
     generator''
     generator'''
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; generator''
-&gt; (Embedding
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing,
    generator''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">((SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
  SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
 -&gt; IxState
      generator''
      generator'''
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing))
-&gt; (SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
    SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; IxState
     generator''
     generator'''
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760301"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760300"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760299"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760292"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760295"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-209"></span><span>        </span><span id="local-6989586621679760282"><span class="annot"><span class="annottext">head :: IxState
  generator'''
  generator''''
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
</span><a href="#local-6989586621679760282"><span class="hs-identifier hs-var hs-var">head</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator'''
 -&gt; (SequenceToSequenceHeadF
       style
       transformerHead
       gradient
       device
       dataType
       inputEmbedDim
       vocabDim,
     generator''''))
-&gt; IxState
     generator'''
     generator''''
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator'''
  -&gt; (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim,
      generator''''))
 -&gt; IxState
      generator'''
      generator''''
      (SequenceToSequenceHeadF
         style
         transformerHead
         gradient
         device
         dataType
         inputEmbedDim
         vocabDim))
-&gt; (HasInitializeSequenceToSequenceHeadInputF
      transformerHead gradient device dataType inputEmbedDim vocabDim
    -&gt; generator'''
    -&gt; (SequenceToSequenceHeadF
          style
          transformerHead
          gradient
          device
          dataType
          inputEmbedDim
          vocabDim,
        generator''''))
-&gt; HasInitializeSequenceToSequenceHeadInputF
     transformerHead gradient device dataType inputEmbedDim vocabDim
-&gt; IxState
     generator'''
     generator''''
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">HasInitializeSequenceToSequenceHeadInputF
  transformerHead gradient device dataType inputEmbedDim vocabDim
-&gt; generator'''
-&gt; (SequenceToSequenceHeadF
      style
      transformerHead
      gradient
      device
      dataType
      inputEmbedDim
      vocabDim,
    generator'''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(HasInitializeSequenceToSequenceHeadInputF
   transformerHead gradient device dataType inputEmbedDim vocabDim
 -&gt; IxState
      generator'''
      generator''''
      (SequenceToSequenceHeadF
         style
         transformerHead
         gradient
         device
         dataType
         inputEmbedDim
         vocabDim))
-&gt; HasInitializeSequenceToSequenceHeadInputF
     transformerHead gradient device dataType inputEmbedDim vocabDim
-&gt; IxState
     generator'''
     generator''''
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI transformerHead =&gt; Sing transformerHead
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760325"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-210"></span><span>          </span><span class="annot"><span class="annottext">Sing transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-211"></span><span>          </span><span class="annot"><span class="annottext">Sing transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760301"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760300"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760299"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760295"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760292"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760290"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span>          </span><span class="annot"><span class="annottext">Sing transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier hs-var">SWithMLMHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeSequenceToSequenceHeadInputF
  transformerHead gradient device dataType inputEmbedDim vocabDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-213"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator''''
  (SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
     dropoutP)
-&gt; generator
-&gt; (SequenceToSequenceTransformer
      style
      transformerHead
      numEncoderLayers
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      vocabDim
      dropoutP,
    generator'''')
forall i j a. IxState i j a -&gt; i -&gt; (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxState</span></a></span><span> </span><span class="annot"><span class="annottext">(IxState
   generator
   generator''''
   (SequenceToSequenceTransformer
      style
      transformerHead
      numEncoderLayers
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      vocabDim
      dropoutP)
 -&gt; generator
 -&gt; (SequenceToSequenceTransformer
       style
       transformerHead
       numEncoderLayers
       numDecoderLayers
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       inputEmbedDim
       ffnDim
       posEncDim
       vocabDim
       dropoutP,
     generator''''))
-&gt; IxState
     generator
     generator''''
     (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim
        dropoutP)
-&gt; generator
-&gt; (SequenceToSequenceTransformer
      style
      transformerHead
      numEncoderLayers
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      vocabDim
      dropoutP,
    generator'''')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-214"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; decoder
-&gt; embedding
-&gt; head
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim encoder decoder embedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-215"></span><span>              </span><span class="annot"><span class="annottext">(SDim inputEmbedDim
 -&gt; TransformerEncoder
      style
      numEncoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP
 -&gt; TransformerDecoder
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP
 -&gt; Embedding
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing
 -&gt; SequenceToSequenceHeadF
      style
      transformerHead
      gradient
      device
      dataType
      inputEmbedDim
      vocabDim
 -&gt; GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      (SequenceToSequenceHeadF
         style
         transformerHead
         gradient
         device
         dataType
         inputEmbedDim
         vocabDim))
-&gt; IxState generator generator (SDim inputEmbedDim)
-&gt; IxState
     generator
     generator
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP
      -&gt; TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP
      -&gt; Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing
      -&gt; SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; IxState generator generator (SDim inputEmbedDim)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760295"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
   -&gt; TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP
   -&gt; Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
   -&gt; SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; IxState
     generator
     generator'
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
-&gt; IxState
     generator
     generator'
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP
      -&gt; Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing
      -&gt; SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
</span><a href="#local-6989586621679760289"><span class="hs-identifier hs-var">encoder</span></a></span><span>
</span><span id="line-216"></span><span>                </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
   -&gt; Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
   -&gt; SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; IxState
     generator'
     generator''
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
-&gt; IxState
     generator
     generator''
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
      -&gt; SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator'
  generator''
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
</span><a href="#local-6989586621679760286"><span class="hs-identifier hs-var">decoder</span></a></span><span>
</span><span id="line-217"></span><span>                </span><span class="annot"><span class="annottext">IxState
  generator
  generator''
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
   -&gt; SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; IxState
     generator''
     generator'''
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
-&gt; IxState
     generator
     generator'''
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator''
  generator'''
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
</span><a href="#local-6989586621679760285"><span class="hs-identifier hs-var">embedding</span></a></span><span>
</span><span id="line-218"></span><span>                </span><span class="annot"><span class="annottext">IxState
  generator
  generator'''
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; IxState
     generator'''
     generator''''
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
-&gt; IxState
     generator
     generator''''
     (GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator'''
  generator''''
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
</span><a href="#local-6989586621679760282"><span class="hs-identifier hs-var">head</span></a></span><span>
</span><span id="line-219"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-220"></span><span>            </span><span class="annot"><span class="annottext">IxState
  generator
  generator''''
  (GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim))
-&gt; (GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      (SequenceToSequenceHeadF
         style
         transformerHead
         gradient
         device
         dataType
         inputEmbedDim
         vocabDim)
    -&gt; IxState
         generator''''
         generator''''
         (SequenceToSequenceTransformer
            style
            transformerHead
            numEncoderLayers
            numDecoderLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            inputEmbedDim
            ffnDim
            posEncDim
            vocabDim
            dropoutP))
-&gt; IxState
     generator
     generator''''
     (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim
        dropoutP)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  style
  transformerHead
  numEncoderLayers
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  vocabDim
  dropoutP
-&gt; IxState
     generator''''
     generator''''
     (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim
        dropoutP)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(SequenceToSequenceTransformer
   style
   transformerHead
   numEncoderLayers
   numDecoderLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   posEncDim
   vocabDim
   dropoutP
 -&gt; IxState
      generator''''
      generator''''
      (SequenceToSequenceTransformer
         style
         transformerHead
         numEncoderLayers
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         vocabDim
         dropoutP))
-&gt; (GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      (SequenceToSequenceHeadF
         style
         transformerHead
         gradient
         device
         dataType
         inputEmbedDim
         vocabDim)
    -&gt; SequenceToSequenceTransformer
         style
         transformerHead
         numEncoderLayers
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         vocabDim
         dropoutP)
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
-&gt; IxState
     generator''''
     generator''''
     (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
     dropoutP
forall (style :: TransformerStyle)
       (transformerHead :: TransformerHead) (numEncoderLayers :: Nat)
       (numDecoderLayers :: Nat) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GSequenceToSequenceTransformer
  inputEmbedDim
  (SequenceToSequenceEncoderF
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (SequenceToSequenceDecoderF
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (SequenceToSequenceEmbeddingF
     style gradient device dataType inputEmbedDim vocabDim)
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-221"></span><span>
</span><span id="line-222"></span><span id="local-6989586621679760265"><span id="local-6989586621679760266"><span id="local-6989586621679760267"><span id="local-6989586621679760268"><span id="local-6989586621679760269"><span id="local-6989586621679760270"><span id="local-6989586621679760271"><span id="local-6989586621679760272"><span id="local-6989586621679760273"><span id="local-6989586621679760274"><span id="local-6989586621679760275"><span id="local-6989586621679760276"><span id="local-6989586621679760277"><span id="local-6989586621679760278"><span id="local-6989586621679760279"><span class="hs-keyword">instance</span><span>
</span><span id="line-223"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760278"><span class="hs-identifier hs-type">transformerHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679760277"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679760276"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-224"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-225"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760278"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760277"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760276"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760275"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760274"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760273"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760272"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760271"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760270"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760269"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760268"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760267"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760266"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760265"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760275"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760274"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760273"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760272"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760271"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760270"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760269"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760268"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760267"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760266"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679760265"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-228"></span><span>  </span><span id="local-6989586621679760261"><span class="annot"><span class="annottext">fromStateDict :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, SDim vocabDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim
        dropoutP)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679760259"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760258"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760257"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760256"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760255"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760254"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760253"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760252"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760251"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760250"><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760249"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760248"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679760247"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-229"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679760246"><span class="annot"><span class="annottext">encoder :: STransformerStyle style
-&gt; m (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
</span><a href="#local-6989586621679760246"><span class="hs-identifier hs-var hs-var">encoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'T5
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-230"></span><span>        </span><span class="annot"><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'ByT5
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>        </span><span class="annot"><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'BART
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-232"></span><span>        </span><span class="annot"><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'MBART
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-233"></span><span>        </span><span class="annot"><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'Pegasus
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-234"></span><span>        </span><span class="annot"><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-235"></span><span>        </span><span class="annot"><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-236"></span><span>        </span><span class="annot"><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-237"></span><span>        </span><span id="local-6989586621679760237"><span class="annot"><span class="annottext">decoder :: STransformerStyle style
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
</span><a href="#local-6989586621679760237"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'T5
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-238"></span><span>        </span><span class="annot"><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'ByT5
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-239"></span><span>        </span><span class="annot"><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'BART
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-240"></span><span>        </span><span class="annot"><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'MBART
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>        </span><span class="annot"><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim inputEmbedDim,
 SDim inputEmbedDim, SDim ffnDim, SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'Pegasus
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679760256"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679760255"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679760254"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679760252"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679760251"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679760249"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-242"></span><span>        </span><span class="annot"><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-243"></span><span>        </span><span class="annot"><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-244"></span><span>        </span><span class="annot"><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-245"></span><span>        </span><span id="local-6989586621679760236"><span class="annot"><span class="annottext">embedding :: STransformerStyle style
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679760236"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-246"></span><span>        </span><span class="annot"><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>        </span><span class="annot"><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-248"></span><span>        </span><span class="annot"><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-249"></span><span>        </span><span class="annot"><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim vocabDim, SDim inputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-250"></span><span>        </span><span class="annot"><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-251"></span><span>        </span><span class="annot"><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-252"></span><span>        </span><span class="annot"><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-253"></span><span>        </span><span id="local-6989586621679760235"><span class="annot"><span class="annottext">lmHead :: STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679760235"><span class="hs-identifier hs-var hs-var">lmHead</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-254"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim inputEmbedDim, SDim vocabDim, Double)
-&gt; StateDictKey
-&gt; m (LMHead 'T5 gradient device dataType inputEmbedDim vocabDim)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim inputEmbedDim, SDim vocabDim, Double)
-&gt; StateDictKey
-&gt; m (LMHead 'ByT5 gradient device dataType inputEmbedDim vocabDim)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim inputEmbedDim, SDim vocabDim, Double)
-&gt; StateDictKey
-&gt; m (LMHead 'BART gradient device dataType inputEmbedDim vocabDim)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-257"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim inputEmbedDim, SDim vocabDim, Double)
-&gt; StateDictKey
-&gt; m (LMHead
        'MBART gradient device dataType inputEmbedDim vocabDim)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-258"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim inputEmbedDim, SDim vocabDim, Double)
-&gt; StateDictKey
-&gt; m (LMHead
        'Pegasus gradient device dataType inputEmbedDim vocabDim)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679760259"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679760258"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679760257"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679760250"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760248"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760247"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-259"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-260"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-261"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-262"></span><span>        </span><span class="annot"><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier hs-var">SWithMLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-263"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
     dropoutP
forall (style :: TransformerStyle)
       (transformerHead :: TransformerHead) (numEncoderLayers :: Nat)
       (numDecoderLayers :: Nat) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GSequenceToSequenceTransformer
  inputEmbedDim
  (SequenceToSequenceEncoderF
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (SequenceToSequenceDecoderF
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
  (SequenceToSequenceEmbeddingF
     style gradient device dataType inputEmbedDim vocabDim)
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-264"></span><span>          </span><span class="annot"><span class="annottext">(GSequenceToSequenceTransformer
   inputEmbedDim
   (TransformerEncoder
      style
      numEncoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP)
   (TransformerDecoder
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP)
   (Embedding
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing)
   (SequenceToSequenceHeadF
      style
      transformerHead
      gradient
      device
      dataType
      inputEmbedDim
      vocabDim)
 -&gt; SequenceToSequenceTransformer
      style
      transformerHead
      numEncoderLayers
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      vocabDim
      dropoutP)
-&gt; m (GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim
        dropoutP)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; decoder
-&gt; embedding
-&gt; head
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim encoder decoder embedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-265"></span><span>                  </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760253"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-266"></span><span>                  </span><span class="annot"><span class="annottext">(TransformerEncoder
   style
   numEncoderLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   posEncDim
   dropoutP
 -&gt; TransformerDecoder
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim
      dropoutP
 -&gt; Embedding
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing
 -&gt; SequenceToSequenceHeadF
      style
      transformerHead
      gradient
      device
      dataType
      inputEmbedDim
      vocabDim
 -&gt; GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      (SequenceToSequenceHeadF
         style
         transformerHead
         gradient
         device
         dataType
         inputEmbedDim
         vocabDim))
-&gt; m (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP
      -&gt; Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing
      -&gt; SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
</span><a href="#local-6989586621679760246"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-267"></span><span>                  </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
   -&gt; Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
   -&gt; SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
      -&gt; SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
</span><a href="#local-6989586621679760237"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-268"></span><span>                  </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
   -&gt; SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim
              dropoutP)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679760236"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-269"></span><span>                  </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
-&gt; m (GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
           dropoutP)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679760235"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI transformerHead =&gt; Sing transformerHead
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760278"><span class="hs-identifier hs-type">transformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-270"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-271"></span><span>  </span><span id="local-6989586621679760233"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
     dropoutP
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679760231"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679760226"><span id="local-6989586621679760227"><span id="local-6989586621679760228"><span id="local-6989586621679760229"><span id="local-6989586621679760230"><span class="annot"><span class="annottext">SDim inputEmbedDim
SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqHead :: SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
seqToSeqEmbedding :: SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
seqToSeqDecoder :: SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqEncoder :: SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqInputEmbedDim :: SDim inputEmbedDim
seqToSeqHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
seqToSeqEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
seqToSeqDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
seqToSeqEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
seqToSeqInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679760226"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-272"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679760225"><span class="annot"><span class="annottext">encoder :: STransformerStyle style
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679760225"><span class="hs-identifier hs-var hs-var">encoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'T5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-273"></span><span>        </span><span class="annot"><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'ByT5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-274"></span><span>        </span><span class="annot"><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'BART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-275"></span><span>        </span><span class="annot"><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'MBART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-276"></span><span>        </span><span class="annot"><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'Pegasus
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-277"></span><span>        </span><span class="annot"><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-278"></span><span>        </span><span class="annot"><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-279"></span><span>        </span><span class="annot"><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-280"></span><span>        </span><span id="local-6989586621679760224"><span class="annot"><span class="annottext">decoder :: STransformerStyle style
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679760224"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'T5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span>        </span><span class="annot"><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'ByT5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>        </span><span class="annot"><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'BART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-283"></span><span>        </span><span class="annot"><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'MBART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-284"></span><span>        </span><span class="annot"><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'Pegasus
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>        </span><span class="annot"><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-286"></span><span>        </span><span class="annot"><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-287"></span><span>        </span><span class="annot"><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-288"></span><span>        </span><span id="local-6989586621679760223"><span class="annot"><span class="annottext">embedding :: STransformerStyle style
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
</span><a href="#local-6989586621679760223"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>        </span><span class="annot"><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>        </span><span class="annot"><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-291"></span><span>        </span><span class="annot"><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-293"></span><span>        </span><span class="annot"><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-294"></span><span>        </span><span class="annot"><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-295"></span><span>        </span><span class="annot"><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-296"></span><span>        </span><span id="local-6989586621679760222"><span class="annot"><span class="annottext">lmHead :: STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
-&gt; m ()
</span><a href="#local-6989586621679760222"><span class="hs-identifier hs-var hs-var">lmHead</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-297"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'T5 gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'ByT5 gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-299"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'BART gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'MBART gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'Pegasus gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679760231"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-302"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-303"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-304"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-305"></span><span>        </span><span class="annot"><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier hs-var">SWithMLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-306"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-307"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679760225"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
</span><a href="#local-6989586621679760229"><span class="hs-identifier hs-var">seqToSeqEncoder</span></a></span><span>
</span><span id="line-308"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679760224"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
</span><a href="#local-6989586621679760228"><span class="hs-identifier hs-var">seqToSeqDecoder</span></a></span><span>
</span><span id="line-309"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
</span><a href="#local-6989586621679760223"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679760227"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-310"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
-&gt; m ()
</span><a href="#local-6989586621679760222"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760279"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI transformerHead =&gt; Sing transformerHead
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760278"><span class="hs-identifier hs-type">transformerHead</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
</span><a href="#local-6989586621679760226"><span class="hs-identifier hs-var">seqToSeqHead</span></a></span><span>
</span><span id="line-311"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-312"></span><span>
</span><span id="line-313"></span><span class="hs-comment">-- | Input data type for use with a sequence-to-sequence transformer.</span><span>
</span><span id="line-314"></span><span class="hs-comment">-- Use this for training.</span><span>
</span><span id="line-315"></span><span class="hs-keyword">data</span><span> </span><span id="SequenceToSequenceTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679760221"><span class="annot"><a href="#local-6989586621679760221"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679760220"><span class="annot"><a href="#local-6989586621679760220"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679760219"><span class="annot"><a href="#local-6989586621679760219"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679760218"><span class="annot"><a href="#local-6989586621679760218"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679760217"><span class="annot"><a href="#local-6989586621679760217"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span> </span><span id="local-6989586621679760216"><span class="annot"><a href="#local-6989586621679760216"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679760215"><span class="annot"><a href="#local-6989586621679760215"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-316"></span><span>  </span><span id="SequenceToSequenceTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-317"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679760585"><span class="annot"><a href="#local-6989586621679760585"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679760584"><span class="annot"><a href="#local-6989586621679760584"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679760583"><span class="annot"><a href="#local-6989586621679760583"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679760582"><span class="annot"><a href="#local-6989586621679760582"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679760581"><span class="annot"><a href="#local-6989586621679760581"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span> </span><span id="local-6989586621679760580"><span class="annot"><a href="#local-6989586621679760580"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679760579"><span class="annot"><a href="#local-6989586621679760579"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-318"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="input"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; input
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#input"><span class="hs-identifier hs-var hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760585"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-319"></span><span>      </span><span id="decoderInput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderInput"><span class="hs-identifier hs-var hs-var">decoderInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760584"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-320"></span><span>      </span><span id="pos"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; pos
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#pos"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760583"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-321"></span><span>      </span><span id="decoderPos"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderPos"><span class="hs-identifier hs-var hs-var">decoderPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760582"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-322"></span><span>      </span><span id="attentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; attentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#attentionMask"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760581"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-323"></span><span>      </span><span id="decoderAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderAttentionMask"><span class="hs-identifier hs-var hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760580"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-324"></span><span>      </span><span id="crossAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#crossAttentionMask"><span class="hs-identifier hs-var hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760579"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-325"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-326"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760585"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760584"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760583"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760582"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760581"><span class="hs-identifier hs-type">attentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760580"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760579"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-327"></span><span>
</span><span id="line-328"></span><span id="local-6989586621679760194"><span id="local-6989586621679760196"><span id="local-6989586621679760198"><span id="local-6989586621679760200"><span id="local-6989586621679760201"><span id="local-6989586621679760202"><span id="local-6989586621679760203"><span id="local-6989586621679760204"><span id="local-6989586621679760205"><span id="local-6989586621679760206"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-329"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760206"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-330"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760205"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-331"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760204"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-332"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760203"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-333"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760202"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-334"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760201"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-335"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760200"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-336"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-337"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760206"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760205"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760204"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760203"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760202"><span class="hs-identifier hs-type">attentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760201"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760200"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-338"></span><span>
</span><span id="line-339"></span><span class="hs-comment">-- | Output data type for use with a sequence-to-sequence transformer.</span><span>
</span><span id="line-340"></span><span class="hs-keyword">data</span><span> </span><span id="SequenceToSequenceTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span></span><span> </span><span id="local-6989586621679760192"><span class="annot"><a href="#local-6989586621679760192"><span class="hs-identifier hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679760191"><span class="annot"><a href="#local-6989586621679760191"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-341"></span><span>  </span><span id="SequenceToSequenceTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-342"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679760546"><span class="annot"><a href="#local-6989586621679760546"><span class="hs-identifier hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679760545"><span class="annot"><a href="#local-6989586621679760545"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-343"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderOutput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput decoderOutput encoderOutput
-&gt; decoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderOutput"><span class="hs-identifier hs-var hs-var">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760546"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-344"></span><span>      </span><span id="encoderOutput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput decoderOutput encoderOutput
-&gt; encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#encoderOutput"><span class="hs-identifier hs-var hs-var">encoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760545"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-345"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-346"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760546"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760545"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-347"></span><span>
</span><span id="line-348"></span><span id="local-6989586621679760180"><span id="local-6989586621679760182"><span id="local-6989586621679760184"><span id="local-6989586621679760186"><span id="local-6989586621679760187"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-349"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760187"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-350"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760186"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-351"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-352"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760187"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760186"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-353"></span><span>
</span><span id="line-354"></span><span class="hs-comment">-- | Input data type for use with a sequence-to-sequence transformer.</span><span>
</span><span id="line-355"></span><span class="hs-comment">-- Use this for inference.</span><span>
</span><span id="line-356"></span><span class="hs-keyword">data</span><span> </span><span id="SequenceToSequenceTransformerGenerationInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerGenerationInput</span></a></span></span><span> </span><span id="local-6989586621679760179"><span class="annot"><a href="#local-6989586621679760179"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679760178"><span class="annot"><a href="#local-6989586621679760178"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span> </span><span id="local-6989586621679760177"><span class="annot"><a href="#local-6989586621679760177"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679760176"><span class="annot"><a href="#local-6989586621679760176"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679760175"><span class="annot"><a href="#local-6989586621679760175"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-357"></span><span>  </span><span id="SequenceToSequenceTransformerGenerationInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerGenerationInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-358"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679760512"><span class="annot"><a href="#local-6989586621679760512"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679760511"><span class="annot"><a href="#local-6989586621679760511"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span> </span><span id="local-6989586621679760510"><span class="annot"><a href="#local-6989586621679760510"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679760509"><span class="annot"><a href="#local-6989586621679760509"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679760508"><span class="annot"><a href="#local-6989586621679760508"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-359"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="generationDecoderInput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationDecoderInput"><span class="hs-identifier hs-var hs-var">generationDecoderInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760512"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-360"></span><span>      </span><span id="generationEncoderOutput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationEncoderOutput"><span class="hs-identifier hs-var hs-var">generationEncoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760511"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-361"></span><span>      </span><span id="generationDecoderPos"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationDecoderPos"><span class="hs-identifier hs-var hs-var">generationDecoderPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760510"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-362"></span><span>      </span><span id="generationDecoderAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationDecoderAttentionMask"><span class="hs-identifier hs-var hs-var">generationDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760509"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-363"></span><span>      </span><span id="generationCrossAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationCrossAttentionMask"><span class="hs-identifier hs-var hs-var">generationCrossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679760508"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-364"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-365"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760512"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760511"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760510"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760509"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760508"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-366"></span><span>
</span><span id="line-367"></span><span id="local-6989586621679760158"><span id="local-6989586621679760160"><span id="local-6989586621679760162"><span id="local-6989586621679760164"><span id="local-6989586621679760165"><span id="local-6989586621679760166"><span id="local-6989586621679760167"><span id="local-6989586621679760168"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-368"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760168"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-369"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760167"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-370"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760166"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-371"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760165"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-372"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679760164"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-373"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-374"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760168"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760167"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760166"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760165"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760164"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span><span>
</span><span id="line-375"></span><span>
</span><span id="line-376"></span><span class="hs-comment">-- | 'HasForward' instance for sequence-to-sequence transformers without additional head(s).</span><span>
</span><span id="line-377"></span><span class="hs-comment">--</span><span>
</span><span id="line-378"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-379"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-380"></span><span class="hs-comment">--     &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;  &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-381"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-382"></span><span class="hs-comment">--         &#9474;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-383"></span><span class="hs-comment">--         &#9660;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-384"></span><span class="hs-comment">-- seqToSeqEmbedding &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-385"></span><span class="hs-comment">--         &#9660;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-386"></span><span class="hs-comment">--   (embedScaling)  &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-387"></span><span class="hs-comment">--         &#9660;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--  seqToSeqEncoder&#9668;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--         &#9474;                                 seqToSeqEmbedding        &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--         &#9474;                                         &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--         &#9474;                                   (embedScaling)         &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-392"></span><span class="hs-comment">--         &#9474;                                         &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-393"></span><span class="hs-comment">--         &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;seqToSeqDecoder&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-394"></span><span class="hs-comment">--         &#9474;                                         &#9474;</span><span>
</span><span id="line-395"></span><span class="hs-comment">--         &#9474;                                  (seqToSeqLMHead)</span><span>
</span><span id="line-396"></span><span class="hs-comment">--         &#9474;                                         &#9474;</span><span>
</span><span id="line-397"></span><span class="hs-comment">--         &#9660;                                         &#9660;</span><span>
</span><span id="line-398"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;                         &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-399"></span><span class="hs-comment">-- &#9474; encoderOutput &#9474;                         &#9474; decoderOutput &#9474;</span><span>
</span><span id="line-400"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                         &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-401"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-402"></span><span id="local-6989586621679760117"><span id="local-6989586621679760118"><span id="local-6989586621679760119"><span id="local-6989586621679760120"><span id="local-6989586621679760121"><span id="local-6989586621679760122"><span id="local-6989586621679760123"><span id="local-6989586621679760124"><span id="local-6989586621679760125"><span id="local-6989586621679760126"><span id="local-6989586621679760127"><span id="local-6989586621679760128"><span id="local-6989586621679760129"><span id="local-6989586621679760130"><span id="local-6989586621679760131"><span id="local-6989586621679760132"><span id="local-6989586621679760133"><span id="local-6989586621679760134"><span id="local-6989586621679760135"><span id="local-6989586621679760136"><span id="local-6989586621679760137"><span id="local-6989586621679760138"><span id="local-6989586621679760139"><span id="local-6989586621679760140"><span id="local-6989586621679760141"><span id="local-6989586621679760142"><span id="local-6989586621679760143"><span id="local-6989586621679760144"><span id="local-6989586621679760145"><span id="local-6989586621679760146"><span id="local-6989586621679760147"><span id="local-6989586621679760148"><span id="local-6989586621679760149"><span id="local-6989586621679760150"><span id="local-6989586621679760151"><span id="local-6989586621679760152"><span id="local-6989586621679760153"><span id="local-6989586621679760154"><span id="local-6989586621679760155"><span id="local-6989586621679760156"><span id="local-6989586621679760157"><span class="hs-keyword">instance</span><span>
</span><span id="line-403"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-404"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-405"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760156"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760155"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760154"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760153"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760152"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-406"></span><span>      </span><span class="annot"><a href="#local-6989586621679760151"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-407"></span><span>      </span><span class="annot"><a href="#local-6989586621679760150"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-408"></span><span>      </span><span class="annot"><a href="#local-6989586621679760149"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span>
</span><span id="line-409"></span><span>      </span><span class="annot"><a href="#local-6989586621679760148"><span class="hs-identifier hs-type">embeddingGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-410"></span><span>    </span><span class="annot"><a href="#local-6989586621679760149"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760147"><span class="hs-identifier hs-type">requiresGradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760146"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760145"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760144"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760143"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-411"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-412"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-type">SequenceToSequenceEncoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760142"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760156"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760155"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760154"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760141"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760140"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760139"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760153"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760138"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760137"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760136"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-413"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679760149"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679760135"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679760134"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>      </span><span class="annot"><a href="#local-6989586621679760148"><span class="hs-identifier hs-type">embeddingGeneratorOutput</span></a></span><span>
</span><span id="line-415"></span><span>      </span><span class="annot"><a href="#local-6989586621679760133"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-416"></span><span>      </span><span class="annot"><a href="#local-6989586621679760132"><span class="hs-identifier hs-type">encoderGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-417"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-418"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760156"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760155"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760154"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760153"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760152"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-419"></span><span>      </span><span class="annot"><a href="#local-6989586621679760131"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-420"></span><span>      </span><span class="annot"><a href="#local-6989586621679760132"><span class="hs-identifier hs-type">encoderGeneratorOutput</span></a></span><span>
</span><span id="line-421"></span><span>      </span><span class="annot"><a href="#local-6989586621679760130"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span>
</span><span id="line-422"></span><span>      </span><span class="annot"><a href="#local-6989586621679760129"><span class="hs-identifier hs-type">embeddingGeneratorOutput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-423"></span><span>    </span><span class="annot"><a href="#local-6989586621679760130"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760128"><span class="hs-identifier hs-type">requiresGradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760127"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760126"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760125"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760124"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-424"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-425"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-type">SequenceToSequenceDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760123"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760156"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760155"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760154"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760141"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760140"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760139"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760153"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760138"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760137"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760136"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-426"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679760130"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-427"></span><span>        </span><span class="annot"><a href="#local-6989586621679760133"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-428"></span><span>        </span><span class="annot"><a href="#local-6989586621679760122"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-429"></span><span>        </span><span class="annot"><a href="#local-6989586621679760121"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-430"></span><span>        </span><span class="annot"><a href="#local-6989586621679760120"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-431"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-432"></span><span>      </span><span class="annot"><a href="#local-6989586621679760129"><span class="hs-identifier hs-type">embeddingGeneratorOutput'</span></a></span><span>
</span><span id="line-433"></span><span>      </span><span class="annot"><a href="#local-6989586621679760119"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-434"></span><span>      </span><span class="annot"><a href="#local-6989586621679760118"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-435"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-436"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-437"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760117"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760142"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760123"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760156"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760155"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760154"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760141"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760140"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760139"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760153"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760138"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760137"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760152"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760136"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-438"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760151"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760131"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760135"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760122"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760134"><span class="hs-identifier hs-type">attentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760121"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760120"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-439"></span><span>    </span><span class="annot"><a href="#local-6989586621679760150"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-440"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760119"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760133"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-441"></span><span>    </span><span class="annot"><a href="#local-6989586621679760118"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-442"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-443"></span><span>  </span><span id="local-6989586621679760114"><span class="annot"><span class="annottext">forward :: SequenceToSequenceTransformer
  style
  transformerHead
  numEncoderLayers
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  vocabDim
  dropoutP
-&gt; SequenceToSequenceTransformerInput
     input
     decoderInput
     pos
     decoderPos
     attentionMask
     decoderAttentionMask
     crossAttentionMask
-&gt; generator
-&gt; (SequenceToSequenceTransformerOutput
      decoderOutput encoderOutput,
    generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679760108"><span id="local-6989586621679760109"><span id="local-6989586621679760110"><span id="local-6989586621679760111"><span id="local-6989586621679760112"><span class="annot"><span class="annottext">SDim inputEmbedDim
SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqHead :: SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
seqToSeqEmbedding :: SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
seqToSeqDecoder :: SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqEncoder :: SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqInputEmbedDim :: SDim inputEmbedDim
seqToSeqHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
seqToSeqEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
seqToSeqDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
seqToSeqEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
seqToSeqInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679760108"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679760101"><span id="local-6989586621679760102"><span id="local-6989586621679760103"><span id="local-6989586621679760104"><span id="local-6989586621679760105"><span id="local-6989586621679760106"><span id="local-6989586621679760107"><span class="annot"><span class="annottext">input
pos
attentionMask
decoderInput
decoderPos
decoderAttentionMask
crossAttentionMask
crossAttentionMask :: crossAttentionMask
decoderAttentionMask :: decoderAttentionMask
attentionMask :: attentionMask
decoderPos :: decoderPos
pos :: pos
decoderInput :: decoderInput
input :: input
crossAttentionMask :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
decoderAttentionMask :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
attentionMask :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; attentionMask
decoderPos :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
pos :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; pos
decoderInput :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
input :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; input
</span><a href="#local-6989586621679760101"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-444"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679760100"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760100"><span class="hs-identifier hs-var">s</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked StateDictKey) (IsChecked Integer)
-&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked StateDictKey) (IsChecked Integer)
 -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked StateDictKey) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; Dim (IsChecked StateDictKey) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760112"><span class="hs-identifier hs-var">seqToSeqInputEmbedDim</span></a></span><span>
</span><span id="line-445"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-type">embedScaling</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-446"></span><span>          </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679760551"><span class="annot"><a href="#local-6989586621679760551"><span class="hs-identifier hs-type">requiresGradient</span></a></span></span><span> </span><span id="local-6989586621679760550"><span class="annot"><a href="#local-6989586621679760550"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679760549"><span class="annot"><a href="#local-6989586621679760549"><span class="hs-identifier hs-type">device'''</span></a></span></span><span> </span><span id="local-6989586621679760548"><span class="annot"><a href="#local-6989586621679760548"><span class="hs-identifier hs-type">dataType'''</span></a></span></span><span> </span><span id="local-6989586621679760547"><span class="annot"><a href="#local-6989586621679760547"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-447"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-448"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760551"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760550"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760549"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760548"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760547"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-449"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760551"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760550"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760549"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760548"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760547"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-450"></span><span>        </span><span id="local-6989586621679760097"><span class="annot"><span class="annottext">embedScaling :: STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679760097"><span class="hs-identifier hs-var hs-var">embedScaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-451"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-452"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-453"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-454"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device''' dataType''' shape
 -&gt; Double
 -&gt; Tensor requiresGradient layout device''' dataType''' shape)
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760100"><span class="hs-identifier hs-var">s</span></a></span><span>
</span><span id="line-455"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-456"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-457"></span><span>        </span><span class="annot"><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-458"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generatorOutput
  (SequenceToSequenceTransformerOutput decoderOutput encoderOutput)
-&gt; generator
-&gt; (SequenceToSequenceTransformerOutput
      decoderOutput encoderOutput,
    generatorOutput)
forall i j a. IxState i j a -&gt; i -&gt; (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxState</span></a></span><span> </span><span class="annot"><span class="annottext">(IxState
   generator
   generatorOutput
   (SequenceToSequenceTransformerOutput decoderOutput encoderOutput)
 -&gt; generator
 -&gt; (SequenceToSequenceTransformerOutput
       decoderOutput encoderOutput,
     generatorOutput))
-&gt; IxState
     generator
     generatorOutput
     (SequenceToSequenceTransformerOutput decoderOutput encoderOutput)
-&gt; generator
-&gt; (SequenceToSequenceTransformerOutput
      decoderOutput encoderOutput,
    generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-459"></span><span>          </span><span class="annot"><span class="annottext">input -&gt; IxState generator generator input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679760107"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-460"></span><span>            </span><span class="annot"><span class="annottext">IxState generator generator input
-&gt; (input
    -&gt; IxState
         generator
         embeddingGeneratorOutput
         (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; IxState
     generator
     embeddingGeneratorOutput
     (Tensor requiresGradient' layout' device' dataType' shape')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; (Tensor requiresGradient' layout' device' dataType' shape',
     embeddingGeneratorOutput))
-&gt; IxState
     generator
     embeddingGeneratorOutput
     (Tensor requiresGradient' layout' device' dataType' shape')
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; (Tensor requiresGradient' layout' device' dataType' shape',
      embeddingGeneratorOutput))
 -&gt; IxState
      generator
      embeddingGeneratorOutput
      (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; (input
    -&gt; generator
    -&gt; (Tensor requiresGradient' layout' device' dataType' shape',
        embeddingGeneratorOutput))
-&gt; input
-&gt; IxState
     generator
     embeddingGeneratorOutput
     (Tensor requiresGradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; input
-&gt; generator
-&gt; (Tensor requiresGradient' layout' device' dataType' shape',
    embeddingGeneratorOutput)
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679760109"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-461"></span><span>            </span><span class="annot"><span class="annottext">IxState
  generator
  embeddingGeneratorOutput
  (Tensor requiresGradient' layout' device' dataType' shape')
-&gt; (Tensor requiresGradient' layout' device' dataType' shape'
    -&gt; IxState
         embeddingGeneratorOutput
         embeddingGeneratorOutput
         (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; IxState
     generator
     embeddingGeneratorOutput
     (Tensor requiresGradient' layout' device' dataType' shape')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient' layout' device' dataType' shape'
-&gt; IxState
     embeddingGeneratorOutput
     embeddingGeneratorOutput
     (Tensor requiresGradient' layout' device' dataType' shape')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient' layout' device' dataType' shape'
 -&gt; IxState
      embeddingGeneratorOutput
      embeddingGeneratorOutput
      (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; (Tensor requiresGradient' layout' device' dataType' shape'
    -&gt; Tensor requiresGradient' layout' device' dataType' shape')
-&gt; Tensor requiresGradient' layout' device' dataType' shape'
-&gt; IxState
     embeddingGeneratorOutput
     embeddingGeneratorOutput
     (Tensor requiresGradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Tensor requiresGradient' layout' device' dataType' shape'
-&gt; Tensor requiresGradient' layout' device' dataType' shape'
forall (requiresGradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType)
       (device''' :: Device (DeviceType Nat))
       (dataType''' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-462"></span><span>            </span><span class="annot"><span class="annottext">IxState
  generator
  embeddingGeneratorOutput
  (Tensor requiresGradient' layout' device' dataType' shape')
-&gt; (Tensor requiresGradient' layout' device' dataType' shape'
    -&gt; IxState
         embeddingGeneratorOutput encoderGeneratorOutput encoderOutput)
-&gt; IxState generator encoderGeneratorOutput encoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679760094"><span class="annot"><span class="annottext">Tensor requiresGradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679760094"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(embeddingGeneratorOutput
 -&gt; (encoderOutput, encoderGeneratorOutput))
-&gt; IxState
     embeddingGeneratorOutput encoderGeneratorOutput encoderOutput
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((embeddingGeneratorOutput
  -&gt; (encoderOutput, encoderGeneratorOutput))
 -&gt; IxState
      embeddingGeneratorOutput encoderGeneratorOutput encoderOutput)
-&gt; (embeddingGeneratorOutput
    -&gt; (encoderOutput, encoderGeneratorOutput))
-&gt; IxState
     embeddingGeneratorOutput encoderGeneratorOutput encoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor requiresGradient' layout' device' dataType' shape', pos,
    attentionMask)
-&gt; embeddingGeneratorOutput
-&gt; (encoderOutput, encoderGeneratorOutput)
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
</span><a href="#local-6989586621679760111"><span class="hs-identifier hs-var">seqToSeqEncoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679760094"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679760105"><span class="hs-identifier hs-var">pos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionMask
</span><a href="#local-6989586621679760103"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-463"></span><span>            </span><span class="annot"><span class="annottext">IxState generator encoderGeneratorOutput encoderOutput
-&gt; (encoderOutput
    -&gt; IxState
         encoderGeneratorOutput
         generatorOutput
         (SequenceToSequenceTransformerOutput decoderOutput encoderOutput))
-&gt; IxState
     generator
     generatorOutput
     (SequenceToSequenceTransformerOutput decoderOutput encoderOutput)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679760093"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679760093"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-464"></span><span>                     </span><span class="annot"><span class="annottext">decoderInput
-&gt; IxState
     encoderGeneratorOutput encoderGeneratorOutput decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679760106"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-465"></span><span>                       </span><span class="annot"><span class="annottext">IxState encoderGeneratorOutput encoderGeneratorOutput decoderInput
-&gt; (decoderInput
    -&gt; IxState
         encoderGeneratorOutput
         embeddingGeneratorOutput'
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxState
     encoderGeneratorOutput
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(encoderGeneratorOutput
 -&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
     embeddingGeneratorOutput'))
-&gt; IxState
     encoderGeneratorOutput
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((encoderGeneratorOutput
  -&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
      embeddingGeneratorOutput'))
 -&gt; IxState
      encoderGeneratorOutput
      embeddingGeneratorOutput'
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (decoderInput
    -&gt; encoderGeneratorOutput
    -&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
        embeddingGeneratorOutput'))
-&gt; decoderInput
-&gt; IxState
     encoderGeneratorOutput
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; decoderInput
-&gt; encoderGeneratorOutput
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
    embeddingGeneratorOutput')
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679760109"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-466"></span><span>                       </span><span class="annot"><span class="annottext">IxState
  encoderGeneratorOutput
  embeddingGeneratorOutput'
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxState
         embeddingGeneratorOutput'
         embeddingGeneratorOutput'
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxState
     encoderGeneratorOutput
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxState
     embeddingGeneratorOutput'
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient'' layout'' device'' dataType'' shape''
 -&gt; IxState
      embeddingGeneratorOutput'
      embeddingGeneratorOutput'
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxState
     embeddingGeneratorOutput'
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
forall (requiresGradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType)
       (device''' :: Device (DeviceType Nat))
       (dataType''' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679760097"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760157"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>                       </span><span class="annot"><span class="annottext">IxState
  encoderGeneratorOutput
  embeddingGeneratorOutput'
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxState embeddingGeneratorOutput' generatorOutput decoderOutput)
-&gt; IxState encoderGeneratorOutput generatorOutput decoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679760092"><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679760092"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-468"></span><span>                                </span><span class="annot"><span class="annottext">(embeddingGeneratorOutput' -&gt; (decoderOutput, generatorOutput))
-&gt; IxState embeddingGeneratorOutput' generatorOutput decoderOutput
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((embeddingGeneratorOutput' -&gt; (decoderOutput, generatorOutput))
 -&gt; IxState embeddingGeneratorOutput' generatorOutput decoderOutput)
-&gt; (embeddingGeneratorOutput' -&gt; (decoderOutput, generatorOutput))
-&gt; IxState embeddingGeneratorOutput' generatorOutput decoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
    encoderOutput, decoderPos, decoderAttentionMask,
    crossAttentionMask)
-&gt; embeddingGeneratorOutput'
-&gt; (decoderOutput, generatorOutput)
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
</span><a href="#local-6989586621679760110"><span class="hs-identifier hs-var">seqToSeqDecoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679760092"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679760093"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderPos
</span><a href="#local-6989586621679760104"><span class="hs-identifier hs-var">decoderPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderAttentionMask
</span><a href="#local-6989586621679760102"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionMask
</span><a href="#local-6989586621679760101"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-469"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-470"></span><span>                       </span><span class="annot"><span class="annottext">IxState encoderGeneratorOutput generatorOutput decoderOutput
-&gt; (decoderOutput
    -&gt; IxState
         generatorOutput
         generatorOutput
         (SequenceToSequenceTransformerOutput decoderOutput encoderOutput))
-&gt; IxState
     encoderGeneratorOutput
     generatorOutput
     (SequenceToSequenceTransformerOutput decoderOutput encoderOutput)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679760091"><span class="annot"><span class="annottext">decoderOutput
</span><a href="#local-6989586621679760091"><span class="hs-identifier hs-var">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput decoderOutput encoderOutput
-&gt; IxState
     generatorOutput
     generatorOutput
     (SequenceToSequenceTransformerOutput decoderOutput encoderOutput)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">decoderOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput decoderOutput encoderOutput
forall decoderOutput encoderOutput.
decoderOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput decoderOutput encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><span class="annottext">decoderOutput
</span><a href="#local-6989586621679760091"><span class="hs-identifier hs-var">decoderOutput</span></a></span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679760093"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>                 </span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-472"></span><span>
</span><span id="line-473"></span><span class="hs-comment">-- | 'HasForward' instance for sequence-to-sequence transformers without language modelling head.</span><span>
</span><span id="line-474"></span><span class="hs-comment">-- Use this instance for sequence generation once the encoder's output is available.</span><span>
</span><span id="line-475"></span><span class="hs-comment">--</span><span>
</span><span id="line-476"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-477"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-478"></span><span class="hs-comment">-- &#9474; encoderOutput &#9474;  &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-479"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-480"></span><span class="hs-comment">--         &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-481"></span><span class="hs-comment">--         &#9474;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-482"></span><span class="hs-comment">--         &#9474;          seqToSeqEmbedding        &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-483"></span><span class="hs-comment">--         &#9474;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-484"></span><span class="hs-comment">--         &#9474;            (embedScaling)         &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-485"></span><span class="hs-comment">--         &#9474;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-486"></span><span class="hs-comment">--         &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;seqToSeqDecoder&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-487"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-488"></span><span class="hs-comment">--         &#9474;           (seqToSeqLMHead)</span><span>
</span><span id="line-489"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-490"></span><span class="hs-comment">--         &#9660;                  &#9660;</span><span>
</span><span id="line-491"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-492"></span><span class="hs-comment">-- &#9474; encoderOutput &#9474;  &#9474; decoderOutput &#9474;</span><span>
</span><span id="line-493"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-494"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-495"></span><span id="local-6989586621679760059"><span id="local-6989586621679760060"><span id="local-6989586621679760061"><span id="local-6989586621679760062"><span id="local-6989586621679760063"><span id="local-6989586621679760064"><span id="local-6989586621679760065"><span id="local-6989586621679760066"><span id="local-6989586621679760067"><span id="local-6989586621679760068"><span id="local-6989586621679760069"><span id="local-6989586621679760070"><span id="local-6989586621679760071"><span id="local-6989586621679760072"><span id="local-6989586621679760073"><span id="local-6989586621679760074"><span id="local-6989586621679760075"><span id="local-6989586621679760076"><span id="local-6989586621679760077"><span id="local-6989586621679760078"><span id="local-6989586621679760079"><span id="local-6989586621679760080"><span id="local-6989586621679760081"><span id="local-6989586621679760082"><span id="local-6989586621679760083"><span id="local-6989586621679760084"><span id="local-6989586621679760085"><span id="local-6989586621679760086"><span id="local-6989586621679760087"><span id="local-6989586621679760088"><span id="local-6989586621679760089"><span id="local-6989586621679760090"><span class="hs-keyword">instance</span><span>
</span><span id="line-496"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760090"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-497"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-498"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760090"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760089"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760088"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760087"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760086"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760085"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-499"></span><span>      </span><span class="annot"><a href="#local-6989586621679760084"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-500"></span><span>      </span><span class="annot"><a href="#local-6989586621679760083"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-501"></span><span>      </span><span class="annot"><a href="#local-6989586621679760082"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span>
</span><span id="line-502"></span><span>      </span><span class="annot"><a href="#local-6989586621679760081"><span class="hs-identifier hs-type">embeddingGeneratorOutput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-503"></span><span>    </span><span class="annot"><a href="#local-6989586621679760082"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760080"><span class="hs-identifier hs-type">requiresGradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760079"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760078"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760077"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760076"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-504"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-505"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-type">SequenceToSequenceDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760090"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760075"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760089"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760088"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760087"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760074"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760073"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760072"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760086"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760071"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760070"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760069"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-506"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679760082"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-507"></span><span>        </span><span class="annot"><a href="#local-6989586621679760068"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-508"></span><span>        </span><span class="annot"><a href="#local-6989586621679760067"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-509"></span><span>        </span><span class="annot"><a href="#local-6989586621679760066"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-510"></span><span>        </span><span class="annot"><a href="#local-6989586621679760065"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-511"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-512"></span><span>      </span><span class="annot"><a href="#local-6989586621679760081"><span class="hs-identifier hs-type">embeddingGeneratorOutput'</span></a></span><span>
</span><span id="line-513"></span><span>      </span><span class="annot"><a href="#local-6989586621679760064"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-514"></span><span>      </span><span class="annot"><a href="#local-6989586621679760063"><span class="hs-identifier hs-type">decoderGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-515"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-516"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-type">SequenceToSequenceHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760090"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760062"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760089"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760088"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760087"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760086"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760085"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-517"></span><span>      </span><span class="annot"><a href="#local-6989586621679760064"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-518"></span><span>      </span><span class="annot"><a href="#local-6989586621679760063"><span class="hs-identifier hs-type">decoderGeneratorOutput</span></a></span><span>
</span><span id="line-519"></span><span>      </span><span class="annot"><a href="#local-6989586621679760061"><span class="hs-identifier hs-type">headOutput</span></a></span><span>
</span><span id="line-520"></span><span>      </span><span class="annot"><a href="#local-6989586621679760060"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-521"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-522"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-523"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760090"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760062"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760059"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760075"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760089"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760088"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760087"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760074"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760073"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760072"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760086"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760071"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760070"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760085"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760069"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-524"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760084"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760068"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760067"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760066"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760065"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-525"></span><span>    </span><span class="annot"><a href="#local-6989586621679760083"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-526"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760061"><span class="hs-identifier hs-type">headOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760068"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-527"></span><span>    </span><span class="annot"><a href="#local-6989586621679760060"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-528"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-529"></span><span>  </span><span id="local-6989586621679760057"><span class="annot"><span class="annottext">forward :: SequenceToSequenceTransformer
  style
  transformerHead
  numEncoderLayers
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  vocabDim
  dropoutP
-&gt; SequenceToSequenceTransformerGenerationInput
     decoderInput
     encoderOutput
     decoderPos
     decoderAttentionMask
     crossAttentionMask
-&gt; generator
-&gt; (SequenceToSequenceTransformerOutput headOutput encoderOutput,
    generatorOutput)
</span><a href="#local-6989586621679760057"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679760052"><span id="local-6989586621679760053"><span id="local-6989586621679760054"><span id="local-6989586621679760055"><span id="local-6989586621679760056"><span class="annot"><span class="annottext">SDim inputEmbedDim
SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqHead :: SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
seqToSeqEmbedding :: SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
seqToSeqDecoder :: SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqEncoder :: SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
seqToSeqInputEmbedDim :: SDim inputEmbedDim
seqToSeqHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
seqToSeqEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
seqToSeqDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
seqToSeqEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
seqToSeqInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679760052"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679760047"><span id="local-6989586621679760048"><span id="local-6989586621679760049"><span id="local-6989586621679760050"><span id="local-6989586621679760051"><span class="annot"><span class="annottext">decoderInput
encoderOutput
decoderPos
decoderAttentionMask
crossAttentionMask
generationCrossAttentionMask :: crossAttentionMask
generationDecoderAttentionMask :: decoderAttentionMask
generationDecoderPos :: decoderPos
generationEncoderOutput :: encoderOutput
generationDecoderInput :: decoderInput
generationCrossAttentionMask :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
generationDecoderAttentionMask :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
generationDecoderPos :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
generationEncoderOutput :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; encoderOutput
generationDecoderInput :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
</span><a href="#local-6989586621679760047"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-530"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679760046"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760046"><span class="hs-identifier hs-var">s</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked StateDictKey) (IsChecked Integer)
-&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked StateDictKey) (IsChecked Integer)
 -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked StateDictKey) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; Dim (IsChecked StateDictKey) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679760056"><span class="hs-identifier hs-var">seqToSeqInputEmbedDim</span></a></span><span>
</span><span id="line-531"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-type">embedScaling</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-532"></span><span>          </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679760502"><span class="annot"><a href="#local-6989586621679760502"><span class="hs-identifier hs-type">requiresGradient</span></a></span></span><span> </span><span id="local-6989586621679760501"><span class="annot"><a href="#local-6989586621679760501"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679760500"><span class="annot"><a href="#local-6989586621679760500"><span class="hs-identifier hs-type">device'''</span></a></span></span><span> </span><span id="local-6989586621679760499"><span class="annot"><a href="#local-6989586621679760499"><span class="hs-identifier hs-type">dataType'''</span></a></span></span><span> </span><span id="local-6989586621679760498"><span class="annot"><a href="#local-6989586621679760498"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-533"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760090"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-534"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760502"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760501"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760500"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760499"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760498"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-535"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760502"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760501"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760500"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760499"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679760498"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-536"></span><span>        </span><span id="local-6989586621679760045"><span class="annot"><span class="annottext">embedScaling :: STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679760045"><span class="hs-identifier hs-var hs-var">embedScaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-537"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-538"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-539"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-540"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device''' dataType''' shape
 -&gt; Double
 -&gt; Tensor requiresGradient layout device''' dataType''' shape)
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760046"><span class="hs-identifier hs-var">s</span></a></span><span>
</span><span id="line-541"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-542"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-543"></span><span>        </span><span class="annot"><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-544"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generatorOutput
  (SequenceToSequenceTransformerOutput headOutput encoderOutput)
-&gt; generator
-&gt; (SequenceToSequenceTransformerOutput headOutput encoderOutput,
    generatorOutput)
forall i j a. IxState i j a -&gt; i -&gt; (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxState</span></a></span><span> </span><span class="annot"><span class="annottext">(IxState
   generator
   generatorOutput
   (SequenceToSequenceTransformerOutput headOutput encoderOutput)
 -&gt; generator
 -&gt; (SequenceToSequenceTransformerOutput headOutput encoderOutput,
     generatorOutput))
-&gt; IxState
     generator
     generatorOutput
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
-&gt; generator
-&gt; (SequenceToSequenceTransformerOutput headOutput encoderOutput,
    generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-545"></span><span>          </span><span class="annot"><span class="annottext">decoderInput -&gt; IxState generator generator decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679760051"><span class="hs-identifier hs-var">generationDecoderInput</span></a></span><span>
</span><span id="line-546"></span><span>            </span><span class="annot"><span class="annottext">IxState generator generator decoderInput
-&gt; (decoderInput
    -&gt; IxState
         generator
         embeddingGeneratorOutput'
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxState
     generator
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
     embeddingGeneratorOutput'))
-&gt; IxState
     generator
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
      embeddingGeneratorOutput'))
 -&gt; IxState
      generator
      embeddingGeneratorOutput'
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (decoderInput
    -&gt; generator
    -&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
        embeddingGeneratorOutput'))
-&gt; decoderInput
-&gt; IxState
     generator
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; decoderInput
-&gt; generator
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
    embeddingGeneratorOutput')
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679760053"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-547"></span><span>            </span><span class="annot"><span class="annottext">IxState
  generator
  embeddingGeneratorOutput'
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxState
         embeddingGeneratorOutput'
         embeddingGeneratorOutput'
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxState
     generator
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxState
     embeddingGeneratorOutput'
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient'' layout'' device'' dataType'' shape''
 -&gt; IxState
      embeddingGeneratorOutput'
      embeddingGeneratorOutput'
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxState
     embeddingGeneratorOutput'
     embeddingGeneratorOutput'
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
forall (requiresGradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType)
       (device''' :: Device (DeviceType Nat))
       (dataType''' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679760045"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679760090"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-548"></span><span>            </span><span class="annot"><span class="annottext">IxState
  generator
  embeddingGeneratorOutput'
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxState
         embeddingGeneratorOutput' decoderGeneratorOutput decoderOutput)
-&gt; IxState generator decoderGeneratorOutput decoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679760044"><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679760044"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-549"></span><span>                     </span><span class="annot"><span class="annottext">(embeddingGeneratorOutput'
 -&gt; (decoderOutput, decoderGeneratorOutput))
-&gt; IxState
     embeddingGeneratorOutput' decoderGeneratorOutput decoderOutput
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((embeddingGeneratorOutput'
  -&gt; (decoderOutput, decoderGeneratorOutput))
 -&gt; IxState
      embeddingGeneratorOutput' decoderGeneratorOutput decoderOutput)
-&gt; (embeddingGeneratorOutput'
    -&gt; (decoderOutput, decoderGeneratorOutput))
-&gt; IxState
     embeddingGeneratorOutput' decoderGeneratorOutput decoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
    encoderOutput, decoderPos, decoderAttentionMask,
    crossAttentionMask)
-&gt; embeddingGeneratorOutput'
-&gt; (decoderOutput, decoderGeneratorOutput)
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  dropoutP
</span><a href="#local-6989586621679760054"><span class="hs-identifier hs-var">seqToSeqDecoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679760044"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679760050"><span class="hs-identifier hs-var">generationEncoderOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderPos
</span><a href="#local-6989586621679760049"><span class="hs-identifier hs-var">generationDecoderPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderAttentionMask
</span><a href="#local-6989586621679760048"><span class="hs-identifier hs-var">generationDecoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionMask
</span><a href="#local-6989586621679760047"><span class="hs-identifier hs-var">generationCrossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-550"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-551"></span><span>            </span><span class="annot"><span class="annottext">IxState generator decoderGeneratorOutput decoderOutput
-&gt; (decoderOutput
    -&gt; IxState decoderGeneratorOutput generatorOutput headOutput)
-&gt; IxState generator generatorOutput headOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(decoderGeneratorOutput -&gt; (headOutput, generatorOutput))
-&gt; IxState decoderGeneratorOutput generatorOutput headOutput
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((decoderGeneratorOutput -&gt; (headOutput, generatorOutput))
 -&gt; IxState decoderGeneratorOutput generatorOutput headOutput)
-&gt; (decoderOutput
    -&gt; decoderGeneratorOutput -&gt; (headOutput, generatorOutput))
-&gt; decoderOutput
-&gt; IxState decoderGeneratorOutput generatorOutput headOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; decoderOutput
-&gt; decoderGeneratorOutput
-&gt; (headOutput, generatorOutput)
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
</span><a href="#local-6989586621679760052"><span class="hs-identifier hs-var">seqToSeqHead</span></a></span><span>
</span><span id="line-552"></span><span>            </span><span class="annot"><span class="annottext">IxState generator generatorOutput headOutput
-&gt; (headOutput
    -&gt; IxState
         generatorOutput
         generatorOutput
         (SequenceToSequenceTransformerOutput headOutput encoderOutput))
-&gt; IxState
     generator
     generatorOutput
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679760043"><span class="annot"><span class="annottext">headOutput
</span><a href="#local-6989586621679760043"><span class="hs-identifier hs-var">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput headOutput encoderOutput
-&gt; IxState
     generatorOutput
     generatorOutput
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">headOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput headOutput encoderOutput
forall decoderOutput encoderOutput.
decoderOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput decoderOutput encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><span class="annottext">headOutput
</span><a href="#local-6989586621679760043"><span class="hs-identifier hs-var">decoderOutput</span></a></span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679760050"><span class="hs-identifier hs-var">generationEncoderOutput</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-553"></span><span>
</span><span id="line-554"></span><span id="testSeqToSeq"><span class="annot"><span class="annottext">testSeqToSeq :: IO
  ((SequenceToSequenceTransformerOutput
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
               'Dim ('Name &quot;*&quot;) ('Size 512)]))
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
               'Dim ('Name &quot;*&quot;) ('Size 512)])),
    SequenceToSequenceTransformerOutput
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
               'Dim ('Name &quot;*&quot;) ('Size 512)]))
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
               'Dim ('Name &quot;*&quot;) ('Size 512)]))),
   Generator ('Device 'CPU))
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#testSeqToSeq"><span class="hs-identifier hs-var hs-var">testSeqToSeq</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-555"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679760041"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679760041"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-556"></span><span>      </span><span id="local-6989586621679760038"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679760038"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-557"></span><span>      </span><span id="local-6989586621679760035"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679760035"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-558"></span><span>      </span><span id="local-6989586621679760032"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679760032"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-559"></span><span>      </span><span id="local-6989586621679760029"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679760029"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-560"></span><span>      </span><span id="local-6989586621679760028"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679760028"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-561"></span><span>      </span><span id="local-6989586621679760027"><span class="annot"><span class="annottext">inputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679760027"><span class="hs-identifier hs-var hs-var">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-562"></span><span>      </span><span id="local-6989586621679760026"><span class="annot"><span class="annottext">ffnDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679760026"><span class="hs-identifier hs-var hs-var">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 2048) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 2048 =&gt; SSize ('Size 2048)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2048</span></span><span>
</span><span id="line-563"></span><span>      </span><span id="local-6989586621679760025"><span class="annot"><span class="annottext">posEncDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679760025"><span class="hs-identifier hs-var hs-var">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SSize ('Size 32)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span>
</span><span id="line-564"></span><span>      </span><span id="local-6989586621679760024"><span class="annot"><span class="annottext">vocabDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679760024"><span class="hs-identifier hs-var hs-var">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32128) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32128 =&gt; SSize ('Size 32128)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32128</span></span><span>
</span><span id="line-565"></span><span>      </span><span id="local-6989586621679760023"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679760023"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-566"></span><span>      </span><span id="local-6989586621679760022"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679760022"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-567"></span><span>  </span><span id="local-6989586621679760021"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760021"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; IO (Generator ('Device 'CPU))
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; IO (Generator device)
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679760038"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-568"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679760020"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679760020"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 3) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SSize ('Size 3)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-569"></span><span>      </span><span id="local-6989586621679760019"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 13) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 13 =&gt; SSize ('Size 13)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">13</span></span><span>
</span><span id="line-570"></span><span>      </span><span id="local-6989586621679760018"><span class="annot"><span class="annottext">decoderSeqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var hs-var">decoderSeqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 7) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 7 =&gt; SSize ('Size 7)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">7</span></span><span>
</span><span id="line-571"></span><span>      </span><span id="local-6989586621679760017"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679760038"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-572"></span><span>      </span><span id="local-6989586621679760015"><span class="annot"><span class="annottext">input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679760015"><span class="hs-identifier hs-var hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679760020"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-573"></span><span>      </span><span id="local-6989586621679760011"><span class="annot"><span class="annottext">attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679760011"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679760035"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-574"></span><span>      </span><span id="local-6989586621679760010"><span class="annot"><span class="annottext">decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679760010"><span class="hs-identifier hs-var hs-var">decoderInput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679760020"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-575"></span><span>      </span><span id="local-6989586621679760009"><span class="annot"><span class="annottext">decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679760009"><span class="hs-identifier hs-var hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679760035"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-576"></span><span>      </span><span id="local-6989586621679760008"><span class="annot"><span class="annottext">crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679760008"><span class="hs-identifier hs-var hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679760035"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-577"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679760007"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679760007"><span class="hs-identifier hs-var">t5Output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760006"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760006"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-578"></span><span>        </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679760005"><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'T5
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
  Float
</span><a href="#local-6989586621679760005"><span class="hs-identifier hs-var">t5</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760004"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760004"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient ('Gradient 'WithGradient), SDevice ('Device 'CPU),
 SDataType ('DataType 'Float), SDim ('Dim ('Name &quot;*&quot;) ('Size 8)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 64)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 2048)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 32)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 32128)), Float, Double)
-&gt; Generator ('Device 'CPU)
-&gt; (SequenceToSequenceTransformer
      'T5
      'WithLMHead
      32
      32
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 2048))
      ('Dim ('Name &quot;*&quot;) ('Size 32))
      ('Dim ('Name &quot;*&quot;) ('Size 32128))
      Float,
    Generator ('Device 'CPU))
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-type">WithLMHead</span></a></span><span> </span><span class="annot"><span class="hs-number">32</span></span><span> </span><span class="annot"><span class="hs-number">32</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679760041"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679760038"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679760035"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679760032"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679760029"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679760028"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679760027"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679760026"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679760025"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679760024"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679760023"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760022"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760021"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-579"></span><span>            </span><span id="local-6989586621679760003"><span class="annot"><span class="annottext">pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679760003"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-580"></span><span>            </span><span id="local-6989586621679760002"><span class="annot"><span class="annottext">decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679760002"><span class="hs-identifier hs-var hs-var">decoderPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-581"></span><span>        </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'T5
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
  Float
-&gt; SequenceToSequenceTransformerInput
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; (SequenceToSequenceTransformerOutput
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
               'Dim ('Name &quot;*&quot;) ('Size 512)]))
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
               'Dim ('Name &quot;*&quot;) ('Size 512)])),
    Generator ('Device 'CPU))
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'T5
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
  Float
</span><a href="#local-6989586621679760005"><span class="hs-identifier hs-var">t5</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
input
-&gt; decoderInput
-&gt; pos
-&gt; decoderPos
-&gt; attentionMask
-&gt; decoderAttentionMask
-&gt; crossAttentionMask
-&gt; SequenceToSequenceTransformerInput
     input
     decoderInput
     pos
     decoderPos
     attentionMask
     decoderAttentionMask
     crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679760002"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span><span class="hs-special">}</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760004"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-582"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679760001"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679760001"><span class="hs-identifier hs-var">bartOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679760000"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760000"><span class="hs-identifier hs-var">g''''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-583"></span><span>        </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679759999"><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'BART
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
  Float
</span><a href="#local-6989586621679759999"><span class="hs-identifier hs-var">bart</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679759998"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679759998"><span class="hs-identifier hs-var">g'''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient ('Gradient 'WithGradient), SDevice ('Device 'CPU),
 SDataType ('DataType 'Float), SDim ('Dim ('Name &quot;*&quot;) ('Size 8)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 64)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 2048)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 32)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 32128)), Float, Double)
-&gt; Generator ('Device 'CPU)
-&gt; (SequenceToSequenceTransformer
      'BART
      'WithLMHead
      32
      32
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 2048))
      ('Dim ('Name &quot;*&quot;) ('Size 32))
      ('Dim ('Name &quot;*&quot;) ('Size 32128))
      Float,
    Generator ('Device 'CPU))
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-type">WithLMHead</span></a></span><span> </span><span class="annot"><span class="hs-number">32</span></span><span> </span><span class="annot"><span class="hs-number">32</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679760041"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679760038"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679760035"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679760032"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679760029"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679760028"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679760027"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679760026"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679760025"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679760024"><span class="hs-identifier hs-var">vocabDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679760023"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679760022"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760006"><span class="hs-identifier hs-var">g''</span></a></span><span>
</span><span id="line-584"></span><span>            </span><span id="local-6989586621679759997"><span class="annot"><span class="annottext">pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679759997"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679760019"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>            </span><span id="local-6989586621679759996"><span class="annot"><span class="annottext">decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679759996"><span class="hs-identifier hs-var hs-var">decoderPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679760017"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679760018"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-586"></span><span>        </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'BART
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
  Float
-&gt; SequenceToSequenceTransformerInput
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; (SequenceToSequenceTransformerOutput
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
               'Dim ('Name &quot;*&quot;) ('Size 512)]))
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
               'Dim ('Name &quot;*&quot;) ('Size 512)])),
    Generator ('Device 'CPU))
forall model input generator output generatorOutput.
HasForward model input generator output generatorOutput =&gt;
model -&gt; input -&gt; generator -&gt; (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'BART
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
  Float
</span><a href="#local-6989586621679759999"><span class="hs-identifier hs-var">bart</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
input
-&gt; decoderInput
-&gt; pos
-&gt; decoderPos
-&gt; attentionMask
-&gt; decoderAttentionMask
-&gt; crossAttentionMask
-&gt; SequenceToSequenceTransformerInput
     input
     decoderInput
     pos
     decoderPos
     attentionMask
     decoderAttentionMask
     crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679759996"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span><span class="hs-special">}</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679759998"><span class="hs-identifier hs-var">g'''</span></a></span><span>
</span><span id="line-587"></span><span>  </span><span class="annot"><span class="annottext">((SequenceToSequenceTransformerOutput
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
             'Dim ('Name &quot;*&quot;) ('Size 512)]))
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
             'Dim ('Name &quot;*&quot;) ('Size 512)])),
  SequenceToSequenceTransformerOutput
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
             'Dim ('Name &quot;*&quot;) ('Size 512)]))
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
             'Dim ('Name &quot;*&quot;) ('Size 512)]))),
 Generator ('Device 'CPU))
-&gt; IO
     ((SequenceToSequenceTransformerOutput
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
                  'Dim ('Name &quot;*&quot;) ('Size 512)]))
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
                  'Dim ('Name &quot;*&quot;) ('Size 512)])),
       SequenceToSequenceTransformerOutput
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
                  'Dim ('Name &quot;*&quot;) ('Size 512)]))
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
                  'Dim ('Name &quot;*&quot;) ('Size 512)]))),
      Generator ('Device 'CPU))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679760007"><span class="hs-identifier hs-var">t5Output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679760001"><span class="hs-identifier hs-var">bartOutput</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679760000"><span class="hs-identifier hs-var">g''''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-588"></span></pre></body></html>