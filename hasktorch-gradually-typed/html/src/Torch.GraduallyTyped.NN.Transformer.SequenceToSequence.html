<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE StandaloneDeriving #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.SequenceToSequence</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-20"></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNothing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNat</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier">EmbeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Decoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier">TransformerDecoder</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier">TransformerDecoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier">TransformerEncoder</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier">TransformerEncoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.LMHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier">LMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier">LMHeadSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerHead"><span class="hs-identifier">STransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier">SWithLMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier">SWithMLMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier">SWithoutHead</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier">TransformerHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier">WithLMHead</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier">WithoutHead</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier">sGeneratorToDevice</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Debug.Trace</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">traceShowId</span></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span>
</span><span id="line-48"></span><span class="hs-keyword">data</span><span>
</span><span id="line-49"></span><span>  </span><span id="GSequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span></span><span>
</span><span id="line-50"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812357"><span class="annot"><a href="#local-6989586621679812357"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812356"><span class="annot"><a href="#local-6989586621679812356"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812355"><span class="annot"><a href="#local-6989586621679812355"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812354"><span class="annot"><a href="#local-6989586621679812354"><span class="hs-identifier hs-type">embedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812353"><span class="annot"><a href="#local-6989586621679812353"><span class="hs-identifier hs-type">head</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-56"></span><span>  </span><span id="GSequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-57"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812770"><span class="annot"><a href="#local-6989586621679812770"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812769"><span class="annot"><a href="#local-6989586621679812769"><span class="hs-identifier hs-type">encoder</span></a></span></span><span> </span><span id="local-6989586621679812768"><span class="annot"><a href="#local-6989586621679812768"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span id="local-6989586621679812767"><span class="annot"><a href="#local-6989586621679812767"><span class="hs-identifier hs-type">embedding</span></a></span></span><span> </span><span id="local-6989586621679812766"><span class="annot"><a href="#local-6989586621679812766"><span class="hs-identifier hs-type">head</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-58"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | input embedding dim for scaling</span><span>
</span><span id="line-59"></span><span>      </span><span id="seqToSeqInputEmbedDim"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqInputEmbedDim"><span class="hs-identifier hs-var hs-var">seqToSeqInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812770"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-60"></span><span>      </span><span class="hs-comment">-- | encoder</span><span>
</span><span id="line-61"></span><span>      </span><span id="seqToSeqEncoder"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqEncoder"><span class="hs-identifier hs-var hs-var">seqToSeqEncoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812769"><span class="hs-identifier hs-type">encoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-62"></span><span>      </span><span class="hs-comment">-- | decoder</span><span>
</span><span id="line-63"></span><span>      </span><span id="seqToSeqDecoder"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqDecoder"><span class="hs-identifier hs-var hs-var">seqToSeqDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812768"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-64"></span><span>      </span><span class="hs-comment">-- | shared embedding</span><span>
</span><span id="line-65"></span><span>      </span><span id="seqToSeqEmbedding"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqEmbedding"><span class="hs-identifier hs-var hs-var">seqToSeqEmbedding</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812767"><span class="hs-identifier hs-type">embedding</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-66"></span><span>      </span><span class="hs-comment">-- | transformer head</span><span>
</span><span id="line-67"></span><span>      </span><span id="seqToSeqHead"><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#seqToSeqHead"><span class="hs-identifier hs-var hs-var">seqToSeqHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812766"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-68"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-69"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812770"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812769"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812768"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812767"><span class="hs-identifier hs-type">embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812766"><span class="hs-identifier hs-type">head</span></a></span><span>
</span><span id="line-70"></span><span>
</span><span id="line-71"></span><span class="hs-comment">-- | Sequence-to-sequence transformer model.</span><span>
</span><span id="line-72"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-73"></span><span>  </span><span id="SequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span></span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812346"><span class="annot"><a href="#local-6989586621679812346"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812345"><span class="annot"><a href="#local-6989586621679812345"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812344"><span class="annot"><a href="#local-6989586621679812344"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812343"><span class="annot"><a href="#local-6989586621679812343"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812342"><span class="annot"><a href="#local-6989586621679812342"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-79"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812341"><span class="annot"><a href="#local-6989586621679812341"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-80"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812340"><span class="annot"><a href="#local-6989586621679812340"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812339"><span class="annot"><a href="#local-6989586621679812339"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812338"><span class="annot"><a href="#local-6989586621679812338"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812337"><span class="annot"><a href="#local-6989586621679812337"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812336"><span class="annot"><a href="#local-6989586621679812336"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812335"><span class="annot"><a href="#local-6989586621679812335"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812334"><span class="annot"><a href="#local-6989586621679812334"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812333"><span class="annot"><a href="#local-6989586621679812333"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-89"></span><span>  </span><span id="SequenceToSequenceTransformer"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812731"><span class="annot"><a href="#local-6989586621679812731"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679812716"><span class="annot"><a href="#local-6989586621679812716"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679812730"><span class="annot"><a href="#local-6989586621679812730"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812720"><span class="annot"><a href="#local-6989586621679812720"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812729"><span class="annot"><a href="#local-6989586621679812729"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812728"><span class="annot"><a href="#local-6989586621679812728"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812727"><span class="annot"><a href="#local-6989586621679812727"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812726"><span class="annot"><a href="#local-6989586621679812726"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679812725"><span class="annot"><a href="#local-6989586621679812725"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812724"><span class="annot"><a href="#local-6989586621679812724"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679812732"><span class="annot"><a href="#local-6989586621679812732"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812723"><span class="annot"><a href="#local-6989586621679812723"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679812722"><span class="annot"><a href="#local-6989586621679812722"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679812718"><span class="annot"><a href="#local-6989586621679812718"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-91"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-92"></span><span>      </span><span class="annot"><a href="#local-6989586621679812732"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-93"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-type">SequenceToSequenceEncoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812731"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812730"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812729"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812728"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812727"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812726"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812725"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812724"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812732"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812723"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812722"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-type">SequenceToSequenceDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812731"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812720"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812729"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812728"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812727"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812726"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812725"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812724"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812732"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812723"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812722"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812731"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812729"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812728"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812727"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812732"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812718"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-type">SequenceToSequenceHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812731"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812716"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812729"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812728"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812727"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812732"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812718"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-97"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812731"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812716"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812730"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812720"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812729"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812728"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812727"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812726"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812725"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812724"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812732"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812723"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812722"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812718"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-98"></span><span>
</span><span id="line-99"></span><span class="hs-keyword">data</span><span>
</span><span id="line-100"></span><span>  </span><span id="SequenceToSequenceTransformerSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-var">SequenceToSequenceTransformerSpec</span></a></span></span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812331"><span class="annot"><a href="#local-6989586621679812331"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812330"><span class="annot"><a href="#local-6989586621679812330"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812329"><span class="annot"><a href="#local-6989586621679812329"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812328"><span class="annot"><a href="#local-6989586621679812328"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812327"><span class="annot"><a href="#local-6989586621679812327"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812326"><span class="annot"><a href="#local-6989586621679812326"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812325"><span class="annot"><a href="#local-6989586621679812325"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812324"><span class="annot"><a href="#local-6989586621679812324"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812323"><span class="annot"><a href="#local-6989586621679812323"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812322"><span class="annot"><a href="#local-6989586621679812322"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812321"><span class="annot"><a href="#local-6989586621679812321"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812320"><span class="annot"><a href="#local-6989586621679812320"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812319"><span class="annot"><a href="#local-6989586621679812319"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812318"><span class="annot"><a href="#local-6989586621679812318"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-116"></span><span>  </span><span id="SequenceToSequenceTransformerSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-var">SequenceToSequenceTransformerSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812392"><span class="annot"><a href="#local-6989586621679812392"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679812391"><span class="annot"><a href="#local-6989586621679812391"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679812390"><span class="annot"><a href="#local-6989586621679812390"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812389"><span class="annot"><a href="#local-6989586621679812389"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812388"><span class="annot"><a href="#local-6989586621679812388"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812387"><span class="annot"><a href="#local-6989586621679812387"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812386"><span class="annot"><a href="#local-6989586621679812386"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812385"><span class="annot"><a href="#local-6989586621679812385"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679812384"><span class="annot"><a href="#local-6989586621679812384"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812383"><span class="annot"><a href="#local-6989586621679812383"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679812382"><span class="annot"><a href="#local-6989586621679812382"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812381"><span class="annot"><a href="#local-6989586621679812381"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679812380"><span class="annot"><a href="#local-6989586621679812380"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679812379"><span class="annot"><a href="#local-6989586621679812379"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-118"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812392"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-119"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerHead"><span class="hs-identifier hs-type">STransformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812391"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-120"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812390"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-121"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812389"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-122"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812388"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-123"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812387"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-124"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812386"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-125"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812385"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-126"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812384"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-127"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812383"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812382"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812381"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-130"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812380"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812379"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-type">SequenceToSequenceTransformerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812392"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812391"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812390"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812389"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812388"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812387"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812386"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812385"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812384"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812383"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812382"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812381"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812380"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812379"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-135"></span><span>
</span><span id="line-136"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span id="local-6989586621679812316"><span class="annot"><a href="#local-6989586621679812316"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679812315"><span class="annot"><a href="#local-6989586621679812315"><span class="hs-identifier hs-type hs-type">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679812314"><span class="annot"><a href="#local-6989586621679812314"><span class="hs-identifier hs-type hs-type">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812313"><span class="annot"><a href="#local-6989586621679812313"><span class="hs-identifier hs-type hs-type">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812312"><span class="annot"><a href="#local-6989586621679812312"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812311"><span class="annot"><a href="#local-6989586621679812311"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812310"><span class="annot"><a href="#local-6989586621679812310"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812309"><span class="annot"><a href="#local-6989586621679812309"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679812308"><span class="annot"><a href="#local-6989586621679812308"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812307"><span class="annot"><a href="#local-6989586621679812307"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679812306"><span class="annot"><a href="#local-6989586621679812306"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812305"><span class="annot"><a href="#local-6989586621679812305"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679812304"><span class="annot"><a href="#local-6989586621679812304"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679812303"><span class="annot"><a href="#local-6989586621679812303"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-type">SequenceToSequenceTransformerSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812316"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812315"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812314"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812313"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812312"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812311"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812310"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812309"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812308"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812307"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812306"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812305"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812304"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812303"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-137"></span><span>
</span><span id="line-138"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-139"></span><span>  </span><span id="SequenceToSequenceEncoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-var">SequenceToSequenceEncoderF</span></a></span></span><span>
</span><span id="line-140"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812302"><span class="annot"><a href="#local-6989586621679812302"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812301"><span class="annot"><a href="#local-6989586621679812301"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812300"><span class="annot"><a href="#local-6989586621679812300"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812299"><span class="annot"><a href="#local-6989586621679812299"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812298"><span class="annot"><a href="#local-6989586621679812298"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812297"><span class="annot"><a href="#local-6989586621679812297"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812296"><span class="annot"><a href="#local-6989586621679812296"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812295"><span class="annot"><a href="#local-6989586621679812295"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812294"><span class="annot"><a href="#local-6989586621679812294"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812293"><span class="annot"><a href="#local-6989586621679812293"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812292"><span class="annot"><a href="#local-6989586621679812292"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-152"></span><span>  </span><span id="SequenceToSequenceEncoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-var">SequenceToSequenceEncoderF</span></a></span></span><span> </span><span id="local-6989586621679812291"><span class="annot"><a href="#local-6989586621679812291"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679812290"><span class="annot"><a href="#local-6989586621679812290"><span class="hs-identifier hs-type hs-type">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812289"><span class="annot"><a href="#local-6989586621679812289"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812288"><span class="annot"><a href="#local-6989586621679812288"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812287"><span class="annot"><a href="#local-6989586621679812287"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812286"><span class="annot"><a href="#local-6989586621679812286"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679812285"><span class="annot"><a href="#local-6989586621679812285"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812284"><span class="annot"><a href="#local-6989586621679812284"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679812283"><span class="annot"><a href="#local-6989586621679812283"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812282"><span class="annot"><a href="#local-6989586621679812282"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679812281"><span class="annot"><a href="#local-6989586621679812281"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-153"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812291"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812290"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812289"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812288"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812287"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812286"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812285"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812284"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812283"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812282"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812281"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-154"></span><span>
</span><span id="line-155"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-156"></span><span>  </span><span id="SequenceToSequenceDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-var">SequenceToSequenceDecoderF</span></a></span></span><span>
</span><span id="line-157"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812280"><span class="annot"><a href="#local-6989586621679812280"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-158"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812279"><span class="annot"><a href="#local-6989586621679812279"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-159"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812278"><span class="annot"><a href="#local-6989586621679812278"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812277"><span class="annot"><a href="#local-6989586621679812277"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812276"><span class="annot"><a href="#local-6989586621679812276"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812275"><span class="annot"><a href="#local-6989586621679812275"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812274"><span class="annot"><a href="#local-6989586621679812274"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812273"><span class="annot"><a href="#local-6989586621679812273"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812272"><span class="annot"><a href="#local-6989586621679812272"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812271"><span class="annot"><a href="#local-6989586621679812271"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812270"><span class="annot"><a href="#local-6989586621679812270"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-168"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-169"></span><span>  </span><span id="SequenceToSequenceDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-var">SequenceToSequenceDecoderF</span></a></span></span><span> </span><span id="local-6989586621679812269"><span class="annot"><a href="#local-6989586621679812269"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679812268"><span class="annot"><a href="#local-6989586621679812268"><span class="hs-identifier hs-type hs-type">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812267"><span class="annot"><a href="#local-6989586621679812267"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812266"><span class="annot"><a href="#local-6989586621679812266"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812265"><span class="annot"><a href="#local-6989586621679812265"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812264"><span class="annot"><a href="#local-6989586621679812264"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679812263"><span class="annot"><a href="#local-6989586621679812263"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812262"><span class="annot"><a href="#local-6989586621679812262"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679812261"><span class="annot"><a href="#local-6989586621679812261"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812260"><span class="annot"><a href="#local-6989586621679812260"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679812259"><span class="annot"><a href="#local-6989586621679812259"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-170"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812269"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812268"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812267"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812266"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812265"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812264"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812263"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812262"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812261"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812261"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812260"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812259"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-171"></span><span>
</span><span id="line-172"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-173"></span><span>  </span><span id="SequenceToSequenceEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-var">SequenceToSequenceEmbeddingF</span></a></span></span><span>
</span><span id="line-174"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812258"><span class="annot"><a href="#local-6989586621679812258"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-175"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812257"><span class="annot"><a href="#local-6989586621679812257"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-176"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812256"><span class="annot"><a href="#local-6989586621679812256"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812255"><span class="annot"><a href="#local-6989586621679812255"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812254"><span class="annot"><a href="#local-6989586621679812254"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812253"><span class="annot"><a href="#local-6989586621679812253"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-181"></span><span>  </span><span id="SequenceToSequenceEmbeddingF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-var">SequenceToSequenceEmbeddingF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679812252"><span class="annot"><a href="#local-6989586621679812252"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812251"><span class="annot"><a href="#local-6989586621679812251"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812250"><span class="annot"><a href="#local-6989586621679812250"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812249"><span class="annot"><a href="#local-6989586621679812249"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812248"><span class="annot"><a href="#local-6989586621679812248"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-182"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812252"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679812251"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812250"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812248"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812249"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-183"></span><span>
</span><span id="line-184"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-185"></span><span>  </span><span id="SequenceToSequenceHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-var">SequenceToSequenceHeadF</span></a></span></span><span>
</span><span id="line-186"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812247"><span class="annot"><a href="#local-6989586621679812247"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812246"><span class="annot"><a href="#local-6989586621679812246"><span class="hs-identifier hs-type">transformerHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-type">TransformerHead</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812245"><span class="annot"><a href="#local-6989586621679812245"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812244"><span class="annot"><a href="#local-6989586621679812244"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-190"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812243"><span class="annot"><a href="#local-6989586621679812243"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-191"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812242"><span class="annot"><a href="#local-6989586621679812242"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-192"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679812241"><span class="annot"><a href="#local-6989586621679812241"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-194"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-195"></span><span>  </span><span id="SequenceToSequenceHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-var">SequenceToSequenceHeadF</span></a></span></span><span> </span><span id="local-6989586621679812240"><span class="annot"><a href="#local-6989586621679812240"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-type">WithoutHead</span></a></span><span> </span><span id="local-6989586621679812239"><span class="annot"><a href="#local-6989586621679812239"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812238"><span class="annot"><a href="#local-6989586621679812238"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812237"><span class="annot"><a href="#local-6989586621679812237"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812236"><span class="annot"><a href="#local-6989586621679812236"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812235"><span class="annot"><a href="#local-6989586621679812235"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-196"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span>  </span><span id="SequenceToSequenceHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-var">SequenceToSequenceHeadF</span></a></span></span><span> </span><span id="local-6989586621679812234"><span class="annot"><a href="#local-6989586621679812234"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-type">WithLMHead</span></a></span><span> </span><span id="local-6989586621679812233"><span class="annot"><a href="#local-6989586621679812233"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679812232"><span class="annot"><a href="#local-6989586621679812232"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679812231"><span class="annot"><a href="#local-6989586621679812231"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679812230"><span class="annot"><a href="#local-6989586621679812230"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812229"><span class="annot"><a href="#local-6989586621679812229"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-198"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHead"><span class="hs-identifier hs-type">LMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812234"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812233"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812232"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812231"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812230"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812229"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-199"></span><span>
</span><span id="line-200"></span><span id="local-6989586621679812210"><span id="local-6989586621679812211"><span id="local-6989586621679812212"><span id="local-6989586621679812213"><span id="local-6989586621679812214"><span id="local-6989586621679812215"><span id="local-6989586621679812216"><span id="local-6989586621679812217"><span id="local-6989586621679812218"><span id="local-6989586621679812219"><span id="local-6989586621679812220"><span id="local-6989586621679812221"><span id="local-6989586621679812222"><span id="local-6989586621679812223"><span id="local-6989586621679812224"><span id="local-6989586621679812225"><span id="local-6989586621679812226"><span id="local-6989586621679812227"><span id="local-6989586621679812228"><span class="hs-keyword">instance</span><span>
</span><span id="line-201"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679812228"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoder"><span class="hs-identifier hs-type">TransformerEncoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812227"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812226"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812223"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812222"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812221"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812220"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812219"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812218"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812217"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-202"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812228"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812228"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-203"></span><span>    </span><span class="annot"><a href="#local-6989586621679812216"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812227"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812215"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812223"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812222"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812221"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812220"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812219"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812219"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812218"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812217"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-204"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812216"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812216"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-205"></span><span>    </span><span class="annot"><a href="#local-6989586621679812214"><span class="hs-identifier hs-type">embedding</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812223"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812213"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812219"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span class="hs-special">,</span><span>
</span><span id="line-206"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812214"><span class="hs-identifier hs-type">embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812214"><span class="hs-identifier hs-type">embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-207"></span><span>    </span><span class="annot"><a href="#local-6989586621679812212"><span class="hs-identifier hs-type">lmHead</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-type">SequenceToSequenceHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812227"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812211"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812223"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812219"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812213"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-208"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812212"><span class="hs-identifier hs-type">lmHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812212"><span class="hs-identifier hs-type">lmHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-209"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-210"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-211"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812227"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812211"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812226"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812215"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812223"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812222"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812221"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812220"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812219"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812218"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812217"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812213"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span>    </span><span class="annot"><a href="#local-6989586621679812210"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-213"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812227"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812211"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812226"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812215"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812223"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812222"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812221"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812220"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812219"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812218"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812217"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812213"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>    </span><span class="annot"><a href="#local-6989586621679812224"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-215"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-216"></span><span>  </span><span id="local-6989586621679812207"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim)
-&gt; Generator generatorDevice
-&gt; m (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim,
      Generator device)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-type">SequenceToSequenceTransformerSpec</span></a></span><span> </span><span id="local-6989586621679812205"><span class="annot"><a href="#local-6989586621679812205"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679812204"><span class="annot"><a href="#local-6989586621679812204"><span class="hs-identifier hs-var">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679812203"><span class="annot"><a href="#local-6989586621679812203"><span class="hs-identifier hs-var">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812202"><span class="annot"><a href="#local-6989586621679812202"><span class="hs-identifier hs-var">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812201"><span class="annot"><a href="#local-6989586621679812201"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679812200"><span class="annot"><a href="#local-6989586621679812200"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679812199"><span class="annot"><a href="#local-6989586621679812199"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679812198"><span class="annot"><a href="#local-6989586621679812198"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679812197"><span class="annot"><a href="#local-6989586621679812197"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812196"><span class="annot"><a href="#local-6989586621679812196"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679812195"><span class="annot"><a href="#local-6989586621679812195"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812194"><span class="annot"><a href="#local-6989586621679812194"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679812193"><span class="annot"><a href="#local-6989586621679812193"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679812192"><span class="annot"><a href="#local-6989586621679812192"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679812191"><span class="annot"><a href="#local-6989586621679812191"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679812190"><span class="annot"><a href="#local-6989586621679812190"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679812189"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679812189"><span class="hs-identifier hs-var">generator</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-217"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679812188"><span class="annot"><span class="annottext">generator' :: Generator device
</span><a href="#local-6989586621679812188"><span class="hs-identifier hs-var hs-var">generator'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; Generator generatorDevice -&gt; Generator device
forall (generatorDevice' :: Device (DeviceType Nat))
       (generatorDevice :: Device (DeviceType Nat)).
SDevice generatorDevice'
-&gt; Generator generatorDevice -&gt; Generator generatorDevice'
</span><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier hs-var">sGeneratorToDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812200"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679812189"><span class="hs-identifier hs-var">generator</span></a></span><span>
</span><span id="line-218"></span><span>        </span><span id="local-6989586621679812187"><span class="annot"><span class="annottext">encoder :: IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
</span><a href="#local-6989586621679812187"><span class="hs-identifier hs-var hs-var">encoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device
 -&gt; m (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim,
       Generator device))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device
  -&gt; m (TransformerEncoder
          style
          numEncoderLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          inputEmbedDim
          ffnDim
          posEncDim,
        Generator device))
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim))
-&gt; (TransformerEncoderSpec
      style
      numEncoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
    -&gt; Generator device
    -&gt; m (TransformerEncoder
            style
            numEncoderLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            inputEmbedDim
            ffnDim
            posEncDim,
          Generator device))
-&gt; TransformerEncoderSpec
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   encoder generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec encoder
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812228"><span class="hs-identifier hs-type">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerEncoderSpec
   style
   numEncoderLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   posEncDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim))
-&gt; TransformerEncoderSpec
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numEncoderLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerEncoderSpec
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerEncoderSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-var">TransformerEncoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812205"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numEncoderLayers
</span><a href="#local-6989586621679812203"><span class="hs-identifier hs-var">numEncoderLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812201"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812200"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812199"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679812198"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679812197"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679812196"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812195"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679812194"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679812193"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812191"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812190"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-219"></span><span>        </span><span id="local-6989586621679812183"><span class="annot"><span class="annottext">decoder :: IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
</span><a href="#local-6989586621679812183"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device
 -&gt; m (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim,
       Generator device))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device
  -&gt; m (TransformerDecoder
          style
          numDecoderLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          inputEmbedDim
          inputEmbedDim
          ffnDim
          posEncDim,
        Generator device))
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim))
-&gt; (TransformerDecoderSpec
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim
    -&gt; Generator device
    -&gt; m (TransformerDecoder
            style
            numDecoderLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            inputEmbedDim
            inputEmbedDim
            ffnDim
            posEncDim,
          Generator device))
-&gt; TransformerDecoderSpec
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   decoder generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec decoder
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812216"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerDecoderSpec
   style
   numDecoderLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   inputEmbedDim
   ffnDim
   posEncDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim))
-&gt; TransformerDecoderSpec
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numDecoderLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderSpec
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (decoderInputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (encoderOutputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim decoderInputEmbedDim
-&gt; SDim encoderOutputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-var">TransformerDecoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812205"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numDecoderLayers
</span><a href="#local-6989586621679812202"><span class="hs-identifier hs-var">numDecoderLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812201"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812200"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812199"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679812198"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679812197"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679812196"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812195"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812195"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679812194"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679812193"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812191"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812190"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-220"></span><span>        </span><span id="local-6989586621679812181"><span class="annot"><span class="annottext">embedding :: IxStateT
  m
  (Generator device)
  (Generator device)
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
</span><a href="#local-6989586621679812181"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device
 -&gt; m (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing,
       Generator device))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device
  -&gt; m (Embedding
          gradient
          ('Layout 'Dense)
          device
          dataType
          vocabDim
          inputEmbedDim
          'Nothing,
        Generator device))
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing))
-&gt; (EmbeddingSpec
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing
    -&gt; Generator device
    -&gt; m (Embedding
            gradient
            ('Layout 'Dense)
            device
            dataType
            vocabDim
            inputEmbedDim
            'Nothing,
          Generator device))
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   embedding generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec embedding
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812214"><span class="hs-identifier hs-type">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">(EmbeddingSpec
   gradient
   ('Layout 'Dense)
   device
   dataType
   vocabDim
   inputEmbedDim
   'Nothing
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing))
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim vocabDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812201"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812200"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812199"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679812192"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812195"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-221"></span><span>        </span><span id="local-6989586621679812177"><span class="annot"><span class="annottext">lmHead :: IxStateT m (Generator device) (Generator device) lmHead
</span><a href="#local-6989586621679812177"><span class="hs-identifier hs-var hs-var">lmHead</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (lmHead, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) lmHead
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (lmHead, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) lmHead)
-&gt; (ModelSpec lmHead
    -&gt; Generator device -&gt; m (lmHead, Generator device))
-&gt; ModelSpec lmHead
-&gt; IxStateT m (Generator device) (Generator device) lmHead
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize lmHead generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec lmHead
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812212"><span class="hs-identifier hs-type">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec lmHead
 -&gt; IxStateT m (Generator device) (Generator device) lmHead)
-&gt; ModelSpec lmHead
-&gt; IxStateT m (Generator device) (Generator device) lmHead
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="#local-6989586621679812204"><span class="hs-identifier hs-var">transformerHead</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-222"></span><span>          </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>          </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-var">LMHeadSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812205"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812201"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812200"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812199"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812195"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679812192"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812190"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-224"></span><span>          </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier hs-var">SWithMLMHead</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec lmHead
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-225"></span><span>        </span><span id="local-6989586621679812174"><span class="annot"><span class="annottext">gSeqToSeq :: IxStateT
  m
  (Generator device)
  (Generator device)
  (GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     lmHead)
</span><a href="#local-6989586621679812174"><span class="hs-identifier hs-var hs-var">gSeqToSeq</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-226"></span><span>          </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; lmHead
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     lmHead
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; decoder
-&gt; embedding
-&gt; head
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim encoder decoder embedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-227"></span><span>            </span><span class="annot"><span class="annottext">(SDim inputEmbedDim
 -&gt; TransformerEncoder
      style
      numEncoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
 -&gt; TransformerDecoder
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim
 -&gt; Embedding
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing
 -&gt; lmHead
 -&gt; GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      lmHead)
-&gt; IxStateT
     m (Generator device) (Generator device) (SDim inputEmbedDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
      -&gt; TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim
      -&gt; Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing
      -&gt; lmHead
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           lmHead)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; IxStateT
     m (Generator device) (Generator device) (SDim inputEmbedDim)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812195"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
   -&gt; TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
   -&gt; Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
   -&gt; lmHead
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        lmHead)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
      -&gt; Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing
      -&gt; lmHead
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           lmHead)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
</span><a href="#local-6989586621679812187"><span class="hs-identifier hs-var">encoder</span></a></span><span>
</span><span id="line-228"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
   -&gt; Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
   -&gt; lmHead
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        lmHead)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
      -&gt; lmHead
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           lmHead)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
</span><a href="#local-6989586621679812183"><span class="hs-identifier hs-var">decoder</span></a></span><span>
</span><span id="line-229"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
   -&gt; lmHead
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        lmHead)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (lmHead
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           lmHead)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
</span><a href="#local-6989586621679812181"><span class="hs-identifier hs-var">embedding</span></a></span><span>
</span><span id="line-230"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (lmHead
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        lmHead)
-&gt; IxStateT m (Generator device) (Generator device) lmHead
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        lmHead)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) lmHead
</span><a href="#local-6989586621679812177"><span class="hs-identifier hs-var">lmHead</span></a></span><span>
</span><span id="line-231"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim)
-&gt; Generator device
-&gt; m (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim,
      Generator device)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     lmHead)
</span><a href="#local-6989586621679812174"><span class="hs-identifier hs-var">gSeqToSeq</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     lmHead)
-&gt; (GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      lmHead
    -&gt; IxStateT
         m
         (Generator device)
         (Generator device)
         (SequenceToSequenceTransformer
            style
            transformerHead
            numEncoderLayers
            numDecoderLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            inputEmbedDim
            ffnDim
            posEncDim
            vocabDim))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  style
  transformerHead
  numEncoderLayers
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  vocabDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(SequenceToSequenceTransformer
   style
   transformerHead
   numEncoderLayers
   numDecoderLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   posEncDim
   vocabDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (SequenceToSequenceTransformer
         style
         transformerHead
         numEncoderLayers
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         vocabDim))
-&gt; (GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      lmHead
    -&gt; SequenceToSequenceTransformer
         style
         transformerHead
         numEncoderLayers
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim
         vocabDim)
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     lmHead
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
  lmHead
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
forall (style :: TransformerStyle)
       (transformerHead :: TransformerHead) (numEncoderLayers :: Nat)
       (numDecoderLayers :: Nat) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
GSequenceToSequenceTransformer
  inputEmbedDim
  (SequenceToSequenceEncoderF
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (SequenceToSequenceDecoderF
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (SequenceToSequenceEmbeddingF
     style gradient device dataType inputEmbedDim vocabDim)
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator device
</span><a href="#local-6989586621679812188"><span class="hs-identifier hs-var">generator'</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-232"></span><span>
</span><span id="line-233"></span><span id="local-6989586621679812159"><span id="local-6989586621679812160"><span id="local-6989586621679812161"><span id="local-6989586621679812162"><span id="local-6989586621679812163"><span id="local-6989586621679812164"><span id="local-6989586621679812165"><span id="local-6989586621679812166"><span id="local-6989586621679812167"><span id="local-6989586621679812168"><span id="local-6989586621679812169"><span id="local-6989586621679812170"><span id="local-6989586621679812171"><span id="local-6989586621679812172"><span class="hs-keyword">instance</span><span>
</span><span id="line-234"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812172"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812171"><span class="hs-identifier hs-type">transformerHead</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-235"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-236"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812172"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812171"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812170"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812169"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812168"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812167"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812166"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812165"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812164"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812163"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812162"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812161"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812160"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812159"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-237"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-238"></span><span>  </span><span id="local-6989586621679812155"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim)
-&gt; StateDictKey
-&gt; m (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-type">SequenceToSequenceTransformerSpec</span></a></span><span> </span><span id="local-6989586621679812153"><span class="annot"><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679812152"><span class="annot"><a href="#local-6989586621679812152"><span class="hs-identifier hs-var">transformerHead</span></a></span></span><span> </span><span id="local-6989586621679812151"><span class="annot"><a href="#local-6989586621679812151"><span class="hs-identifier hs-var">numEncoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812150"><span class="annot"><a href="#local-6989586621679812150"><span class="hs-identifier hs-var">numDecoderLayers</span></a></span></span><span> </span><span id="local-6989586621679812149"><span class="annot"><a href="#local-6989586621679812149"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679812148"><span class="annot"><a href="#local-6989586621679812148"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679812147"><span class="annot"><a href="#local-6989586621679812147"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679812146"><span class="annot"><a href="#local-6989586621679812146"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679812145"><span class="annot"><a href="#local-6989586621679812145"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812144"><span class="annot"><a href="#local-6989586621679812144"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679812143"><span class="annot"><a href="#local-6989586621679812143"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679812142"><span class="annot"><a href="#local-6989586621679812142"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679812141"><span class="annot"><a href="#local-6989586621679812141"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679812140"><span class="annot"><a href="#local-6989586621679812140"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679812139"><span class="annot"><a href="#local-6989586621679812139"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679812138"><span class="annot"><a href="#local-6989586621679812138"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679812137"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-239"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679812136"><span class="annot"><span class="annottext">encoderSpec :: TransformerEncoderSpec
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812136"><span class="hs-identifier hs-var hs-var">encoderSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numEncoderLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerEncoderSpec
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerEncoderSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Encoder.html#TransformerEncoderSpec"><span class="hs-identifier hs-var">TransformerEncoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numEncoderLayers
</span><a href="#local-6989586621679812151"><span class="hs-identifier hs-var">numEncoderLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812149"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812148"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812147"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679812146"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679812145"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679812144"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812143"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679812142"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679812141"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812139"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812138"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-240"></span><span>        </span><span id="local-6989586621679812135"><span class="annot"><span class="annottext">encoder :: STransformerStyle style
-&gt; m (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
</span><a href="#local-6989586621679812135"><span class="hs-identifier hs-var hs-var">encoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'T5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'T5
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'T5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerEncoderSpec
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812136"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>        </span><span class="annot"><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'ByT5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'ByT5
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'ByT5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerEncoderSpec
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812136"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-242"></span><span>        </span><span class="annot"><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'BART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'BART
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'BART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerEncoderSpec
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812136"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-243"></span><span>        </span><span class="annot"><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'MBART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'MBART
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'MBART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerEncoderSpec
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812136"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-244"></span><span>        </span><span class="annot"><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'Pegasus
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerEncoder
        'Pegasus
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerEncoder
     'Pegasus
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerEncoderSpec
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812136"><span class="hs-identifier hs-var">encoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-245"></span><span>        </span><span class="annot"><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-246"></span><span>        </span><span class="annot"><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-247"></span><span>        </span><span class="annot"><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-248"></span><span>        </span><span id="local-6989586621679812126"><span class="annot"><span class="annottext">decoderSpec :: TransformerDecoderSpec
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812126"><span class="hs-identifier hs-var hs-var">decoderSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numDecoderLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderSpec
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (decoderInputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (encoderOutputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim decoderInputEmbedDim
-&gt; SDim encoderOutputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-var">TransformerDecoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numDecoderLayers
</span><a href="#local-6989586621679812150"><span class="hs-identifier hs-var">numDecoderLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812149"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812148"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812147"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679812146"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679812145"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679812144"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812143"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812143"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679812142"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679812141"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812139"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812138"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-249"></span><span>        </span><span id="local-6989586621679812125"><span class="annot"><span class="annottext">decoder :: STransformerStyle style
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
</span><a href="#local-6989586621679812125"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'T5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'T5
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'T5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerDecoderSpec
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812126"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-250"></span><span>        </span><span class="annot"><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'ByT5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'ByT5
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'ByT5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerDecoderSpec
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812126"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span>        </span><span class="annot"><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'BART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'BART
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'BART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerDecoderSpec
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812126"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-252"></span><span>        </span><span class="annot"><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'MBART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'MBART
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'MBART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerDecoderSpec
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812126"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span>        </span><span class="annot"><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'Pegasus
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        'Pegasus
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'Pegasus
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
TransformerDecoderSpec
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812126"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-254"></span><span>        </span><span class="annot"><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-255"></span><span>        </span><span class="annot"><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-256"></span><span>        </span><span class="annot"><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-257"></span><span>        </span><span id="local-6989586621679812124"><span class="annot"><span class="annottext">embeddingSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679812124"><span class="hs-identifier hs-var hs-var">embeddingSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim vocabDim
-&gt; SDim inputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812149"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812148"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812147"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679812140"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812143"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-258"></span><span>        </span><span id="local-6989586621679812123"><span class="annot"><span class="annottext">embedding :: STransformerStyle style
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679812123"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679812124"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>        </span><span class="annot"><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679812124"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-260"></span><span>        </span><span class="annot"><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679812124"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>        </span><span class="annot"><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679812124"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>        </span><span class="annot"><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
</span><a href="#local-6989586621679812124"><span class="hs-identifier hs-var">embeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;model.shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>        </span><span class="annot"><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-264"></span><span>        </span><span class="annot"><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-265"></span><span>        </span><span class="annot"><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-266"></span><span>        </span><span id="local-6989586621679812122"><span class="annot"><span class="annottext">lmHeadSpec :: LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679812122"><span class="hs-identifier hs-var hs-var">lmHeadSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.LMHead.html#LMHeadSpec"><span class="hs-identifier hs-var">LMHeadSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679812149"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679812148"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679812147"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812143"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679812140"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679812138"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-267"></span><span>        </span><span id="local-6989586621679812121"><span class="annot"><span class="annottext">lmHead :: STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679812121"><span class="hs-identifier hs-var hs-var">lmHead</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-268"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'T5 gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (LMHead 'T5 gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'T5 gradient device dataType inputEmbedDim vocabDim)
LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679812122"><span class="hs-identifier hs-var">lmHeadSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-269"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'ByT5 gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (LMHead 'ByT5 gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'ByT5 gradient device dataType inputEmbedDim vocabDim)
LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679812122"><span class="hs-identifier hs-var">lmHeadSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-270"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'BART gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (LMHead 'BART gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'BART gradient device dataType inputEmbedDim vocabDim)
LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679812122"><span class="hs-identifier hs-var">lmHeadSpec</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-271"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'MBART gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (LMHead
        'MBART gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'MBART gradient device dataType inputEmbedDim vocabDim)
LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679812122"><span class="hs-identifier hs-var">lmHeadSpec</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-272"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'Pegasus gradient device dataType inputEmbedDim vocabDim)
-&gt; StateDictKey
-&gt; m (LMHead
        'Pegasus gradient device dataType inputEmbedDim vocabDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHead 'Pegasus gradient device dataType inputEmbedDim vocabDim)
LMHeadSpec style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679812122"><span class="hs-identifier hs-var">lmHeadSpec</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812137"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-273"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-274"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-275"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-276"></span><span>        </span><span class="annot"><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier hs-var">SWithMLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-277"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GSequenceToSequenceTransformer
  inputEmbedDim
  (TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing)
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
forall (style :: TransformerStyle)
       (transformerHead :: TransformerHead) (numEncoderLayers :: Nat)
       (numDecoderLayers :: Nat) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
GSequenceToSequenceTransformer
  inputEmbedDim
  (SequenceToSequenceEncoderF
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (SequenceToSequenceDecoderF
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim)
  (SequenceToSequenceEmbeddingF
     style gradient device dataType inputEmbedDim vocabDim)
  (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim)
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-var">SequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-278"></span><span>          </span><span class="annot"><span class="annottext">(GSequenceToSequenceTransformer
   inputEmbedDim
   (TransformerEncoder
      style
      numEncoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim)
   (TransformerDecoder
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim)
   (Embedding
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing)
   (SequenceToSequenceHeadF
      style
      transformerHead
      gradient
      device
      dataType
      inputEmbedDim
      vocabDim)
 -&gt; SequenceToSequenceTransformer
      style
      transformerHead
      numEncoderLayers
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      ffnDim
      posEncDim
      vocabDim)
-&gt; m (GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (SequenceToSequenceTransformer
        style
        transformerHead
        numEncoderLayers
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim
        vocabDim)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim
     (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
     (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
     (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
SDim inputEmbedDim
-&gt; encoder
-&gt; decoder
-&gt; embedding
-&gt; head
-&gt; GSequenceToSequenceTransformer
     inputEmbedDim encoder decoder embedding head
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-var">GSequenceToSequenceTransformer</span></a></span><span>
</span><span id="line-279"></span><span>                  </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679812143"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-280"></span><span>                  </span><span class="annot"><span class="annottext">(TransformerEncoder
   style
   numEncoderLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   inputEmbedDim
   ffnDim
   posEncDim
 -&gt; TransformerDecoder
      style
      numDecoderLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      inputEmbedDim
      inputEmbedDim
      ffnDim
      posEncDim
 -&gt; Embedding
      gradient
      ('Layout 'Dense)
      device
      dataType
      vocabDim
      inputEmbedDim
      'Nothing
 -&gt; SequenceToSequenceHeadF
      style
      transformerHead
      gradient
      device
      dataType
      inputEmbedDim
      vocabDim
 -&gt; GSequenceToSequenceTransformer
      inputEmbedDim
      (TransformerEncoder
         style
         numEncoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (TransformerDecoder
         style
         numDecoderLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         inputEmbedDim
         inputEmbedDim
         ffnDim
         posEncDim)
      (Embedding
         gradient
         ('Layout 'Dense)
         device
         dataType
         vocabDim
         inputEmbedDim
         'Nothing)
      (SequenceToSequenceHeadF
         style
         transformerHead
         gradient
         device
         dataType
         inputEmbedDim
         vocabDim))
-&gt; m (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim
      -&gt; Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing
      -&gt; SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerEncoder
        style
        numEncoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        ffnDim
        posEncDim)
</span><a href="#local-6989586621679812135"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-281"></span><span>                  </span><span class="annot"><span class="annottext">m (TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
   -&gt; Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
   -&gt; SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing
      -&gt; SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerDecoder
        style
        numDecoderLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        inputEmbedDim
        inputEmbedDim
        ffnDim
        posEncDim)
</span><a href="#local-6989586621679812125"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-282"></span><span>                  </span><span class="annot"><span class="annottext">m (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
   -&gt; SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim
      -&gt; GSequenceToSequenceTransformer
           inputEmbedDim
           (TransformerEncoder
              style
              numEncoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (TransformerDecoder
              style
              numDecoderLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              inputEmbedDim
              inputEmbedDim
              ffnDim
              posEncDim)
           (Embedding
              gradient
              ('Layout 'Dense)
              device
              dataType
              vocabDim
              inputEmbedDim
              'Nothing)
           (SequenceToSequenceHeadF
              style
              transformerHead
              gradient
              device
              dataType
              inputEmbedDim
              vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        vocabDim
        inputEmbedDim
        'Nothing)
</span><a href="#local-6989586621679812123"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-283"></span><span>                  </span><span class="annot"><span class="annottext">m (SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
   -&gt; GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
-&gt; m (GSequenceToSequenceTransformer
        inputEmbedDim
        (TransformerEncoder
           style
           numEncoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (TransformerDecoder
           style
           numDecoderLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           inputEmbedDim
           inputEmbedDim
           ffnDim
           posEncDim)
        (Embedding
           gradient
           ('Layout 'Dense)
           device
           dataType
           vocabDim
           inputEmbedDim
           'Nothing)
        (SequenceToSequenceHeadF
           style
           transformerHead
           gradient
           device
           dataType
           inputEmbedDim
           vocabDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; m (SequenceToSequenceHeadF
        style
        transformerHead
        gradient
        device
        dataType
        inputEmbedDim
        vocabDim)
</span><a href="#local-6989586621679812121"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679812153"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="#local-6989586621679812152"><span class="hs-identifier hs-var">transformerHead</span></a></span><span>
</span><span id="line-284"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>  </span><span id="local-6989586621679812119"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; SequenceToSequenceTransformer
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679812117"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679812112"><span id="local-6989586621679812113"><span id="local-6989586621679812114"><span id="local-6989586621679812115"><span id="local-6989586621679812116"><span class="annot"><span class="annottext">SDim inputEmbedDim
SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqHead :: SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
seqToSeqEmbedding :: SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
seqToSeqDecoder :: SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqEncoder :: SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqInputEmbedDim :: SDim inputEmbedDim
seqToSeqHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
seqToSeqEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
seqToSeqDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
seqToSeqEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
seqToSeqInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679812112"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-286"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679812111"><span class="annot"><span class="annottext">encoder :: STransformerStyle style
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679812111"><span class="hs-identifier hs-var hs-var">encoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'T5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-287"></span><span>        </span><span class="annot"><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'ByT5
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>        </span><span class="annot"><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'BART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>        </span><span class="annot"><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'MBART
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>        </span><span class="annot"><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerEncoder
     'Pegasus
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-291"></span><span>        </span><span class="annot"><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-293"></span><span>        </span><span class="annot"><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-294"></span><span>        </span><span id="local-6989586621679812110"><span class="annot"><span class="annottext">decoder :: STransformerStyle style
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679812110"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'T5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-295"></span><span>        </span><span class="annot"><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'ByT5
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-296"></span><span>        </span><span class="annot"><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'BART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-297"></span><span>        </span><span class="annot"><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'MBART
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span>        </span><span class="annot"><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoder
     'Pegasus
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-299"></span><span>        </span><span class="annot"><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-302"></span><span>        </span><span id="local-6989586621679812109"><span class="annot"><span class="annottext">embedding :: STransformerStyle style
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
</span><a href="#local-6989586621679812109"><span class="hs-identifier hs-var hs-var">embedding</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>        </span><span class="annot"><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-304"></span><span>        </span><span class="annot"><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-305"></span><span>        </span><span class="annot"><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>        </span><span class="annot"><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;shared.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-307"></span><span>        </span><span class="annot"><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-308"></span><span>        </span><span class="annot"><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-309"></span><span>        </span><span class="annot"><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-310"></span><span>        </span><span id="local-6989586621679812108"><span class="annot"><span class="annottext">lmHead :: STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
-&gt; m ()
</span><a href="#local-6989586621679812108"><span class="hs-identifier hs-var hs-var">lmHead</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithoutHead"><span class="hs-identifier hs-var">SWithoutHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-311"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'T5 gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'ByT5 gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'BART gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-314"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'MBART gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-315"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LMHead 'Pegasus gradient device dataType inputEmbedDim vocabDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679812117"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-316"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-317"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-318"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-319"></span><span>        </span><span class="annot"><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">STransformerHead transformerHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithMLMHead"><span class="hs-identifier hs-var">SWithMLMHead</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-320"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-321"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerEncoder
     style
     numEncoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679812111"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812172"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812115"><span class="hs-identifier hs-var">seqToSeqEncoder</span></a></span><span>
</span><span id="line-322"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerDecoder
     style
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     inputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679812110"><span class="hs-identifier hs-var">decoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812172"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679812114"><span class="hs-identifier hs-var">seqToSeqDecoder</span></a></span><span>
</span><span id="line-323"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     vocabDim
     inputEmbedDim
     'Nothing
-&gt; m ()
</span><a href="#local-6989586621679812109"><span class="hs-identifier hs-var">embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812172"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679812113"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-324"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SequenceToSequenceHeadF
     style
     transformerHead
     gradient
     device
     dataType
     inputEmbedDim
     vocabDim
-&gt; m ()
</span><a href="#local-6989586621679812108"><span class="hs-identifier hs-var">lmHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812172"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI transformerHead =&gt; Sing transformerHead
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812171"><span class="hs-identifier hs-type">transformerHead</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
</span><a href="#local-6989586621679812112"><span class="hs-identifier hs-var">seqToSeqHead</span></a></span><span>
</span><span id="line-325"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-326"></span><span>
</span><span id="line-327"></span><span class="hs-comment">-- | Input data type for use with a sequence-to-sequence transformer.</span><span>
</span><span id="line-328"></span><span class="hs-comment">-- Use this for training.</span><span>
</span><span id="line-329"></span><span class="hs-keyword">data</span><span> </span><span id="SequenceToSequenceTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679812107"><span class="annot"><a href="#local-6989586621679812107"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679812106"><span class="annot"><a href="#local-6989586621679812106"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679812105"><span class="annot"><a href="#local-6989586621679812105"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679812104"><span class="annot"><a href="#local-6989586621679812104"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679812103"><span class="annot"><a href="#local-6989586621679812103"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span> </span><span id="local-6989586621679812102"><span class="annot"><a href="#local-6989586621679812102"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679812101"><span class="annot"><a href="#local-6989586621679812101"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-330"></span><span>  </span><span id="SequenceToSequenceTransformerInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-331"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812526"><span class="annot"><a href="#local-6989586621679812526"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679812525"><span class="annot"><a href="#local-6989586621679812525"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679812524"><span class="annot"><a href="#local-6989586621679812524"><span class="hs-identifier hs-type">pos</span></a></span></span><span> </span><span id="local-6989586621679812523"><span class="annot"><a href="#local-6989586621679812523"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679812522"><span class="annot"><a href="#local-6989586621679812522"><span class="hs-identifier hs-type">attentionMask</span></a></span></span><span> </span><span id="local-6989586621679812521"><span class="annot"><a href="#local-6989586621679812521"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679812520"><span class="annot"><a href="#local-6989586621679812520"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-332"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="input"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; input
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#input"><span class="hs-identifier hs-var hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812526"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-333"></span><span>      </span><span id="decoderInput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderInput"><span class="hs-identifier hs-var hs-var">decoderInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812525"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-334"></span><span>      </span><span id="pos"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; pos
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#pos"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812524"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-335"></span><span>      </span><span id="decoderPos"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderPos"><span class="hs-identifier hs-var hs-var">decoderPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812523"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-336"></span><span>      </span><span id="attentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; attentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#attentionMask"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812522"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-337"></span><span>      </span><span id="decoderAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderAttentionMask"><span class="hs-identifier hs-var hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812521"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-338"></span><span>      </span><span id="crossAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#crossAttentionMask"><span class="hs-identifier hs-var hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812520"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-339"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-340"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812526"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812525"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812524"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812523"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812522"><span class="hs-identifier hs-type">attentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812521"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812520"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-341"></span><span>
</span><span id="line-342"></span><span id="local-6989586621679812080"><span id="local-6989586621679812082"><span id="local-6989586621679812084"><span id="local-6989586621679812086"><span id="local-6989586621679812087"><span id="local-6989586621679812088"><span id="local-6989586621679812089"><span id="local-6989586621679812090"><span id="local-6989586621679812091"><span id="local-6989586621679812092"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-343"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812092"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-344"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812091"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-345"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812090"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-346"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812089"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-347"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812088"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-348"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812087"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-349"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812086"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-350"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-351"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812092"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812091"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812090"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812089"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812088"><span class="hs-identifier hs-type">attentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812087"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812086"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-352"></span><span>
</span><span id="line-353"></span><span class="hs-comment">-- | Output data type for use with a sequence-to-sequence transformer.</span><span>
</span><span id="line-354"></span><span class="hs-keyword">data</span><span> </span><span id="SequenceToSequenceTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span></span><span> </span><span id="local-6989586621679812078"><span class="annot"><a href="#local-6989586621679812078"><span class="hs-identifier hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679812077"><span class="annot"><a href="#local-6989586621679812077"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-355"></span><span>  </span><span id="SequenceToSequenceTransformerOutput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-356"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812487"><span class="annot"><a href="#local-6989586621679812487"><span class="hs-identifier hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679812486"><span class="annot"><a href="#local-6989586621679812486"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-357"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderOutput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput decoderOutput encoderOutput
-&gt; decoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#decoderOutput"><span class="hs-identifier hs-var hs-var">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812487"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-358"></span><span>      </span><span id="encoderOutput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput decoderOutput encoderOutput
-&gt; encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#encoderOutput"><span class="hs-identifier hs-var hs-var">encoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812486"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-359"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-360"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812487"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812486"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-361"></span><span>
</span><span id="line-362"></span><span id="local-6989586621679812066"><span id="local-6989586621679812068"><span id="local-6989586621679812070"><span id="local-6989586621679812072"><span id="local-6989586621679812073"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-363"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812073"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-364"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812072"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-365"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-366"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812073"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812072"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-367"></span><span>
</span><span id="line-368"></span><span class="hs-comment">-- | Input data type for use with a sequence-to-sequence transformer.</span><span>
</span><span id="line-369"></span><span class="hs-comment">-- Use this for inference.</span><span>
</span><span id="line-370"></span><span class="hs-keyword">data</span><span> </span><span id="SequenceToSequenceTransformerGenerationInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerGenerationInput</span></a></span></span><span> </span><span id="local-6989586621679812065"><span class="annot"><a href="#local-6989586621679812065"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679812064"><span class="annot"><a href="#local-6989586621679812064"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span> </span><span id="local-6989586621679812063"><span class="annot"><a href="#local-6989586621679812063"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679812062"><span class="annot"><a href="#local-6989586621679812062"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679812061"><span class="annot"><a href="#local-6989586621679812061"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-371"></span><span>  </span><span id="SequenceToSequenceTransformerGenerationInput"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerGenerationInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-372"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812453"><span class="annot"><a href="#local-6989586621679812453"><span class="hs-identifier hs-type">decoderInput</span></a></span></span><span> </span><span id="local-6989586621679812452"><span class="annot"><a href="#local-6989586621679812452"><span class="hs-identifier hs-type">encoderOutput</span></a></span></span><span> </span><span id="local-6989586621679812451"><span class="annot"><a href="#local-6989586621679812451"><span class="hs-identifier hs-type">decoderPos</span></a></span></span><span> </span><span id="local-6989586621679812450"><span class="annot"><a href="#local-6989586621679812450"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679812449"><span class="annot"><a href="#local-6989586621679812449"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-373"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="generationDecoderInput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationDecoderInput"><span class="hs-identifier hs-var hs-var">generationDecoderInput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812453"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-374"></span><span>      </span><span id="generationEncoderOutput"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationEncoderOutput"><span class="hs-identifier hs-var hs-var">generationEncoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812452"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-375"></span><span>      </span><span id="generationDecoderPos"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationDecoderPos"><span class="hs-identifier hs-var hs-var">generationDecoderPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812451"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-376"></span><span>      </span><span id="generationDecoderAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationDecoderAttentionMask"><span class="hs-identifier hs-var hs-var">generationDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812450"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-377"></span><span>      </span><span id="generationCrossAttentionMask"><span class="annot"><span class="annottext">SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#generationCrossAttentionMask"><span class="hs-identifier hs-var hs-var">generationCrossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679812449"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-378"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-379"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812453"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812452"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812451"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812450"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812449"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-380"></span><span>
</span><span id="line-381"></span><span id="local-6989586621679812044"><span id="local-6989586621679812046"><span id="local-6989586621679812048"><span id="local-6989586621679812050"><span id="local-6989586621679812051"><span id="local-6989586621679812052"><span id="local-6989586621679812053"><span id="local-6989586621679812054"><span class="hs-keyword">deriving</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-382"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812054"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-383"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812053"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-384"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812052"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-385"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812051"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-386"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679812050"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-387"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-388"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812054"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812053"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812052"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812051"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812050"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span><span>
</span><span id="line-389"></span><span>
</span><span id="line-390"></span><span class="hs-comment">-- | 'HasForward' instance for sequence-to-sequence transformers without additional head(s).</span><span>
</span><span id="line-391"></span><span class="hs-comment">--</span><span>
</span><span id="line-392"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-393"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-394"></span><span class="hs-comment">--     &#9474; input &#9474;  &#9474; pos &#9474;  &#9474; attentionMask &#9474;  &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-395"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-396"></span><span class="hs-comment">--         &#9474;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-397"></span><span class="hs-comment">--         &#9660;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-398"></span><span class="hs-comment">-- seqToSeqEmbedding &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-399"></span><span class="hs-comment">--         &#9660;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-400"></span><span class="hs-comment">--   (embedScaling)  &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-401"></span><span class="hs-comment">--         &#9660;         &#9474;            &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-402"></span><span class="hs-comment">--  seqToSeqEncoder&#9668;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-403"></span><span class="hs-comment">--         &#9474;                                 seqToSeqEmbedding        &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-404"></span><span class="hs-comment">--         &#9474;                                         &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-405"></span><span class="hs-comment">--         &#9474;                                   (embedScaling)         &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-406"></span><span class="hs-comment">--         &#9474;                                         &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-407"></span><span class="hs-comment">--         &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;seqToSeqDecoder&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-408"></span><span class="hs-comment">--         &#9474;                                         &#9474;</span><span>
</span><span id="line-409"></span><span class="hs-comment">--         &#9474;                                  (seqToSeqLMHead)</span><span>
</span><span id="line-410"></span><span class="hs-comment">--         &#9474;                                         &#9474;</span><span>
</span><span id="line-411"></span><span class="hs-comment">--         &#9660;                                         &#9660;</span><span>
</span><span id="line-412"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;                         &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-413"></span><span class="hs-comment">-- &#9474; encoderOutput &#9474;                         &#9474; decoderOutput &#9474;</span><span>
</span><span id="line-414"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                         &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-415"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-416"></span><span id="local-6989586621679812002"><span id="local-6989586621679812003"><span id="local-6989586621679812004"><span id="local-6989586621679812005"><span id="local-6989586621679812006"><span id="local-6989586621679812007"><span id="local-6989586621679812008"><span id="local-6989586621679812009"><span id="local-6989586621679812010"><span id="local-6989586621679812011"><span id="local-6989586621679812012"><span id="local-6989586621679812013"><span id="local-6989586621679812014"><span id="local-6989586621679812015"><span id="local-6989586621679812016"><span id="local-6989586621679812017"><span id="local-6989586621679812018"><span id="local-6989586621679812019"><span id="local-6989586621679812020"><span id="local-6989586621679812021"><span id="local-6989586621679812022"><span id="local-6989586621679812023"><span id="local-6989586621679812024"><span id="local-6989586621679812025"><span id="local-6989586621679812026"><span id="local-6989586621679812027"><span id="local-6989586621679812028"><span id="local-6989586621679812029"><span id="local-6989586621679812030"><span id="local-6989586621679812031"><span id="local-6989586621679812032"><span id="local-6989586621679812033"><span id="local-6989586621679812034"><span id="local-6989586621679812035"><span id="local-6989586621679812036"><span id="local-6989586621679812037"><span id="local-6989586621679812038"><span id="local-6989586621679812039"><span id="local-6989586621679812040"><span id="local-6989586621679812041"><span id="local-6989586621679812042"><span id="local-6989586621679812043"><span class="hs-keyword">instance</span><span>
</span><span id="line-417"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-418"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-419"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812041"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812040"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812039"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812038"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-420"></span><span>      </span><span class="annot"><a href="#local-6989586621679812037"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-421"></span><span>      </span><span class="annot"><a href="#local-6989586621679812036"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-422"></span><span>      </span><span class="annot"><a href="#local-6989586621679812035"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span>
</span><span id="line-423"></span><span>      </span><span class="annot"><a href="#local-6989586621679812034"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-424"></span><span>    </span><span class="annot"><a href="#local-6989586621679812035"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812033"><span class="hs-identifier hs-type">requiresGradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812032"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812031"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812030"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812029"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-425"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-426"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEncoderF"><span class="hs-identifier hs-type">SequenceToSequenceEncoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812028"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812041"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812040"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812027"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812026"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812025"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812039"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812024"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812023"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-427"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679812035"><span class="hs-identifier hs-type">embeddingOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679812022"><span class="hs-identifier hs-type">pos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679812021"><span class="hs-identifier hs-type">attentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-428"></span><span>      </span><span class="annot"><a href="#local-6989586621679812034"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice</span></a></span><span>
</span><span id="line-429"></span><span>      </span><span class="annot"><a href="#local-6989586621679812020"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span>
</span><span id="line-430"></span><span>      </span><span class="annot"><a href="#local-6989586621679812019"><span class="hs-identifier hs-type">encoderGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-431"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-432"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812041"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812040"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812039"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812038"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-433"></span><span>      </span><span class="annot"><a href="#local-6989586621679812018"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-434"></span><span>      </span><span class="annot"><a href="#local-6989586621679812019"><span class="hs-identifier hs-type">encoderGeneratorOutputDevice</span></a></span><span>
</span><span id="line-435"></span><span>      </span><span class="annot"><a href="#local-6989586621679812017"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span>
</span><span id="line-436"></span><span>      </span><span class="annot"><a href="#local-6989586621679812016"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-437"></span><span>    </span><span class="annot"><a href="#local-6989586621679812017"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812015"><span class="hs-identifier hs-type">requiresGradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812014"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812013"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812012"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812011"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-438"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-439"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-type">SequenceToSequenceDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812010"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812041"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812040"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812027"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812026"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812025"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812039"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812024"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812023"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-440"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679812017"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-441"></span><span>        </span><span class="annot"><a href="#local-6989586621679812020"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-442"></span><span>        </span><span class="annot"><a href="#local-6989586621679812009"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-443"></span><span>        </span><span class="annot"><a href="#local-6989586621679812008"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-444"></span><span>        </span><span class="annot"><a href="#local-6989586621679812007"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-445"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-446"></span><span>      </span><span class="annot"><a href="#local-6989586621679812016"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice'</span></a></span><span>
</span><span id="line-447"></span><span>      </span><span class="annot"><a href="#local-6989586621679812006"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-448"></span><span>      </span><span class="annot"><a href="#local-6989586621679812005"><span class="hs-identifier hs-type">decoderGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-449"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-450"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-type">SequenceToSequenceHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812004"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812041"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812040"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812039"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812038"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-451"></span><span>      </span><span class="annot"><a href="#local-6989586621679812006"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-452"></span><span>      </span><span class="annot"><a href="#local-6989586621679812005"><span class="hs-identifier hs-type">decoderGeneratorOutputDevice</span></a></span><span>
</span><span id="line-453"></span><span>      </span><span class="annot"><a href="#local-6989586621679812003"><span class="hs-identifier hs-type">headOutput</span></a></span><span>
</span><span id="line-454"></span><span>      </span><span class="annot"><a href="#local-6989586621679812002"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-455"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-456"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-457"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812004"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812028"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812010"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812041"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812040"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812027"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812026"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812025"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812039"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812024"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812023"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812038"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-458"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812037"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812018"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812022"><span class="hs-identifier hs-type">pos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812009"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812021"><span class="hs-identifier hs-type">attentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812008"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812007"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-459"></span><span>    </span><span class="annot"><a href="#local-6989586621679812036"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-460"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812003"><span class="hs-identifier hs-type">headOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812020"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-461"></span><span>    </span><span class="annot"><a href="#local-6989586621679812002"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-462"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-463"></span><span>  </span><span id="local-6989586621679811999"><span class="annot"><span class="annottext">forward :: SequenceToSequenceTransformer
  style
  transformerHead
  numEncoderLayers
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  vocabDim
-&gt; SequenceToSequenceTransformerInput
     input
     decoderInput
     pos
     decoderPos
     attentionMask
     decoderAttentionMask
     crossAttentionMask
-&gt; Generator generatorDevice
-&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
      Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679811993"><span id="local-6989586621679811994"><span id="local-6989586621679811995"><span id="local-6989586621679811996"><span id="local-6989586621679811997"><span class="annot"><span class="annottext">SDim inputEmbedDim
SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqHead :: SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
seqToSeqEmbedding :: SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
seqToSeqDecoder :: SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqEncoder :: SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqInputEmbedDim :: SDim inputEmbedDim
seqToSeqHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
seqToSeqEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
seqToSeqDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
seqToSeqEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
seqToSeqInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679811993"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679811986"><span id="local-6989586621679811987"><span id="local-6989586621679811988"><span id="local-6989586621679811989"><span id="local-6989586621679811990"><span id="local-6989586621679811991"><span id="local-6989586621679811992"><span class="annot"><span class="annottext">input
pos
attentionMask
decoderInput
decoderPos
decoderAttentionMask
crossAttentionMask
crossAttentionMask :: crossAttentionMask
decoderAttentionMask :: decoderAttentionMask
attentionMask :: attentionMask
decoderPos :: decoderPos
pos :: pos
decoderInput :: decoderInput
input :: input
crossAttentionMask :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
decoderAttentionMask :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
attentionMask :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; attentionMask
decoderPos :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
pos :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; pos
decoderInput :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
input :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
SequenceToSequenceTransformerInput
  input
  decoderInput
  pos
  decoderPos
  attentionMask
  decoderAttentionMask
  crossAttentionMask
-&gt; input
</span><a href="#local-6989586621679811986"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-464"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679811985"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811985"><span class="hs-identifier hs-var">s</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked StateDictKey) (IsChecked Integer)
-&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked StateDictKey) (IsChecked Integer)
 -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked StateDictKey) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; Dim (IsChecked StateDictKey) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679811997"><span class="hs-identifier hs-var">seqToSeqInputEmbedDim</span></a></span><span>
</span><span id="line-465"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-type">embedScaling</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-466"></span><span>          </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812492"><span class="annot"><a href="#local-6989586621679812492"><span class="hs-identifier hs-type">requiresGradient</span></a></span></span><span> </span><span id="local-6989586621679812491"><span class="annot"><a href="#local-6989586621679812491"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679812490"><span class="annot"><a href="#local-6989586621679812490"><span class="hs-identifier hs-type">device'''</span></a></span></span><span> </span><span id="local-6989586621679812489"><span class="annot"><a href="#local-6989586621679812489"><span class="hs-identifier hs-type">dataType'''</span></a></span></span><span> </span><span id="local-6989586621679812488"><span class="annot"><a href="#local-6989586621679812488"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-467"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-468"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812492"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812491"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812490"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812489"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812488"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-469"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812492"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812491"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812490"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812489"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812488"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-470"></span><span>        </span><span id="local-6989586621679811982"><span class="annot"><span class="annottext">embedScaling :: STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679811982"><span class="hs-identifier hs-var hs-var">embedScaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-471"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-472"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-473"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-474"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device''' dataType''' shape
 -&gt; Double
 -&gt; Tensor requiresGradient layout device''' dataType''' shape)
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811985"><span class="hs-identifier hs-var">s</span></a></span><span>
</span><span id="line-475"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-476"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-477"></span><span>        </span><span class="annot"><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-478"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (SequenceToSequenceTransformerOutput headOutput encoderOutput)
-&gt; Generator generatorDevice
-&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
      Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   (SequenceToSequenceTransformerOutput headOutput encoderOutput)
 -&gt; Generator generatorDevice
 -&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
-&gt; Generator generatorDevice
-&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
      Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-479"></span><span>          </span><span class="annot"><span class="annottext">input
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) input
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679811992"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-480"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) input
-&gt; (input
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator embeddingGeneratorOutputDevice)
         (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor requiresGradient' layout' device' dataType' shape')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor requiresGradient' layout' device' dataType' shape',
       Generator embeddingGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor requiresGradient' layout' device' dataType' shape')
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor requiresGradient' layout' device' dataType' shape',
        Generator embeddingGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator embeddingGeneratorOutputDevice)
      (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; (input
    -&gt; Generator generatorDevice
    -&gt; m (Tensor requiresGradient' layout' device' dataType' shape',
          Generator embeddingGeneratorOutputDevice))
-&gt; input
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor requiresGradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (Tensor requiresGradient' layout' device' dataType' shape',
      Generator embeddingGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679811994"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-481"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor requiresGradient' layout' device' dataType' shape')
-&gt; (Tensor requiresGradient' layout' device' dataType' shape'
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice)
         (Generator embeddingGeneratorOutputDevice)
         (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor requiresGradient' layout' device' dataType' shape')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient' layout' device' dataType' shape'
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor requiresGradient' layout' device' dataType' shape')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient' layout' device' dataType' shape'
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice)
      (Generator embeddingGeneratorOutputDevice)
      (Tensor requiresGradient' layout' device' dataType' shape'))
-&gt; (Tensor requiresGradient' layout' device' dataType' shape'
    -&gt; Tensor requiresGradient' layout' device' dataType' shape')
-&gt; Tensor requiresGradient' layout' device' dataType' shape'
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice)
     (Tensor requiresGradient' layout' device' dataType' shape')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Tensor requiresGradient' layout' device' dataType' shape'
-&gt; Tensor requiresGradient' layout' device' dataType' shape'
forall (requiresGradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType)
       (device''' :: Device (DeviceType Nat))
       (dataType''' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-482"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice)
  (Tensor requiresGradient' layout' device' dataType' shape')
-&gt; (Tensor requiresGradient' layout' device' dataType' shape'
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice)
         (Generator encoderGeneratorOutputDevice)
         encoderOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679811979"><span class="annot"><span class="annottext">Tensor requiresGradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679811979"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator embeddingGeneratorOutputDevice
 -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator embeddingGeneratorOutputDevice
  -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice)
      (Generator encoderGeneratorOutputDevice)
      encoderOutput)
-&gt; (Generator embeddingGeneratorOutputDevice
    -&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice)
     (Generator encoderGeneratorOutputDevice)
     encoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor requiresGradient' layout' device' dataType' shape', pos,
    attentionMask)
-&gt; Generator embeddingGeneratorOutputDevice
-&gt; m (encoderOutput, Generator encoderGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerEncoder
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679811996"><span class="hs-identifier hs-var">seqToSeqEncoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679811979"><span class="hs-identifier hs-var">input'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">pos
</span><a href="#local-6989586621679811990"><span class="hs-identifier hs-var">pos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionMask
</span><a href="#local-6989586621679811988"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-483"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator encoderGeneratorOutputDevice)
  encoderOutput
-&gt; (encoderOutput
    -&gt; IxStateT
         m
         (Generator encoderGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         (SequenceToSequenceTransformerOutput headOutput encoderOutput))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679811978"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679811978"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-484"></span><span>                     </span><span class="annot"><span class="annottext">decoderInput
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator encoderGeneratorOutputDevice)
     decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679811991"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-485"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator encoderGeneratorOutputDevice)
  (Generator encoderGeneratorOutputDevice)
  decoderInput
-&gt; (decoderInput
    -&gt; IxStateT
         m
         (Generator encoderGeneratorOutputDevice)
         (Generator embeddingGeneratorOutputDevice')
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator encoderGeneratorOutputDevice
 -&gt; m (Tensor
         requiresGradient'' layout'' device'' dataType'' shape'',
       Generator embeddingGeneratorOutputDevice'))
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator encoderGeneratorOutputDevice
  -&gt; m (Tensor
          requiresGradient'' layout'' device'' dataType'' shape'',
        Generator embeddingGeneratorOutputDevice'))
 -&gt; IxStateT
      m
      (Generator encoderGeneratorOutputDevice)
      (Generator embeddingGeneratorOutputDevice')
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (decoderInput
    -&gt; Generator encoderGeneratorOutputDevice
    -&gt; m (Tensor
            requiresGradient'' layout'' device'' dataType'' shape'',
          Generator embeddingGeneratorOutputDevice'))
-&gt; decoderInput
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; decoderInput
-&gt; Generator encoderGeneratorOutputDevice
-&gt; m (Tensor
        requiresGradient'' layout'' device'' dataType'' shape'',
      Generator embeddingGeneratorOutputDevice')
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679811994"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-486"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator encoderGeneratorOutputDevice)
  (Generator embeddingGeneratorOutputDevice')
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice')
         (Generator embeddingGeneratorOutputDevice')
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient'' layout'' device'' dataType'' shape''
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice')
      (Generator embeddingGeneratorOutputDevice')
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
forall (requiresGradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType)
       (device''' :: Device (DeviceType Nat))
       (dataType''' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679811982"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679812043"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator encoderGeneratorOutputDevice)
  (Generator embeddingGeneratorOutputDevice')
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice')
         (Generator decoderGeneratorOutputDevice)
         decoderOutput)
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator decoderGeneratorOutputDevice)
     decoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679811977"><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679811977"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-488"></span><span>                                </span><span class="annot"><span class="annottext">(Generator embeddingGeneratorOutputDevice'
 -&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator decoderGeneratorOutputDevice)
     decoderOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator embeddingGeneratorOutputDevice'
  -&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice')
      (Generator decoderGeneratorOutputDevice)
      decoderOutput)
-&gt; (Generator embeddingGeneratorOutputDevice'
    -&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator decoderGeneratorOutputDevice)
     decoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
    encoderOutput, decoderPos, decoderAttentionMask,
    crossAttentionMask)
-&gt; Generator embeddingGeneratorOutputDevice'
-&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679811995"><span class="hs-identifier hs-var">seqToSeqDecoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679811977"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679811978"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderPos
</span><a href="#local-6989586621679811989"><span class="hs-identifier hs-var">decoderPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderAttentionMask
</span><a href="#local-6989586621679811987"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionMask
</span><a href="#local-6989586621679811986"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-489"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-490"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator encoderGeneratorOutputDevice)
  (Generator decoderGeneratorOutputDevice)
  decoderOutput
-&gt; (decoderOutput
    -&gt; IxStateT
         m
         (Generator decoderGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         headOutput)
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator decoderGeneratorOutputDevice
 -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator decoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator decoderGeneratorOutputDevice
  -&gt; m (headOutput, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator decoderGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      headOutput)
-&gt; (decoderOutput
    -&gt; Generator decoderGeneratorOutputDevice
    -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; decoderOutput
-&gt; IxStateT
     m
     (Generator decoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; decoderOutput
-&gt; Generator decoderGeneratorOutputDevice
-&gt; m (headOutput, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
</span><a href="#local-6989586621679811993"><span class="hs-identifier hs-var">seqToSeqHead</span></a></span><span>
</span><span id="line-491"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator encoderGeneratorOutputDevice)
  (Generator generatorOutputDevice)
  headOutput
-&gt; (headOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (SequenceToSequenceTransformerOutput headOutput encoderOutput))
-&gt; IxStateT
     m
     (Generator encoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679811976"><span class="annot"><span class="annottext">headOutput
</span><a href="#local-6989586621679811976"><span class="hs-identifier hs-var">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput headOutput encoderOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">headOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput headOutput encoderOutput
forall decoderOutput encoderOutput.
decoderOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput decoderOutput encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><span class="annottext">headOutput
</span><a href="#local-6989586621679811976"><span class="hs-identifier hs-var">decoderOutput</span></a></span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679811978"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-492"></span><span>                 </span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-493"></span><span>
</span><span id="line-494"></span><span class="hs-comment">-- | 'HasForward' instance for sequence-to-sequence transformers without language modelling head.</span><span>
</span><span id="line-495"></span><span class="hs-comment">-- Use this instance for sequence generation once the encoder's output is available.</span><span>
</span><span id="line-496"></span><span class="hs-comment">--</span><span>
</span><span id="line-497"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-498"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-499"></span><span class="hs-comment">-- &#9474; encoderOutput &#9474;  &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-500"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-501"></span><span class="hs-comment">--         &#9474;                  &#9474;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-502"></span><span class="hs-comment">--         &#9474;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-503"></span><span class="hs-comment">--         &#9474;          seqToSeqEmbedding        &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-504"></span><span class="hs-comment">--         &#9474;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-505"></span><span class="hs-comment">--         &#9474;            (embedScaling)         &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-506"></span><span class="hs-comment">--         &#9474;                  &#9660;                &#9474;                    &#9474;                        &#9474;</span><span>
</span><span id="line-507"></span><span class="hs-comment">--         &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;seqToSeqDecoder&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-508"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-509"></span><span class="hs-comment">--         &#9474;           (seqToSeqLMHead)</span><span>
</span><span id="line-510"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-511"></span><span class="hs-comment">--         &#9660;                  &#9660;</span><span>
</span><span id="line-512"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-513"></span><span class="hs-comment">-- &#9474; encoderOutput &#9474;  &#9474; decoderOutput &#9474;</span><span>
</span><span id="line-514"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-515"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-516"></span><span id="local-6989586621679811945"><span id="local-6989586621679811946"><span id="local-6989586621679811947"><span id="local-6989586621679811948"><span id="local-6989586621679811949"><span id="local-6989586621679811950"><span id="local-6989586621679811951"><span id="local-6989586621679811952"><span id="local-6989586621679811953"><span id="local-6989586621679811954"><span id="local-6989586621679811955"><span id="local-6989586621679811956"><span id="local-6989586621679811957"><span id="local-6989586621679811958"><span id="local-6989586621679811959"><span id="local-6989586621679811960"><span id="local-6989586621679811961"><span id="local-6989586621679811962"><span id="local-6989586621679811963"><span id="local-6989586621679811964"><span id="local-6989586621679811965"><span id="local-6989586621679811966"><span id="local-6989586621679811967"><span id="local-6989586621679811968"><span id="local-6989586621679811969"><span id="local-6989586621679811970"><span id="local-6989586621679811971"><span id="local-6989586621679811972"><span id="local-6989586621679811973"><span id="local-6989586621679811974"><span id="local-6989586621679811975"><span class="hs-keyword">instance</span><span>
</span><span id="line-517"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811975"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-518"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-519"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceEmbeddingF"><span class="hs-identifier hs-type">SequenceToSequenceEmbeddingF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811975"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811974"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811973"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811972"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811971"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811970"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-520"></span><span>      </span><span class="annot"><a href="#local-6989586621679811969"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-521"></span><span>      </span><span class="annot"><a href="#local-6989586621679811968"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-522"></span><span>      </span><span class="annot"><a href="#local-6989586621679811967"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span>
</span><span id="line-523"></span><span>      </span><span class="annot"><a href="#local-6989586621679811966"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-524"></span><span>    </span><span class="annot"><a href="#local-6989586621679811967"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811965"><span class="hs-identifier hs-type">requiresGradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811964"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811963"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811962"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811961"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-525"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-526"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceDecoderF"><span class="hs-identifier hs-type">SequenceToSequenceDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811975"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811960"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811974"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811973"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811972"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811959"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811958"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811957"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811971"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811956"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811955"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-527"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679811967"><span class="hs-identifier hs-type">embeddingOutput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-528"></span><span>        </span><span class="annot"><a href="#local-6989586621679811954"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-529"></span><span>        </span><span class="annot"><a href="#local-6989586621679811953"><span class="hs-identifier hs-type">decoderPos</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-530"></span><span>        </span><span class="annot"><a href="#local-6989586621679811952"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-531"></span><span>        </span><span class="annot"><a href="#local-6989586621679811951"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span>
</span><span id="line-532"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-533"></span><span>      </span><span class="annot"><a href="#local-6989586621679811966"><span class="hs-identifier hs-type">embeddingGeneratorOutputDevice'</span></a></span><span>
</span><span id="line-534"></span><span>      </span><span class="annot"><a href="#local-6989586621679811950"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-535"></span><span>      </span><span class="annot"><a href="#local-6989586621679811949"><span class="hs-identifier hs-type">decoderGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-536"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-537"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceHeadF"><span class="hs-identifier hs-type">SequenceToSequenceHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811975"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811948"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811974"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811973"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811972"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811971"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811970"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-538"></span><span>      </span><span class="annot"><a href="#local-6989586621679811950"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-539"></span><span>      </span><span class="annot"><a href="#local-6989586621679811949"><span class="hs-identifier hs-type">decoderGeneratorOutputDevice</span></a></span><span>
</span><span id="line-540"></span><span>      </span><span class="annot"><a href="#local-6989586621679811947"><span class="hs-identifier hs-type">headOutput</span></a></span><span>
</span><span id="line-541"></span><span>      </span><span class="annot"><a href="#local-6989586621679811946"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-542"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-543"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-544"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811975"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811948"><span class="hs-identifier hs-type">transformerHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811945"><span class="hs-identifier hs-type">numEncoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811960"><span class="hs-identifier hs-type">numDecoderLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811974"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811973"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811972"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811959"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811958"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811957"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811971"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811956"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811955"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811970"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-545"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811969"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811954"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811953"><span class="hs-identifier hs-type">decoderPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811952"><span class="hs-identifier hs-type">decoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811951"><span class="hs-identifier hs-type">crossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-546"></span><span>    </span><span class="annot"><a href="#local-6989586621679811968"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-547"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811947"><span class="hs-identifier hs-type">headOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811954"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-548"></span><span>    </span><span class="annot"><a href="#local-6989586621679811946"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-549"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-550"></span><span>  </span><span id="local-6989586621679811943"><span class="annot"><span class="annottext">forward :: SequenceToSequenceTransformer
  style
  transformerHead
  numEncoderLayers
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
  vocabDim
-&gt; SequenceToSequenceTransformerGenerationInput
     decoderInput
     encoderOutput
     decoderPos
     decoderAttentionMask
     crossAttentionMask
-&gt; Generator generatorDevice
-&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
      Generator generatorOutputDevice)
</span><a href="#local-6989586621679811943"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformer"><span class="hs-identifier hs-type">SequenceToSequenceTransformer</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#GSequenceToSequenceTransformer"><span class="hs-identifier hs-type">GSequenceToSequenceTransformer</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679811938"><span id="local-6989586621679811939"><span id="local-6989586621679811940"><span id="local-6989586621679811941"><span id="local-6989586621679811942"><span class="annot"><span class="annottext">SDim inputEmbedDim
SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqHead :: SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
seqToSeqEmbedding :: SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
seqToSeqDecoder :: SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqEncoder :: SequenceToSequenceEncoderF
  style
  numEncoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
seqToSeqInputEmbedDim :: SDim inputEmbedDim
seqToSeqHead :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; head
seqToSeqEmbedding :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; embedding
seqToSeqDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; decoder
seqToSeqEncoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; encoder
seqToSeqInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) encoder
       decoder embedding head.
GSequenceToSequenceTransformer
  inputEmbedDim encoder decoder embedding head
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679811938"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerGenerationInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerGenerationInput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679811933"><span id="local-6989586621679811934"><span id="local-6989586621679811935"><span id="local-6989586621679811936"><span id="local-6989586621679811937"><span class="annot"><span class="annottext">decoderInput
encoderOutput
decoderPos
decoderAttentionMask
crossAttentionMask
generationCrossAttentionMask :: crossAttentionMask
generationDecoderAttentionMask :: decoderAttentionMask
generationDecoderPos :: decoderPos
generationEncoderOutput :: encoderOutput
generationDecoderInput :: decoderInput
generationCrossAttentionMask :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; crossAttentionMask
generationDecoderAttentionMask :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderAttentionMask
generationDecoderPos :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderPos
generationEncoderOutput :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; encoderOutput
generationDecoderInput :: forall decoderInput encoderOutput decoderPos decoderAttentionMask
       crossAttentionMask.
SequenceToSequenceTransformerGenerationInput
  decoderInput
  encoderOutput
  decoderPos
  decoderAttentionMask
  crossAttentionMask
-&gt; decoderInput
</span><a href="#local-6989586621679811933"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-551"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679811932"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811932"><span class="hs-identifier hs-var">s</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked StateDictKey) (IsChecked Integer)
-&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked StateDictKey) (IsChecked Integer)
 -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked StateDictKey) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; Dim (IsChecked StateDictKey) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679811942"><span class="hs-identifier hs-var">seqToSeqInputEmbedDim</span></a></span><span>
</span><span id="line-552"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-type">embedScaling</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-553"></span><span>          </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679812443"><span class="annot"><a href="#local-6989586621679812443"><span class="hs-identifier hs-type">requiresGradient</span></a></span></span><span> </span><span id="local-6989586621679812442"><span class="annot"><a href="#local-6989586621679812442"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679812441"><span class="annot"><a href="#local-6989586621679812441"><span class="hs-identifier hs-type">device'''</span></a></span></span><span> </span><span id="local-6989586621679812440"><span class="annot"><a href="#local-6989586621679812440"><span class="hs-identifier hs-type">dataType'''</span></a></span></span><span> </span><span id="local-6989586621679812439"><span class="annot"><a href="#local-6989586621679812439"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-554"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679811975"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-555"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812443"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812442"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812441"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812440"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812439"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-556"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812443"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812442"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812441"><span class="hs-identifier hs-type">device'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812440"><span class="hs-identifier hs-type">dataType'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679812439"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-557"></span><span>        </span><span id="local-6989586621679811931"><span class="annot"><span class="annottext">embedScaling :: STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679811931"><span class="hs-identifier hs-var hs-var">embedScaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-558"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-559"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-560"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-561"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device''' dataType''' shape
 -&gt; Double
 -&gt; Tensor requiresGradient layout device''' dataType''' shape)
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Double
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811932"><span class="hs-identifier hs-var">s</span></a></span><span>
</span><span id="line-562"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-563"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-564"></span><span>        </span><span class="annot"><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-565"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (SequenceToSequenceTransformerOutput headOutput encoderOutput)
-&gt; Generator generatorDevice
-&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
      Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   (SequenceToSequenceTransformerOutput headOutput encoderOutput)
 -&gt; Generator generatorDevice
 -&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
-&gt; Generator generatorDevice
-&gt; m (SequenceToSequenceTransformerOutput headOutput encoderOutput,
      Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-566"></span><span>          </span><span class="annot"><span class="annottext">decoderInput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679811937"><span class="hs-identifier hs-var">generationDecoderInput</span></a></span><span>
</span><span id="line-567"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  decoderInput
-&gt; (decoderInput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator embeddingGeneratorOutputDevice')
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         requiresGradient'' layout'' device'' dataType'' shape'',
       Generator embeddingGeneratorOutputDevice'))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          requiresGradient'' layout'' device'' dataType'' shape'',
        Generator embeddingGeneratorOutputDevice'))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator embeddingGeneratorOutputDevice')
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (decoderInput
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            requiresGradient'' layout'' device'' dataType'' shape'',
          Generator embeddingGeneratorOutputDevice'))
-&gt; decoderInput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
-&gt; decoderInput
-&gt; Generator generatorDevice
-&gt; m (Tensor
        requiresGradient'' layout'' device'' dataType'' shape'',
      Generator embeddingGeneratorOutputDevice')
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  vocabDim
  inputEmbedDim
  'Nothing
SequenceToSequenceEmbeddingF
  style gradient device dataType inputEmbedDim vocabDim
</span><a href="#local-6989586621679811939"><span class="hs-identifier hs-var">seqToSeqEmbedding</span></a></span><span>
</span><span id="line-568"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice')
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice')
         (Generator embeddingGeneratorOutputDevice')
         (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient'' layout'' device'' dataType'' shape''
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice')
      (Generator embeddingGeneratorOutputDevice')
      (Tensor requiresGradient'' layout'' device'' dataType'' shape''))
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator embeddingGeneratorOutputDevice')
     (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
-&gt; Tensor requiresGradient'' layout'' device'' dataType'' shape''
forall (requiresGradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType)
       (device''' :: Device (DeviceType Nat))
       (dataType''' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
STransformerStyle style
-&gt; Tensor requiresGradient layout device''' dataType''' shape
-&gt; Tensor requiresGradient layout device''' dataType''' shape
</span><a href="#local-6989586621679811931"><span class="hs-identifier hs-var">embedScaling</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679811975"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-569"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator embeddingGeneratorOutputDevice')
  (Tensor requiresGradient'' layout'' device'' dataType'' shape'')
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape''
    -&gt; IxStateT
         m
         (Generator embeddingGeneratorOutputDevice')
         (Generator decoderGeneratorOutputDevice)
         decoderOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator decoderGeneratorOutputDevice)
     decoderOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679811930"><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679811930"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-570"></span><span>                     </span><span class="annot"><span class="annottext">(Generator embeddingGeneratorOutputDevice'
 -&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator decoderGeneratorOutputDevice)
     decoderOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator embeddingGeneratorOutputDevice'
  -&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator embeddingGeneratorOutputDevice')
      (Generator decoderGeneratorOutputDevice)
      decoderOutput)
-&gt; (Generator embeddingGeneratorOutputDevice'
    -&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator embeddingGeneratorOutputDevice')
     (Generator decoderGeneratorOutputDevice)
     decoderOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor requiresGradient'' layout'' device'' dataType'' shape'',
    encoderOutput, decoderPos, decoderAttentionMask,
    crossAttentionMask)
-&gt; Generator embeddingGeneratorOutputDevice'
-&gt; m (decoderOutput, Generator decoderGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  inputEmbedDim
  ffnDim
  posEncDim
SequenceToSequenceDecoderF
  style
  numDecoderLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  inputEmbedDim
  ffnDim
  posEncDim
</span><a href="#local-6989586621679811940"><span class="hs-identifier hs-var">seqToSeqDecoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679811930"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679811936"><span class="hs-identifier hs-var">generationEncoderOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderPos
</span><a href="#local-6989586621679811935"><span class="hs-identifier hs-var">generationDecoderPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderAttentionMask
</span><a href="#local-6989586621679811934"><span class="hs-identifier hs-var">generationDecoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionMask
</span><a href="#local-6989586621679811933"><span class="hs-identifier hs-var">generationCrossAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-571"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-572"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator decoderGeneratorOutputDevice)
  decoderOutput
-&gt; (decoderOutput
    -&gt; IxStateT
         m
         (Generator decoderGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         headOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     headOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator decoderGeneratorOutputDevice
 -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator decoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator decoderGeneratorOutputDevice
  -&gt; m (headOutput, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator decoderGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      headOutput)
-&gt; (decoderOutput
    -&gt; Generator decoderGeneratorOutputDevice
    -&gt; m (headOutput, Generator generatorOutputDevice))
-&gt; decoderOutput
-&gt; IxStateT
     m
     (Generator decoderGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     headOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
-&gt; decoderOutput
-&gt; Generator decoderGeneratorOutputDevice
-&gt; m (headOutput, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceHeadF
  style
  transformerHead
  gradient
  device
  dataType
  inputEmbedDim
  vocabDim
</span><a href="#local-6989586621679811938"><span class="hs-identifier hs-var">seqToSeqHead</span></a></span><span>
</span><span id="line-573"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  headOutput
-&gt; (headOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (SequenceToSequenceTransformerOutput headOutput encoderOutput))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679811929"><span class="annot"><span class="annottext">headOutput
</span><a href="#local-6989586621679811929"><span class="hs-identifier hs-var">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput headOutput encoderOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (SequenceToSequenceTransformerOutput headOutput encoderOutput)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">headOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput headOutput encoderOutput
forall decoderOutput encoderOutput.
decoderOutput
-&gt; encoderOutput
-&gt; SequenceToSequenceTransformerOutput decoderOutput encoderOutput
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerOutput"><span class="hs-identifier hs-var">SequenceToSequenceTransformerOutput</span></a></span><span> </span><span class="annot"><span class="annottext">headOutput
</span><a href="#local-6989586621679811929"><span class="hs-identifier hs-var">decoderOutput</span></a></span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679811936"><span class="hs-identifier hs-var">generationEncoderOutput</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-574"></span><span>
</span><span id="line-575"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#testSeqToSeq"><span class="hs-identifier hs-type">testSeqToSeq</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-576"></span><span id="testSeqToSeq"><span class="annot"><span class="annottext">testSeqToSeq :: IO
  ((SequenceToSequenceTransformerOutput
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
               'Dim ('Name &quot;*&quot;) ('Size 32128)]))
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
               'Dim ('Name &quot;*&quot;) ('Size 512)])),
    SequenceToSequenceTransformerOutput
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
               'Dim ('Name &quot;*&quot;) ('Size 32128)]))
      (Tensor
         ('Gradient 'WithGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
               'Dim ('Name &quot;*&quot;) ('Size 512)]))),
   Generator ('Device 'CPU))
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#testSeqToSeq"><span class="hs-identifier hs-var hs-var">testSeqToSeq</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-577"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679811927"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679811927"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-578"></span><span>      </span><span id="local-6989586621679811924"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679811924"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-579"></span><span>      </span><span id="local-6989586621679811921"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679811921"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-580"></span><span>      </span><span id="local-6989586621679811918"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679811918"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-581"></span><span>      </span><span id="local-6989586621679811915"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679811915"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-582"></span><span>      </span><span id="local-6989586621679811914"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679811914"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-583"></span><span>      </span><span id="local-6989586621679811913"><span class="annot"><span class="annottext">inputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679811913"><span class="hs-identifier hs-var hs-var">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-584"></span><span>      </span><span id="local-6989586621679811912"><span class="annot"><span class="annottext">ffnDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679811912"><span class="hs-identifier hs-var hs-var">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 2048) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 2048 =&gt; SSize ('Size 2048)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2048</span></span><span>
</span><span id="line-585"></span><span>      </span><span id="local-6989586621679811911"><span class="annot"><span class="annottext">posEncDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679811911"><span class="hs-identifier hs-var hs-var">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SSize ('Size 32)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span>
</span><span id="line-586"></span><span>      </span><span id="local-6989586621679811910"><span class="annot"><span class="annottext">vocabDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679811910"><span class="hs-identifier hs-var hs-var">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32128) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32128 =&gt; SSize ('Size 32128)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32128</span></span><span>
</span><span id="line-587"></span><span>      </span><span id="local-6989586621679811909"><span class="annot"><span class="annottext">dropoutP :: Double
</span><a href="#local-6989586621679811909"><span class="hs-identifier hs-var hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-588"></span><span>      </span><span id="local-6989586621679811908"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679811908"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-589"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679811907"><span class="annot"><span class="annottext">g :: Generator ('Device 'CPU)
</span><a href="#local-6989586621679811907"><span class="hs-identifier hs-var hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; Generator ('Device 'CPU)
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; Generator device
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679811924"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-590"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679811906"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679811906"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 3) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SSize ('Size 3)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-591"></span><span>      </span><span id="local-6989586621679811905"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 13) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 13 =&gt; SSize ('Size 13)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">13</span></span><span>
</span><span id="line-592"></span><span>      </span><span id="local-6989586621679811904"><span class="annot"><span class="annottext">decoderSeqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var hs-var">decoderSeqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 7) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 7 =&gt; SSize ('Size 7)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">7</span></span><span>
</span><span id="line-593"></span><span>      </span><span id="local-6989586621679811903"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  dataType
  shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   ('Device 'CPU)
   dataType
   shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((SShape shape
  -&gt; TensorSpec
       ('Gradient 'WithoutGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       dataType
       shape)
 -&gt; SShape shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SDataType dataType
    -&gt; SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679811924"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-594"></span><span>      </span><span id="local-6989586621679811900"><span class="annot"><span class="annottext">input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679811900"><span class="hs-identifier hs-var hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679811906"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-595"></span><span>      </span><span id="local-6989586621679811896"><span class="annot"><span class="annottext">attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679811896"><span class="hs-identifier hs-var hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679811921"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-596"></span><span>      </span><span id="local-6989586621679811895"><span class="annot"><span class="annottext">decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679811895"><span class="hs-identifier hs-var hs-var">decoderInput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679811906"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-597"></span><span>      </span><span id="local-6989586621679811894"><span class="annot"><span class="annottext">decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679811894"><span class="hs-identifier hs-var hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679811921"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-598"></span><span>      </span><span id="local-6989586621679811893"><span class="annot"><span class="annottext">crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679811893"><span class="hs-identifier hs-var hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679811921"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-599"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679811892"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 32128)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679811892"><span class="hs-identifier hs-var">t5Output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679811891"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811891"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-600"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679811890"><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'T5
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679811890"><span class="hs-identifier hs-var">t5</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679811889"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811889"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (SequenceToSequenceTransformer
     'T5
     'WithLMHead
     32
     32
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32))
     ('Dim ('Name &quot;*&quot;) ('Size 32128)))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (SequenceToSequenceTransformer
        'T5
        'WithLMHead
        32
        32
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 2048))
        ('Dim ('Name &quot;*&quot;) ('Size 32))
        ('Dim ('Name &quot;*&quot;) ('Size 32128)),
      Generator ('Device 'CPU))
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; STransformerHead 'WithLMHead
-&gt; SNat 32
-&gt; SNat 32
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
-&gt; Double
-&gt; Double
-&gt; SequenceToSequenceTransformerSpec
     'T5
     'WithLMHead
     32
     32
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32))
     ('Dim ('Name &quot;*&quot;) ('Size 32128))
forall (style :: TransformerStyle)
       (transformerHead :: TransformerHead) (numEncoderLayers :: Nat)
       (numDecoderLayers :: Nat) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SNat numEncoderLayers
-&gt; SNat numDecoderLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; Double
-&gt; SequenceToSequenceTransformerSpec
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-var">SequenceToSequenceTransformerSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead 'WithLMHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SNat 32
forall (n :: Nat). KnownNat n =&gt; SNat n
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SNat 32
forall (n :: Nat). KnownNat n =&gt; SNat n
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679811927"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679811924"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679811921"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679811918"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679811915"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679811914"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679811913"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679811912"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679811911"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679811910"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811909"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811908"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811907"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-601"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679811888"><span class="annot"><span class="annottext">pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679811888"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-602"></span><span>        </span><span id="local-6989586621679811887"><span class="annot"><span class="annottext">decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679811887"><span class="hs-identifier hs-var hs-var">decoderPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-603"></span><span>    </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'T5
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
-&gt; SequenceToSequenceTransformerInput
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (SequenceToSequenceTransformerOutput
        (Tensor
           ('Gradient 'WithGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
                 'Dim ('Name &quot;*&quot;) ('Size 32128)]))
        (Tensor
           ('Gradient 'WithGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
                 'Dim ('Name &quot;*&quot;) ('Size 512)])),
      Generator ('Device 'CPU))
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'T5
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679811890"><span class="hs-identifier hs-var">t5</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
input
-&gt; decoderInput
-&gt; pos
-&gt; decoderPos
-&gt; attentionMask
-&gt; decoderAttentionMask
-&gt; crossAttentionMask
-&gt; SequenceToSequenceTransformerInput
     input
     decoderInput
     pos
     decoderPos
     attentionMask
     decoderAttentionMask
     crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679811887"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span><span class="hs-special">}</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811889"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-604"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679811886"><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 32128)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679811886"><span class="hs-identifier hs-var">bartOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679811885"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811885"><span class="hs-identifier hs-var">g''''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-605"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679811884"><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'BART
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679811884"><span class="hs-identifier hs-var">bart</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679811883"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811883"><span class="hs-identifier hs-var">g'''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (SequenceToSequenceTransformer
     'BART
     'WithLMHead
     32
     32
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32))
     ('Dim ('Name &quot;*&quot;) ('Size 32128)))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (SequenceToSequenceTransformer
        'BART
        'WithLMHead
        32
        32
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 2048))
        ('Dim ('Name &quot;*&quot;) ('Size 32))
        ('Dim ('Name &quot;*&quot;) ('Size 32128)),
      Generator ('Device 'CPU))
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'BART
-&gt; STransformerHead 'WithLMHead
-&gt; SNat 32
-&gt; SNat 32
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
-&gt; Double
-&gt; Double
-&gt; SequenceToSequenceTransformerSpec
     'BART
     'WithLMHead
     32
     32
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32))
     ('Dim ('Name &quot;*&quot;) ('Size 32128))
forall (style :: TransformerStyle)
       (transformerHead :: TransformerHead) (numEncoderLayers :: Nat)
       (numDecoderLayers :: Nat) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (inputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat))
       (vocabDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; STransformerHead transformerHead
-&gt; SNat numEncoderLayers
-&gt; SNat numDecoderLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim inputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; Double
-&gt; SequenceToSequenceTransformerSpec
     style
     transformerHead
     numEncoderLayers
     numDecoderLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     inputEmbedDim
     ffnDim
     posEncDim
     vocabDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerSpec"><span class="hs-identifier hs-var">SequenceToSequenceTransformerSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BART
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerHead 'WithLMHead
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SWithLMHead"><span class="hs-identifier hs-var">SWithLMHead</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SNat 32
forall (n :: Nat). KnownNat n =&gt; SNat n
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SNat 32
forall (n :: Nat). KnownNat n =&gt; SNat n
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679811927"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679811924"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679811921"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679811918"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679811915"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679811914"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679811913"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679811912"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679811911"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679811910"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811909"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679811908"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811891"><span class="hs-identifier hs-var">g''</span></a></span><span>
</span><span id="line-606"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679811882"><span class="annot"><span class="annottext">pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679811882"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679811905"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-607"></span><span>        </span><span id="local-6989586621679811881"><span class="annot"><span class="annottext">decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679811881"><span class="hs-identifier hs-var hs-var">decoderPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679811903"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679811904"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-608"></span><span>    </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'BART
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
-&gt; SequenceToSequenceTransformerInput
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 7)]))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (SequenceToSequenceTransformerOutput
        (Tensor
           ('Gradient 'WithGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
                 'Dim ('Name &quot;*&quot;) ('Size 32128)]))
        (Tensor
           ('Gradient 'WithGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
                 'Dim ('Name &quot;*&quot;) ('Size 512)])),
      Generator ('Device 'CPU))
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformer
  'BART
  'WithLMHead
  32
  32
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  ('Dim ('Name &quot;*&quot;) ('Size 32128))
</span><a href="#local-6989586621679811884"><span class="hs-identifier hs-var">bart</span></a></span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerInput :: forall input decoderInput pos decoderPos attentionMask
       decoderAttentionMask crossAttentionMask.
input
-&gt; decoderInput
-&gt; pos
-&gt; decoderPos
-&gt; attentionMask
-&gt; decoderAttentionMask
-&gt; crossAttentionMask
-&gt; SequenceToSequenceTransformerInput
     input
     decoderInput
     pos
     decoderPos
     attentionMask
     decoderAttentionMask
     crossAttentionMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.SequenceToSequence.html#SequenceToSequenceTransformerInput"><span class="hs-identifier hs-type">SequenceToSequenceTransformerInput</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
attentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)])
pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 13)])
decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)])
input :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679811881"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span><span class="hs-special">}</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811883"><span class="hs-identifier hs-var">g'''</span></a></span><span>
</span><span id="line-609"></span><span>  </span><span class="annot"><span class="annottext">((SequenceToSequenceTransformerOutput
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
             'Dim ('Name &quot;*&quot;) ('Size 32128)]))
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
             'Dim ('Name &quot;*&quot;) ('Size 512)])),
  SequenceToSequenceTransformerOutput
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
             'Dim ('Name &quot;*&quot;) ('Size 32128)]))
    (Tensor
       ('Gradient 'WithGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
             'Dim ('Name &quot;*&quot;) ('Size 512)]))),
 Generator ('Device 'CPU))
-&gt; IO
     ((SequenceToSequenceTransformerOutput
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
                  'Dim ('Name &quot;*&quot;) ('Size 32128)]))
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
                  'Dim ('Name &quot;*&quot;) ('Size 512)])),
       SequenceToSequenceTransformerOutput
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
                  'Dim ('Name &quot;*&quot;) ('Size 32128)]))
         (Tensor
            ('Gradient 'WithGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
                  'Dim ('Name &quot;*&quot;) ('Size 512)]))),
      Generator ('Device 'CPU))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 32128)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679811892"><span class="hs-identifier hs-var">t5Output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SequenceToSequenceTransformerOutput
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 32128)]))
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="#local-6989586621679811886"><span class="hs-identifier hs-var">bartOutput</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679811885"><span class="hs-identifier hs-var">g''''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-610"></span></pre></body></html>