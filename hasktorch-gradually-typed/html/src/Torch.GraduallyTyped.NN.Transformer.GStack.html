<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FunctionalDependencies #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-12"></span><span>
</span><span id="line-13"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GStack</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-14"></span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/9vd3i68x2pzxh3qw451rcslqd0w6f46f-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/cdv23r2x3jsa4zy3rx4k8dq2s3magv3j-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/548vldv3qjqlzpixqp52j6jawbid5vk9-vector-lib-vector-0.12.3.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier">Data.Vector</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">V</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/548vldv3qjqlzpixqp52j6jawbid5vk9-vector-lib-vector-0.12.3.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier">uncons</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Generic.Sized.Internal</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">VGS</span></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Sized</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">VS</span></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><span class="hs-operator">(+)</span></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Internal.Vector.html"><span class="hs-identifier">Torch.GraduallyTyped.Internal.Vector</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">V</span></span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#VectorSpec"><span class="hs-identifier">VectorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GBlock</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockF"><span class="hs-identifier">DecoderBlockF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockF"><span class="hs-identifier">EncoderBlockF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#decoderBlockSpec"><span class="hs-identifier">decoderBlockSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#encoderBlockSpec"><span class="hs-identifier">encoderBlockSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier">HasDropout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier">SHasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.TypeLits.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SNat</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span>
</span><span id="line-34"></span><span class="hs-comment">-- | Generic transformer stack.</span><span>
</span><span id="line-35"></span><span class="hs-comment">--</span><span>
</span><span id="line-36"></span><span class="hs-comment">-- - @stack@ is a stack of tranformer blocks.</span><span>
</span><span id="line-37"></span><span id="local-6989586621679697423"><span id="local-6989586621679697424"></span></span><span class="hs-keyword">newtype</span><span> </span><span id="GTransformerStack"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697755"><span class="annot"><a href="#local-6989586621679697755"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-38"></span><span>  </span><span id="GTransformerStack"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679697678"><span class="annot"><a href="#local-6989586621679697678"><span class="hs-identifier hs-type">stack</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="#local-6989586621679697678"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697678"><span class="hs-identifier hs-type">stack</span></a></span><span>
</span><span id="line-39"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697417"><span id="local-6989586621679697420"><span class="annot"><span class="annottext">GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
(GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool)
-&gt; (GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool)
-&gt; Eq (GTransformerStack stack)
forall stack.
Eq stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
$c/= :: forall stack.
Eq stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
== :: GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
$c== :: forall stack.
Eq stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697395"><span id="local-6989586621679697397"><span id="local-6989586621679697400"><span id="local-6989586621679697403"><span id="local-6989586621679697406"><span id="local-6989586621679697409"><span id="local-6989586621679697412"><span class="annot"><span class="annottext">Eq (GTransformerStack stack)
Eq (GTransformerStack stack)
-&gt; (GTransformerStack stack -&gt; GTransformerStack stack -&gt; Ordering)
-&gt; (GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool)
-&gt; (GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool)
-&gt; (GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool)
-&gt; (GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool)
-&gt; (GTransformerStack stack
    -&gt; GTransformerStack stack -&gt; GTransformerStack stack)
-&gt; (GTransformerStack stack
    -&gt; GTransformerStack stack -&gt; GTransformerStack stack)
-&gt; Ord (GTransformerStack stack)
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Ordering
GTransformerStack stack
-&gt; GTransformerStack stack -&gt; GTransformerStack stack
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall {stack}. Ord stack =&gt; Eq (GTransformerStack stack)
forall stack.
Ord stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
forall stack.
Ord stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Ordering
forall stack.
Ord stack =&gt;
GTransformerStack stack
-&gt; GTransformerStack stack -&gt; GTransformerStack stack
min :: GTransformerStack stack
-&gt; GTransformerStack stack -&gt; GTransformerStack stack
$cmin :: forall stack.
Ord stack =&gt;
GTransformerStack stack
-&gt; GTransformerStack stack -&gt; GTransformerStack stack
max :: GTransformerStack stack
-&gt; GTransformerStack stack -&gt; GTransformerStack stack
$cmax :: forall stack.
Ord stack =&gt;
GTransformerStack stack
-&gt; GTransformerStack stack -&gt; GTransformerStack stack
&gt;= :: GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
$c&gt;= :: forall stack.
Ord stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
&gt; :: GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
$c&gt; :: forall stack.
Ord stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
&lt;= :: GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
$c&lt;= :: forall stack.
Ord stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
&lt; :: GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
$c&lt; :: forall stack.
Ord stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Bool
compare :: GTransformerStack stack -&gt; GTransformerStack stack -&gt; Ordering
$ccompare :: forall stack.
Ord stack =&gt;
GTransformerStack stack -&gt; GTransformerStack stack -&gt; Ordering
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697385"><span id="local-6989586621679697387"><span id="local-6989586621679697392"><span class="annot"><span class="annottext">Int -&gt; GTransformerStack stack -&gt; ShowS
[GTransformerStack stack] -&gt; ShowS
GTransformerStack stack -&gt; String
(Int -&gt; GTransformerStack stack -&gt; ShowS)
-&gt; (GTransformerStack stack -&gt; String)
-&gt; ([GTransformerStack stack] -&gt; ShowS)
-&gt; Show (GTransformerStack stack)
forall stack. Show stack =&gt; Int -&gt; GTransformerStack stack -&gt; ShowS
forall stack. Show stack =&gt; [GTransformerStack stack] -&gt; ShowS
forall stack. Show stack =&gt; GTransformerStack stack -&gt; String
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [GTransformerStack stack] -&gt; ShowS
$cshowList :: forall stack. Show stack =&gt; [GTransformerStack stack] -&gt; ShowS
show :: GTransformerStack stack -&gt; String
$cshow :: forall stack. Show stack =&gt; GTransformerStack stack -&gt; String
showsPrec :: Int -&gt; GTransformerStack stack -&gt; ShowS
$cshowsPrec :: forall stack. Show stack =&gt; Int -&gt; GTransformerStack stack -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 GTransformerStack stack -&gt; Rep (GTransformerStack stack) x)
-&gt; (forall x.
    Rep (GTransformerStack stack) x -&gt; GTransformerStack stack)
-&gt; Generic (GTransformerStack stack)
forall x.
Rep (GTransformerStack stack) x -&gt; GTransformerStack stack
forall x.
GTransformerStack stack -&gt; Rep (GTransformerStack stack) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall stack x.
Rep (GTransformerStack stack) x -&gt; GTransformerStack stack
forall stack x.
GTransformerStack stack -&gt; Rep (GTransformerStack stack) x
$cto :: forall stack x.
Rep (GTransformerStack stack) x -&gt; GTransformerStack stack
$cfrom :: forall stack x.
GTransformerStack stack -&gt; Rep (GTransformerStack stack) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span>
</span><span id="line-41"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-42"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span id="local-6989586621679697380"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697380"><span class="hs-identifier hs-type">stack</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-43"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697380"><span class="hs-identifier hs-type">stack</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span>
</span><span id="line-45"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-46"></span><span>  </span><span id="EncoderStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#EncoderStackF"><span class="hs-identifier hs-var">EncoderStackF</span></a></span></span><span>
</span><span id="line-47"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697379"><span class="annot"><a href="#local-6989586621679697379"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697378"><span class="annot"><a href="#local-6989586621679697378"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697377"><span class="annot"><a href="#local-6989586621679697377"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697376"><span class="annot"><a href="#local-6989586621679697376"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697375"><span class="annot"><a href="#local-6989586621679697375"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697374"><span class="annot"><a href="#local-6989586621679697374"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697373"><span class="annot"><a href="#local-6989586621679697373"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697372"><span class="annot"><a href="#local-6989586621679697372"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697371"><span class="annot"><a href="#local-6989586621679697371"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697370"><span class="annot"><a href="#local-6989586621679697370"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697369"><span class="annot"><a href="#local-6989586621679697369"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-59"></span><span>  </span><span id="EncoderStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#EncoderStackF"><span class="hs-identifier hs-var">EncoderStackF</span></a></span></span><span> </span><span id="local-6989586621679697358"><span id="local-6989586621679697359"><span id="local-6989586621679697360"><span id="local-6989586621679697361"><span id="local-6989586621679697362"><span id="local-6989586621679697363"><span id="local-6989586621679697364"><span id="local-6989586621679697365"><span id="local-6989586621679697366"><span id="local-6989586621679697367"><span id="local-6989586621679697368"><span class="annot"><a href="#local-6989586621679697368"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697367"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697366"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697365"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697364"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697363"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697362"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697361"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697360"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697359"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697358"><span class="hs-identifier hs-type">hasDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-60"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span>
</span><span id="line-61"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span>
</span><span id="line-62"></span><span>          </span><span class="annot"><a href="#local-6989586621679697367"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-63"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockF"><span class="hs-identifier hs-type">EncoderBlockF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697368"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697366"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697365"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697364"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697363"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697362"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697361"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697360"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697359"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697358"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span>
</span><span id="line-66"></span><span class="hs-comment">-- | Specifies the parameters of a transformer stack in an encoder configuration.</span><span>
</span><span id="line-67"></span><span class="hs-comment">--</span><span>
</span><span id="line-68"></span><span class="hs-comment">-- - @style@: the style of the transformer stack, e.g. 'ST5', 'SByT5', etc.</span><span>
</span><span id="line-69"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the stack's parameters.</span><span>
</span><span id="line-70"></span><span class="hs-comment">-- - @device@: the computational device on which the stack is allocated.</span><span>
</span><span id="line-71"></span><span class="hs-comment">-- - @dataType@: the data type of the stack's parameters.</span><span>
</span><span id="line-72"></span><span class="hs-comment">-- - @headDim@: the dimension of all transformer heads in the stack.</span><span>
</span><span id="line-73"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the transformer head embeddings.</span><span>
</span><span id="line-74"></span><span class="hs-comment">-- - @embedDim@: the dimension of the transformer embeddings.</span><span>
</span><span id="line-75"></span><span class="hs-comment">-- - @queryEmbedDim@: the dimension of the transformer query embeddings.</span><span>
</span><span id="line-76"></span><span class="hs-comment">-- - @ffnDim@: the dimension of the feed-forward network.</span><span>
</span><span id="line-77"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-78"></span><span class="hs-comment">-- - @eps@: the epsilon value for numerical stability of the layer normalization.</span><span>
</span><span id="line-79"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#encoderStackSpec"><span class="hs-identifier hs-type">encoderStackSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-80"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679697739"><span class="annot"><a href="#local-6989586621679697739"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679697737"><span class="annot"><a href="#local-6989586621679697737"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679697735"><span class="annot"><a href="#local-6989586621679697735"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697733"><span class="annot"><a href="#local-6989586621679697733"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697731"><span class="annot"><a href="#local-6989586621679697731"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697729"><span class="annot"><a href="#local-6989586621679697729"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679697727"><span class="annot"><a href="#local-6989586621679697727"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697726"><span class="annot"><a href="#local-6989586621679697726"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697725"><span class="annot"><a href="#local-6989586621679697725"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697724"><span class="annot"><a href="#local-6989586621679697724"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679697723"><span class="annot"><a href="#local-6989586621679697723"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-81"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697739"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-82"></span><span>  </span><span class="annot"><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697737"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-83"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697735"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-84"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697733"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-85"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697731"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-86"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697729"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-87"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697727"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-88"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697726"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-89"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697725"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-90"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697724"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-91"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier hs-type">SHasDropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697723"><span class="hs-identifier hs-type">hasDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-92"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-93"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-94"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#EncoderStackF"><span class="hs-identifier hs-type">EncoderStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697739"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697737"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697735"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697733"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697731"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697729"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697727"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697726"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697725"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697724"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697723"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span id="encoderStackSpec"><span class="annot"><span class="annottext">encoderStackSpec :: forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (EncoderStackF
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        ffnDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#encoderStackSpec"><span class="hs-identifier hs-var hs-var">encoderStackSpec</span></a></span></span><span> </span><span id="local-6989586621679697356"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697356"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679697355"><span class="annot"><span class="annottext">numLayers :: SNat numLayers
</span><a href="#local-6989586621679697355"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span id="local-6989586621679697351"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679697351"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679697350"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679697350"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679697349"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679697349"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679697348"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679697348"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679697347"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679697347"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697346"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697346"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697345"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697345"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697344"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679697344"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679697343"><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679697343"><span class="hs-identifier hs-var">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679697342"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697342"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679697341"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697341"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-96"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697340"><span class="annot"><span class="annottext">blockSpec :: ModelSpec
  (EncoderBlockF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     ffnDim
     hasDropout)
</span><a href="#local-6989586621679697340"><span class="hs-identifier hs-var hs-var">blockSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (EncoderBlockF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        ffnDim
        hasDropout)
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (EncoderBlockF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        ffnDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#encoderBlockSpec"><span class="hs-identifier hs-var">encoderBlockSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697356"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679697351"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679697350"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679697349"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679697348"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679697347"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697346"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697345"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679697344"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679697343"><span class="hs-identifier hs-var">hasDropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697342"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697341"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-97"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">VectorSpec
  numLayers
  (GTransformerBlock
     (NamedModel
        (GSelfAttention
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (QInProjF style gradient device dataType queryEmbedDim embedDim)
                 (KInProjF style gradient device dataType queryEmbedDim embedDim)
                 (VInProjF style gradient device dataType queryEmbedDim embedDim)
                 (OutProjF style gradient device dataType embedDim queryEmbedDim)
                 (DropoutF style hasDropout)))
           (SADropoutF style hasDropout)
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
     ()
     (NamedModel
        (GTransformerFeedForwardNetwork
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim)
           (FFNActivationF style)
           (FFNActivationDropoutF style)
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim)
           (FFNOutputDropoutF style hasDropout)
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (SADropoutF style hasDropout)
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           ()
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNOutputDropoutF style hasDropout)
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall stack. stack -&gt; GTransformerStack stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span><span> </span><span class="annot"><span class="annottext">(VectorSpec
   numLayers
   (GTransformerBlock
      (NamedModel
         (GSelfAttention
            (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
            (NamedModel
               (GMultiHeadAttention
                  headDim
                  headEmbedDim
                  embedDim
                  (QInProjF style gradient device dataType queryEmbedDim embedDim)
                  (KInProjF style gradient device dataType queryEmbedDim embedDim)
                  (VInProjF style gradient device dataType queryEmbedDim embedDim)
                  (OutProjF style gradient device dataType embedDim queryEmbedDim)
                  (DropoutF style hasDropout)))
            (SADropoutF style hasDropout)
            (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
      ()
      (NamedModel
         (GTransformerFeedForwardNetwork
            (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
            (FFNInputTransformationF
               style gradient device dataType queryEmbedDim ffnDim)
            (FFNActivationF style)
            (FFNActivationDropoutF style)
            (FFNOutputProjectionF
               style gradient device dataType queryEmbedDim ffnDim)
            (FFNOutputDropoutF style hasDropout)
            (FFNOutputLayerNormF
               style gradient device dataType queryEmbedDim))))
 -&gt; GTransformerStack
      (VectorSpec
         numLayers
         (GTransformerBlock
            (NamedModel
               (GSelfAttention
                  (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                  (NamedModel
                     (GMultiHeadAttention
                        headDim
                        headEmbedDim
                        embedDim
                        (QInProjF style gradient device dataType queryEmbedDim embedDim)
                        (KInProjF style gradient device dataType queryEmbedDim embedDim)
                        (VInProjF style gradient device dataType queryEmbedDim embedDim)
                        (OutProjF style gradient device dataType embedDim queryEmbedDim)
                        (DropoutF style hasDropout)))
                  (SADropoutF style hasDropout)
                  (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
            ()
            (NamedModel
               (GTransformerFeedForwardNetwork
                  (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                  (FFNInputTransformationF
                     style gradient device dataType queryEmbedDim ffnDim)
                  (FFNActivationF style)
                  (FFNActivationDropoutF style)
                  (FFNOutputProjectionF
                     style gradient device dataType queryEmbedDim ffnDim)
                  (FFNOutputDropoutF style hasDropout)
                  (FFNOutputLayerNormF
                     style gradient device dataType queryEmbedDim))))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    (DropoutF style hasDropout)))
              (SADropoutF style hasDropout)
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        ()
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNOutputDropoutF style hasDropout)
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (SADropoutF style hasDropout)
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           ()
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNOutputDropoutF style hasDropout)
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
-&gt; Vector
     numLayers
     (ModelSpec
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (SADropoutF style hasDropout)
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           ()
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNOutputDropoutF style hasDropout)
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    (DropoutF style hasDropout)))
              (SADropoutF style hasDropout)
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        ()
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNOutputDropoutF style hasDropout)
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
forall (n :: Nat) a.
SNat n -&gt; Vector n (ModelSpec a) -&gt; VectorSpec n a
</span><a href="Torch.GraduallyTyped.NN.Class.html#VectorSpec"><span class="hs-identifier hs-var">VectorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679697355"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SNat numLayers
-&gt; GTransformerBlock
     (NamedModel
        (GSelfAttention
           (ModelSpec
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (ModelSpec
                    (QInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (KInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (VInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (OutProjF style gradient device dataType embedDim queryEmbedDim))
                 (ModelSpec (DropoutF style hasDropout))))
           (ModelSpec (SADropoutF style hasDropout))
           (ModelSpec
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
     ()
     (NamedModel
        (GTransformerFeedForwardNetwork
           (ModelSpec
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
           (ModelSpec
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim))
           (ModelSpec (FFNActivationF style))
           (ModelSpec (FFNActivationDropoutF style))
           (ModelSpec
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim))
           (ModelSpec (FFNOutputDropoutF style hasDropout))
           (ModelSpec
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; Vector
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (ModelSpec
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (ModelSpec
                       (QInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (KInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (VInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (OutProjF style gradient device dataType embedDim queryEmbedDim))
                    (ModelSpec (DropoutF style hasDropout))))
              (ModelSpec (SADropoutF style hasDropout))
              (ModelSpec
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
        ()
        (NamedModel
           (GTransformerFeedForwardNetwork
              (ModelSpec
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
              (ModelSpec
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim))
              (ModelSpec (FFNActivationF style))
              (ModelSpec (FFNActivationDropoutF style))
              (ModelSpec
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim))
              (ModelSpec (FFNOutputDropoutF style hasDropout))
              (ModelSpec
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall (n :: Nat) a (p :: Nat -&gt; *).
KnownNat n =&gt;
p n -&gt; a -&gt; Vector n a
</span><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">VS.replicate'</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679697355"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (EncoderBlockF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     ffnDim
     hasDropout)
GTransformerBlock
  (NamedModel
     (GSelfAttention
        (ModelSpec
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
        (NamedModel
           (GMultiHeadAttention
              headDim
              headEmbedDim
              embedDim
              (ModelSpec
                 (QInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (KInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (VInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (OutProjF style gradient device dataType embedDim queryEmbedDim))
              (ModelSpec (DropoutF style hasDropout))))
        (ModelSpec (SADropoutF style hasDropout))
        (ModelSpec
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
  ()
  (NamedModel
     (GTransformerFeedForwardNetwork
        (ModelSpec
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
        (ModelSpec
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim))
        (ModelSpec (FFNActivationF style))
        (ModelSpec (FFNActivationDropoutF style))
        (ModelSpec
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim))
        (ModelSpec (FFNOutputDropoutF style hasDropout))
        (ModelSpec
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
</span><a href="#local-6989586621679697340"><span class="hs-identifier hs-var">blockSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>
</span><span id="line-99"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-100"></span><span>  </span><span id="DecoderStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#DecoderStackF"><span class="hs-identifier hs-var">DecoderStackF</span></a></span></span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697337"><span class="annot"><a href="#local-6989586621679697337"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697336"><span class="annot"><a href="#local-6989586621679697336"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697335"><span class="annot"><a href="#local-6989586621679697335"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697334"><span class="annot"><a href="#local-6989586621679697334"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697333"><span class="annot"><a href="#local-6989586621679697333"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697332"><span class="annot"><a href="#local-6989586621679697332"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697331"><span class="annot"><a href="#local-6989586621679697331"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697330"><span class="annot"><a href="#local-6989586621679697330"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697329"><span class="annot"><a href="#local-6989586621679697329"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697328"><span class="annot"><a href="#local-6989586621679697328"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697327"><span class="annot"><a href="#local-6989586621679697327"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679697326"><span class="annot"><a href="#local-6989586621679697326"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasDropout"><span class="hs-identifier hs-type">HasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-114"></span><span>  </span><span id="DecoderStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#DecoderStackF"><span class="hs-identifier hs-var">DecoderStackF</span></a></span></span><span> </span><span id="local-6989586621679697314"><span id="local-6989586621679697315"><span id="local-6989586621679697316"><span id="local-6989586621679697317"><span id="local-6989586621679697318"><span id="local-6989586621679697319"><span id="local-6989586621679697320"><span id="local-6989586621679697321"><span id="local-6989586621679697322"><span id="local-6989586621679697323"><span id="local-6989586621679697324"><span id="local-6989586621679697325"><span class="annot"><a href="#local-6989586621679697325"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697324"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697323"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697321"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697320"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697319"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697318"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697317"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697316"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697314"><span class="hs-identifier hs-type">hasDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-115"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span>
</span><span id="line-116"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span>
</span><span id="line-117"></span><span>          </span><span class="annot"><a href="#local-6989586621679697324"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-118"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockF"><span class="hs-identifier hs-type">DecoderBlockF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697325"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697323"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697322"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697321"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697320"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697319"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697318"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697317"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697316"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697315"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697314"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>
</span><span id="line-121"></span><span class="hs-comment">-- | Specifies the parameters of a transformer stack in a decoder configuration.</span><span>
</span><span id="line-122"></span><span class="hs-comment">--</span><span>
</span><span id="line-123"></span><span class="hs-comment">-- - @style@: the style of the transformer stack, e.g. 'ST5', 'SByT5', etc.</span><span>
</span><span id="line-124"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the stack's parameters.</span><span>
</span><span id="line-125"></span><span class="hs-comment">-- - @device@: the computational device on which the stack is allocated.</span><span>
</span><span id="line-126"></span><span class="hs-comment">-- - @dataType@: the data type of the stack's parameters.</span><span>
</span><span id="line-127"></span><span class="hs-comment">-- - @headDim@: the dimension of all transformer heads in the stack.</span><span>
</span><span id="line-128"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the transformer head embeddings.</span><span>
</span><span id="line-129"></span><span class="hs-comment">-- - @embedDim@: the dimension of the transformer embeddings.</span><span>
</span><span id="line-130"></span><span class="hs-comment">-- - @queryEmbedDim@: the dimension of the transformer query embeddings.</span><span>
</span><span id="line-131"></span><span class="hs-comment">-- - @keyEmbedDim@: the dimension of the transformer key embeddings.</span><span>
</span><span id="line-132"></span><span class="hs-comment">-- - @ffnDim@: the dimension of the feed-forward network.</span><span>
</span><span id="line-133"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-134"></span><span class="hs-comment">-- - @eps@: the epsilon value for numerical stability of the layer normalization.</span><span>
</span><span id="line-135"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#decoderStackSpec"><span class="hs-identifier hs-type">decoderStackSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-136"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679697669"><span class="annot"><a href="#local-6989586621679697669"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679697668"><span class="annot"><a href="#local-6989586621679697668"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679697667"><span class="annot"><a href="#local-6989586621679697667"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679697666"><span class="annot"><a href="#local-6989586621679697666"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679697665"><span class="annot"><a href="#local-6989586621679697665"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679697664"><span class="annot"><a href="#local-6989586621679697664"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679697663"><span class="annot"><a href="#local-6989586621679697663"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697662"><span class="annot"><a href="#local-6989586621679697662"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697661"><span class="annot"><a href="#local-6989586621679697661"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697660"><span class="annot"><a href="#local-6989586621679697660"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697659"><span class="annot"><a href="#local-6989586621679697659"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679697658"><span class="annot"><a href="#local-6989586621679697658"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-137"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697669"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-138"></span><span>  </span><span class="annot"><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697668"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-139"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697667"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-140"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697666"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-141"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697665"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-142"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697664"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-143"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697663"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-144"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697662"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-145"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697661"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-146"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697660"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-147"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697659"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-148"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier hs-type">SHasDropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697658"><span class="hs-identifier hs-type">hasDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-149"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-150"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-151"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#DecoderStackF"><span class="hs-identifier hs-type">DecoderStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697669"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697668"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697667"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697666"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697665"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697664"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697663"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697662"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697661"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697660"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697659"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697658"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span id="decoderStackSpec"><span class="annot"><span class="annottext">decoderStackSpec :: forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (DecoderStackF
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        ffnDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#decoderStackSpec"><span class="hs-identifier hs-var hs-var">decoderStackSpec</span></a></span></span><span> </span><span id="local-6989586621679697312"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697312"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679697311"><span class="annot"><span class="annottext">numLayers :: SNat numLayers
</span><a href="#local-6989586621679697311"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="../file:///nix/store/p1ad99g2h08f8pcsni3lf2prwyd71f49-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span id="local-6989586621679697308"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679697308"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679697307"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679697307"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679697306"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679697306"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679697305"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679697305"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679697304"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679697304"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697303"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697303"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679697302"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697302"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697301"><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697301"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697300"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679697300"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679697299"><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679697299"><span class="hs-identifier hs-var">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679697298"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697298"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679697297"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697297"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-153"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679697296"><span class="annot"><span class="annottext">blockSpec :: ModelSpec
  (DecoderBlockF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     ffnDim
     hasDropout)
</span><a href="#local-6989586621679697296"><span class="hs-identifier hs-var hs-var">blockSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (DecoderBlockF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        ffnDim
        hasDropout)
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (hasDropout :: HasDropout).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; SHasDropout hasDropout
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (DecoderBlockF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        ffnDim
        hasDropout)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#decoderBlockSpec"><span class="hs-identifier hs-var">decoderBlockSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679697312"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679697308"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679697307"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679697306"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679697305"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679697304"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679697303"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679697302"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679697301"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679697300"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679697299"><span class="hs-identifier hs-var">hasDropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697298"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679697297"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-154"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">VectorSpec
  numLayers
  (GTransformerBlock
     (NamedModel
        (GSelfAttention
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (QInProjF style gradient device dataType queryEmbedDim embedDim)
                 (KInProjF style gradient device dataType queryEmbedDim embedDim)
                 (VInProjF style gradient device dataType queryEmbedDim embedDim)
                 (OutProjF style gradient device dataType embedDim queryEmbedDim)
                 (DropoutF style hasDropout)))
           (SADropoutF style hasDropout)
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
     (NamedModel
        (GCrossAttention
           (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (QInProjF style gradient device dataType queryEmbedDim embedDim)
                 (KInProjF style gradient device dataType keyEmbedDim embedDim)
                 (VInProjF style gradient device dataType keyEmbedDim embedDim)
                 (OutProjF style gradient device dataType embedDim queryEmbedDim)
                 (DropoutF style hasDropout)))
           (CADropoutF style hasDropout)
           (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
     (NamedModel
        (GTransformerFeedForwardNetwork
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim)
           (FFNActivationF style)
           (FFNActivationDropoutF style)
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim)
           (FFNOutputDropoutF style hasDropout)
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (SADropoutF style hasDropout)
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GCrossAttention
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType keyEmbedDim embedDim)
                       (VInProjF style gradient device dataType keyEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (CADropoutF style hasDropout)
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNOutputDropoutF style hasDropout)
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall stack. stack -&gt; GTransformerStack stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span><span> </span><span class="annot"><span class="annottext">(VectorSpec
   numLayers
   (GTransformerBlock
      (NamedModel
         (GSelfAttention
            (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
            (NamedModel
               (GMultiHeadAttention
                  headDim
                  headEmbedDim
                  embedDim
                  (QInProjF style gradient device dataType queryEmbedDim embedDim)
                  (KInProjF style gradient device dataType queryEmbedDim embedDim)
                  (VInProjF style gradient device dataType queryEmbedDim embedDim)
                  (OutProjF style gradient device dataType embedDim queryEmbedDim)
                  (DropoutF style hasDropout)))
            (SADropoutF style hasDropout)
            (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
      (NamedModel
         (GCrossAttention
            (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
            (NamedModel
               (GMultiHeadAttention
                  headDim
                  headEmbedDim
                  embedDim
                  (QInProjF style gradient device dataType queryEmbedDim embedDim)
                  (KInProjF style gradient device dataType keyEmbedDim embedDim)
                  (VInProjF style gradient device dataType keyEmbedDim embedDim)
                  (OutProjF style gradient device dataType embedDim queryEmbedDim)
                  (DropoutF style hasDropout)))
            (CADropoutF style hasDropout)
            (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
      (NamedModel
         (GTransformerFeedForwardNetwork
            (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
            (FFNInputTransformationF
               style gradient device dataType queryEmbedDim ffnDim)
            (FFNActivationF style)
            (FFNActivationDropoutF style)
            (FFNOutputProjectionF
               style gradient device dataType queryEmbedDim ffnDim)
            (FFNOutputDropoutF style hasDropout)
            (FFNOutputLayerNormF
               style gradient device dataType queryEmbedDim))))
 -&gt; GTransformerStack
      (VectorSpec
         numLayers
         (GTransformerBlock
            (NamedModel
               (GSelfAttention
                  (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                  (NamedModel
                     (GMultiHeadAttention
                        headDim
                        headEmbedDim
                        embedDim
                        (QInProjF style gradient device dataType queryEmbedDim embedDim)
                        (KInProjF style gradient device dataType queryEmbedDim embedDim)
                        (VInProjF style gradient device dataType queryEmbedDim embedDim)
                        (OutProjF style gradient device dataType embedDim queryEmbedDim)
                        (DropoutF style hasDropout)))
                  (SADropoutF style hasDropout)
                  (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
            (NamedModel
               (GCrossAttention
                  (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                  (NamedModel
                     (GMultiHeadAttention
                        headDim
                        headEmbedDim
                        embedDim
                        (QInProjF style gradient device dataType queryEmbedDim embedDim)
                        (KInProjF style gradient device dataType keyEmbedDim embedDim)
                        (VInProjF style gradient device dataType keyEmbedDim embedDim)
                        (OutProjF style gradient device dataType embedDim queryEmbedDim)
                        (DropoutF style hasDropout)))
                  (CADropoutF style hasDropout)
                  (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
            (NamedModel
               (GTransformerFeedForwardNetwork
                  (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                  (FFNInputTransformationF
                     style gradient device dataType queryEmbedDim ffnDim)
                  (FFNActivationF style)
                  (FFNActivationDropoutF style)
                  (FFNOutputProjectionF
                     style gradient device dataType queryEmbedDim ffnDim)
                  (FFNOutputDropoutF style hasDropout)
                  (FFNOutputLayerNormF
                     style gradient device dataType queryEmbedDim))))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    (DropoutF style hasDropout)))
              (SADropoutF style hasDropout)
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GCrossAttention
              (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType keyEmbedDim embedDim)
                    (VInProjF style gradient device dataType keyEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    (DropoutF style hasDropout)))
              (CADropoutF style hasDropout)
              (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNOutputDropoutF style hasDropout)
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (SADropoutF style hasDropout)
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GCrossAttention
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType keyEmbedDim embedDim)
                       (VInProjF style gradient device dataType keyEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (CADropoutF style hasDropout)
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNOutputDropoutF style hasDropout)
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
-&gt; Vector
     numLayers
     (ModelSpec
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (SADropoutF style hasDropout)
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GCrossAttention
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType keyEmbedDim embedDim)
                       (VInProjF style gradient device dataType keyEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       (DropoutF style hasDropout)))
                 (CADropoutF style hasDropout)
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNOutputDropoutF style hasDropout)
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    (DropoutF style hasDropout)))
              (SADropoutF style hasDropout)
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GCrossAttention
              (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType keyEmbedDim embedDim)
                    (VInProjF style gradient device dataType keyEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    (DropoutF style hasDropout)))
              (CADropoutF style hasDropout)
              (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNOutputDropoutF style hasDropout)
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
forall (n :: Nat) a.
SNat n -&gt; Vector n (ModelSpec a) -&gt; VectorSpec n a
</span><a href="Torch.GraduallyTyped.NN.Class.html#VectorSpec"><span class="hs-identifier hs-var">VectorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679697311"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SNat numLayers
-&gt; GTransformerBlock
     (NamedModel
        (GSelfAttention
           (ModelSpec
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (ModelSpec
                    (QInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (KInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (VInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (OutProjF style gradient device dataType embedDim queryEmbedDim))
                 (ModelSpec (DropoutF style hasDropout))))
           (ModelSpec (SADropoutF style hasDropout))
           (ModelSpec
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
     (NamedModel
        (GCrossAttention
           (ModelSpec
              (CAInitialLayerNormF style gradient device dataType queryEmbedDim))
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (ModelSpec
                    (QInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (KInProjF style gradient device dataType keyEmbedDim embedDim))
                 (ModelSpec
                    (VInProjF style gradient device dataType keyEmbedDim embedDim))
                 (ModelSpec
                    (OutProjF style gradient device dataType embedDim queryEmbedDim))
                 (ModelSpec (DropoutF style hasDropout))))
           (ModelSpec (CADropoutF style hasDropout))
           (ModelSpec
              (CAFinalLayerNormF style gradient device dataType queryEmbedDim))))
     (NamedModel
        (GTransformerFeedForwardNetwork
           (ModelSpec
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
           (ModelSpec
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim))
           (ModelSpec (FFNActivationF style))
           (ModelSpec (FFNActivationDropoutF style))
           (ModelSpec
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim))
           (ModelSpec (FFNOutputDropoutF style hasDropout))
           (ModelSpec
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; Vector
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (ModelSpec
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (ModelSpec
                       (QInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (KInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (VInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (OutProjF style gradient device dataType embedDim queryEmbedDim))
                    (ModelSpec (DropoutF style hasDropout))))
              (ModelSpec (SADropoutF style hasDropout))
              (ModelSpec
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
        (NamedModel
           (GCrossAttention
              (ModelSpec
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim))
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (ModelSpec
                       (QInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (KInProjF style gradient device dataType keyEmbedDim embedDim))
                    (ModelSpec
                       (VInProjF style gradient device dataType keyEmbedDim embedDim))
                    (ModelSpec
                       (OutProjF style gradient device dataType embedDim queryEmbedDim))
                    (ModelSpec (DropoutF style hasDropout))))
              (ModelSpec (CADropoutF style hasDropout))
              (ModelSpec
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim))))
        (NamedModel
           (GTransformerFeedForwardNetwork
              (ModelSpec
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
              (ModelSpec
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim))
              (ModelSpec (FFNActivationF style))
              (ModelSpec (FFNActivationDropoutF style))
              (ModelSpec
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim))
              (ModelSpec (FFNOutputDropoutF style hasDropout))
              (ModelSpec
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall (n :: Nat) a (p :: Nat -&gt; *).
KnownNat n =&gt;
p n -&gt; a -&gt; Vector n a
</span><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">VS.replicate'</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679697311"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (DecoderBlockF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     ffnDim
     hasDropout)
GTransformerBlock
  (NamedModel
     (GSelfAttention
        (ModelSpec
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
        (NamedModel
           (GMultiHeadAttention
              headDim
              headEmbedDim
              embedDim
              (ModelSpec
                 (QInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (KInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (VInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (OutProjF style gradient device dataType embedDim queryEmbedDim))
              (ModelSpec (DropoutF style hasDropout))))
        (ModelSpec (SADropoutF style hasDropout))
        (ModelSpec
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
  (NamedModel
     (GCrossAttention
        (ModelSpec
           (CAInitialLayerNormF style gradient device dataType queryEmbedDim))
        (NamedModel
           (GMultiHeadAttention
              headDim
              headEmbedDim
              embedDim
              (ModelSpec
                 (QInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (KInProjF style gradient device dataType keyEmbedDim embedDim))
              (ModelSpec
                 (VInProjF style gradient device dataType keyEmbedDim embedDim))
              (ModelSpec
                 (OutProjF style gradient device dataType embedDim queryEmbedDim))
              (ModelSpec (DropoutF style hasDropout))))
        (ModelSpec (CADropoutF style hasDropout))
        (ModelSpec
           (CAFinalLayerNormF style gradient device dataType queryEmbedDim))))
  (NamedModel
     (GTransformerFeedForwardNetwork
        (ModelSpec
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
        (ModelSpec
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim))
        (ModelSpec (FFNActivationF style))
        (ModelSpec (FFNActivationDropoutF style))
        (ModelSpec
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim))
        (ModelSpec (FFNOutputDropoutF style hasDropout))
        (ModelSpec
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
</span><a href="#local-6989586621679697296"><span class="hs-identifier hs-var">blockSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span id="local-6989586621679697618"><span id="local-6989586621679697619"><span id="local-6989586621679697620"><span id="local-6989586621679697621"><span id="local-6989586621679697622"><span class="hs-keyword">instance</span><span>
</span><span id="line-157"></span><span>  </span><span id="local-6989586621679697294"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697622"><span class="hs-identifier hs-type">block</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697621"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697620"><span class="hs-identifier hs-type">block'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697621"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-158"></span><span>    </span><span class="annot"><a href="#local-6989586621679697619"><span class="hs-identifier hs-type">numLayers'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697618"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-159"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-160"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697619"><span class="hs-identifier hs-type">numLayers'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697622"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="annot"><a href="#local-6989586621679697621"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697619"><span class="hs-identifier hs-type">numLayers'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697620"><span class="hs-identifier hs-type">block'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="annot"><a href="#local-6989586621679697621"><span class="hs-identifier hs-type">generatorDevice</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-165"></span><span>
</span><span id="line-166"></span><span id="local-6989586621679697612"><span id="local-6989586621679697613"><span class="hs-keyword">instance</span><span>
</span><span id="line-167"></span><span>  </span><span id="local-6989586621679697289"><span id="local-6989586621679697291"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697613"><span class="hs-identifier hs-type">block</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-168"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697612"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697613"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-169"></span><span>
</span><span id="line-170"></span><span id="local-6989586621679697597"><span id="local-6989586621679697598"><span id="local-6989586621679697599"><span id="local-6989586621679697600"><span class="hs-keyword">instance</span><span>
</span><span id="line-171"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-172"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="annot"><a href="#local-6989586621679697600"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-173"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697599"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697598"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-174"></span><span>    </span><span class="annot"><a href="#local-6989586621679697597"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-175"></span><span>    </span><span class="annot"><a href="#local-6989586621679697599"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-176"></span><span>    </span><span class="annot"><a href="#local-6989586621679697597"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-177"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-178"></span><span>  </span><span id="local-6989586621679697278"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GTransformerStack (Vector 0 block)
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (query, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">GTransformerStack (Vector 0 block)
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697276"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697276"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(query, Generator generatorDevice)
-&gt; m (query, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">((query, Generator generatorDevice)
 -&gt; m (query, Generator generatorDevice))
-&gt; (Generator generatorDevice
    -&gt; (query, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (query, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697276"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-179"></span><span>
</span><span id="line-180"></span><span id="local-6989586621679697577"><span id="local-6989586621679697578"><span id="local-6989586621679697579"><span id="local-6989586621679697580"><span id="local-6989586621679697581"><span id="local-6989586621679697582"><span class="hs-keyword">instance</span><span>
</span><span id="line-181"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-182"></span><span>    </span><span class="annot"><a href="#local-6989586621679697582"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-183"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697581"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697580"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-184"></span><span>    </span><span class="annot"><a href="#local-6989586621679697579"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-185"></span><span>    </span><span class="annot"><a href="#local-6989586621679697578"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-186"></span><span>    </span><span class="annot"><a href="#local-6989586621679697577"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-187"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-188"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679697582"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697581"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697580"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-190"></span><span>    </span><span class="annot"><a href="#local-6989586621679697579"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-191"></span><span>    </span><span class="annot"><a href="#local-6989586621679697578"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="annot"><a href="#local-6989586621679697577"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-193"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-194"></span><span>  </span><span id="local-6989586621679697268"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GTransformerStack (Vector 1 block)
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697268"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679697266"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697266"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679697265"><span class="annot"><span class="annottext">(query, attentionBias)
</span><a href="#local-6989586621679697265"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679697264"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697264"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-195"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697263"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697263"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Vector block
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="Torch.GraduallyTyped.Internal.Vector.html#uncons"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697266"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-196"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697263"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="annot"><span class="annottext">(query, attentionBias)
</span><a href="#local-6989586621679697265"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697264"><span class="hs-identifier hs-var">g</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-197"></span><span>
</span><span id="line-198"></span><span id="local-6989586621679697562"><span id="local-6989586621679697563"><span id="local-6989586621679697564"><span id="local-6989586621679697565"><span id="local-6989586621679697566"><span id="local-6989586621679697567"><span class="hs-keyword">instance</span><span>
</span><span id="line-199"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-200"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="annot"><a href="#local-6989586621679697567"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-201"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697566"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697565"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697564"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697563"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>    </span><span class="annot"><a href="#local-6989586621679697562"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-203"></span><span>    </span><span class="annot"><a href="#local-6989586621679697566"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-204"></span><span>    </span><span class="annot"><a href="#local-6989586621679697562"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-205"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-206"></span><span>  </span><span id="local-6989586621679697255"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GTransformerStack (Vector 0 block)
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generator
-&gt; m (query, Generator generator)
</span><a href="#local-6989586621679697255"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">GTransformerStack (Vector 0 block)
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697254"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697254"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionBias
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(query, Generator generator) -&gt; m (query, Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">((query, Generator generator) -&gt; m (query, Generator generator))
-&gt; (Generator generator -&gt; (query, Generator generator))
-&gt; Generator generator
-&gt; m (query, Generator generator)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697254"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-207"></span><span>
</span><span id="line-208"></span><span id="local-6989586621679697545"><span id="local-6989586621679697546"><span id="local-6989586621679697547"><span id="local-6989586621679697548"><span id="local-6989586621679697549"><span id="local-6989586621679697550"><span id="local-6989586621679697551"><span id="local-6989586621679697552"><span class="hs-keyword">instance</span><span>
</span><span id="line-209"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-210"></span><span>    </span><span class="annot"><a href="#local-6989586621679697552"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-211"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697551"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697550"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697549"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697548"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span>    </span><span class="annot"><a href="#local-6989586621679697547"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-213"></span><span>    </span><span class="annot"><a href="#local-6989586621679697546"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-214"></span><span>    </span><span class="annot"><a href="#local-6989586621679697545"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-215"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-216"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679697552"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697551"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697550"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697549"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697548"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-218"></span><span>    </span><span class="annot"><a href="#local-6989586621679697547"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-219"></span><span>    </span><span class="annot"><a href="#local-6989586621679697546"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-220"></span><span>    </span><span class="annot"><a href="#local-6989586621679697545"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-221"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-222"></span><span>  </span><span id="local-6989586621679697247"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GTransformerStack (Vector 1 block)
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697247"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679697246"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697246"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679697245"><span class="annot"><span class="annottext">(query, key, attentionBias, crossAttentionBias)
</span><a href="#local-6989586621679697245"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679697244"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697244"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-223"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697243"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697243"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Vector block
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="Torch.GraduallyTyped.Internal.Vector.html#uncons"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697246"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-224"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697243"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="annot"><span class="annottext">(query, key, attentionBias, crossAttentionBias)
</span><a href="#local-6989586621679697245"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697244"><span class="hs-identifier hs-var">g</span></a></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-225"></span><span>
</span><span id="line-226"></span><span class="hs-comment">-- | 'HasForward' instance for 'GTransformerStack' in an encoder configuration.</span><span>
</span><span id="line-227"></span><span class="hs-comment">--</span><span>
</span><span id="line-228"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-229"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-230"></span><span class="hs-comment">-- &#9474; query &#9474;  &#9474; attentionBias &#9474;</span><span>
</span><span id="line-231"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-232"></span><span class="hs-comment">--     &#9474;              &#9474;</span><span>
</span><span id="line-233"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-234"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-235"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-236"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-237"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-238"></span><span class="hs-comment">--    ...            ...</span><span>
</span><span id="line-239"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-240"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-241"></span><span class="hs-comment">--     &#9474;</span><span>
</span><span id="line-242"></span><span class="hs-comment">--     &#9660;</span><span>
</span><span id="line-243"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-244"></span><span class="hs-comment">-- &#9474; query &#9474;</span><span>
</span><span id="line-245"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-246"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-247"></span><span id="local-6989586621679697530"><span id="local-6989586621679697531"><span id="local-6989586621679697532"><span id="local-6989586621679697533"><span id="local-6989586621679697534"><span id="local-6989586621679697535"><span id="local-6989586621679697536"><span class="hs-keyword">instance</span><span>
</span><span id="line-248"></span><span>  </span><span class="hs-pragma">{-# OVERLAPPABLE</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-249"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-250"></span><span>      </span><span class="annot"><a href="#local-6989586621679697536"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-251"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697535"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697534"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-252"></span><span>      </span><span class="annot"><a href="#local-6989586621679697533"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-253"></span><span>      </span><span class="annot"><a href="#local-6989586621679697532"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-254"></span><span>      </span><span class="annot"><a href="#local-6989586621679697531"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-255"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-256"></span><span>      </span><span class="annot"><a href="#local-6989586621679697536"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-257"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697532"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697534"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>      </span><span class="annot"><a href="#local-6989586621679697531"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-259"></span><span>      </span><span class="annot"><a href="#local-6989586621679697532"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-260"></span><span>      </span><span class="annot"><a href="#local-6989586621679697531"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-261"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-262"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-263"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697530"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697536"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-264"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697535"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697534"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-265"></span><span>    </span><span class="annot"><a href="#local-6989586621679697533"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-266"></span><span>    </span><span class="annot"><a href="#local-6989586621679697532"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-267"></span><span>    </span><span class="annot"><a href="#local-6989586621679697531"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-268"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-269"></span><span>  </span><span id="local-6989586621679697226"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GTransformerStack (Vector n block)
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697226"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679697225"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697225"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697224"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697224"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697223"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679697223"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679697222"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697222"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-270"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697221"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697221"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697220"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697220"><span class="hs-identifier hs-var">blocks</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="Torch.GraduallyTyped.Internal.Vector.html#uncons"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697225"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-271"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(m (output, Generator generatorOutputDevice)
 -&gt; block -&gt; m (output, Generator generatorOutputDevice))
-&gt; m (output, Generator generatorOutputDevice)
-&gt; Vector block
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b -&gt; a) -&gt; a -&gt; Vector b -&gt; a
</span><a href="../file:///nix/store/548vldv3qjqlzpixqp52j6jawbid5vk9-vector-lib-vector-0.12.3.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.foldl</span></a></span><span>
</span><span id="line-272"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679697218"><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697218"><span class="hs-identifier hs-var">agg</span></a></span></span><span> </span><span id="local-6989586621679697217"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697217"><span class="hs-identifier hs-var">block'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-273"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679697216"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697216"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697215"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697215"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697218"><span class="hs-identifier hs-var">agg</span></a></span><span>
</span><span id="line-274"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679697214"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697214"><span class="hs-identifier hs-var">output'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697213"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697213"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (output, attentionBias)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697217"><span class="hs-identifier hs-var">block'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697216"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679697223"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697215"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-275"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697214"><span class="hs-identifier hs-var">output'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697213"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-276"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-277"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-278"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679697212"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697212"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697211"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697211"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697221"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697224"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679697223"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697222"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-279"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697212"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697211"><span class="hs-identifier hs-var">g'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-280"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span>          </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697220"><span class="hs-identifier hs-var">blocks</span></a></span></span></span></span></span></span></span></span><span>
</span><span id="line-282"></span><span>
</span><span id="line-283"></span><span class="hs-comment">-- | 'HasForward' instance for 'GTransformerStack' in a decoder configuration.</span><span>
</span><span id="line-284"></span><span class="hs-comment">--</span><span>
</span><span id="line-285"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-286"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-287"></span><span class="hs-comment">-- &#9474; query &#9474;  &#9474; key &#9474;  &#9474; attentionBias &#9474;  &#9474; crossAttentionBias &#9474;</span><span>
</span><span id="line-288"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-289"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-290"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-291"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-292"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-293"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-294"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-295"></span><span class="hs-comment">--    ...       ...           ...                  ...</span><span>
</span><span id="line-296"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-297"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-298"></span><span class="hs-comment">--     &#9474;</span><span>
</span><span id="line-299"></span><span class="hs-comment">--     &#9660;</span><span>
</span><span id="line-300"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-301"></span><span class="hs-comment">-- &#9474; query &#9474;</span><span>
</span><span id="line-302"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-303"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-304"></span><span id="local-6989586621679697509"><span id="local-6989586621679697510"><span id="local-6989586621679697511"><span id="local-6989586621679697512"><span id="local-6989586621679697513"><span id="local-6989586621679697514"><span id="local-6989586621679697515"><span id="local-6989586621679697516"><span id="local-6989586621679697517"><span class="hs-keyword">instance</span><span>
</span><span id="line-305"></span><span>  </span><span class="hs-pragma">{-# OVERLAPPABLE</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-306"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-307"></span><span>      </span><span class="annot"><a href="#local-6989586621679697517"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-308"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697516"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697515"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697514"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697513"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-309"></span><span>      </span><span class="annot"><a href="#local-6989586621679697512"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-310"></span><span>      </span><span class="annot"><a href="#local-6989586621679697511"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-311"></span><span>      </span><span class="annot"><a href="#local-6989586621679697510"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-312"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-313"></span><span>      </span><span class="annot"><a href="#local-6989586621679697517"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-314"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697511"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697515"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697514"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697513"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>      </span><span class="annot"><a href="#local-6989586621679697510"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-316"></span><span>      </span><span class="annot"><a href="#local-6989586621679697511"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-317"></span><span>      </span><span class="annot"><a href="#local-6989586621679697510"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-318"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-319"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-320"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697509"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697517"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-321"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679697516"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697515"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697514"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679697513"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>    </span><span class="annot"><a href="#local-6989586621679697512"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-323"></span><span>    </span><span class="annot"><a href="#local-6989586621679697511"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-324"></span><span>    </span><span class="annot"><a href="#local-6989586621679697510"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-325"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-326"></span><span>  </span><span id="local-6989586621679697194"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GTransformerStack (Vector n block)
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697194"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/10qhmpq73qhw4m88a4g7856ndhzyhqfw-vector-sized-lib-vector-sized-1.4.4-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679697193"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697193"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697192"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697192"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697191"><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679697191"><span class="hs-identifier hs-var">key</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697190"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679697190"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697189"><span class="annot"><span class="annottext">crossAttentionBias
</span><a href="#local-6989586621679697189"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679697188"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697188"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-327"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697187"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697187"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697186"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697186"><span class="hs-identifier hs-var">blocks</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="Torch.GraduallyTyped.Internal.Vector.html#uncons"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697193"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-328"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(m (output, Generator generatorOutputDevice)
 -&gt; block -&gt; m (output, Generator generatorOutputDevice))
-&gt; m (output, Generator generatorOutputDevice)
-&gt; Vector block
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b -&gt; a) -&gt; a -&gt; Vector b -&gt; a
</span><a href="../file:///nix/store/548vldv3qjqlzpixqp52j6jawbid5vk9-vector-lib-vector-0.12.3.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.foldl</span></a></span><span>
</span><span id="line-329"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679697185"><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697185"><span class="hs-identifier hs-var">agg</span></a></span></span><span> </span><span id="local-6989586621679697184"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697184"><span class="hs-identifier hs-var">block'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-330"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679697183"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697183"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697182"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697182"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679697185"><span class="hs-identifier hs-var">agg</span></a></span><span>
</span><span id="line-331"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679697181"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697181"><span class="hs-identifier hs-var">output'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697180"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697180"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (output, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697184"><span class="hs-identifier hs-var">block'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697183"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679697191"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679697190"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionBias
</span><a href="#local-6989586621679697189"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697182"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-332"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697181"><span class="hs-identifier hs-var">output'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697180"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-334"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-335"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679697179"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697179"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679697178"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697178"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679697187"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679697192"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679697191"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679697190"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionBias
</span><a href="#local-6989586621679697189"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679697188"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-336"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679697179"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679697178"><span class="hs-identifier hs-var">g'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-337"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-338"></span><span>          </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679697186"><span class="hs-identifier hs-var">blocks</span></a></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-339"></span></pre></body></html>