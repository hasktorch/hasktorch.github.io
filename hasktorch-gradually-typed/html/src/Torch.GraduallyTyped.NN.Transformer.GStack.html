<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FunctionalDependencies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-10"></span><span>
</span><span id="line-11"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GStack</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-12"></span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNat</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier">Data.Vector</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">V</span></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Generic.Sized.Internal</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">VGS</span></span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Sized</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">VS</span></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><span class="hs-operator">(+)</span></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#VectorSpec"><span class="hs-identifier">VectorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GBlock</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockCrossAttentionF"><span class="hs-identifier">DecoderBlockCrossAttentionF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockFeedForwardNetworkF"><span class="hs-identifier">DecoderBlockFeedForwardNetworkF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockSelfAttentionF"><span class="hs-identifier">DecoderBlockSelfAttentionF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockCrossAttentionF"><span class="hs-identifier">EncoderBlockCrossAttentionF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockFeedForwardNetworkF"><span class="hs-identifier">EncoderBlockFeedForwardNetworkF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockSelfAttentionF"><span class="hs-identifier">EncoderBlockSelfAttentionF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#GTransformerBlock"><span class="hs-identifier">GTransformerBlock</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#decoderBlockSpec"><span class="hs-identifier">decoderBlockSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#encoderBlockSpec"><span class="hs-identifier">encoderBlockSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span>
</span><span id="line-29"></span><span class="hs-comment">-- | Generic transformer stack.</span><span>
</span><span id="line-30"></span><span class="hs-comment">--</span><span>
</span><span id="line-31"></span><span class="hs-comment">-- - @stack@ is a stack of tranformer blocks.</span><span>
</span><span id="line-32"></span><span class="hs-keyword">newtype</span><span> </span><span id="GTransformerStack"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584587"><span class="annot"><a href="#local-6989586621679584587"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-33"></span><span>  </span><span id="GTransformerStack"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679584733"><span class="annot"><a href="#local-6989586621679584733"><span class="hs-identifier hs-type">stack</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="#local-6989586621679584733"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584733"><span class="hs-identifier hs-type">stack</span></a></span><span>
</span><span id="line-34"></span><span>
</span><span id="line-35"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-36"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span id="local-6989586621679584585"><span class="annot"><a href="#local-6989586621679584585"><span class="hs-identifier hs-type hs-type">stack</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-37"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584585"><span class="hs-identifier hs-type">stack</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span>
</span><span id="line-39"></span><span class="hs-comment">-- | Specifies the parameters of a transformer stack in an encoder configuration.</span><span>
</span><span id="line-40"></span><span class="hs-comment">--</span><span>
</span><span id="line-41"></span><span class="hs-comment">-- - @style@: the style of the transformer stack, e.g. 'ST5', 'SByT5', etc.</span><span>
</span><span id="line-42"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the stack's parameters.</span><span>
</span><span id="line-43"></span><span class="hs-comment">-- - @device@: the computational device on which the stack is allocated.</span><span>
</span><span id="line-44"></span><span class="hs-comment">-- - @dataType@: the data type of the stack's parameters.</span><span>
</span><span id="line-45"></span><span class="hs-comment">-- - @headDim@: the dimension of all transformer heads in the stack.</span><span>
</span><span id="line-46"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the transformer head embeddings.</span><span>
</span><span id="line-47"></span><span class="hs-comment">-- - @embedDim@: the dimension of the transformer embeddings.</span><span>
</span><span id="line-48"></span><span class="hs-comment">-- - @queryEmbedDim@: the dimension of the transformer query embeddings.</span><span>
</span><span id="line-49"></span><span class="hs-comment">-- - @ffnDim@: the dimension of the feed-forward network.</span><span>
</span><span id="line-50"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-51"></span><span class="hs-comment">-- - @eps@: the epsilon value for numerical stability of the layer normalization.</span><span>
</span><span id="line-52"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#encoderStackSpec"><span class="hs-identifier hs-type">encoderStackSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-53"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679584583"><span class="annot"><a href="#local-6989586621679584583"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679584582"><span class="annot"><a href="#local-6989586621679584582"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679584581"><span class="annot"><a href="#local-6989586621679584581"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679584580"><span class="annot"><a href="#local-6989586621679584580"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679584579"><span class="annot"><a href="#local-6989586621679584579"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679584578"><span class="annot"><a href="#local-6989586621679584578"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679584577"><span class="annot"><a href="#local-6989586621679584577"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584576"><span class="annot"><a href="#local-6989586621679584576"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679584575"><span class="annot"><a href="#local-6989586621679584575"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584574"><span class="annot"><a href="#local-6989586621679584574"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-54"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584583"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-55"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584582"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-56"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584581"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-57"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584580"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-58"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584579"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-59"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584578"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-60"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584577"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-61"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584576"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-62"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584575"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-63"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584574"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-64"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-65"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-66"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span>
</span><span id="line-67"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span>
</span><span id="line-68"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span>
</span><span id="line-69"></span><span>            </span><span class="annot"><a href="#local-6989586621679584582"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-70"></span><span>            </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#GTransformerBlock"><span class="hs-identifier hs-type">GTransformerBlock</span></a></span><span>
</span><span id="line-71"></span><span>                </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockSelfAttentionF"><span class="hs-identifier hs-type">EncoderBlockSelfAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584583"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584581"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584580"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584579"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584578"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584577"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584576"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584575"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-72"></span><span>                </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockCrossAttentionF"><span class="hs-identifier hs-type">EncoderBlockCrossAttentionF</span></a></span><span>
</span><span id="line-73"></span><span>                </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#EncoderBlockFeedForwardNetworkF"><span class="hs-identifier hs-type">EncoderBlockFeedForwardNetworkF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584583"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584581"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584580"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584579"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584575"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584574"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>            </span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span id="encoderStackSpec"><span class="annot"><span class="annottext">encoderStackSpec :: STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformerStack
        (Vector
           numLayers
           (GTransformerBlock
              (EncoderBlockSelfAttentionF
                 style
                 gradient
                 device
                 dataType
                 headDim
                 headEmbedDim
                 embedDim
                 queryEmbedDim)
              EncoderBlockCrossAttentionF
              (EncoderBlockFeedForwardNetworkF
                 style gradient device dataType queryEmbedDim ffnDim))))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#encoderStackSpec"><span class="hs-identifier hs-var hs-var">encoderStackSpec</span></a></span></span><span> </span><span id="local-6989586621679584573"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679584573"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679584572"><span class="annot"><span class="annottext">numLayers :: SNat numLayers
</span><a href="#local-6989586621679584572"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span id="local-6989586621679584570"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679584570"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679584569"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679584569"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679584568"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679584568"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679584567"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679584567"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679584566"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679584566"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584565"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679584565"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679584564"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679584564"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584563"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679584563"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679584562"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584562"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679584561"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584561"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-78"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679584560"><span class="annot"><span class="annottext">blockSpec :: ModelSpec
  (GTransformerBlock
     (EncoderBlockSelfAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
     EncoderBlockCrossAttentionF
     (EncoderBlockFeedForwardNetworkF
        style gradient device dataType queryEmbedDim ffnDim))
</span><a href="#local-6989586621679584560"><span class="hs-identifier hs-var hs-var">blockSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformerBlock
        (EncoderBlockSelfAttentionF
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim)
        EncoderBlockCrossAttentionF
        (EncoderBlockFeedForwardNetworkF
           style gradient device dataType queryEmbedDim ffnDim))
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformerBlock
        (EncoderBlockSelfAttentionF
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim)
        EncoderBlockCrossAttentionF
        (EncoderBlockFeedForwardNetworkF
           style gradient device dataType queryEmbedDim ffnDim))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#encoderBlockSpec"><span class="hs-identifier hs-var">encoderBlockSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679584573"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679584570"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679584569"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679584568"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679584567"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679584566"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679584565"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679584564"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679584563"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584562"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584561"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-79"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">VectorSpec
  numLayers
  (GTransformerBlock
     (NamedModel
        (GSelfAttention
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (QInProjF style gradient device dataType queryEmbedDim embedDim)
                 (KInProjF style gradient device dataType queryEmbedDim embedDim)
                 (VInProjF style gradient device dataType queryEmbedDim embedDim)
                 (OutProjF style gradient device dataType embedDim queryEmbedDim)
                 Dropout))
           Dropout
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
     ()
     (NamedModel
        (GTransformerFeedForwardNetwork
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim)
           (FFNActivationF style)
           (FFNActivationDropoutF style)
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim)
           Dropout
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           ()
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 Dropout
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall stack. stack -&gt; GTransformerStack stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span><span> </span><span class="annot"><span class="annottext">(VectorSpec
   numLayers
   (GTransformerBlock
      (NamedModel
         (GSelfAttention
            (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
            (NamedModel
               (GMultiHeadAttention
                  headDim
                  headEmbedDim
                  embedDim
                  (QInProjF style gradient device dataType queryEmbedDim embedDim)
                  (KInProjF style gradient device dataType queryEmbedDim embedDim)
                  (VInProjF style gradient device dataType queryEmbedDim embedDim)
                  (OutProjF style gradient device dataType embedDim queryEmbedDim)
                  Dropout))
            Dropout
            (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
      ()
      (NamedModel
         (GTransformerFeedForwardNetwork
            (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
            (FFNInputTransformationF
               style gradient device dataType queryEmbedDim ffnDim)
            (FFNActivationF style)
            (FFNActivationDropoutF style)
            (FFNOutputProjectionF
               style gradient device dataType queryEmbedDim ffnDim)
            Dropout
            (FFNOutputLayerNormF
               style gradient device dataType queryEmbedDim))))
 -&gt; GTransformerStack
      (VectorSpec
         numLayers
         (GTransformerBlock
            (NamedModel
               (GSelfAttention
                  (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                  (NamedModel
                     (GMultiHeadAttention
                        headDim
                        headEmbedDim
                        embedDim
                        (QInProjF style gradient device dataType queryEmbedDim embedDim)
                        (KInProjF style gradient device dataType queryEmbedDim embedDim)
                        (VInProjF style gradient device dataType queryEmbedDim embedDim)
                        (OutProjF style gradient device dataType embedDim queryEmbedDim)
                        Dropout))
                  Dropout
                  (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
            ()
            (NamedModel
               (GTransformerFeedForwardNetwork
                  (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                  (FFNInputTransformationF
                     style gradient device dataType queryEmbedDim ffnDim)
                  (FFNActivationF style)
                  (FFNActivationDropoutF style)
                  (FFNOutputProjectionF
                     style gradient device dataType queryEmbedDim ffnDim)
                  Dropout
                  (FFNOutputLayerNormF
                     style gradient device dataType queryEmbedDim))))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    Dropout))
              Dropout
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        ()
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              Dropout
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           ()
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 Dropout
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
-&gt; Vector
     numLayers
     (ModelSpec
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           ()
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 Dropout
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    Dropout))
              Dropout
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        ()
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              Dropout
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
forall (n :: Nat) a.
SNat n -&gt; Vector n (ModelSpec a) -&gt; VectorSpec n a
</span><a href="Torch.GraduallyTyped.NN.Class.html#VectorSpec"><span class="hs-identifier hs-var">VectorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679584572"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SNat numLayers
-&gt; GTransformerBlock
     (NamedModel
        (GSelfAttention
           (ModelSpec
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (ModelSpec
                    (QInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (KInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (VInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (OutProjF style gradient device dataType embedDim queryEmbedDim))
                 Dropout))
           Dropout
           (ModelSpec
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
     ()
     (NamedModel
        (GTransformerFeedForwardNetwork
           (ModelSpec
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
           (ModelSpec
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim))
           (ModelSpec (FFNActivationF style))
           (ModelSpec (FFNActivationDropoutF style))
           (ModelSpec
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim))
           Dropout
           (ModelSpec
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; Vector
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (ModelSpec
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (ModelSpec
                       (QInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (KInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (VInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (OutProjF style gradient device dataType embedDim queryEmbedDim))
                    Dropout))
              Dropout
              (ModelSpec
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
        ()
        (NamedModel
           (GTransformerFeedForwardNetwork
              (ModelSpec
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
              (ModelSpec
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim))
              (ModelSpec (FFNActivationF style))
              (ModelSpec (FFNActivationDropoutF style))
              (ModelSpec
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim))
              Dropout
              (ModelSpec
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall (n :: Nat) a (p :: Nat -&gt; *).
KnownNat n =&gt;
p n -&gt; a -&gt; Vector n a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">VS.replicate'</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679584572"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GTransformerBlock
     (EncoderBlockSelfAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
     EncoderBlockCrossAttentionF
     (EncoderBlockFeedForwardNetworkF
        style gradient device dataType queryEmbedDim ffnDim))
GTransformerBlock
  (NamedModel
     (GSelfAttention
        (ModelSpec
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
        (NamedModel
           (GMultiHeadAttention
              headDim
              headEmbedDim
              embedDim
              (ModelSpec
                 (QInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (KInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (VInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (OutProjF style gradient device dataType embedDim queryEmbedDim))
              Dropout))
        Dropout
        (ModelSpec
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
  ()
  (NamedModel
     (GTransformerFeedForwardNetwork
        (ModelSpec
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
        (ModelSpec
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim))
        (ModelSpec (FFNActivationF style))
        (ModelSpec (FFNActivationDropoutF style))
        (ModelSpec
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim))
        Dropout
        (ModelSpec
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
</span><a href="#local-6989586621679584560"><span class="hs-identifier hs-var">blockSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-80"></span><span>
</span><span id="line-81"></span><span class="hs-comment">-- | Specifies the parameters of a transformer stack in a decoder configuration.</span><span>
</span><span id="line-82"></span><span class="hs-comment">--</span><span>
</span><span id="line-83"></span><span class="hs-comment">-- - @style@: the style of the transformer stack, e.g. 'ST5', 'SByT5', etc.</span><span>
</span><span id="line-84"></span><span class="hs-comment">-- - @gradient@: whether to compute the gradient of the stack's parameters.</span><span>
</span><span id="line-85"></span><span class="hs-comment">-- - @device@: the computational device on which the stack is allocated.</span><span>
</span><span id="line-86"></span><span class="hs-comment">-- - @dataType@: the data type of the stack's parameters.</span><span>
</span><span id="line-87"></span><span class="hs-comment">-- - @headDim@: the dimension of all transformer heads in the stack.</span><span>
</span><span id="line-88"></span><span class="hs-comment">-- - @headEmbedDim@: the dimension of the transformer head embeddings.</span><span>
</span><span id="line-89"></span><span class="hs-comment">-- - @embedDim@: the dimension of the transformer embeddings.</span><span>
</span><span id="line-90"></span><span class="hs-comment">-- - @queryEmbedDim@: the dimension of the transformer query embeddings.</span><span>
</span><span id="line-91"></span><span class="hs-comment">-- - @keyEmbedDim@: the dimension of the transformer key embeddings.</span><span>
</span><span id="line-92"></span><span class="hs-comment">-- - @ffnDim@: the dimension of the feed-forward network.</span><span>
</span><span id="line-93"></span><span class="hs-comment">-- - @dropoutP@: the dropout rate.</span><span>
</span><span id="line-94"></span><span class="hs-comment">-- - @eps@: the epsilon value for numerical stability of the layer normalization.</span><span>
</span><span id="line-95"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#decoderStackSpec"><span class="hs-identifier hs-type">decoderStackSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-96"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679584556"><span class="annot"><a href="#local-6989586621679584556"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679584555"><span class="annot"><a href="#local-6989586621679584555"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679584554"><span class="annot"><a href="#local-6989586621679584554"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679584553"><span class="annot"><a href="#local-6989586621679584553"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679584552"><span class="annot"><a href="#local-6989586621679584552"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679584551"><span class="annot"><a href="#local-6989586621679584551"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679584550"><span class="annot"><a href="#local-6989586621679584550"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584549"><span class="annot"><a href="#local-6989586621679584549"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679584548"><span class="annot"><a href="#local-6989586621679584548"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584547"><span class="annot"><a href="#local-6989586621679584547"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584546"><span class="annot"><a href="#local-6989586621679584546"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-97"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584556"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-98"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584555"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-99"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584554"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-100"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584553"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-101"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584552"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-102"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584551"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-103"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584550"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-104"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584549"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-105"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584548"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-106"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584547"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-107"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584546"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-108"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-109"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-110"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span>
</span><span id="line-112"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span>
</span><span id="line-113"></span><span>            </span><span class="annot"><a href="#local-6989586621679584555"><span class="hs-identifier hs-type">numLayers</span></a></span><span>
</span><span id="line-114"></span><span>            </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#GTransformerBlock"><span class="hs-identifier hs-type">GTransformerBlock</span></a></span><span>
</span><span id="line-115"></span><span>                </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockSelfAttentionF"><span class="hs-identifier hs-type">DecoderBlockSelfAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584556"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584554"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584553"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584552"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584551"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584550"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584549"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584548"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>                </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockCrossAttentionF"><span class="hs-identifier hs-type">DecoderBlockCrossAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584556"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584554"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584553"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584552"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584551"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584550"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584549"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584548"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584547"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>                </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#DecoderBlockFeedForwardNetworkF"><span class="hs-identifier hs-type">DecoderBlockFeedForwardNetworkF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584556"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584554"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584553"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584552"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584548"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584546"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>            </span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span id="decoderStackSpec"><span class="annot"><span class="annottext">decoderStackSpec :: STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformerStack
        (Vector
           numLayers
           (GTransformerBlock
              (DecoderBlockSelfAttentionF
                 style
                 gradient
                 device
                 dataType
                 headDim
                 headEmbedDim
                 embedDim
                 queryEmbedDim)
              (DecoderBlockCrossAttentionF
                 style
                 gradient
                 device
                 dataType
                 headDim
                 headEmbedDim
                 embedDim
                 queryEmbedDim
                 keyEmbedDim)
              (DecoderBlockFeedForwardNetworkF
                 style gradient device dataType queryEmbedDim ffnDim))))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#decoderStackSpec"><span class="hs-identifier hs-var hs-var">decoderStackSpec</span></a></span></span><span> </span><span id="local-6989586621679584545"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679584545"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679584544"><span class="annot"><span class="annottext">numLayers :: SNat numLayers
</span><a href="#local-6989586621679584544"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span id="local-6989586621679584543"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679584543"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679584542"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679584542"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679584541"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679584541"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679584540"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679584540"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679584539"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679584539"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584538"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679584538"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679584537"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679584537"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584536"><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679584536"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679584535"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679584535"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679584534"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584534"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679584533"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584533"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-122"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679584532"><span class="annot"><span class="annottext">blockSpec :: ModelSpec
  (GTransformerBlock
     (DecoderBlockSelfAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
     (DecoderBlockCrossAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim)
     (DecoderBlockFeedForwardNetworkF
        style gradient device dataType queryEmbedDim ffnDim))
</span><a href="#local-6989586621679584532"><span class="hs-identifier hs-var hs-var">blockSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformerBlock
        (DecoderBlockSelfAttentionF
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim)
        (DecoderBlockCrossAttentionF
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim)
        (DecoderBlockFeedForwardNetworkF
           style gradient device dataType queryEmbedDim ffnDim))
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; ModelSpec
     (GTransformerBlock
        (DecoderBlockSelfAttentionF
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim)
        (DecoderBlockCrossAttentionF
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim)
        (DecoderBlockFeedForwardNetworkF
           style gradient device dataType queryEmbedDim ffnDim))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GBlock.html#decoderBlockSpec"><span class="hs-identifier hs-var">decoderBlockSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679584545"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679584543"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679584542"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679584541"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679584540"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679584539"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679584538"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679584537"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679584536"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679584535"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584534"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679584533"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-123"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">VectorSpec
  numLayers
  (GTransformerBlock
     (NamedModel
        (GSelfAttention
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (QInProjF style gradient device dataType queryEmbedDim embedDim)
                 (KInProjF style gradient device dataType queryEmbedDim embedDim)
                 (VInProjF style gradient device dataType queryEmbedDim embedDim)
                 (OutProjF style gradient device dataType embedDim queryEmbedDim)
                 Dropout))
           Dropout
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
     (NamedModel
        (GCrossAttention
           (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (QInProjF style gradient device dataType queryEmbedDim embedDim)
                 (KInProjF style gradient device dataType keyEmbedDim embedDim)
                 (VInProjF style gradient device dataType keyEmbedDim embedDim)
                 (OutProjF style gradient device dataType embedDim queryEmbedDim)
                 Dropout))
           Dropout
           (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
     (NamedModel
        (GTransformerFeedForwardNetwork
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim)
           (FFNActivationF style)
           (FFNActivationDropoutF style)
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim)
           Dropout
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GCrossAttention
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType keyEmbedDim embedDim)
                       (VInProjF style gradient device dataType keyEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 Dropout
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall stack. stack -&gt; GTransformerStack stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span><span> </span><span class="annot"><span class="annottext">(VectorSpec
   numLayers
   (GTransformerBlock
      (NamedModel
         (GSelfAttention
            (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
            (NamedModel
               (GMultiHeadAttention
                  headDim
                  headEmbedDim
                  embedDim
                  (QInProjF style gradient device dataType queryEmbedDim embedDim)
                  (KInProjF style gradient device dataType queryEmbedDim embedDim)
                  (VInProjF style gradient device dataType queryEmbedDim embedDim)
                  (OutProjF style gradient device dataType embedDim queryEmbedDim)
                  Dropout))
            Dropout
            (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
      (NamedModel
         (GCrossAttention
            (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
            (NamedModel
               (GMultiHeadAttention
                  headDim
                  headEmbedDim
                  embedDim
                  (QInProjF style gradient device dataType queryEmbedDim embedDim)
                  (KInProjF style gradient device dataType keyEmbedDim embedDim)
                  (VInProjF style gradient device dataType keyEmbedDim embedDim)
                  (OutProjF style gradient device dataType embedDim queryEmbedDim)
                  Dropout))
            Dropout
            (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
      (NamedModel
         (GTransformerFeedForwardNetwork
            (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
            (FFNInputTransformationF
               style gradient device dataType queryEmbedDim ffnDim)
            (FFNActivationF style)
            (FFNActivationDropoutF style)
            (FFNOutputProjectionF
               style gradient device dataType queryEmbedDim ffnDim)
            Dropout
            (FFNOutputLayerNormF
               style gradient device dataType queryEmbedDim))))
 -&gt; GTransformerStack
      (VectorSpec
         numLayers
         (GTransformerBlock
            (NamedModel
               (GSelfAttention
                  (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                  (NamedModel
                     (GMultiHeadAttention
                        headDim
                        headEmbedDim
                        embedDim
                        (QInProjF style gradient device dataType queryEmbedDim embedDim)
                        (KInProjF style gradient device dataType queryEmbedDim embedDim)
                        (VInProjF style gradient device dataType queryEmbedDim embedDim)
                        (OutProjF style gradient device dataType embedDim queryEmbedDim)
                        Dropout))
                  Dropout
                  (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
            (NamedModel
               (GCrossAttention
                  (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                  (NamedModel
                     (GMultiHeadAttention
                        headDim
                        headEmbedDim
                        embedDim
                        (QInProjF style gradient device dataType queryEmbedDim embedDim)
                        (KInProjF style gradient device dataType keyEmbedDim embedDim)
                        (VInProjF style gradient device dataType keyEmbedDim embedDim)
                        (OutProjF style gradient device dataType embedDim queryEmbedDim)
                        Dropout))
                  Dropout
                  (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
            (NamedModel
               (GTransformerFeedForwardNetwork
                  (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                  (FFNInputTransformationF
                     style gradient device dataType queryEmbedDim ffnDim)
                  (FFNActivationF style)
                  (FFNActivationDropoutF style)
                  (FFNOutputProjectionF
                     style gradient device dataType queryEmbedDim ffnDim)
                  Dropout
                  (FFNOutputLayerNormF
                     style gradient device dataType queryEmbedDim))))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    Dropout))
              Dropout
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GCrossAttention
              (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType keyEmbedDim embedDim)
                    (VInProjF style gradient device dataType keyEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    Dropout))
              Dropout
              (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              Dropout
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; GTransformerStack
     (VectorSpec
        numLayers
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GCrossAttention
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType keyEmbedDim embedDim)
                       (VInProjF style gradient device dataType keyEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 Dropout
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
-&gt; Vector
     numLayers
     (ModelSpec
        (GTransformerBlock
           (NamedModel
              (GSelfAttention
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType queryEmbedDim embedDim)
                       (VInProjF style gradient device dataType queryEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GCrossAttention
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
                 (NamedModel
                    (GMultiHeadAttention
                       headDim
                       headEmbedDim
                       embedDim
                       (QInProjF style gradient device dataType queryEmbedDim embedDim)
                       (KInProjF style gradient device dataType keyEmbedDim embedDim)
                       (VInProjF style gradient device dataType keyEmbedDim embedDim)
                       (OutProjF style gradient device dataType embedDim queryEmbedDim)
                       Dropout))
                 Dropout
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
           (NamedModel
              (GTransformerFeedForwardNetwork
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim)
                 (FFNActivationF style)
                 (FFNActivationDropoutF style)
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim)
                 Dropout
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
-&gt; VectorSpec
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType queryEmbedDim embedDim)
                    (VInProjF style gradient device dataType queryEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    Dropout))
              Dropout
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GCrossAttention
              (CAInitialLayerNormF style gradient device dataType queryEmbedDim)
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (QInProjF style gradient device dataType queryEmbedDim embedDim)
                    (KInProjF style gradient device dataType keyEmbedDim embedDim)
                    (VInProjF style gradient device dataType keyEmbedDim embedDim)
                    (OutProjF style gradient device dataType embedDim queryEmbedDim)
                    Dropout))
              Dropout
              (CAFinalLayerNormF style gradient device dataType queryEmbedDim)))
        (NamedModel
           (GTransformerFeedForwardNetwork
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim)
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim)
              (FFNActivationF style)
              (FFNActivationDropoutF style)
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim)
              Dropout
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
forall (n :: Nat) a.
SNat n -&gt; Vector n (ModelSpec a) -&gt; VectorSpec n a
</span><a href="Torch.GraduallyTyped.NN.Class.html#VectorSpec"><span class="hs-identifier hs-var">VectorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679584544"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SNat numLayers
-&gt; GTransformerBlock
     (NamedModel
        (GSelfAttention
           (ModelSpec
              (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (ModelSpec
                    (QInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (KInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (VInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (OutProjF style gradient device dataType embedDim queryEmbedDim))
                 Dropout))
           Dropout
           (ModelSpec
              (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
     (NamedModel
        (GCrossAttention
           (ModelSpec
              (CAInitialLayerNormF style gradient device dataType queryEmbedDim))
           (NamedModel
              (GMultiHeadAttention
                 headDim
                 headEmbedDim
                 embedDim
                 (ModelSpec
                    (QInProjF style gradient device dataType queryEmbedDim embedDim))
                 (ModelSpec
                    (KInProjF style gradient device dataType keyEmbedDim embedDim))
                 (ModelSpec
                    (VInProjF style gradient device dataType keyEmbedDim embedDim))
                 (ModelSpec
                    (OutProjF style gradient device dataType embedDim queryEmbedDim))
                 Dropout))
           Dropout
           (ModelSpec
              (CAFinalLayerNormF style gradient device dataType queryEmbedDim))))
     (NamedModel
        (GTransformerFeedForwardNetwork
           (ModelSpec
              (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
           (ModelSpec
              (FFNInputTransformationF
                 style gradient device dataType queryEmbedDim ffnDim))
           (ModelSpec (FFNActivationF style))
           (ModelSpec (FFNActivationDropoutF style))
           (ModelSpec
              (FFNOutputProjectionF
                 style gradient device dataType queryEmbedDim ffnDim))
           Dropout
           (ModelSpec
              (FFNOutputLayerNormF
                 style gradient device dataType queryEmbedDim))))
-&gt; Vector
     numLayers
     (GTransformerBlock
        (NamedModel
           (GSelfAttention
              (ModelSpec
                 (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (ModelSpec
                       (QInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (KInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (VInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (OutProjF style gradient device dataType embedDim queryEmbedDim))
                    Dropout))
              Dropout
              (ModelSpec
                 (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
        (NamedModel
           (GCrossAttention
              (ModelSpec
                 (CAInitialLayerNormF style gradient device dataType queryEmbedDim))
              (NamedModel
                 (GMultiHeadAttention
                    headDim
                    headEmbedDim
                    embedDim
                    (ModelSpec
                       (QInProjF style gradient device dataType queryEmbedDim embedDim))
                    (ModelSpec
                       (KInProjF style gradient device dataType keyEmbedDim embedDim))
                    (ModelSpec
                       (VInProjF style gradient device dataType keyEmbedDim embedDim))
                    (ModelSpec
                       (OutProjF style gradient device dataType embedDim queryEmbedDim))
                    Dropout))
              Dropout
              (ModelSpec
                 (CAFinalLayerNormF style gradient device dataType queryEmbedDim))))
        (NamedModel
           (GTransformerFeedForwardNetwork
              (ModelSpec
                 (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
              (ModelSpec
                 (FFNInputTransformationF
                    style gradient device dataType queryEmbedDim ffnDim))
              (ModelSpec (FFNActivationF style))
              (ModelSpec (FFNActivationDropoutF style))
              (ModelSpec
                 (FFNOutputProjectionF
                    style gradient device dataType queryEmbedDim ffnDim))
              Dropout
              (ModelSpec
                 (FFNOutputLayerNormF
                    style gradient device dataType queryEmbedDim)))))
forall (n :: Nat) a (p :: Nat -&gt; *).
KnownNat n =&gt;
p n -&gt; a -&gt; Vector n a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">VS.replicate'</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679584544"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GTransformerBlock
     (DecoderBlockSelfAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
     (DecoderBlockCrossAttentionF
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim)
     (DecoderBlockFeedForwardNetworkF
        style gradient device dataType queryEmbedDim ffnDim))
GTransformerBlock
  (NamedModel
     (GSelfAttention
        (ModelSpec
           (SAInitialLayerNormF style gradient device dataType queryEmbedDim))
        (NamedModel
           (GMultiHeadAttention
              headDim
              headEmbedDim
              embedDim
              (ModelSpec
                 (QInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (KInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (VInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (OutProjF style gradient device dataType embedDim queryEmbedDim))
              Dropout))
        Dropout
        (ModelSpec
           (SAFinalLayerNormF style gradient device dataType queryEmbedDim))))
  (NamedModel
     (GCrossAttention
        (ModelSpec
           (CAInitialLayerNormF style gradient device dataType queryEmbedDim))
        (NamedModel
           (GMultiHeadAttention
              headDim
              headEmbedDim
              embedDim
              (ModelSpec
                 (QInProjF style gradient device dataType queryEmbedDim embedDim))
              (ModelSpec
                 (KInProjF style gradient device dataType keyEmbedDim embedDim))
              (ModelSpec
                 (VInProjF style gradient device dataType keyEmbedDim embedDim))
              (ModelSpec
                 (OutProjF style gradient device dataType embedDim queryEmbedDim))
              Dropout))
        Dropout
        (ModelSpec
           (CAFinalLayerNormF style gradient device dataType queryEmbedDim))))
  (NamedModel
     (GTransformerFeedForwardNetwork
        (ModelSpec
           (FFNInputLayerNormF style gradient device dataType queryEmbedDim))
        (ModelSpec
           (FFNInputTransformationF
              style gradient device dataType queryEmbedDim ffnDim))
        (ModelSpec (FFNActivationF style))
        (ModelSpec (FFNActivationDropoutF style))
        (ModelSpec
           (FFNOutputProjectionF
              style gradient device dataType queryEmbedDim ffnDim))
        Dropout
        (ModelSpec
           (FFNOutputLayerNormF
              style gradient device dataType queryEmbedDim))))
</span><a href="#local-6989586621679584532"><span class="hs-identifier hs-var">blockSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>
</span><span id="line-125"></span><span id="local-6989586621679584528"><span id="local-6989586621679584529"><span id="local-6989586621679584530"><span id="local-6989586621679584531"><span class="hs-keyword">instance</span><span>
</span><span id="line-126"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584531"><span class="hs-identifier hs-type">block</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584530"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584531"><span class="hs-identifier hs-type">block</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584530"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-127"></span><span>    </span><span class="annot"><a href="#local-6989586621679584529"><span class="hs-identifier hs-type">numLayers'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584528"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-129"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-130"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584529"><span class="hs-identifier hs-type">numLayers'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584531"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><a href="#local-6989586621679584530"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-132"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584529"><span class="hs-identifier hs-type">numLayers'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584531"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><a href="#local-6989586621679584530"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-134"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-135"></span><span>  </span><span id="local-6989586621679584525"><span class="annot"><span class="annottext">initialize :: ModelSpec (GTransformerStack (Vector numLayers' block))
-&gt; Generator generatorDevice
-&gt; m (GTransformerStack (Vector numLayers' block),
      Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span id="local-6989586621679584523"><span class="annot"><a href="#local-6989586621679584523"><span class="hs-identifier hs-var">vSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-136"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679584522"><span class="annot"><span class="annottext">v :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Vector numLayers' block)
</span><a href="#local-6989586621679584522"><span class="hs-identifier hs-var hs-var">v</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Vector numLayers' block, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Vector numLayers' block)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Vector numLayers' block, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Vector numLayers' block))
-&gt; (VectorSpec numLayers' block
    -&gt; Generator generatorDevice
    -&gt; m (Vector numLayers' block, Generator generatorDevice))
-&gt; VectorSpec numLayers' block
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Vector numLayers' block)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">VectorSpec numLayers' block
-&gt; Generator generatorDevice
-&gt; m (Vector numLayers' block, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(VectorSpec numLayers' block
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Vector numLayers' block))
-&gt; VectorSpec numLayers' block
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Vector numLayers' block)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">VectorSpec numLayers' block
</span><a href="#local-6989586621679584523"><span class="hs-identifier hs-var">vSpec</span></a></span><span>
</span><span id="line-137"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GTransformerStack (Vector numLayers' block))
-&gt; Generator generatorDevice
-&gt; m (GTransformerStack (Vector numLayers' block),
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Vector numLayers' block
-&gt; GTransformerStack (Vector numLayers' block)
forall stack. stack -&gt; GTransformerStack stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span><span> </span><span class="annot"><span class="annottext">(Vector numLayers' block
 -&gt; GTransformerStack (Vector numLayers' block))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Vector numLayers' block)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GTransformerStack (Vector numLayers' block))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Vector numLayers' block)
</span><a href="#local-6989586621679584522"><span class="hs-identifier hs-var">v</span></a></span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-138"></span><span>
</span><span id="line-139"></span><span id="local-6989586621679584517"><span id="local-6989586621679584518"><span class="hs-keyword">instance</span><span>
</span><span id="line-140"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584518"><span class="hs-identifier hs-type">block</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-141"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584517"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584518"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-143"></span><span>  </span><span id="local-6989586621679584513"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (GTransformerStack (Vector numLayers block))
-&gt; StateDictKey -&gt; m (GTransformerStack (Vector numLayers block))
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span id="local-6989586621679584511"><span class="annot"><a href="#local-6989586621679584511"><span class="hs-identifier hs-var">vSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679584510"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679584510"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-144"></span><span>    </span><span class="annot"><span class="annottext">Vector numLayers block
-&gt; GTransformerStack (Vector numLayers block)
forall stack. stack -&gt; GTransformerStack stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-var">GTransformerStack</span></a></span><span> </span><span class="annot"><span class="annottext">(Vector numLayers block
 -&gt; GTransformerStack (Vector numLayers block))
-&gt; m (Vector numLayers block)
-&gt; m (GTransformerStack (Vector numLayers block))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (Vector numLayers block)
-&gt; StateDictKey -&gt; m (Vector numLayers block)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">VectorSpec numLayers block
ModelSpec (Vector numLayers block)
</span><a href="#local-6989586621679584511"><span class="hs-identifier hs-var">vSpec</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679584510"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-145"></span><span>  </span><span id="local-6989586621679584508"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; GTransformerStack (Vector numLayers block) -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679584506"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679584506"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span id="local-6989586621679584505"><span class="annot"><span class="annottext">Vector numLayers block
</span><a href="#local-6989586621679584505"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Vector numLayers block -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679584506"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">Vector numLayers block
</span><a href="#local-6989586621679584505"><span class="hs-identifier hs-var">v</span></a></span></span></span><span>
</span><span id="line-146"></span><span>
</span><span id="line-147"></span><span id="local-6989586621679584501"><span id="local-6989586621679584502"><span id="local-6989586621679584503"><span id="local-6989586621679584504"><span class="hs-keyword">instance</span><span>
</span><span id="line-148"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="annot"><a href="#local-6989586621679584504"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584503"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584502"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="annot"><a href="#local-6989586621679584501"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-152"></span><span>    </span><span class="annot"><a href="#local-6989586621679584503"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-153"></span><span>    </span><span class="annot"><a href="#local-6989586621679584501"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-154"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-155"></span><span>  </span><span id="local-6989586621679584498"><span class="annot"><span class="annottext">forward :: GTransformerStack (Vector 0 block)
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (query, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">GTransformerStack (Vector 0 block)
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584496"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584496"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(query, Generator generatorDevice)
-&gt; m (query, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">((query, Generator generatorDevice)
 -&gt; m (query, Generator generatorDevice))
-&gt; (Generator generatorDevice
    -&gt; (query, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (query, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584496"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-156"></span><span>
</span><span id="line-157"></span><span id="local-6989586621679584490"><span id="local-6989586621679584491"><span id="local-6989586621679584492"><span id="local-6989586621679584493"><span id="local-6989586621679584494"><span id="local-6989586621679584495"><span class="hs-keyword">instance</span><span>
</span><span id="line-158"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-159"></span><span>    </span><span class="annot"><a href="#local-6989586621679584495"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-160"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584494"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584493"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>    </span><span class="annot"><a href="#local-6989586621679584492"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-162"></span><span>    </span><span class="annot"><a href="#local-6989586621679584491"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-163"></span><span>    </span><span class="annot"><a href="#local-6989586621679584490"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-164"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679584495"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584494"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584493"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="annot"><a href="#local-6989586621679584492"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-168"></span><span>    </span><span class="annot"><a href="#local-6989586621679584491"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-169"></span><span>    </span><span class="annot"><a href="#local-6989586621679584490"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-170"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-171"></span><span>  </span><span id="local-6989586621679584488"><span class="annot"><span class="annottext">forward :: GTransformerStack (Vector 1 block)
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584488"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679584486"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584486"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679584485"><span class="annot"><span class="annottext">(query, attentionBias)
</span><a href="#local-6989586621679584485"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679584484"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584484"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-172"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584483"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584483"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Vector block
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584486"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-173"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584483"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="annot"><span class="annottext">(query, attentionBias)
</span><a href="#local-6989586621679584485"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584484"><span class="hs-identifier hs-var">g</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-174"></span><span>
</span><span id="line-175"></span><span id="local-6989586621679584476"><span id="local-6989586621679584477"><span id="local-6989586621679584478"><span id="local-6989586621679584479"><span id="local-6989586621679584480"><span id="local-6989586621679584481"><span class="hs-keyword">instance</span><span>
</span><span id="line-176"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span> </span><span class="annot"><a href="#local-6989586621679584481"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584480"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584479"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584478"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584477"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>    </span><span class="annot"><a href="#local-6989586621679584476"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-180"></span><span>    </span><span class="annot"><a href="#local-6989586621679584480"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-181"></span><span>    </span><span class="annot"><a href="#local-6989586621679584476"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-182"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-183"></span><span>  </span><span id="local-6989586621679584474"><span class="annot"><span class="annottext">forward :: GTransformerStack (Vector 0 block)
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generator
-&gt; m (query, Generator generator)
</span><a href="#local-6989586621679584474"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">GTransformerStack (Vector 0 block)
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584473"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584473"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionBias
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(query, Generator generator) -&gt; m (query, Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">((query, Generator generator) -&gt; m (query, Generator generator))
-&gt; (Generator generator -&gt; (query, Generator generator))
-&gt; Generator generator
-&gt; m (query, Generator generator)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584473"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-184"></span><span>
</span><span id="line-185"></span><span id="local-6989586621679584465"><span id="local-6989586621679584466"><span id="local-6989586621679584467"><span id="local-6989586621679584468"><span id="local-6989586621679584469"><span id="local-6989586621679584470"><span id="local-6989586621679584471"><span id="local-6989586621679584472"><span class="hs-keyword">instance</span><span>
</span><span id="line-186"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span class="annot"><a href="#local-6989586621679584472"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-188"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584471"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584470"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584469"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584468"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>    </span><span class="annot"><a href="#local-6989586621679584467"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-190"></span><span>    </span><span class="annot"><a href="#local-6989586621679584466"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-191"></span><span>    </span><span class="annot"><a href="#local-6989586621679584465"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-192"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-193"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><a href="#local-6989586621679584472"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-194"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584471"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584470"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584469"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584468"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-195"></span><span>    </span><span class="annot"><a href="#local-6989586621679584467"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-196"></span><span>    </span><span class="annot"><a href="#local-6989586621679584466"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-197"></span><span>    </span><span class="annot"><a href="#local-6989586621679584465"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-198"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-199"></span><span>  </span><span id="local-6989586621679584463"><span class="annot"><span class="annottext">forward :: GTransformerStack (Vector 1 block)
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584463"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679584462"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584462"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679584461"><span class="annot"><span class="annottext">(query, key, attentionBias, crossAttentionBias)
</span><a href="#local-6989586621679584461"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679584460"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584460"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-200"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584459"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584459"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Vector block
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584462"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-201"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584459"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="annot"><span class="annottext">(query, key, attentionBias, crossAttentionBias)
</span><a href="#local-6989586621679584461"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584460"><span class="hs-identifier hs-var">g</span></a></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-202"></span><span>
</span><span id="line-203"></span><span class="hs-comment">-- | 'HasForward' instance for 'GTransformerStack' in an encoder configuration.</span><span>
</span><span id="line-204"></span><span class="hs-comment">--</span><span>
</span><span id="line-205"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-206"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-207"></span><span class="hs-comment">-- &#9474; query &#9474;  &#9474; attentionBias &#9474;</span><span>
</span><span id="line-208"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-209"></span><span class="hs-comment">--     &#9474;              &#9474;</span><span>
</span><span id="line-210"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-211"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-212"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-213"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-214"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-215"></span><span class="hs-comment">--    ...            ...</span><span>
</span><span id="line-216"></span><span class="hs-comment">--     &#9660;              &#9474;</span><span>
</span><span id="line-217"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-218"></span><span class="hs-comment">--     &#9474;</span><span>
</span><span id="line-219"></span><span class="hs-comment">--     &#9660;</span><span>
</span><span id="line-220"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-221"></span><span class="hs-comment">-- &#9474; query &#9474;</span><span>
</span><span id="line-222"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-223"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-224"></span><span id="local-6989586621679584452"><span id="local-6989586621679584453"><span id="local-6989586621679584454"><span id="local-6989586621679584455"><span id="local-6989586621679584456"><span id="local-6989586621679584457"><span id="local-6989586621679584458"><span class="hs-keyword">instance</span><span>
</span><span id="line-225"></span><span>  </span><span class="hs-pragma">{-# OVERLAPPABLE</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-226"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-227"></span><span>      </span><span class="annot"><a href="#local-6989586621679584458"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-228"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584457"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584456"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>      </span><span class="annot"><a href="#local-6989586621679584455"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-230"></span><span>      </span><span class="annot"><a href="#local-6989586621679584454"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-231"></span><span>      </span><span class="annot"><a href="#local-6989586621679584453"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-232"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-233"></span><span>      </span><span class="annot"><a href="#local-6989586621679584458"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-234"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584454"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584456"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-235"></span><span>      </span><span class="annot"><a href="#local-6989586621679584453"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-236"></span><span>      </span><span class="annot"><a href="#local-6989586621679584454"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-237"></span><span>      </span><span class="annot"><a href="#local-6989586621679584453"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-238"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-239"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-240"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584452"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584458"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584457"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584456"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-242"></span><span>    </span><span class="annot"><a href="#local-6989586621679584455"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-243"></span><span>    </span><span class="annot"><a href="#local-6989586621679584454"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-244"></span><span>    </span><span class="annot"><a href="#local-6989586621679584453"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-245"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-246"></span><span>  </span><span id="local-6989586621679584450"><span class="annot"><span class="annottext">forward :: GTransformerStack (Vector n block)
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584450"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679584449"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584449"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584448"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584448"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584447"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679584447"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679584446"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584446"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-247"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584445"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584445"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584444"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584444"><span class="hs-identifier hs-var">blocks</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584449"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-248"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(m (output, Generator generatorOutputDevice)
 -&gt; block -&gt; m (output, Generator generatorOutputDevice))
-&gt; m (output, Generator generatorOutputDevice)
-&gt; Vector block
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b -&gt; a) -&gt; a -&gt; Vector b -&gt; a
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.foldl</span></a></span><span>
</span><span id="line-249"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679584442"><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584442"><span class="hs-identifier hs-var">agg</span></a></span></span><span> </span><span id="local-6989586621679584441"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584441"><span class="hs-identifier hs-var">block'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-250"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679584440"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584440"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584439"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584439"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584442"><span class="hs-identifier hs-var">agg</span></a></span><span>
</span><span id="line-251"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679584438"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584438"><span class="hs-identifier hs-var">output'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584437"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584437"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (output, attentionBias)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584441"><span class="hs-identifier hs-var">block'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584440"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679584447"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584439"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-252"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584438"><span class="hs-identifier hs-var">output'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584437"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-254"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-255"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679584436"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584436"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584435"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584435"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584445"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584448"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679584447"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584446"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-256"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584436"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584435"><span class="hs-identifier hs-var">g'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>          </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584444"><span class="hs-identifier hs-var">blocks</span></a></span></span></span></span></span></span></span></span><span>
</span><span id="line-259"></span><span>
</span><span id="line-260"></span><span class="hs-comment">-- | 'HasForward' instance for 'GTransformerStack' in a decoder configuration.</span><span>
</span><span id="line-261"></span><span class="hs-comment">--</span><span>
</span><span id="line-262"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-263"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-264"></span><span class="hs-comment">-- &#9474; query &#9474;  &#9474; key &#9474;  &#9474; attentionBias &#9474;  &#9474; crossAttentionBias &#9474;</span><span>
</span><span id="line-265"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-266"></span><span class="hs-comment">--     &#9474;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-267"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-268"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-269"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-270"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;</span><span>
</span><span id="line-271"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-272"></span><span class="hs-comment">--    ...       ...           ...                  ...</span><span>
</span><span id="line-273"></span><span class="hs-comment">--     &#9660;         &#9474;             &#9474;                    &#9474;</span><span>
</span><span id="line-274"></span><span class="hs-comment">--   block&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-275"></span><span class="hs-comment">--     &#9474;</span><span>
</span><span id="line-276"></span><span class="hs-comment">--     &#9660;</span><span>
</span><span id="line-277"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-278"></span><span class="hs-comment">-- &#9474; query &#9474;</span><span>
</span><span id="line-279"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-280"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-281"></span><span id="local-6989586621679584426"><span id="local-6989586621679584427"><span id="local-6989586621679584428"><span id="local-6989586621679584429"><span id="local-6989586621679584430"><span id="local-6989586621679584431"><span id="local-6989586621679584432"><span id="local-6989586621679584433"><span id="local-6989586621679584434"><span class="hs-keyword">instance</span><span>
</span><span id="line-282"></span><span>  </span><span class="hs-pragma">{-# OVERLAPPABLE</span><span> </span><span class="hs-pragma">#-}</span><span>
</span><span id="line-283"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-284"></span><span>      </span><span class="annot"><a href="#local-6989586621679584434"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-285"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584433"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584432"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584431"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584430"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-286"></span><span>      </span><span class="annot"><a href="#local-6989586621679584429"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-287"></span><span>      </span><span class="annot"><a href="#local-6989586621679584428"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-288"></span><span>      </span><span class="annot"><a href="#local-6989586621679584427"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-289"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-290"></span><span>      </span><span class="annot"><a href="#local-6989586621679584434"><span class="hs-identifier hs-type">block</span></a></span><span>
</span><span id="line-291"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584428"><span class="hs-identifier hs-type">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584432"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584431"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584430"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>      </span><span class="annot"><a href="#local-6989586621679584427"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-293"></span><span>      </span><span class="annot"><a href="#local-6989586621679584428"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-294"></span><span>      </span><span class="annot"><a href="#local-6989586621679584427"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-295"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-296"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-297"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VS.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584426"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679584434"><span class="hs-identifier hs-type">block</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679584433"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584432"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584431"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679584430"><span class="hs-identifier hs-type">crossAttentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-299"></span><span>    </span><span class="annot"><a href="#local-6989586621679584429"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-300"></span><span>    </span><span class="annot"><a href="#local-6989586621679584428"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-301"></span><span>    </span><span class="annot"><a href="#local-6989586621679584427"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-302"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-303"></span><span>  </span><span id="local-6989586621679584424"><span class="annot"><span class="annottext">forward :: GTransformerStack (Vector n block)
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584424"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GStack.html#GTransformerStack"><span class="hs-identifier hs-type">GTransformerStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">VGS.Vector</span></a></span><span> </span><span id="local-6989586621679584423"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584423"><span class="hs-identifier hs-var">v</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584422"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584422"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584421"><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679584421"><span class="hs-identifier hs-var">key</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584420"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679584420"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584419"><span class="annot"><span class="annottext">crossAttentionBias
</span><a href="#local-6989586621679584419"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679584418"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584418"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-304"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679584417"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584417"><span class="hs-identifier hs-var">block</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584416"><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584416"><span class="hs-identifier hs-var">blocks</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector block -&gt; Maybe (block, Vector block)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.uncons</span></a></span><span> </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584423"><span class="hs-identifier hs-var">v</span></a></span><span>
</span><span id="line-305"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(m (output, Generator generatorOutputDevice)
 -&gt; block -&gt; m (output, Generator generatorOutputDevice))
-&gt; m (output, Generator generatorOutputDevice)
-&gt; Vector block
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b -&gt; a) -&gt; a -&gt; Vector b -&gt; a
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.foldl</span></a></span><span>
</span><span id="line-306"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679584415"><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584415"><span class="hs-identifier hs-var">agg</span></a></span></span><span> </span><span id="local-6989586621679584414"><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584414"><span class="hs-identifier hs-var">block'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-307"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679584413"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584413"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584412"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584412"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679584415"><span class="hs-identifier hs-var">agg</span></a></span><span>
</span><span id="line-308"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679584411"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584411"><span class="hs-identifier hs-var">output'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584410"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584410"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (output, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584414"><span class="hs-identifier hs-var">block'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584413"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679584421"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679584420"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionBias
</span><a href="#local-6989586621679584419"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584412"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-309"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584411"><span class="hs-identifier hs-var">output'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584410"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-310"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-312"></span><span>              </span><span class="hs-special">(</span><span id="local-6989586621679584409"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584409"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679584408"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584408"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">block
-&gt; (query, key, attentionBias, crossAttentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">block
</span><a href="#local-6989586621679584417"><span class="hs-identifier hs-var">block</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679584422"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679584421"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679584420"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">crossAttentionBias
</span><a href="#local-6989586621679584419"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679584418"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-313"></span><span>              </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679584409"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679584408"><span class="hs-identifier hs-var">g'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-314"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>          </span><span class="annot"><span class="annottext">Vector block
</span><a href="#local-6989586621679584416"><span class="hs-identifier hs-var">blocks</span></a></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-316"></span></pre></body></html>