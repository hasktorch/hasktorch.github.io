<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE FunctionalDependencies #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE InstanceSigs #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE LambdaCase #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE RoleAnnotations #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-20"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-21"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-22"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-23"></span><span class="hs-pragma">{-# LANGUAGE UndecidableSuperClasses #-}</span><span>
</span><span id="line-24"></span><span class="hs-pragma">{-# LANGUAGE ViewPatterns #-}</span><span>
</span><span id="line-25"></span><span class="hs-pragma">{-# OPTIONS_GHC -Wall #-}</span><span>
</span><span id="line-26"></span><span>
</span><span id="line-27"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-28"></span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Applicative</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">empty</span></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Category</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-operator">(&gt;&gt;&gt;)</span></span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Exception</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Exception</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">forM</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">forM_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">when</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-operator">(&lt;=&lt;)</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-operator">(&gt;=&gt;)</span></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Bifunctor</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">bimap</span></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Coerce</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">coerce</span></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Foldable</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">traverse_</span></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Functor</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-operator">(&lt;&amp;&gt;)</span></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Int</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Int16</span></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.List.NonEmpty</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">NonEmpty</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-operator">(:|)</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">nonEmpty</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">unzip</span></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">maybeToList</span></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Proxy</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Proxy</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Typeable</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier">Data.Vector</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">V</span></span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Generic.Sized.Internal</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">SVI</span></span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Sized</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">SV</span></span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Ptr</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Word8</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">castPtr</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">fromBool</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">peekElemOff</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">pokeElemOff</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">withForeignPtr</span></span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign.ForeignPtr</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">ForeignPtr</span></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">KnownNat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">KnownSymbol</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">natVal</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">symbolVal</span></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">unsafePerformIO</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#KnownDType"><span class="hs-identifier">KnownDType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#dTypeVal"><span class="hs-identifier">dTypeVal</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Internal.TensorOptions.html"><span class="hs-identifier">Torch.GraduallyTyped.Internal.TensorOptions</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorOptions"><span class="hs-identifier">tensorOptions</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier">ifM</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier">Demoted'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier">InsertDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier">ReplaceDimF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier">ByIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-operator">(:.)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast2</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast4</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-65"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Context</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-66"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Extra</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-67"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-68"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">TensorList</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-69"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Unmanaged.Type.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Unmanaged</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">tensor_data_ptr</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Unsafe</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-71"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">unzip</span></span><span class="hs-special">)</span><span>
</span><span id="line-72"></span><span>
</span><span id="line-73"></span><span class="hs-comment">-- $setup</span><span>
</span><span id="line-74"></span><span class="hs-comment">-- &gt;&gt;&gt; import Data.Singletons.Prelude.List (SList (..))</span><span>
</span><span id="line-75"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped</span><span>
</span><span id="line-76"></span><span>
</span><span id="line-77"></span><span class="hs-comment">-- | A gradually typed tensor.</span><span>
</span><span id="line-78"></span><span class="hs-comment">--</span><span>
</span><span id="line-79"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-80"></span><span class="hs-comment">--                          &#9484;&#9472;&#9658; Compute device, e.g. `'Device 'CPU`</span><span>
</span><span id="line-81"></span><span class="hs-comment">--                          &#9474;</span><span>
</span><span id="line-82"></span><span class="hs-comment">--                          &#9474;               &#9484;&#9472;&#9658; List of dimensions, e.g. `'Shape '[ 'Dim 'UncheckedName ('Size 8), 'Dim 'UncheckedName ('Size 1) ]`</span><span>
</span><span id="line-83"></span><span class="hs-comment">--                          &#9474;               &#9474;</span><span>
</span><span id="line-84"></span><span class="hs-comment">-- Tensor gradient layout device dataType shape</span><span>
</span><span id="line-85"></span><span class="hs-comment">--           &#9474;       &#9474;              &#9474;</span><span>
</span><span id="line-86"></span><span class="hs-comment">--           &#9474;       &#9474;              &#9492;&#9472;&#9658; Data type, e.g. `'DataType 'Float`</span><span>
</span><span id="line-87"></span><span class="hs-comment">--           &#9474;       &#9474;</span><span>
</span><span id="line-88"></span><span class="hs-comment">--           &#9474;       &#9492;&#9472;&#9658; Memory layout, e.g. `'Layout 'Dense`</span><span>
</span><span id="line-89"></span><span class="hs-comment">--           &#9474;</span><span>
</span><span id="line-90"></span><span class="hs-comment">--           &#9492;&#9472;&#9658; Whether or not the tensor requires a gradient, e.g. `'Gradient 'WithGradient` for one that does</span><span>
</span><span id="line-91"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-92"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-93"></span><span>  </span><span id="Tensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-var">Tensor</span></a></span></span><span>
</span><span id="line-94"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679757806"><span class="annot"><a href="#local-6989586621679757806"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679757805"><span class="annot"><a href="#local-6989586621679757805"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679757804"><span class="annot"><a href="#local-6989586621679757804"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679757803"><span class="annot"><a href="#local-6989586621679757803"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679757802"><span class="annot"><a href="#local-6989586621679757802"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-100"></span><span>  </span><span class="hs-comment">-- | Unsafe constructor for tensors.</span><span>
</span><span id="line-101"></span><span>  </span><span class="hs-comment">-- Do not call this constructor directly,</span><span>
</span><span id="line-102"></span><span>  </span><span class="hs-comment">-- use smart constructors like 'ones' or 'randn' instead.</span><span>
</span><span id="line-103"></span><span>  </span><span id="UnsafeTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758740"><span class="annot"><a href="#local-6989586621679758740"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758739"><span class="annot"><a href="#local-6989586621679758739"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758738"><span class="annot"><a href="#local-6989586621679758738"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758737"><span class="annot"><a href="#local-6989586621679758737"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758736"><span class="annot"><a href="#local-6989586621679758736"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-105"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-106"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758740"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758739"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758738"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758737"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758736"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-107"></span><span>
</span><span id="line-108"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">role</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span>
</span><span id="line-109"></span><span>
</span><span id="line-110"></span><span id="local-6989586621679757796"><span id="local-6989586621679757797"><span id="local-6989586621679757798"><span id="local-6989586621679757799"><span id="local-6989586621679757800"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757791"><span id="local-6989586621679757794"><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757800"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757799"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757796"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-111"></span><span>  </span><span id="local-6989586621679757789"><span class="annot"><span class="annottext">show :: Tensor gradient layout device dataType shape -&gt; String
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">show</span></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-type">UnsafeTensor</span></a></span><span> </span><span id="local-6989586621679757787"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757787"><span class="hs-identifier hs-var">t</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Tensor
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">Torch.Tensor.Unsafe</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757787"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-112"></span><span>
</span><span id="line-113"></span><span class="hs-comment">-- | Alias for an untyped tensor without gradients.</span><span>
</span><span id="line-114"></span><span class="hs-keyword">type</span><span> </span><span id="UncheckedTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UncheckedTensor"><span class="hs-identifier hs-var">UncheckedTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#UncheckedGradient"><span class="hs-identifier hs-type">UncheckedGradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-115"></span><span>
</span><span id="line-116"></span><span class="hs-comment">-- | Alias for an untyped tensor with gradients.</span><span>
</span><span id="line-117"></span><span class="hs-keyword">type</span><span> </span><span id="UncheckedParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UncheckedParameter"><span class="hs-identifier hs-var">UncheckedParameter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-118"></span><span>
</span><span id="line-119"></span><span class="hs-comment">-- | Alias for a tensor on CPU memory without gradients.</span><span>
</span><span id="line-120"></span><span class="hs-keyword">type</span><span> </span><span id="CPUTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CPUTensor"><span class="hs-identifier hs-var">CPUTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>
</span><span id="line-122"></span><span class="hs-comment">-- | Alias for a tensor on CPU memory with gradients.</span><span>
</span><span id="line-123"></span><span class="hs-keyword">type</span><span> </span><span id="CPUParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CPUParameter"><span class="hs-identifier hs-var">CPUParameter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>
</span><span id="line-125"></span><span class="hs-comment">-- | Alias for a sparse tensor on CPU memory without gradients.</span><span>
</span><span id="line-126"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCPUTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCPUTensor"><span class="hs-identifier hs-var">SparseCPUTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>
</span><span id="line-128"></span><span class="hs-comment">-- | Alias for a sparse tensor on CPU memory with gradients.</span><span>
</span><span id="line-129"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCPUParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCPUParameter"><span class="hs-identifier hs-var">SparseCPUParameter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>
</span><span id="line-131"></span><span class="hs-comment">-- | Alias for a tensor on CUDA memory without gradients.</span><span>
</span><span id="line-132"></span><span class="hs-keyword">type</span><span> </span><span id="CUDATensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CUDATensor"><span class="hs-identifier hs-var">CUDATensor</span></a></span></span><span> </span><span id="local-6989586621679757779"><span class="annot"><a href="#local-6989586621679757779"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757779"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>
</span><span id="line-134"></span><span class="hs-comment">-- | Alias for a tensor on CUDA memory with gradients.</span><span>
</span><span id="line-135"></span><span class="hs-keyword">type</span><span> </span><span id="CUDAParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CUDAParameter"><span class="hs-identifier hs-var">CUDAParameter</span></a></span></span><span> </span><span id="local-6989586621679757777"><span class="annot"><a href="#local-6989586621679757777"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757777"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>
</span><span id="line-137"></span><span class="hs-comment">-- | Alias for a sparse tensor on CUDA memory without gradients.</span><span>
</span><span id="line-138"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCUDATensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCUDATensor"><span class="hs-identifier hs-var">SparseCUDATensor</span></a></span></span><span> </span><span id="local-6989586621679757775"><span class="annot"><a href="#local-6989586621679757775"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757775"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-139"></span><span>
</span><span id="line-140"></span><span class="hs-comment">-- | Alias for a sparse tensor on CUDA memory with gradients.</span><span>
</span><span id="line-141"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCUDAParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCUDAParameter"><span class="hs-identifier hs-var">SparseCUDAParameter</span></a></span></span><span> </span><span id="local-6989586621679757773"><span class="annot"><a href="#local-6989586621679757773"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757773"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>
</span><span id="line-143"></span><span id="local-6989586621679757768"><span id="local-6989586621679757769"><span id="local-6989586621679757770"><span id="local-6989586621679757771"><span id="local-6989586621679757772"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Num</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757772"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757771"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757770"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757769"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757768"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-144"></span><span>  </span><span id="local-6989586621679757759"><span class="annot"><span class="annottext">+ :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-operator hs-var hs-var hs-var hs-var">(+)</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Tensor gradient layout device dataType shape
  -&gt; IO (Tensor gradient layout device dataType shape))
 -&gt; Tensor gradient layout device dataType shape
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_tt</span></a></span><span>
</span><span id="line-145"></span><span>  </span><span id="local-6989586621679757755"><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="hs-special">)</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Tensor gradient layout device dataType shape
  -&gt; IO (Tensor gradient layout device dataType shape))
 -&gt; Tensor gradient layout device dataType shape
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_tt</span></a></span><span>
</span><span id="line-146"></span><span>  </span><span id="local-6989586621679757753"><span class="annot"><span class="annottext">* :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-operator hs-var hs-var hs-var hs-var">(*)</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Tensor gradient layout device dataType shape
  -&gt; IO (Tensor gradient layout device dataType shape))
 -&gt; Tensor gradient layout device dataType shape
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_tt</span></a></span><span>
</span><span id="line-147"></span><span>  </span><span id="local-6989586621679757750"><span class="annot"><span class="annottext">negate :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">negate</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.neg_t</span></a></span><span>
</span><span id="line-148"></span><span>  </span><span id="local-6989586621679757748"><span class="annot"><span class="annottext">abs :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">abs</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.abs_t</span></a></span><span>
</span><span id="line-149"></span><span>  </span><span id="local-6989586621679757745"><span class="annot"><span class="annottext">signum :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">signum</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sign_t</span></a></span><span>
</span><span id="line-150"></span><span>  </span><span id="local-6989586621679757742"><span class="annot"><span class="annottext">fromInteger :: Integer -&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">fromInteger</span></span></span><span> </span><span id="local-6989586621679757741"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757741"><span class="hs-identifier hs-var">_a</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span></span></span></span></span></span><span>
</span><span id="line-151"></span><span>
</span><span id="line-152"></span><span id="local-6989586621679757735"><span id="local-6989586621679757736"><span id="local-6989586621679757737"><span id="local-6989586621679757738"><span id="local-6989586621679757739"><span class="hs-keyword">instance</span><span>
</span><span id="line-153"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span>
</span><span id="line-154"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757739"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757738"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757737"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757736"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757735"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-155"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-156"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-157"></span><span>  </span><span id="local-6989586621679757731"><span class="annot"><span class="annottext">cast :: Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-type">UnsafeTensor</span></a></span><span> </span><span id="local-6989586621679757729"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757729"><span class="hs-identifier hs-var">atenTensor</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679757728"><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO r
</span><a href="#local-6989586621679757728"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO r
</span><a href="#local-6989586621679757728"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757729"><span class="hs-identifier hs-var">atenTensor</span></a></span><span>
</span><span id="line-158"></span><span>  </span><span id="local-6989586621679757727"><span class="annot"><span class="annottext">uncast :: ForeignPtr Tensor
-&gt; (Tensor gradient layout device dataType shape -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span id="local-6989586621679757725"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757725"><span class="hs-identifier hs-var">atenTensor</span></a></span></span><span> </span><span id="local-6989586621679757724"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; IO r
</span><a href="#local-6989586621679757724"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; IO r
</span><a href="#local-6989586621679757724"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape -&gt; IO r)
-&gt; Tensor gradient layout device dataType shape -&gt; IO r
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757725"><span class="hs-identifier hs-var">atenTensor</span></a></span></span></span></span></span></span><span>
</span><span id="line-159"></span><span>
</span><span id="line-160"></span><span id="local-6989586621679757719"><span id="local-6989586621679757720"><span id="local-6989586621679757721"><span id="local-6989586621679757722"><span id="local-6989586621679757723"><span class="hs-keyword">instance</span><span>
</span><span id="line-161"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757723"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757722"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757721"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757720"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757719"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorList</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-165"></span><span>  </span><span id="local-6989586621679757716"><span class="annot"><span class="annottext">cast :: [Tensor gradient layout device dataType shape]
-&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679757716"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span id="local-6989586621679757715"><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679757715"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679757714"><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679757714"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-166"></span><span>    </span><span id="local-6989586621679757713"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757713"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; IO (ForeignPtr Tensor))
-&gt; [Tensor gradient layout device dataType shape]
-&gt; IO [ForeignPtr Tensor]
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
(a -&gt; m b) -&gt; t a -&gt; m (t b)
</span><span class="hs-identifier hs-var">mapM</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679757711"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757711"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; IO (ForeignPtr Tensor)
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757711"><span class="hs-identifier hs-var">x</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679757715"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-167"></span><span>    </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757713"><span class="hs-identifier hs-var">ptrList</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679757714"><span class="hs-identifier hs-var">f</span></a></span><span>
</span><span id="line-168"></span><span>  </span><span id="local-6989586621679757710"><span class="annot"><span class="annottext">uncast :: ForeignPtr TensorList
-&gt; ([Tensor gradient layout device dataType shape] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679757710"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span id="local-6989586621679757709"><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679757709"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679757708"><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape] -&gt; IO r
</span><a href="#local-6989586621679757708"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679757709"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">(([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r)
-&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679757707"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757707"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-169"></span><span>    </span><span id="local-6989586621679757706"><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679757706"><span class="hs-identifier hs-var">tensorList</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; [ForeignPtr Tensor]
-&gt; IO [Tensor gradient layout device dataType shape]
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
(a -&gt; m b) -&gt; t a -&gt; m (t b)
</span><span class="hs-identifier hs-var">mapM</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679757705"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757705"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; IO (Tensor gradient layout device dataType shape)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757705"><span class="hs-identifier hs-var">x</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757707"><span class="hs-identifier hs-var">ptrList</span></a></span><span>
</span><span id="line-170"></span><span>    </span><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape] -&gt; IO r
</span><a href="#local-6989586621679757708"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679757706"><span class="hs-identifier hs-var">tensorList</span></a></span></span></span></span></span></span><span>
</span><span id="line-171"></span><span>
</span><span id="line-172"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-173"></span><span>  </span><span id="local-6989586621679757702"><span class="annot"><span class="annottext">cast :: HList '[] -&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679757702"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="annot"><span class="annottext">HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span> </span><span id="local-6989586621679757700"><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679757700"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679757700"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-174"></span><span>  </span><span id="local-6989586621679757699"><span class="annot"><span class="annottext">uncast :: [ForeignPtr Tensor] -&gt; (HList '[] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679757699"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679757698"><span class="annot"><span class="annottext">HList '[] -&gt; IO r
</span><a href="#local-6989586621679757698"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList '[] -&gt; IO r
</span><a href="#local-6989586621679757698"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span>
</span><span id="line-175"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList '[] -&gt; IO r
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; IO r
forall (m :: * -&gt; *) a. MonadFail m =&gt; String -&gt; m a
</span><span class="hs-identifier hs-var">fail</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The list of tensors has more elements than expected. This means that the runtime length of the list exceeded its compile-time length.&quot;</span></span><span>
</span><span id="line-176"></span><span>
</span><span id="line-177"></span><span id="local-6989586621679757692"><span id="local-6989586621679757693"><span id="local-6989586621679757694"><span id="local-6989586621679757695"><span id="local-6989586621679757696"><span id="local-6989586621679757697"><span class="hs-keyword">instance</span><span>
</span><span id="line-178"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757697"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-179"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-180"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757696"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757695"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757694"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757693"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757692"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679757697"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-181"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-182"></span><span>  </span><span id="local-6989586621679757689"><span class="annot"><span class="annottext">cast :: HList (Tensor gradient layout device dataType shape : tensors)
-&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679757689"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757688"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757688"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-type">:.</span></a></span><span> </span><span id="local-6989586621679757687"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679757687"><span class="hs-identifier hs-var">tensors</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679757686"><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679757686"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-183"></span><span>    </span><span id="local-6989586621679757685"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757685"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; IO (ForeignPtr Tensor)
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757688"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-184"></span><span>    </span><span id="local-6989586621679757684"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757684"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">HList tensors
-&gt; ([ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor])
-&gt; IO [ForeignPtr Tensor]
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679757687"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-185"></span><span>    </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679757686"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757685"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; [ForeignPtr Tensor] -&gt; [ForeignPtr Tensor]
forall a. a -&gt; [a] -&gt; [a]
</span><span class="hs-glyph hs-var">:</span></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757684"><span class="hs-identifier hs-var">ptrList</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>  </span><span id="local-6989586621679757683"><span class="annot"><span class="annottext">uncast :: [ForeignPtr Tensor]
-&gt; (HList (Tensor gradient layout device dataType shape : tensors)
    -&gt; IO r)
-&gt; IO r
</span><a href="#local-6989586621679757683"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">HList (Tensor gradient layout device dataType shape : tensors)
-&gt; IO r
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; IO r
forall (m :: * -&gt; *) a. MonadFail m =&gt; String -&gt; m a
</span><span class="hs-identifier hs-var">fail</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The list of tensors ended prematurely. This means that the runtime length of the list was smaller than its compile-time length.&quot;</span></span><span>
</span><span id="line-187"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757682"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757682"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679757681"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757681"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679757680"><span class="annot"><span class="annottext">HList (Tensor gradient layout device dataType shape : tensors)
-&gt; IO r
</span><a href="#local-6989586621679757680"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-188"></span><span>    </span><span id="local-6989586621679757679"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757679"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; IO (Tensor gradient layout device dataType shape)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757682"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-189"></span><span>    </span><span id="local-6989586621679757678"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679757678"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
-&gt; (HList tensors -&gt; IO (HList tensors)) -&gt; IO (HList tensors)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757681"><span class="hs-identifier hs-var">ptrList</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors -&gt; IO (HList tensors)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-190"></span><span>    </span><span class="annot"><span class="annottext">HList (Tensor gradient layout device dataType shape : tensors)
-&gt; IO r
</span><a href="#local-6989586621679757680"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757679"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; HList tensors
-&gt; HList (Tensor gradient layout device dataType shape : tensors)
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679757678"><span class="hs-identifier hs-var">tensors</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-191"></span><span>
</span><span id="line-192"></span><span id="local-6989586621679757677"><span class="hs-keyword">instance</span><span>
</span><span id="line-193"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757677"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-194"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757677"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorList</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-195"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-196"></span><span>  </span><span id="local-6989586621679757674"><span class="annot"><span class="annottext">cast :: HList l -&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679757674"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span id="local-6989586621679757673"><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679757673"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679757672"><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679757672"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-197"></span><span>    </span><span id="local-6989586621679757671"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757671"><span class="hs-identifier hs-var">ts</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">HList l
-&gt; ([ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor])
-&gt; IO [ForeignPtr Tensor]
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679757673"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor]
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-198"></span><span>    </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757671"><span class="hs-identifier hs-var">ts</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679757672"><span class="hs-identifier hs-var">f</span></a></span><span>
</span><span id="line-199"></span><span>  </span><span id="local-6989586621679757670"><span class="annot"><span class="annottext">uncast :: ForeignPtr TensorList -&gt; (HList l -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679757670"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span id="local-6989586621679757669"><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679757669"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679757668"><span class="annot"><span class="annottext">HList l -&gt; IO r
</span><a href="#local-6989586621679757668"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679757669"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">(([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r)
-&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679757667"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757667"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-200"></span><span>    </span><span id="local-6989586621679757666"><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679757666"><span class="hs-identifier hs-var">ts</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; (HList l -&gt; IO (HList l)) -&gt; IO (HList l)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679757667"><span class="hs-identifier hs-var">ptrList</span></a></span><span> </span><span class="annot"><span class="annottext">HList l -&gt; IO (HList l)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757677"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-201"></span><span>    </span><span class="annot"><span class="annottext">HList l -&gt; IO r
</span><a href="#local-6989586621679757668"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679757666"><span class="hs-identifier hs-var">ts</span></a></span></span><span>
</span><span id="line-202"></span><span>
</span><span id="line-203"></span><span class="hs-comment">-- | Takes a tensor that may or may not require gradient computations</span><span>
</span><span id="line-204"></span><span class="hs-comment">-- and returns a copy that does not require them.</span><span>
</span><span id="line-205"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#withoutGradient"><span class="hs-identifier hs-type">withoutGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-206"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757664"><span class="annot"><a href="#local-6989586621679757664"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757663"><span class="annot"><a href="#local-6989586621679757663"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757662"><span class="annot"><a href="#local-6989586621679757662"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757661"><span class="annot"><a href="#local-6989586621679757661"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757660"><span class="annot"><a href="#local-6989586621679757660"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-207"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-208"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757664"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757663"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757662"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757661"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757660"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-209"></span><span>  </span><span class="hs-comment">-- | copy of the input tensor without gradient computations turned off.</span><span>
</span><span id="line-210"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757663"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757662"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757661"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757660"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-211"></span><span id="withoutGradient"><span class="annot"><span class="annottext">withoutGradient :: Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor ('Gradient 'WithoutGradient) layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withoutGradient"><span class="hs-identifier hs-var hs-var">withoutGradient</span></a></span></span><span> </span><span id="local-6989586621679757659"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757659"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Bool
-&gt; IO
     (Tensor ('Gradient 'WithoutGradient) layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_set_requires_grad_b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757659"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-212"></span><span>
</span><span id="line-213"></span><span class="hs-comment">-- | Takes a tensor that does not requires gradient computations</span><span>
</span><span id="line-214"></span><span class="hs-comment">-- and returns a copy that requires them.</span><span>
</span><span id="line-215"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#withGradient"><span class="hs-identifier hs-type">withGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-216"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757656"><span class="annot"><a href="#local-6989586621679757656"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757655"><span class="annot"><a href="#local-6989586621679757655"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757654"><span class="annot"><a href="#local-6989586621679757654"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757653"><span class="annot"><a href="#local-6989586621679757653"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757652"><span class="annot"><a href="#local-6989586621679757652"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-218"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757656"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757655"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757654"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757653"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757652"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-219"></span><span>  </span><span class="hs-comment">-- | copy of the input tensor with gradient computations turned on.</span><span>
</span><span id="line-220"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757655"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757654"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757653"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757652"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span id="withGradient"><span class="annot"><span class="annottext">withGradient :: Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor ('Gradient 'WithGradient) layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withGradient"><span class="hs-identifier hs-var hs-var">withGradient</span></a></span></span><span> </span><span id="local-6989586621679757651"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757651"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Bool
-&gt; IO
     (Tensor ('Gradient 'WithGradient) layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_set_requires_grad_b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757651"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-222"></span><span>
</span><span id="line-223"></span><span class="hs-keyword">class</span><span> </span><span id="SGetGradient"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-var">SGetGradient</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758683"><span class="annot"><a href="#local-6989586621679758683"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-224"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed information for whether or not gradient computations for the tensor are turned on.</span><span>
</span><span id="line-225"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-226"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' gradient = sOnes gradient (SLayout SDense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-227"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SGradient SWithGradient</span><span>
</span><span id="line-228"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGradient t</span><span>
</span><span id="line-229"></span><span>  </span><span class="hs-comment">-- SGradient SWithGradient</span><span>
</span><span id="line-230"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedGradient WithoutGradient</span><span>
</span><span id="line-231"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGradient t</span><span>
</span><span id="line-232"></span><span>  </span><span class="hs-comment">-- SUncheckedGradient WithoutGradient</span><span>
</span><span id="line-233"></span><span>  </span><span id="sGradient"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGradient"><span class="hs-identifier hs-type">sGradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-234"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758669"><span class="annot"><a href="#local-6989586621679758669"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758668"><span class="annot"><a href="#local-6989586621679758668"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758667"><span class="annot"><a href="#local-6989586621679758667"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758666"><span class="annot"><a href="#local-6989586621679758666"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-235"></span><span>    </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-236"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758669"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758668"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758667"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758666"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-237"></span><span>    </span><span class="hs-comment">-- | information about whether or not gradient computations are required</span><span>
</span><span id="line-238"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758683"><span class="hs-identifier hs-type">gradient</span></a></span><span>
</span><span id="line-239"></span><span>
</span><span id="line-240"></span><span>  </span><span class="hs-comment">-- | Returns the untyped memory layout of the input tensor.</span><span>
</span><span id="line-241"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-242"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' gradient = sOnes gradient (SLayout SDense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-243"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SGradient SWithGradient</span><span>
</span><span id="line-244"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; gradient t</span><span>
</span><span id="line-245"></span><span>  </span><span class="hs-comment">-- WithGradient</span><span>
</span><span id="line-246"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedGradient WithoutGradient</span><span>
</span><span id="line-247"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; gradient t</span><span>
</span><span id="line-248"></span><span>  </span><span class="hs-comment">-- WithoutGradient</span><span>
</span><span id="line-249"></span><span>  </span><span id="gradient"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#gradient"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-250"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758664"><span class="annot"><a href="#local-6989586621679758664"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758663"><span class="annot"><a href="#local-6989586621679758663"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758662"><span class="annot"><a href="#local-6989586621679758662"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758661"><span class="annot"><a href="#local-6989586621679758661"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-251"></span><span>    </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-252"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758664"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758663"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758662"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758661"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-253"></span><span>    </span><span class="hs-comment">-- | information about whether or not gradient computations are required</span><span>
</span><span id="line-254"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span>
</span><span id="line-255"></span><span>  </span><span id="local-6989586621679757648"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#gradient"><span class="hs-identifier hs-var hs-var">gradient</span></a></span><span> </span><span id="local-6989586621679757647"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757647"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked RequiresGradient -&gt; RequiresGradient
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked RequiresGradient -&gt; RequiresGradient)
-&gt; (SGradient gradient -&gt; IsChecked RequiresGradient)
-&gt; SGradient gradient
-&gt; RequiresGradient
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient -&gt; IsChecked RequiresGradient
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient -&gt; RequiresGradient)
-&gt; SGradient gradient -&gt; RequiresGradient
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SGradient gradient
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetGradient gradient =&gt;
Tensor gradient layout device dataType shape -&gt; SGradient gradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGradient"><span class="hs-identifier hs-var">sGradient</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757647"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-256"></span><span>
</span><span id="line-257"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757644"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#UncheckedGradient"><span class="hs-identifier hs-type">UncheckedGradient</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-258"></span><span>  </span><span id="local-6989586621679757642"><span class="annot"><span class="annottext">sGradient :: Tensor 'UncheckedGradient layout device dataType shape
-&gt; SGradient 'UncheckedGradient
</span><a href="#local-6989586621679757642"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGradient</span></a></span></span><span> </span><span id="local-6989586621679757641"><span class="annot"><span class="annottext">Tensor 'UncheckedGradient layout device dataType shape
</span><a href="#local-6989586621679757641"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-259"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor 'UncheckedGradient layout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_requires_grad</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor 'UncheckedGradient layout device dataType shape
</span><a href="#local-6989586621679757641"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; SGradient 'UncheckedGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SUncheckedGradient"><span class="hs-identifier hs-var">SUncheckedGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-var">WithGradient</span></a></span><span>
</span><span id="line-260"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; SGradient 'UncheckedGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SUncheckedGradient"><span class="hs-identifier hs-var">SUncheckedGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-var">WithoutGradient</span></a></span><span>
</span><span id="line-261"></span><span>
</span><span id="line-262"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757636"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-263"></span><span>  </span><span id="local-6989586621679757635"><span class="annot"><span class="annottext">sGradient :: Tensor ('Gradient 'WithGradient) layout device dataType shape
-&gt; SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679757635"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGradient</span></a></span></span><span> </span><span id="local-6989586621679757634"><span class="annot"><span class="annottext">Tensor ('Gradient 'WithGradient) layout device dataType shape
</span><a href="#local-6989586621679757634"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-264"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor ('Gradient 'WithGradient) layout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_requires_grad</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ('Gradient 'WithGradient) layout device dataType shape
</span><a href="#local-6989586621679757634"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-265"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-266"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SGradient ('Gradient 'WithGradient)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SGradient ('Gradient 'WithGradient))
-&gt; String -&gt; SGradient ('Gradient 'WithGradient)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-267"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should require gradient computations but doesn't. &quot;</span></span><span>
</span><span id="line-268"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-269"></span><span>
</span><span id="line-270"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757627"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-271"></span><span>  </span><span id="local-6989586621679757626"><span class="annot"><span class="annottext">sGradient :: Tensor ('Gradient 'WithoutGradient) layout device dataType shape
-&gt; SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679757626"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGradient</span></a></span></span><span> </span><span id="local-6989586621679757625"><span class="annot"><span class="annottext">Tensor ('Gradient 'WithoutGradient) layout device dataType shape
</span><a href="#local-6989586621679757625"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-272"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor ('Gradient 'WithoutGradient) layout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_requires_grad</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ('Gradient 'WithoutGradient) layout device dataType shape
</span><a href="#local-6989586621679757625"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-273"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SGradient ('Gradient 'WithoutGradient)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SGradient ('Gradient 'WithoutGradient))
-&gt; String -&gt; SGradient ('Gradient 'WithoutGradient)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-274"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should not require gradient computations but does. &quot;</span></span><span>
</span><span id="line-275"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-276"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-277"></span><span>
</span><span id="line-278"></span><span class="hs-keyword">data</span><span> </span><span id="GradientError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-var">GradientError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="GradientError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-var">GradientError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="geExpected"><span class="annot"><span class="annottext">GradientError -&gt; RequiresGradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#geExpected"><span class="hs-identifier hs-var hs-var">geExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">,</span><span> </span><span id="geActual"><span class="annot"><span class="annottext">GradientError -&gt; RequiresGradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#geActual"><span class="hs-identifier hs-var hs-var">geActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">}</span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757615"><span id="local-6989586621679757617"><span id="local-6989586621679757619"><span class="annot"><span class="annottext">Int -&gt; GradientError -&gt; ShowS
[GradientError] -&gt; ShowS
GradientError -&gt; String
(Int -&gt; GradientError -&gt; ShowS)
-&gt; (GradientError -&gt; String)
-&gt; ([GradientError] -&gt; ShowS)
-&gt; Show GradientError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [GradientError] -&gt; ShowS
$cshowList :: [GradientError] -&gt; ShowS
show :: GradientError -&gt; String
$cshow :: GradientError -&gt; String
showsPrec :: Int -&gt; GradientError -&gt; ShowS
$cshowsPrec :: Int -&gt; GradientError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-280"></span><span>
</span><span id="line-281"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757609"><span id="local-6989586621679757611"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-type">GradientError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-282"></span><span>  </span><span id="local-6989586621679757606"><span class="annot"><span class="annottext">displayException :: GradientError -&gt; String
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-type">GradientError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679757603"><span id="local-6989586621679757604"><span class="annot"><span class="annottext">RequiresGradient
geActual :: RequiresGradient
geExpected :: RequiresGradient
geActual :: GradientError -&gt; RequiresGradient
geExpected :: GradientError -&gt; RequiresGradient
</span><a href="#local-6989586621679757603"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-283"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor's information about whether or not gradient computations are required reads `&quot;</span></span><span>
</span><span id="line-284"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679757603"><span class="hs-identifier hs-var">geActual</span></a></span><span>
</span><span id="line-285"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` instead of `&quot;</span></span><span>
</span><span id="line-286"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679757604"><span class="hs-identifier hs-var">geExpected</span></a></span><span>
</span><span id="line-287"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-288"></span><span>
</span><span id="line-289"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the memory layout 'layout'</span><span>
</span><span id="line-290"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-291"></span><span class="hs-comment">--</span><span>
</span><span id="line-292"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the memory layout 'layout'.</span><span>
</span><span id="line-293"></span><span class="hs-comment">-- If it does not have it, then the result will be 'Nothing'.</span><span>
</span><span id="line-294"></span><span class="hs-comment">--</span><span>
</span><span id="line-295"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-296"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes (SGradient SWithGradient) (SUncheckedLayout Dense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-297"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SDense) t</span><span>
</span><span id="line-298"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-299"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-300"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-301"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-302"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-303"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-304"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-305"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-306"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-307"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-308"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SSparse) t</span><span>
</span><span id="line-309"></span><span class="hs-comment">-- *** Exception: LayoutError {leExpected = Sparse, leActual = Dense}</span><span>
</span><span id="line-310"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedGradient"><span class="hs-identifier hs-type">sCheckedGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-311"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758601"><span class="annot"><a href="#local-6989586621679758601"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679758602"><span class="annot"><a href="#local-6989586621679758602"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679758603"><span class="annot"><a href="#local-6989586621679758603"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758600"><span class="annot"><a href="#local-6989586621679758600"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758599"><span class="annot"><a href="#local-6989586621679758599"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758598"><span class="annot"><a href="#local-6989586621679758598"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758597"><span class="annot"><a href="#local-6989586621679758597"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-312"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758603"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758602"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-313"></span><span>  </span><span class="hs-comment">-- | layout</span><span>
</span><span id="line-314"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758601"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-315"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-316"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758603"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758600"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758599"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758598"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758597"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-317"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-318"></span><span>  </span><span class="annot"><a href="#local-6989586621679758602"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679758603"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758601"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758601"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758600"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758599"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758598"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758597"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span id="sCheckedGradient"><span class="annot"><span class="annottext">sCheckedGradient :: SGradient gradient'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedGradient"><span class="hs-identifier hs-var hs-var">sCheckedGradient</span></a></span></span><span> </span><span id="local-6989586621679757601"><span class="annot"><span class="annottext">SGradient gradient'
</span><a href="#local-6989586621679757601"><span class="hs-identifier hs-var">gradient'</span></a></span></span><span> </span><span id="local-6989586621679757600"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757600"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679757599"><span class="annot"><span class="annottext">actualGradient :: RequiresGradient
</span><a href="#local-6989586621679757599"><span class="hs-identifier hs-var hs-var">actualGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked RequiresGradient -&gt; RequiresGradient
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked RequiresGradient -&gt; RequiresGradient)
-&gt; (SGradient gradient -&gt; IsChecked RequiresGradient)
-&gt; SGradient gradient
-&gt; RequiresGradient
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient -&gt; IsChecked RequiresGradient
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient -&gt; RequiresGradient)
-&gt; SGradient gradient -&gt; RequiresGradient
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SGradient gradient
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetGradient gradient =&gt;
Tensor gradient layout device dataType shape -&gt; SGradient gradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGradient"><span class="hs-identifier hs-var">sGradient</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757600"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-321"></span><span>      </span><span id="local-6989586621679757598"><span class="annot"><span class="annottext">expectedGradient :: RequiresGradient
</span><a href="#local-6989586621679757598"><span class="hs-identifier hs-var hs-var">expectedGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked RequiresGradient -&gt; RequiresGradient
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked RequiresGradient -&gt; RequiresGradient)
-&gt; (SGradient gradient' -&gt; IsChecked RequiresGradient)
-&gt; SGradient gradient'
-&gt; RequiresGradient
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient' -&gt; IsChecked RequiresGradient
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient' -&gt; RequiresGradient)
-&gt; SGradient gradient' -&gt; RequiresGradient
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient'
</span><a href="#local-6989586621679757601"><span class="hs-identifier hs-var">gradient'</span></a></span><span>
</span><span id="line-322"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679757599"><span class="hs-identifier hs-var">actualGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; RequiresGradient -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679757598"><span class="hs-identifier hs-var">expectedGradient</span></a></span><span>
</span><span id="line-323"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  (Seq
     (Unify (Gradient RequiresGradient) gradient gradient') gradient')
  layout
  device
  dataType
  shape
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Seq
      (Unify (Gradient RequiresGradient) gradient gradient') gradient')
   layout
   device
   dataType
   shape
 -&gt; m (Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     (Seq
        (Unify (Gradient RequiresGradient) gradient gradient') gradient')
     layout
     device
     dataType
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757600"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-324"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">GradientError
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(GradientError
 -&gt; m (Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape))
-&gt; GradientError
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; RequiresGradient -&gt; GradientError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-var">GradientError</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679757598"><span class="hs-identifier hs-var">expectedGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679757599"><span class="hs-identifier hs-var">actualGradient</span></a></span><span>
</span><span id="line-325"></span><span>
</span><span id="line-326"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedGradient"><span class="hs-identifier hs-type">checkedGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757595"><span class="annot"><a href="#local-6989586621679757595"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679757594"><span class="annot"><a href="#local-6989586621679757594"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679757593"><span class="annot"><a href="#local-6989586621679757593"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757592"><span class="annot"><a href="#local-6989586621679757592"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757591"><span class="annot"><a href="#local-6989586621679757591"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757590"><span class="annot"><a href="#local-6989586621679757590"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757589"><span class="annot"><a href="#local-6989586621679757589"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-328"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757595"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757593"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757594"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-329"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-330"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757593"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757592"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757591"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757590"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757589"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-332"></span><span>  </span><span class="annot"><a href="#local-6989586621679757594"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757593"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757595"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757595"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757592"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757591"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757590"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757589"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span id="checkedGradient"><span class="annot"><span class="annottext">checkedGradient :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedGradient"><span class="hs-identifier hs-var hs-var">checkedGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
forall (gradient' :: Gradient RequiresGradient) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetGradient gradient, MonadThrow m) =&gt;
SGradient gradient'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedGradient"><span class="hs-identifier hs-var">sCheckedGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI gradient' =&gt; Sing gradient'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757595"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-334"></span><span>
</span><span id="line-335"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedLayout' as memory layout type annotation.</span><span>
</span><span id="line-336"></span><span class="hs-comment">-- Any static information about the tensor's memory layout is thus erased.</span><span>
</span><span id="line-337"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-338"></span><span class="hs-comment">--</span><span>
</span><span id="line-339"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-340"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedLayout t</span><span>
</span><span id="line-341"></span><span class="hs-comment">-- uncheckedLayout t</span><span>
</span><span id="line-342"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-343"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-344"></span><span class="hs-comment">--        'UncheckedLayout</span><span>
</span><span id="line-345"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-346"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-347"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-348"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-349"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-350"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedGradient"><span class="hs-identifier hs-type">uncheckedGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-351"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757587"><span class="annot"><a href="#local-6989586621679757587"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757586"><span class="annot"><a href="#local-6989586621679757586"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757585"><span class="annot"><a href="#local-6989586621679757585"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757584"><span class="annot"><a href="#local-6989586621679757584"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757583"><span class="annot"><a href="#local-6989586621679757583"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-352"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-353"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757587"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757586"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757585"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757584"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757583"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-354"></span><span>  </span><span class="hs-comment">-- | tensor without checked layout</span><span>
</span><span id="line-355"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#UncheckedGradient"><span class="hs-identifier hs-type">UncheckedGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757586"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757585"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757584"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757583"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-356"></span><span id="uncheckedGradient"><span class="annot"><span class="annottext">uncheckedGradient :: Tensor gradient layout device dataType shape
-&gt; Tensor 'UncheckedGradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedGradient"><span class="hs-identifier hs-var hs-var">uncheckedGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor 'UncheckedGradient layout device dataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-357"></span><span>
</span><span id="line-358"></span><span class="hs-comment">-- | Returns a dense copy of the tensor.</span><span>
</span><span id="line-359"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#toDense"><span class="hs-identifier hs-type">toDense</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-360"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757581"><span class="annot"><a href="#local-6989586621679757581"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757580"><span class="annot"><a href="#local-6989586621679757580"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757579"><span class="annot"><a href="#local-6989586621679757579"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757578"><span class="annot"><a href="#local-6989586621679757578"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757577"><span class="annot"><a href="#local-6989586621679757577"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-361"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-362"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757581"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757580"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757579"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757578"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757577"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-363"></span><span>  </span><span class="hs-comment">-- | dense copy</span><span>
</span><span id="line-364"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757581"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757579"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757578"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757577"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-365"></span><span id="toDense"><span class="annot"><span class="annottext">toDense :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient ('Layout 'Dense) device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#toDense"><span class="hs-identifier hs-var hs-var">toDense</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient ('Layout 'Dense) device dataType shape)
-&gt; Tensor gradient ('Layout 'Dense) device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient ('Layout 'Dense) device dataType shape)
 -&gt; Tensor gradient ('Layout 'Dense) device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient ('Layout 'Dense) device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient ('Layout 'Dense) device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient ('Layout 'Dense) device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_dense</span></a></span><span>
</span><span id="line-366"></span><span>
</span><span id="line-367"></span><span class="hs-comment">-- | Returns a sparse copy of the tensor.</span><span>
</span><span id="line-368"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#toSparse"><span class="hs-identifier hs-type">toSparse</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-369"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757574"><span class="annot"><a href="#local-6989586621679757574"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757573"><span class="annot"><a href="#local-6989586621679757573"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757572"><span class="annot"><a href="#local-6989586621679757572"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757571"><span class="annot"><a href="#local-6989586621679757571"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757570"><span class="annot"><a href="#local-6989586621679757570"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-370"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-371"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757574"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757573"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757572"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757571"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757570"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-372"></span><span>  </span><span class="hs-comment">-- | sparse copy</span><span>
</span><span id="line-373"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757574"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757572"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757571"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757570"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-374"></span><span id="toSparse"><span class="annot"><span class="annottext">toSparse :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient ('Layout 'Sparse) device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#toSparse"><span class="hs-identifier hs-var hs-var">toSparse</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient ('Layout 'Sparse) device dataType shape)
-&gt; Tensor gradient ('Layout 'Sparse) device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient ('Layout 'Sparse) device dataType shape)
 -&gt; Tensor gradient ('Layout 'Sparse) device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient ('Layout 'Sparse) device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient ('Layout 'Sparse) device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient ('Layout 'Sparse) device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_sparse</span></a></span><span>
</span><span id="line-375"></span><span>
</span><span id="line-376"></span><span class="hs-keyword">class</span><span> </span><span id="SGetLayout"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-var">SGetLayout</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758574"><span class="annot"><a href="#local-6989586621679758574"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-377"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed memory layout of the input tensor.</span><span>
</span><span id="line-378"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-379"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' layout = sOnes (SGradient SWithGradient) layout (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-380"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SLayout SDense</span><span>
</span><span id="line-381"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sLayout t</span><span>
</span><span id="line-382"></span><span>  </span><span class="hs-comment">-- SLayout SDense</span><span>
</span><span id="line-383"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedLayout Dense</span><span>
</span><span id="line-384"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sLayout t</span><span>
</span><span id="line-385"></span><span>  </span><span class="hs-comment">-- SUncheckedLayout Dense</span><span>
</span><span id="line-386"></span><span>  </span><span id="sLayout"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sLayout"><span class="hs-identifier hs-type">sLayout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-387"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758568"><span class="annot"><a href="#local-6989586621679758568"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758567"><span class="annot"><a href="#local-6989586621679758567"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758566"><span class="annot"><a href="#local-6989586621679758566"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758565"><span class="annot"><a href="#local-6989586621679758565"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-388"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-389"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758568"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758574"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758567"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758566"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758565"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-390"></span><span>    </span><span class="hs-comment">-- | memory layout</span><span>
</span><span id="line-391"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758574"><span class="hs-identifier hs-type">layout</span></a></span><span>
</span><span id="line-392"></span><span>
</span><span id="line-393"></span><span>  </span><span class="hs-comment">-- | Returns the untyped memory layout of the input tensor.</span><span>
</span><span id="line-394"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-395"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' layout = sOnes (SGradient SWithGradient) layout (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-396"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SLayout SDense</span><span>
</span><span id="line-397"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; layoutType t</span><span>
</span><span id="line-398"></span><span>  </span><span class="hs-comment">-- Dense</span><span>
</span><span id="line-399"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedLayout Dense</span><span>
</span><span id="line-400"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; layoutType t</span><span>
</span><span id="line-401"></span><span>  </span><span class="hs-comment">-- Dense</span><span>
</span><span id="line-402"></span><span>  </span><span id="layoutType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#layoutType"><span class="hs-identifier hs-type">layoutType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-403"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758563"><span class="annot"><a href="#local-6989586621679758563"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758562"><span class="annot"><a href="#local-6989586621679758562"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758561"><span class="annot"><a href="#local-6989586621679758561"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758560"><span class="annot"><a href="#local-6989586621679758560"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-404"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-405"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758563"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758574"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758562"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758561"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758560"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-406"></span><span>    </span><span class="hs-comment">-- | memory layout</span><span>
</span><span id="line-407"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span>
</span><span id="line-408"></span><span>  </span><span id="local-6989586621679757566"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#layoutType"><span class="hs-identifier hs-var hs-var">layoutType</span></a></span><span> </span><span id="local-6989586621679757565"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757565"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked LayoutType -&gt; LayoutType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked LayoutType -&gt; LayoutType)
-&gt; (SLayout layout -&gt; IsChecked LayoutType)
-&gt; SLayout layout
-&gt; LayoutType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout -&gt; IsChecked LayoutType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SLayout layout -&gt; LayoutType) -&gt; SLayout layout -&gt; LayoutType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sLayout"><span class="hs-identifier hs-var">sLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757565"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-409"></span><span>
</span><span id="line-410"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757562"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-411"></span><span>  </span><span id="local-6989586621679757560"><span class="annot"><span class="annottext">sLayout :: Tensor gradient 'UncheckedLayout device dataType shape
-&gt; SLayout 'UncheckedLayout
</span><a href="#local-6989586621679757560"><span class="hs-identifier hs-var hs-var hs-var hs-var">sLayout</span></a></span></span><span> </span><span id="local-6989586621679757559"><span class="annot"><span class="annottext">Tensor gradient 'UncheckedLayout device dataType shape
</span><a href="#local-6989586621679757559"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-412"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient 'UncheckedLayout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_sparse</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient 'UncheckedLayout device dataType shape
</span><a href="#local-6989586621679757559"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; SLayout 'UncheckedLayout
</span><a href="Torch.GraduallyTyped.Layout.html#SUncheckedLayout"><span class="hs-identifier hs-var">SUncheckedLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-var">Sparse</span></a></span><span>
</span><span id="line-413"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; SLayout 'UncheckedLayout
</span><a href="Torch.GraduallyTyped.Layout.html#SUncheckedLayout"><span class="hs-identifier hs-var">SUncheckedLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-var">Dense</span></a></span><span>
</span><span id="line-414"></span><span>
</span><span id="line-415"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757554"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-416"></span><span>  </span><span id="local-6989586621679757553"><span class="annot"><span class="annottext">sLayout :: Tensor gradient ('Layout 'Sparse) device dataType shape
-&gt; SLayout ('Layout 'Sparse)
</span><a href="#local-6989586621679757553"><span class="hs-identifier hs-var hs-var hs-var hs-var">sLayout</span></a></span></span><span> </span><span id="local-6989586621679757552"><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Sparse) device dataType shape
</span><a href="#local-6989586621679757552"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-417"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient ('Layout 'Sparse) device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_sparse</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Sparse) device dataType shape
</span><a href="#local-6989586621679757552"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Sparse -&gt; SLayout ('Layout 'Sparse)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Sparse
</span><a href="Torch.GraduallyTyped.Layout.html#SSparse"><span class="hs-identifier hs-var">SSparse</span></a></span><span>
</span><span id="line-418"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-419"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SLayout ('Layout 'Sparse)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SLayout ('Layout 'Sparse))
-&gt; String -&gt; SLayout ('Layout 'Sparse)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-420"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be sparse but isn't. &quot;</span></span><span>
</span><span id="line-421"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-422"></span><span>
</span><span id="line-423"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757547"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-424"></span><span>  </span><span id="local-6989586621679757546"><span class="annot"><span class="annottext">sLayout :: Tensor gradient ('Layout 'Dense) device dataType shape
-&gt; SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679757546"><span class="hs-identifier hs-var hs-var hs-var hs-var">sLayout</span></a></span></span><span> </span><span id="local-6989586621679757545"><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Dense) device dataType shape
</span><a href="#local-6989586621679757545"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-425"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient ('Layout 'Dense) device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_sparse</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Dense) device dataType shape
</span><a href="#local-6989586621679757545"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-426"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SLayout ('Layout 'Dense)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SLayout ('Layout 'Dense))
-&gt; String -&gt; SLayout ('Layout 'Dense)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-427"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be dense but isn't. &quot;</span></span><span>
</span><span id="line-428"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-429"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-430"></span><span>
</span><span id="line-431"></span><span class="hs-keyword">data</span><span> </span><span id="LayoutError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-var">LayoutError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="LayoutError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-var">LayoutError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="leExpected"><span class="annot"><span class="annottext">LayoutError -&gt; LayoutType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#leExpected"><span class="hs-identifier hs-var hs-var">leExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">,</span><span> </span><span id="leActual"><span class="annot"><span class="annottext">LayoutError -&gt; LayoutType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#leActual"><span class="hs-identifier hs-var hs-var">leActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">}</span><span>
</span><span id="line-432"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757535"><span id="local-6989586621679757537"><span id="local-6989586621679757539"><span class="annot"><span class="annottext">Int -&gt; LayoutError -&gt; ShowS
[LayoutError] -&gt; ShowS
LayoutError -&gt; String
(Int -&gt; LayoutError -&gt; ShowS)
-&gt; (LayoutError -&gt; String)
-&gt; ([LayoutError] -&gt; ShowS)
-&gt; Show LayoutError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [LayoutError] -&gt; ShowS
$cshowList :: [LayoutError] -&gt; ShowS
show :: LayoutError -&gt; String
$cshow :: LayoutError -&gt; String
showsPrec :: Int -&gt; LayoutError -&gt; ShowS
$cshowsPrec :: Int -&gt; LayoutError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-433"></span><span>
</span><span id="line-434"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757529"><span id="local-6989586621679757531"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-type">LayoutError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-435"></span><span>  </span><span id="local-6989586621679757527"><span class="annot"><span class="annottext">displayException :: LayoutError -&gt; String
</span><a href="#local-6989586621679757527"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-type">LayoutError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679757525"><span id="local-6989586621679757526"><span class="annot"><span class="annottext">LayoutType
leActual :: LayoutType
leExpected :: LayoutType
leActual :: LayoutError -&gt; LayoutType
leExpected :: LayoutError -&gt; LayoutType
</span><a href="#local-6989586621679757525"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-436"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor does not have the memory layout `&quot;</span></span><span>
</span><span id="line-437"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679757526"><span class="hs-identifier hs-var">leExpected</span></a></span><span>
</span><span id="line-438"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-439"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679757525"><span class="hs-identifier hs-var">leActual</span></a></span><span>
</span><span id="line-440"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-441"></span><span>
</span><span id="line-442"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the memory layout 'layout'</span><span>
</span><span id="line-443"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-444"></span><span class="hs-comment">--</span><span>
</span><span id="line-445"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the memory layout 'layout'.</span><span>
</span><span id="line-446"></span><span class="hs-comment">-- If it does not have it, then the result will be 'Nothing'.</span><span>
</span><span id="line-447"></span><span class="hs-comment">--</span><span>
</span><span id="line-448"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-449"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes (SGradient SWithGradient) (SUncheckedLayout Dense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-450"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SDense) t</span><span>
</span><span id="line-451"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-452"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-453"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-454"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-455"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-456"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-457"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-458"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-459"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-460"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-461"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SSparse) t</span><span>
</span><span id="line-462"></span><span class="hs-comment">-- *** Exception: LayoutError {leExpected = Sparse, leActual = Dense}</span><span>
</span><span id="line-463"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedLayout"><span class="hs-identifier hs-type">sCheckedLayout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-464"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758516"><span class="annot"><a href="#local-6989586621679758516"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679758517"><span class="annot"><a href="#local-6989586621679758517"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679758515"><span class="annot"><a href="#local-6989586621679758515"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758518"><span class="annot"><a href="#local-6989586621679758518"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758514"><span class="annot"><a href="#local-6989586621679758514"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758513"><span class="annot"><a href="#local-6989586621679758513"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758512"><span class="annot"><a href="#local-6989586621679758512"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-465"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758518"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758517"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-466"></span><span>  </span><span class="hs-comment">-- | layout</span><span>
</span><span id="line-467"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758516"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-468"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-469"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758515"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758518"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758514"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758513"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758512"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-470"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-471"></span><span>  </span><span class="annot"><a href="#local-6989586621679758517"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758515"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679758518"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758516"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758516"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758514"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758513"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758512"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-472"></span><span id="sCheckedLayout"><span class="annot"><span class="annottext">sCheckedLayout :: SLayout layout'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedLayout"><span class="hs-identifier hs-var hs-var">sCheckedLayout</span></a></span></span><span> </span><span id="local-6989586621679757523"><span class="annot"><span class="annottext">SLayout layout'
</span><a href="#local-6989586621679757523"><span class="hs-identifier hs-var">layout'</span></a></span></span><span> </span><span id="local-6989586621679757522"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757522"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-473"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679757521"><span class="annot"><span class="annottext">actualLayout :: LayoutType
</span><a href="#local-6989586621679757521"><span class="hs-identifier hs-var hs-var">actualLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked LayoutType -&gt; LayoutType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked LayoutType -&gt; LayoutType)
-&gt; (SLayout layout -&gt; IsChecked LayoutType)
-&gt; SLayout layout
-&gt; LayoutType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout -&gt; IsChecked LayoutType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SLayout layout -&gt; LayoutType) -&gt; SLayout layout -&gt; LayoutType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sLayout"><span class="hs-identifier hs-var">sLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757522"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-474"></span><span>      </span><span id="local-6989586621679757520"><span class="annot"><span class="annottext">expectedLayout :: LayoutType
</span><a href="#local-6989586621679757520"><span class="hs-identifier hs-var hs-var">expectedLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked LayoutType -&gt; LayoutType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked LayoutType -&gt; LayoutType)
-&gt; (SLayout layout' -&gt; IsChecked LayoutType)
-&gt; SLayout layout'
-&gt; LayoutType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout' -&gt; IsChecked LayoutType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SLayout layout' -&gt; LayoutType) -&gt; SLayout layout' -&gt; LayoutType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout'
</span><a href="#local-6989586621679757523"><span class="hs-identifier hs-var">layout'</span></a></span><span>
</span><span id="line-475"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679757521"><span class="hs-identifier hs-var">actualLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; LayoutType -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679757520"><span class="hs-identifier hs-var">expectedLayout</span></a></span><span>
</span><span id="line-476"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  (Seq (Unify (Layout LayoutType) layout layout') layout')
  device
  dataType
  shape
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   (Seq (Unify (Layout LayoutType) layout layout') layout')
   device
   dataType
   shape
 -&gt; m (Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     (Seq (Unify (Layout LayoutType) layout layout') layout')
     device
     dataType
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757522"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-477"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">LayoutError
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(LayoutError
 -&gt; m (Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape))
-&gt; LayoutError
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; LayoutType -&gt; LayoutError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-var">LayoutError</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679757520"><span class="hs-identifier hs-var">expectedLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679757521"><span class="hs-identifier hs-var">actualLayout</span></a></span><span>
</span><span id="line-478"></span><span>
</span><span id="line-479"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedLayout"><span class="hs-identifier hs-type">checkedLayout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-480"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757518"><span class="annot"><a href="#local-6989586621679757518"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679757517"><span class="annot"><a href="#local-6989586621679757517"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679757516"><span class="annot"><a href="#local-6989586621679757516"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757515"><span class="annot"><a href="#local-6989586621679757515"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757514"><span class="annot"><a href="#local-6989586621679757514"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757513"><span class="annot"><a href="#local-6989586621679757513"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757512"><span class="annot"><a href="#local-6989586621679757512"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-481"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757518"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757515"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757517"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-482"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-483"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757516"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757515"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757514"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757513"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757512"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-484"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-485"></span><span>  </span><span class="annot"><a href="#local-6989586621679757517"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757516"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757515"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757518"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757518"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757514"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757513"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757512"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-486"></span><span id="checkedLayout"><span class="annot"><span class="annottext">checkedLayout :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedLayout"><span class="hs-identifier hs-var hs-var">checkedLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayout layout'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
forall (layout' :: Layout LayoutType) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetLayout layout, MonadThrow m) =&gt;
SLayout layout'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedLayout"><span class="hs-identifier hs-var">sCheckedLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI layout' =&gt; Sing layout'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757518"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>
</span><span id="line-488"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedLayout' as memory layout type annotation.</span><span>
</span><span id="line-489"></span><span class="hs-comment">-- Any static information about the tensor's memory layout is thus erased.</span><span>
</span><span id="line-490"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-491"></span><span class="hs-comment">--</span><span>
</span><span id="line-492"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-493"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedLayout t</span><span>
</span><span id="line-494"></span><span class="hs-comment">-- uncheckedLayout t</span><span>
</span><span id="line-495"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-496"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-497"></span><span class="hs-comment">--        'UncheckedLayout</span><span>
</span><span id="line-498"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-499"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-500"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-501"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-502"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-503"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedLayout"><span class="hs-identifier hs-type">uncheckedLayout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-504"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757510"><span class="annot"><a href="#local-6989586621679757510"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757509"><span class="annot"><a href="#local-6989586621679757509"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757508"><span class="annot"><a href="#local-6989586621679757508"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757507"><span class="annot"><a href="#local-6989586621679757507"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757506"><span class="annot"><a href="#local-6989586621679757506"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-505"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-506"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757510"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757509"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757508"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757507"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757506"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-507"></span><span>  </span><span class="hs-comment">-- | tensor without checked layout</span><span>
</span><span id="line-508"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757510"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757508"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757507"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757506"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-509"></span><span id="uncheckedLayout"><span class="annot"><span class="annottext">uncheckedLayout :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient 'UncheckedLayout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedLayout"><span class="hs-identifier hs-var hs-var">uncheckedLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient 'UncheckedLayout device dataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-510"></span><span>
</span><span id="line-511"></span><span class="hs-comment">-- | Returns a copy of the tensor in CPU memory.</span><span>
</span><span id="line-512"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#cpu"><span class="hs-identifier hs-type">cpu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-513"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757504"><span class="annot"><a href="#local-6989586621679757504"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757503"><span class="annot"><a href="#local-6989586621679757503"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757502"><span class="annot"><a href="#local-6989586621679757502"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757501"><span class="annot"><a href="#local-6989586621679757501"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757500"><span class="annot"><a href="#local-6989586621679757500"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-514"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-515"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757504"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757503"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757502"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757501"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757500"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-516"></span><span>  </span><span class="hs-comment">-- | copy in CPU memory</span><span>
</span><span id="line-517"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757504"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757503"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757501"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757500"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-518"></span><span id="cpu"><span class="annot"><span class="annottext">cpu :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout ('Device 'CPU) dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#cpu"><span class="hs-identifier hs-var hs-var">cpu</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout ('Device 'CPU) dataType shape)
-&gt; Tensor gradient layout ('Device 'CPU) dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout ('Device 'CPU) dataType shape)
 -&gt; Tensor gradient layout ('Device 'CPU) dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout ('Device 'CPU) dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout ('Device 'CPU) dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout ('Device 'CPU) dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_cpu</span></a></span><span>
</span><span id="line-519"></span><span>
</span><span id="line-520"></span><span class="hs-comment">-- | Returns a copy of the tensor in CUDA memory.</span><span>
</span><span id="line-521"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#cuda"><span class="hs-identifier hs-type">cuda</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-522"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757497"><span class="annot"><a href="#local-6989586621679757497"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757496"><span class="annot"><a href="#local-6989586621679757496"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757495"><span class="annot"><a href="#local-6989586621679757495"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757494"><span class="annot"><a href="#local-6989586621679757494"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757493"><span class="annot"><a href="#local-6989586621679757493"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-523"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-524"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757497"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757496"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757495"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757494"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757493"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-525"></span><span>  </span><span class="hs-comment">-- | copy in CUDA memory</span><span>
</span><span id="line-526"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757497"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757496"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757494"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757493"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-527"></span><span id="cuda"><span class="annot"><span class="annottext">cuda :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout ('Device ('CUDA 0)) dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#cuda"><span class="hs-identifier hs-var hs-var">cuda</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
-&gt; Tensor gradient layout ('Device ('CUDA 0)) dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
 -&gt; Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout ('Device ('CUDA 0)) dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_cuda</span></a></span><span>
</span><span id="line-528"></span><span>
</span><span id="line-529"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDevice"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-var">SGetDevice</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758491"><span class="annot"><a href="#local-6989586621679758491"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-530"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed compute device of the input tensor.</span><span>
</span><span id="line-531"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-532"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; ones' device = sOnes (SGradient SWithGradient) (SLayout SDense) device (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-533"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SDevice SCPU</span><span>
</span><span id="line-534"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sDevice t</span><span>
</span><span id="line-535"></span><span>  </span><span class="hs-comment">-- SDevice SCPU</span><span>
</span><span id="line-536"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SUncheckedDevice CPU</span><span>
</span><span id="line-537"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sDevice t</span><span>
</span><span id="line-538"></span><span>  </span><span class="hs-comment">-- SUncheckedDevice CPU</span><span>
</span><span id="line-539"></span><span>  </span><span id="sDevice"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sDevice"><span class="hs-identifier hs-type">sDevice</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-540"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758486"><span class="annot"><a href="#local-6989586621679758486"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758485"><span class="annot"><a href="#local-6989586621679758485"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758484"><span class="annot"><a href="#local-6989586621679758484"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758483"><span class="annot"><a href="#local-6989586621679758483"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-541"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-542"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758486"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758485"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758491"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758484"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758483"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-543"></span><span>    </span><span class="hs-comment">-- | compute device of the input tensor</span><span>
</span><span id="line-544"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758491"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-545"></span><span>
</span><span id="line-546"></span><span>  </span><span class="hs-comment">-- | Returns the untyped compute device of the input tensor.</span><span>
</span><span id="line-547"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-548"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; ones' device = sOnes (SGradient SWithGradient) (SLayout SDense) device (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-549"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SDevice SCPU</span><span>
</span><span id="line-550"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; deviceType t</span><span>
</span><span id="line-551"></span><span>  </span><span class="hs-comment">-- CPU</span><span>
</span><span id="line-552"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SUncheckedDevice CPU</span><span>
</span><span id="line-553"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; deviceType t</span><span>
</span><span id="line-554"></span><span>  </span><span class="hs-comment">-- CPU</span><span>
</span><span id="line-555"></span><span>  </span><span id="deviceType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#deviceType"><span class="hs-identifier hs-type">deviceType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-556"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758481"><span class="annot"><a href="#local-6989586621679758481"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758480"><span class="annot"><a href="#local-6989586621679758480"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758479"><span class="annot"><a href="#local-6989586621679758479"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758478"><span class="annot"><a href="#local-6989586621679758478"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-557"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-558"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758481"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758480"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758491"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758479"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758478"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-559"></span><span>    </span><span class="hs-comment">-- | compute device of the input tensor</span><span>
</span><span id="line-560"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int16</span></span><span>
</span><span id="line-561"></span><span>  </span><span id="local-6989586621679757489"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#deviceType"><span class="hs-identifier hs-var hs-var">deviceType</span></a></span><span> </span><span id="local-6989586621679757488"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757488"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked (DeviceType Int16) -&gt; DeviceType Int16
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked (DeviceType Int16) -&gt; DeviceType Int16)
-&gt; (SDevice device -&gt; IsChecked (DeviceType Int16))
-&gt; SDevice device
-&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; IsChecked (DeviceType Int16)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDevice device -&gt; DeviceType Int16)
-&gt; SDevice device -&gt; DeviceType Int16
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sDevice"><span class="hs-identifier hs-var">sDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757488"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-562"></span><span>
</span><span id="line-563"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757485"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-564"></span><span>  </span><span id="local-6989586621679757483"><span class="annot"><span class="annottext">sDevice :: Tensor gradient layout 'UncheckedDevice dataType shape
-&gt; SDevice 'UncheckedDevice
</span><a href="#local-6989586621679757483"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDevice</span></a></span></span><span> </span><span id="local-6989586621679757482"><span class="annot"><span class="annottext">Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="#local-6989586621679757482"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-565"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO CBool -&gt; IO Bool
forall a ca. Castable a ca =&gt; IO ca -&gt; IO a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast0</span></a></span><span> </span><span class="annot"><span class="annottext">IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.hasCUDA</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_cuda</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="#local-6989586621679757482"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-566"></span><span>      </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IO Int -&gt; Int
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape -&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_get_device</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="#local-6989586621679757482"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-567"></span><span>        </span><span id="local-6989586621679757477"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757477"><span class="hs-identifier hs-var">deviceIndex</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; SDevice 'UncheckedDevice
</span><a href="Torch.GraduallyTyped.Device.html#SUncheckedDevice"><span class="hs-identifier hs-var">SUncheckedDevice</span></a></span><span> </span><span class="annot"><span class="annottext">(DeviceType Int16 -&gt; SDevice 'UncheckedDevice)
-&gt; (Int -&gt; DeviceType Int16) -&gt; Int -&gt; SDevice 'UncheckedDevice
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int16 -&gt; DeviceType Int16
forall deviceId. deviceId -&gt; DeviceType deviceId
</span><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-var">CUDA</span></a></span><span> </span><span class="annot"><span class="annottext">(Int16 -&gt; DeviceType Int16)
-&gt; (Int -&gt; Int16) -&gt; Int -&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int16
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; SDevice 'UncheckedDevice)
-&gt; Int -&gt; SDevice 'UncheckedDevice
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757477"><span class="hs-identifier hs-var">deviceIndex</span></a></span><span>
</span><span id="line-568"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; SDevice 'UncheckedDevice
</span><a href="Torch.GraduallyTyped.Device.html#SUncheckedDevice"><span class="hs-identifier hs-var">SUncheckedDevice</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
forall deviceId. DeviceType deviceId
</span><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-var">CPU</span></a></span><span>
</span><span id="line-569"></span><span>
</span><span id="line-570"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757473"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-571"></span><span>  </span><span id="local-6989586621679757472"><span class="annot"><span class="annottext">sDevice :: Tensor gradient layout ('Device 'CPU) dataType shape
-&gt; SDevice ('Device 'CPU)
</span><a href="#local-6989586621679757472"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDevice</span></a></span></span><span> </span><span id="local-6989586621679757471"><span class="annot"><span class="annottext">Tensor gradient layout ('Device 'CPU) dataType shape
</span><a href="#local-6989586621679757471"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-572"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO CBool -&gt; IO Bool
forall a ca. Castable a ca =&gt; IO ca -&gt; IO a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast0</span></a></span><span> </span><span class="annot"><span class="annottext">IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.hasCUDA</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout ('Device 'CPU) dataType shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_cuda</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout ('Device 'CPU) dataType shape
</span><a href="#local-6989586621679757471"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-573"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SDevice ('Device 'CPU)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDevice ('Device 'CPU))
-&gt; String -&gt; SDevice ('Device 'CPU)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-574"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be on CPU but is on CUDA. &quot;</span></span><span>
</span><span id="line-575"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-576"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-577"></span><span>
</span><span id="line-578"></span><span id="local-6989586621679757468"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757465"><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679757468"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757468"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-579"></span><span>  </span><span id="local-6989586621679757464"><span class="annot"><span class="annottext">sDevice :: Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
-&gt; SDevice ('Device ('CUDA deviceIndex))
</span><a href="#local-6989586621679757464"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDevice</span></a></span></span><span> </span><span id="local-6989586621679757463"><span class="annot"><span class="annottext">Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
</span><a href="#local-6989586621679757463"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-580"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO CBool -&gt; IO Bool
forall a ca. Castable a ca =&gt; IO ca -&gt; IO a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast0</span></a></span><span> </span><span class="annot"><span class="annottext">IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.hasCUDA</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor
     gradient layout ('Device ('CUDA deviceIndex)) dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_cuda</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
</span><a href="#local-6989586621679757463"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-581"></span><span>      </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IO Int -&gt; Int
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor
     gradient layout ('Device ('CUDA deviceIndex)) dataType shape
-&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_get_device</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
</span><a href="#local-6989586621679757463"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-582"></span><span>        </span><span id="local-6989586621679757462"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757462"><span class="hs-identifier hs-var">deviceIndex</span></a></span></span><span>
</span><span id="line-583"></span><span>          </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757462"><span class="hs-identifier hs-var">deviceIndex</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757468"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SDeviceType ('CUDA deviceIndex)
-&gt; SDevice ('Device ('CUDA deviceIndex))
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType ('CUDA deviceIndex)
forall (deviceId :: Nat).
KnownNat deviceId =&gt;
SDeviceType ('CUDA deviceId)
</span><a href="Torch.GraduallyTyped.Device.html#SCUDA"><span class="hs-identifier hs-var">SCUDA</span></a></span><span>
</span><span id="line-584"></span><span>          </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-585"></span><span>            </span><span class="annot"><span class="annottext">String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDevice ('Device ('CUDA deviceIndex)))
-&gt; String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-586"></span><span>              </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be on CUDA device &quot;</span></span><span>
</span><span id="line-587"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757468"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-588"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; but is on device &quot;</span></span><span>
</span><span id="line-589"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757462"><span class="hs-identifier hs-var">deviceIndex</span></a></span><span>
</span><span id="line-590"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;. &quot;</span></span><span>
</span><span id="line-591"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-592"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-593"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDevice ('Device ('CUDA deviceIndex)))
-&gt; String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-594"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be on CUDA but is on CPU. &quot;</span></span><span>
</span><span id="line-595"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span></span><span>
</span><span id="line-596"></span><span>
</span><span id="line-597"></span><span class="hs-keyword">data</span><span> </span><span id="DeviceError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-var">DeviceError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="DeviceError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-var">DeviceError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="deExpected"><span class="annot"><span class="annottext">DeviceError -&gt; DeviceType Int16
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#deExpected"><span class="hs-identifier hs-var hs-var">deExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int16</span></span><span class="hs-special">,</span><span> </span><span id="deActual"><span class="annot"><span class="annottext">DeviceError -&gt; DeviceType Int16
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#deActual"><span class="hs-identifier hs-var hs-var">deActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int16</span></span><span class="hs-special">}</span><span>
</span><span id="line-598"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757451"><span id="local-6989586621679757453"><span id="local-6989586621679757455"><span class="annot"><span class="annottext">Int -&gt; DeviceError -&gt; ShowS
[DeviceError] -&gt; ShowS
DeviceError -&gt; String
(Int -&gt; DeviceError -&gt; ShowS)
-&gt; (DeviceError -&gt; String)
-&gt; ([DeviceError] -&gt; ShowS)
-&gt; Show DeviceError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [DeviceError] -&gt; ShowS
$cshowList :: [DeviceError] -&gt; ShowS
show :: DeviceError -&gt; String
$cshow :: DeviceError -&gt; String
showsPrec :: Int -&gt; DeviceError -&gt; ShowS
$cshowsPrec :: Int -&gt; DeviceError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-599"></span><span>
</span><span id="line-600"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757445"><span id="local-6989586621679757447"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-type">DeviceError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-601"></span><span>  </span><span id="local-6989586621679757443"><span class="annot"><span class="annottext">displayException :: DeviceError -&gt; String
</span><a href="#local-6989586621679757443"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-type">DeviceError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679757441"><span id="local-6989586621679757442"><span class="annot"><span class="annottext">DeviceType Int16
deActual :: DeviceType Int16
deExpected :: DeviceType Int16
deActual :: DeviceError -&gt; DeviceType Int16
deExpected :: DeviceError -&gt; DeviceType Int16
</span><a href="#local-6989586621679757441"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-602"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor is not in the memory of the device `&quot;</span></span><span>
</span><span id="line-603"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679757442"><span class="hs-identifier hs-var">deExpected</span></a></span><span>
</span><span id="line-604"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-605"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679757441"><span class="hs-identifier hs-var">deActual</span></a></span><span>
</span><span id="line-606"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-607"></span><span>
</span><span id="line-608"></span><span class="hs-comment">-- | Checks whether or not the input tensor is in the memory of 'device'</span><span>
</span><span id="line-609"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-610"></span><span class="hs-comment">--</span><span>
</span><span id="line-611"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor is indeed on 'device'.</span><span>
</span><span id="line-612"></span><span class="hs-comment">-- If it is not, then the result will be 'Nothing'.</span><span>
</span><span id="line-613"></span><span class="hs-comment">--</span><span>
</span><span id="line-614"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-615"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes (SGradient SWithGradient) (SLayout SDense) (SUncheckedDevice CPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-616"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedDevice (SDevice SCPU) t</span><span>
</span><span id="line-617"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-618"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-619"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-620"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-621"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-622"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-623"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-624"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-625"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-626"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-627"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedDevice (SDevice (SCUDA @0)) t</span><span>
</span><span id="line-628"></span><span class="hs-comment">-- *** Exception: DeviceError {deExpected = CUDA 0, deActual = CPU}</span><span>
</span><span id="line-629"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDevice"><span class="hs-identifier hs-type">sCheckedDevice</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-630"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758421"><span class="annot"><a href="#local-6989586621679758421"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679758422"><span class="annot"><a href="#local-6989586621679758422"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679758420"><span class="annot"><a href="#local-6989586621679758420"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758419"><span class="annot"><a href="#local-6989586621679758419"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758423"><span class="annot"><a href="#local-6989586621679758423"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758418"><span class="annot"><a href="#local-6989586621679758418"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758417"><span class="annot"><a href="#local-6989586621679758417"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-631"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758423"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758422"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-632"></span><span>  </span><span class="hs-comment">-- | device</span><span>
</span><span id="line-633"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758421"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-634"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-635"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758420"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758419"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758423"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758418"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758417"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-636"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-637"></span><span>  </span><span class="annot"><a href="#local-6989586621679758422"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758420"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758419"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679758423"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758421"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758421"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758418"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758417"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-638"></span><span id="sCheckedDevice"><span class="annot"><span class="annottext">sCheckedDevice :: SDevice device'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDevice"><span class="hs-identifier hs-var hs-var">sCheckedDevice</span></a></span></span><span> </span><span id="local-6989586621679757439"><span class="annot"><span class="annottext">SDevice device'
</span><a href="#local-6989586621679757439"><span class="hs-identifier hs-var">device'</span></a></span></span><span> </span><span id="local-6989586621679757438"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757438"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-639"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679757437"><span class="annot"><span class="annottext">actualDevice :: DeviceType Int16
</span><a href="#local-6989586621679757437"><span class="hs-identifier hs-var hs-var">actualDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked (DeviceType Int16) -&gt; DeviceType Int16
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked (DeviceType Int16) -&gt; DeviceType Int16)
-&gt; (SDevice device -&gt; IsChecked (DeviceType Int16))
-&gt; SDevice device
-&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; IsChecked (DeviceType Int16)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDevice device -&gt; DeviceType Int16)
-&gt; SDevice device -&gt; DeviceType Int16
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sDevice"><span class="hs-identifier hs-var">sDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757438"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-640"></span><span>      </span><span id="local-6989586621679757436"><span class="annot"><span class="annottext">expectedDevice :: DeviceType Int16
</span><a href="#local-6989586621679757436"><span class="hs-identifier hs-var hs-var">expectedDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked (DeviceType Int16) -&gt; DeviceType Int16
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked (DeviceType Int16) -&gt; DeviceType Int16)
-&gt; (SDevice device' -&gt; IsChecked (DeviceType Int16))
-&gt; SDevice device'
-&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDevice device' -&gt; IsChecked (DeviceType Int16)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDevice device' -&gt; DeviceType Int16)
-&gt; SDevice device' -&gt; DeviceType Int16
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDevice device'
</span><a href="#local-6989586621679757439"><span class="hs-identifier hs-var">device'</span></a></span><span>
</span><span id="line-641"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679757437"><span class="hs-identifier hs-var">actualDevice</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; DeviceType Int16 -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679757436"><span class="hs-identifier hs-var">expectedDevice</span></a></span><span>
</span><span id="line-642"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Seq (Unify (Device (DeviceType Nat)) device device') device')
  dataType
  shape
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   (Seq (Unify (Device (DeviceType Nat)) device device') device')
   dataType
   shape
 -&gt; m (Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     (Seq (Unify (Device (DeviceType Nat)) device device') device')
     dataType
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757438"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-643"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">DeviceError
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(DeviceError
 -&gt; m (Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape))
-&gt; DeviceError
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; DeviceType Int16 -&gt; DeviceError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-var">DeviceError</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679757436"><span class="hs-identifier hs-var">expectedDevice</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679757437"><span class="hs-identifier hs-var">actualDevice</span></a></span><span>
</span><span id="line-644"></span><span>
</span><span id="line-645"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDevice"><span class="hs-identifier hs-type">checkedDevice</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-646"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757434"><span class="annot"><a href="#local-6989586621679757434"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679757433"><span class="annot"><a href="#local-6989586621679757433"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679757432"><span class="annot"><a href="#local-6989586621679757432"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757431"><span class="annot"><a href="#local-6989586621679757431"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757430"><span class="annot"><a href="#local-6989586621679757430"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757429"><span class="annot"><a href="#local-6989586621679757429"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757428"><span class="annot"><a href="#local-6989586621679757428"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-647"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757434"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757430"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757433"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-648"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-649"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757432"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757431"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757430"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757429"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757428"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-650"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-651"></span><span>  </span><span class="annot"><a href="#local-6989586621679757433"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757432"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757431"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757430"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757434"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757434"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757429"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757428"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-652"></span><span id="checkedDevice"><span class="annot"><span class="annottext">checkedDevice :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDevice"><span class="hs-identifier hs-var hs-var">checkedDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
forall (device' :: Device (DeviceType Nat)) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetDevice device, MonadThrow m) =&gt;
SDevice device'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDevice"><span class="hs-identifier hs-var">sCheckedDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI device' =&gt; Sing device'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757434"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-653"></span><span>
</span><span id="line-654"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedDevice' as device type annotation.</span><span>
</span><span id="line-655"></span><span class="hs-comment">-- Any static information about the tensor's device is thus erased.</span><span>
</span><span id="line-656"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-657"></span><span class="hs-comment">--</span><span>
</span><span id="line-658"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-659"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDevice t</span><span>
</span><span id="line-660"></span><span class="hs-comment">-- uncheckedDevice t</span><span>
</span><span id="line-661"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-662"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-663"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-664"></span><span class="hs-comment">--        'UncheckedDevice</span><span>
</span><span id="line-665"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-666"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-667"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-668"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-669"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDevice"><span class="hs-identifier hs-type">uncheckedDevice</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-670"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757426"><span class="annot"><a href="#local-6989586621679757426"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757425"><span class="annot"><a href="#local-6989586621679757425"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757424"><span class="annot"><a href="#local-6989586621679757424"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757423"><span class="annot"><a href="#local-6989586621679757423"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757422"><span class="annot"><a href="#local-6989586621679757422"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-671"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-672"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757426"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757425"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757424"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757423"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757422"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-673"></span><span>  </span><span class="hs-comment">-- | tensor without checked device</span><span>
</span><span id="line-674"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757426"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757425"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757423"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757422"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-675"></span><span id="uncheckedDevice"><span class="annot"><span class="annottext">uncheckedDevice :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDevice"><span class="hs-identifier hs-var hs-var">uncheckedDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-676"></span><span>
</span><span id="line-677"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Bool'.</span><span>
</span><span id="line-678"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier hs-type">bool</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-679"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757420"><span class="annot"><a href="#local-6989586621679757420"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757419"><span class="annot"><a href="#local-6989586621679757419"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757418"><span class="annot"><a href="#local-6989586621679757418"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757417"><span class="annot"><a href="#local-6989586621679757417"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757416"><span class="annot"><a href="#local-6989586621679757416"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-680"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-681"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757420"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757419"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757418"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757417"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757416"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-682"></span><span>  </span><span class="hs-comment">-- | 'Bool' copy</span><span>
</span><span id="line-683"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757419"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757418"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757416"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-684"></span><span id="bool"><span class="annot"><span class="annottext">bool :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier hs-var hs-var">bool</span></a></span></span><span> </span><span id="local-6989586621679757415"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757415"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757415"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-var">Bool</span></a></span><span>
</span><span id="line-685"></span><span>
</span><span id="line-686"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'UInt8'.</span><span>
</span><span id="line-687"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#byte"><span class="hs-identifier hs-type">byte</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-688"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757412"><span class="annot"><a href="#local-6989586621679757412"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757411"><span class="annot"><a href="#local-6989586621679757411"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757410"><span class="annot"><a href="#local-6989586621679757410"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757409"><span class="annot"><a href="#local-6989586621679757409"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757408"><span class="annot"><a href="#local-6989586621679757408"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-689"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-690"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757412"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757411"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757410"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757409"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757408"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-691"></span><span>  </span><span class="hs-comment">-- | 'UInt8' copy</span><span>
</span><span id="line-692"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757411"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757410"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UInt8"><span class="hs-identifier hs-type">UInt8</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757408"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-693"></span><span id="byte"><span class="annot"><span class="annottext">byte :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'UInt8) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#byte"><span class="hs-identifier hs-var hs-var">byte</span></a></span></span><span> </span><span id="local-6989586621679757407"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757407"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'UInt8)
     shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'UInt8) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'UInt8)
      shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'UInt8)
      shape)
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'UInt8)
        shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'UInt8) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'UInt8)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757407"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#UInt8"><span class="hs-identifier hs-var">UInt8</span></a></span><span>
</span><span id="line-694"></span><span>
</span><span id="line-695"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int8'.</span><span>
</span><span id="line-696"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#char"><span class="hs-identifier hs-type">char</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-697"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757405"><span class="annot"><a href="#local-6989586621679757405"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757404"><span class="annot"><a href="#local-6989586621679757404"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757403"><span class="annot"><a href="#local-6989586621679757403"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757402"><span class="annot"><a href="#local-6989586621679757402"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757401"><span class="annot"><a href="#local-6989586621679757401"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-698"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-699"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757405"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757404"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757403"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757402"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757401"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-700"></span><span>  </span><span class="hs-comment">-- | 'Int8' copy</span><span>
</span><span id="line-701"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757404"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757403"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int8"><span class="hs-identifier hs-type">Int8</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757401"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-702"></span><span id="char"><span class="annot"><span class="annottext">char :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#char"><span class="hs-identifier hs-var hs-var">char</span></a></span></span><span> </span><span id="local-6989586621679757400"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757400"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757400"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int8"><span class="hs-identifier hs-var">Int8</span></a></span><span>
</span><span id="line-703"></span><span>
</span><span id="line-704"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int16'.</span><span>
</span><span id="line-705"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#short"><span class="hs-identifier hs-type">short</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-706"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757398"><span class="annot"><a href="#local-6989586621679757398"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757397"><span class="annot"><a href="#local-6989586621679757397"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757396"><span class="annot"><a href="#local-6989586621679757396"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757395"><span class="annot"><a href="#local-6989586621679757395"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757394"><span class="annot"><a href="#local-6989586621679757394"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-707"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-708"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757398"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757397"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757396"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757395"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757394"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-709"></span><span>  </span><span class="hs-comment">-- | 'Int16' copy</span><span>
</span><span id="line-710"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757397"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757396"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int16"><span class="hs-identifier hs-type">Int16</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757394"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-711"></span><span id="short"><span class="annot"><span class="annottext">short :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int16) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#short"><span class="hs-identifier hs-var hs-var">short</span></a></span></span><span> </span><span id="local-6989586621679757393"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757393"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'Int16)
     shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int16) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int16)
      shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int16)
      shape)
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int16)
        shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int16) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int16)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757393"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int16"><span class="hs-identifier hs-var">Int16</span></a></span><span>
</span><span id="line-712"></span><span>
</span><span id="line-713"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int32'.</span><span>
</span><span id="line-714"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#int"><span class="hs-identifier hs-type">int</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-715"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757391"><span class="annot"><a href="#local-6989586621679757391"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757390"><span class="annot"><a href="#local-6989586621679757390"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757389"><span class="annot"><a href="#local-6989586621679757389"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757388"><span class="annot"><a href="#local-6989586621679757388"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757387"><span class="annot"><a href="#local-6989586621679757387"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-716"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-717"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757391"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757390"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757389"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757388"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757387"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-718"></span><span>  </span><span class="hs-comment">-- | 'Int32' copy</span><span>
</span><span id="line-719"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757390"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757389"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int32"><span class="hs-identifier hs-type">Int32</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757387"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-720"></span><span id="int"><span class="annot"><span class="annottext">int :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int32) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#int"><span class="hs-identifier hs-var hs-var">int</span></a></span></span><span> </span><span id="local-6989586621679757386"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757386"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'Int32)
     shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int32) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int32)
      shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int32)
      shape)
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int32)
        shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int32) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int32)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757386"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int32"><span class="hs-identifier hs-var">Int32</span></a></span><span>
</span><span id="line-721"></span><span>
</span><span id="line-722"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int64'.</span><span>
</span><span id="line-723"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#long"><span class="hs-identifier hs-type">long</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-724"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757384"><span class="annot"><a href="#local-6989586621679757384"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757383"><span class="annot"><a href="#local-6989586621679757383"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757382"><span class="annot"><a href="#local-6989586621679757382"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757381"><span class="annot"><a href="#local-6989586621679757381"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757380"><span class="annot"><a href="#local-6989586621679757380"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-725"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-726"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757384"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757383"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757382"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757381"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757380"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-727"></span><span>  </span><span class="hs-comment">-- | 'Int64' copy</span><span>
</span><span id="line-728"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757383"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757382"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757380"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-729"></span><span id="long"><span class="annot"><span class="annottext">long :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int64) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#long"><span class="hs-identifier hs-var hs-var">long</span></a></span></span><span> </span><span id="local-6989586621679757379"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757379"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'Int64)
     shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int64) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int64)
      shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int64)
      shape)
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int64) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757379"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-var">Int64</span></a></span><span>
</span><span id="line-730"></span><span>
</span><span id="line-731"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to the 16-bit floating point format 'Half'.</span><span>
</span><span id="line-732"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#half"><span class="hs-identifier hs-type">half</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-733"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757377"><span class="annot"><a href="#local-6989586621679757377"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757376"><span class="annot"><a href="#local-6989586621679757376"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757375"><span class="annot"><a href="#local-6989586621679757375"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757374"><span class="annot"><a href="#local-6989586621679757374"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757373"><span class="annot"><a href="#local-6989586621679757373"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-734"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-735"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757377"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757376"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757375"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757374"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757373"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-736"></span><span>  </span><span class="hs-comment">-- | 'Half' copy</span><span>
</span><span id="line-737"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757377"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757376"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757375"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Half"><span class="hs-identifier hs-type">Half</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757373"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-738"></span><span id="half"><span class="annot"><span class="annottext">half :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Half) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#half"><span class="hs-identifier hs-var hs-var">half</span></a></span></span><span> </span><span id="local-6989586621679757372"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757372"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Half) shape)
-&gt; Tensor gradient layout device ('DataType 'Half) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Half) shape)
 -&gt; Tensor gradient layout device ('DataType 'Half) shape)
-&gt; IO (Tensor gradient layout device ('DataType 'Half) shape)
-&gt; Tensor gradient layout device ('DataType 'Half) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO (Tensor gradient layout device ('DataType 'Half) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757372"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Half"><span class="hs-identifier hs-var">Half</span></a></span><span>
</span><span id="line-739"></span><span>
</span><span id="line-740"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to the 32-bit floating point format 'Float'.</span><span>
</span><span id="line-741"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#float"><span class="hs-identifier hs-type">float</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-742"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757370"><span class="annot"><a href="#local-6989586621679757370"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757369"><span class="annot"><a href="#local-6989586621679757369"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757368"><span class="annot"><a href="#local-6989586621679757368"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757367"><span class="annot"><a href="#local-6989586621679757367"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757366"><span class="annot"><a href="#local-6989586621679757366"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-743"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-744"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757370"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757367"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757366"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-745"></span><span>  </span><span class="hs-comment">-- | 'Float' copy</span><span>
</span><span id="line-746"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757370"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-type">Float</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757366"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-747"></span><span id="float"><span class="annot"><span class="annottext">float :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Float) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#float"><span class="hs-identifier hs-var hs-var">float</span></a></span></span><span> </span><span id="local-6989586621679757365"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757365"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Float) shape)
-&gt; Tensor gradient layout device ('DataType 'Float) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Float) shape)
 -&gt; Tensor gradient layout device ('DataType 'Float) shape)
-&gt; IO (Tensor gradient layout device ('DataType 'Float) shape)
-&gt; Tensor gradient layout device ('DataType 'Float) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO (Tensor gradient layout device ('DataType 'Float) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757365"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-var">Float</span></a></span><span>
</span><span id="line-748"></span><span>
</span><span id="line-749"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to the 32-bit floating point format 'Double'.</span><span>
</span><span id="line-750"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#double"><span class="hs-identifier hs-type">double</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-751"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757363"><span class="annot"><a href="#local-6989586621679757363"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757362"><span class="annot"><a href="#local-6989586621679757362"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757361"><span class="annot"><a href="#local-6989586621679757361"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757360"><span class="annot"><a href="#local-6989586621679757360"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757359"><span class="annot"><a href="#local-6989586621679757359"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-752"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-753"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757359"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-754"></span><span>  </span><span class="hs-comment">-- | 'Double' copy</span><span>
</span><span id="line-755"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Double"><span class="hs-identifier hs-type">Double</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757359"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-756"></span><span id="double"><span class="annot"><span class="annottext">double :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Double) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#double"><span class="hs-identifier hs-var hs-var">double</span></a></span></span><span> </span><span id="local-6989586621679757358"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757358"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Double) shape)
-&gt; Tensor gradient layout device ('DataType 'Double) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Double) shape)
 -&gt; Tensor gradient layout device ('DataType 'Double) shape)
-&gt; IO (Tensor gradient layout device ('DataType 'Double) shape)
-&gt; Tensor gradient layout device ('DataType 'Double) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO (Tensor gradient layout device ('DataType 'Double) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757358"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Double"><span class="hs-identifier hs-var">Double</span></a></span><span>
</span><span id="line-757"></span><span>
</span><span id="line-758"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDataType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-var">SGetDataType</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758352"><span class="annot"><a href="#local-6989586621679758352"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-759"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed compute data type of the input tensor.</span><span>
</span><span id="line-760"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-761"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' dataType = sOnes (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) dataType (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-762"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SDataType SFloat</span><span>
</span><span id="line-763"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sDataType t</span><span>
</span><span id="line-764"></span><span>  </span><span class="hs-comment">-- SDataType SFloat</span><span>
</span><span id="line-765"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedDataType Float</span><span>
</span><span id="line-766"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sDataType t</span><span>
</span><span id="line-767"></span><span>  </span><span class="hs-comment">-- SUncheckedDataType Float</span><span>
</span><span id="line-768"></span><span>  </span><span id="sDataType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sDataType"><span class="hs-identifier hs-type">sDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-769"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758348"><span class="annot"><a href="#local-6989586621679758348"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758347"><span class="annot"><a href="#local-6989586621679758347"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758346"><span class="annot"><a href="#local-6989586621679758346"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758345"><span class="annot"><a href="#local-6989586621679758345"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-770"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-771"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758348"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758347"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758346"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758352"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758345"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-772"></span><span>    </span><span class="hs-comment">-- | data type of the input tensor</span><span>
</span><span id="line-773"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758352"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-774"></span><span>
</span><span id="line-775"></span><span>  </span><span class="hs-comment">-- | Returns the untyped compute data type of the input tensor.</span><span>
</span><span id="line-776"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-777"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' dataType = sOnes (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) dataType (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-778"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SDataType SFloat</span><span>
</span><span id="line-779"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; dType t</span><span>
</span><span id="line-780"></span><span>  </span><span class="hs-comment">-- Float</span><span>
</span><span id="line-781"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedDataType Float</span><span>
</span><span id="line-782"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; dType t</span><span>
</span><span id="line-783"></span><span>  </span><span class="hs-comment">-- Float</span><span>
</span><span id="line-784"></span><span>  </span><span id="dType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dType"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-785"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758343"><span class="annot"><a href="#local-6989586621679758343"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758342"><span class="annot"><a href="#local-6989586621679758342"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758341"><span class="annot"><a href="#local-6989586621679758341"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758340"><span class="annot"><a href="#local-6989586621679758340"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-786"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-787"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758343"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758342"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758341"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758352"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758340"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-788"></span><span>    </span><span class="hs-comment">-- | data type of the input tensor</span><span>
</span><span id="line-789"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span>
</span><span id="line-790"></span><span>  </span><span id="local-6989586621679757355"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dType"><span class="hs-identifier hs-var hs-var">dType</span></a></span><span> </span><span id="local-6989586621679757354"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757354"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked DType -&gt; DType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked DType -&gt; DType)
-&gt; (SDataType dataType -&gt; IsChecked DType)
-&gt; SDataType dataType
-&gt; DType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType -&gt; IsChecked DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDataType dataType -&gt; DType) -&gt; SDataType dataType -&gt; DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDataType dataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sDataType"><span class="hs-identifier hs-var">sDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757354"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-791"></span><span>
</span><span id="line-792"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757351"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-793"></span><span>  </span><span id="local-6989586621679757349"><span class="annot"><span class="annottext">sDataType :: Tensor gradient layout device 'UncheckedDataType shape
-&gt; SDataType 'UncheckedDataType
</span><a href="#local-6989586621679757349"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDataType</span></a></span></span><span> </span><span id="local-6989586621679757348"><span class="annot"><span class="annottext">Tensor gradient layout device 'UncheckedDataType shape
</span><a href="#local-6989586621679757348"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">DType -&gt; SDataType 'UncheckedDataType
</span><a href="Torch.GraduallyTyped.DType.html#SUncheckedDataType"><span class="hs-identifier hs-var">SUncheckedDataType</span></a></span><span> </span><span class="annot"><span class="annottext">(DType -&gt; SDataType 'UncheckedDataType)
-&gt; (IO DType -&gt; DType) -&gt; IO DType -&gt; SDataType 'UncheckedDataType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IO DType -&gt; DType
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO DType -&gt; SDataType 'UncheckedDataType)
-&gt; IO DType -&gt; SDataType 'UncheckedDataType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO ScalarType)
-&gt; Tensor gradient layout device 'UncheckedDataType shape
-&gt; IO DType
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO ScalarType
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_scalar_type</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device 'UncheckedDataType shape
</span><a href="#local-6989586621679757348"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-794"></span><span>
</span><span id="line-795"></span><span id="local-6989586621679757345"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757342"><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757345"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757345"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-796"></span><span>  </span><span id="local-6989586621679757341"><span class="annot"><span class="annottext">sDataType :: Tensor gradient layout device ('DataType dType) shape
-&gt; SDataType ('DataType dType)
</span><a href="#local-6989586621679757341"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDataType</span></a></span></span><span> </span><span id="local-6989586621679757340"><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) shape
</span><a href="#local-6989586621679757340"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-797"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO DType -&gt; DType
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO ScalarType)
-&gt; Tensor gradient layout device ('DataType dType) shape
-&gt; IO DType
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO ScalarType
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_scalar_type</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) shape
</span><a href="#local-6989586621679757340"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">DType -&gt; DType -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Sing dType -&gt; Demote DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI dType =&gt; Sing dType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757345"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType dType -&gt; SDataType ('DataType dType)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">(SDType dType -&gt; SDataType ('DataType dType))
-&gt; SDType dType -&gt; SDataType ('DataType dType)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SingI dType =&gt; Sing dType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757345"><span class="hs-identifier hs-type">dType</span></a></span><span>
</span><span id="line-798"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-799"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SDataType ('DataType dType)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDataType ('DataType dType))
-&gt; String -&gt; SDataType ('DataType dType)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-800"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should have data type &quot;</span></span><span>
</span><span id="line-801"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing dType -&gt; Demote DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(Sing dType -&gt; Demote DType) -&gt; Sing dType -&gt; Demote DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SingI dType =&gt; Sing dType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757345"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-802"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; but hasn't. &quot;</span></span><span>
</span><span id="line-803"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span></span><span>
</span><span id="line-804"></span><span>
</span><span id="line-805"></span><span class="hs-keyword">data</span><span> </span><span id="DataTypeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-var">DataTypeError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="DataTypeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-var">DataTypeError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="dtExpected"><span class="annot"><span class="annottext">DataTypeError -&gt; DType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dtExpected"><span class="hs-identifier hs-var hs-var">dtExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">,</span><span> </span><span id="dtActual"><span class="annot"><span class="annottext">DataTypeError -&gt; DType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dtActual"><span class="hs-identifier hs-var hs-var">dtActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">}</span><span>
</span><span id="line-806"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757330"><span id="local-6989586621679757332"><span id="local-6989586621679757334"><span class="annot"><span class="annottext">Int -&gt; DataTypeError -&gt; ShowS
[DataTypeError] -&gt; ShowS
DataTypeError -&gt; String
(Int -&gt; DataTypeError -&gt; ShowS)
-&gt; (DataTypeError -&gt; String)
-&gt; ([DataTypeError] -&gt; ShowS)
-&gt; Show DataTypeError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [DataTypeError] -&gt; ShowS
$cshowList :: [DataTypeError] -&gt; ShowS
show :: DataTypeError -&gt; String
$cshow :: DataTypeError -&gt; String
showsPrec :: Int -&gt; DataTypeError -&gt; ShowS
$cshowsPrec :: Int -&gt; DataTypeError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-807"></span><span>
</span><span id="line-808"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757324"><span id="local-6989586621679757326"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-type">DataTypeError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-809"></span><span>  </span><span id="local-6989586621679757322"><span class="annot"><span class="annottext">displayException :: DataTypeError -&gt; String
</span><a href="#local-6989586621679757322"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-type">DataTypeError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679757320"><span id="local-6989586621679757321"><span class="annot"><span class="annottext">DType
dtActual :: DType
dtExpected :: DType
dtActual :: DataTypeError -&gt; DType
dtExpected :: DataTypeError -&gt; DType
</span><a href="#local-6989586621679757320"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-810"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor does not have the data type `&quot;</span></span><span>
</span><span id="line-811"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679757321"><span class="hs-identifier hs-var">dtExpected</span></a></span><span>
</span><span id="line-812"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-813"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679757320"><span class="hs-identifier hs-var">dtActual</span></a></span><span>
</span><span id="line-814"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-815"></span><span>
</span><span id="line-816"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the data type 'dataType'</span><span>
</span><span id="line-817"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-818"></span><span class="hs-comment">--</span><span>
</span><span id="line-819"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the data type 'dataType'.</span><span>
</span><span id="line-820"></span><span class="hs-comment">-- If it does not have it, then the result will be 'Nothing'.</span><span>
</span><span id="line-821"></span><span class="hs-comment">--</span><span>
</span><span id="line-822"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-823"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SUncheckedDataType Float) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-824"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- checkedDataType @('DataType 'Float) t</span><span>
</span><span id="line-825"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-826"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-827"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-828"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-829"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-830"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-831"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-832"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-833"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-834"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-835"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- checkedDataType @('DataType 'Double) t</span><span>
</span><span id="line-836"></span><span class="hs-comment">-- *** Exception: DataTypeError {dtExpected = Double, dtActual = Float}</span><span>
</span><span id="line-837"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDataType"><span class="hs-identifier hs-type">sCheckedDataType</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-838"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758303"><span class="annot"><a href="#local-6989586621679758303"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679758304"><span class="annot"><a href="#local-6989586621679758304"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679758302"><span class="annot"><a href="#local-6989586621679758302"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758301"><span class="annot"><a href="#local-6989586621679758301"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758300"><span class="annot"><a href="#local-6989586621679758300"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758305"><span class="annot"><a href="#local-6989586621679758305"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758299"><span class="annot"><a href="#local-6989586621679758299"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-839"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758305"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758304"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-840"></span><span>  </span><span class="hs-comment">-- | data type</span><span>
</span><span id="line-841"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758303"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-842"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-843"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758302"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758301"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758300"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758305"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758299"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-844"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-845"></span><span>  </span><span class="annot"><a href="#local-6989586621679758304"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758302"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758301"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758300"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679758305"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758303"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758303"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758299"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-846"></span><span id="sCheckedDataType"><span class="annot"><span class="annottext">sCheckedDataType :: SDataType dataType'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDataType"><span class="hs-identifier hs-var hs-var">sCheckedDataType</span></a></span></span><span> </span><span id="local-6989586621679757318"><span class="annot"><span class="annottext">SDataType dataType'
</span><a href="#local-6989586621679757318"><span class="hs-identifier hs-var">dataType'</span></a></span></span><span> </span><span id="local-6989586621679757317"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757317"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-847"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679757316"><span class="annot"><span class="annottext">actualDataType :: DType
</span><a href="#local-6989586621679757316"><span class="hs-identifier hs-var hs-var">actualDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked DType -&gt; DType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked DType -&gt; DType)
-&gt; (SDataType dataType -&gt; IsChecked DType)
-&gt; SDataType dataType
-&gt; DType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType -&gt; IsChecked DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDataType dataType -&gt; DType) -&gt; SDataType dataType -&gt; DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDataType dataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sDataType"><span class="hs-identifier hs-var">sDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757317"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-848"></span><span>      </span><span id="local-6989586621679757315"><span class="annot"><span class="annottext">expectedDataType :: DType
</span><a href="#local-6989586621679757315"><span class="hs-identifier hs-var hs-var">expectedDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked DType -&gt; DType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked DType -&gt; DType)
-&gt; (SDataType dataType' -&gt; IsChecked DType)
-&gt; SDataType dataType'
-&gt; DType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType' -&gt; IsChecked DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDataType dataType' -&gt; DType) -&gt; SDataType dataType' -&gt; DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType'
</span><a href="#local-6989586621679757318"><span class="hs-identifier hs-var">dataType'</span></a></span><span>
</span><span id="line-849"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679757316"><span class="hs-identifier hs-var">actualDataType</span></a></span><span> </span><span class="annot"><span class="annottext">DType -&gt; DType -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679757315"><span class="hs-identifier hs-var">expectedDataType</span></a></span><span>
</span><span id="line-850"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  (Seq (Unify (DataType DType) dataType dataType') dataType')
  shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   device
   (Seq (Unify (DataType DType) dataType dataType') dataType')
   shape
 -&gt; m (Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     (Seq (Unify (DataType DType) dataType dataType') dataType')
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757317"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-851"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">DataTypeError
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(DataTypeError
 -&gt; m (Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape))
-&gt; DataTypeError
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; DType -&gt; DataTypeError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-var">DataTypeError</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679757315"><span class="hs-identifier hs-var">expectedDataType</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679757316"><span class="hs-identifier hs-var">actualDataType</span></a></span><span>
</span><span id="line-852"></span><span>
</span><span id="line-853"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDataType"><span class="hs-identifier hs-type">checkedDataType</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-854"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757313"><span class="annot"><a href="#local-6989586621679757313"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679757312"><span class="annot"><a href="#local-6989586621679757312"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679757311"><span class="annot"><a href="#local-6989586621679757311"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757310"><span class="annot"><a href="#local-6989586621679757310"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757309"><span class="annot"><a href="#local-6989586621679757309"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757308"><span class="annot"><a href="#local-6989586621679757308"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757307"><span class="annot"><a href="#local-6989586621679757307"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-855"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757313"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757308"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757312"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-856"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-857"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757311"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757310"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757309"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757308"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757307"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-858"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-859"></span><span>  </span><span class="annot"><a href="#local-6989586621679757312"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757311"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757310"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757309"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757308"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757313"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757313"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757307"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-860"></span><span id="checkedDataType"><span class="annot"><span class="annottext">checkedDataType :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDataType"><span class="hs-identifier hs-var hs-var">checkedDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType dataType'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
forall (dataType' :: DataType DType) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetDataType dataType, MonadThrow m) =&gt;
SDataType dataType'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDataType"><span class="hs-identifier hs-var">sCheckedDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI dataType' =&gt; Sing dataType'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757313"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-861"></span><span>
</span><span id="line-862"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedDataType' as data-type type annotation.</span><span>
</span><span id="line-863"></span><span class="hs-comment">-- Any static information about the tensor's data type is thus erased.</span><span>
</span><span id="line-864"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-865"></span><span class="hs-comment">--</span><span>
</span><span id="line-866"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-867"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDataType t</span><span>
</span><span id="line-868"></span><span class="hs-comment">-- uncheckedDataType t</span><span>
</span><span id="line-869"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-870"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-871"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-872"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-873"></span><span class="hs-comment">--        'UncheckedDataType</span><span>
</span><span id="line-874"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-875"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-876"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-877"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDataType"><span class="hs-identifier hs-type">uncheckedDataType</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-878"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757305"><span class="annot"><a href="#local-6989586621679757305"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757304"><span class="annot"><a href="#local-6989586621679757304"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757303"><span class="annot"><a href="#local-6989586621679757303"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757302"><span class="annot"><a href="#local-6989586621679757302"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757301"><span class="annot"><a href="#local-6989586621679757301"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-879"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-880"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757305"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757304"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757303"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757302"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757301"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-881"></span><span>  </span><span class="hs-comment">-- | tensor without checked data type</span><span>
</span><span id="line-882"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757305"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757304"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757303"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757301"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-883"></span><span id="uncheckedDataType"><span class="annot"><span class="annottext">uncheckedDataType :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device 'UncheckedDataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDataType"><span class="hs-identifier hs-var hs-var">uncheckedDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device 'UncheckedDataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-884"></span><span>
</span><span id="line-885"></span><span class="hs-keyword">class</span><span> </span><span id="SGetShape"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-var">SGetShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758289"><span class="annot"><a href="#local-6989586621679758289"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-886"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed shape of the input tensor.</span><span>
</span><span id="line-887"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-888"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' = sOnes (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)</span><span>
</span><span id="line-889"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil</span><span>
</span><span id="line-890"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sShape t</span><span>
</span><span id="line-891"></span><span>  </span><span class="hs-comment">-- SShape (SCons (SDim {sDimName = SName, sDimSize = SSize}) (SCons (SDim {sDimName = SName, sDimSize = SSize}) SNil))</span><span>
</span><span id="line-892"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SUncheckedShape $ [Dim &quot;batch&quot; 32, Dim &quot;feature&quot; 8]</span><span>
</span><span id="line-893"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sShape t</span><span>
</span><span id="line-894"></span><span>  </span><span class="hs-comment">-- SUncheckedShape [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-895"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SUncheckedName &quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SUncheckedName &quot;feature&quot; :&amp;: SSize @32 :|: SNil</span><span>
</span><span id="line-896"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sShape t</span><span>
</span><span id="line-897"></span><span>  </span><span class="hs-comment">-- SShape (SCons (SDim {sDimName = SUncheckedName &quot;batch&quot;, sDimSize = SUncheckedSize 32}) (SCons (SDim {sDimName = SUncheckedName &quot;feature&quot;, sDimSize = SSize}) SNil))</span><span>
</span><span id="line-898"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 8 :|: SNil</span><span>
</span><span id="line-899"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sShape t</span><span>
</span><span id="line-900"></span><span>  </span><span class="hs-comment">-- SShape (SCons (SDim {sDimName = SName, sDimSize = SUncheckedSize 32}) (SCons (SDim {sDimName = SName, sDimSize = SUncheckedSize 8}) SNil))</span><span>
</span><span id="line-901"></span><span>  </span><span id="sShape"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sShape"><span class="hs-identifier hs-type">sShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-902"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758277"><span class="annot"><a href="#local-6989586621679758277"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758276"><span class="annot"><a href="#local-6989586621679758276"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758275"><span class="annot"><a href="#local-6989586621679758275"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758274"><span class="annot"><a href="#local-6989586621679758274"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-903"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758277"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758276"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758275"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758274"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758289"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-904"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758289"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-905"></span><span>
</span><span id="line-906"></span><span>  </span><span class="hs-comment">-- | Returns the untyped shape of the input tensor.</span><span>
</span><span id="line-907"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-908"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' = sOnes (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)</span><span>
</span><span id="line-909"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil</span><span>
</span><span id="line-910"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; dims t</span><span>
</span><span id="line-911"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-912"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SUncheckedShape $ [Dim &quot;batch&quot; 32, Dim &quot;feature&quot; 8]</span><span>
</span><span id="line-913"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; dims t</span><span>
</span><span id="line-914"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-915"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SUncheckedName &quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SUncheckedName &quot;feature&quot; :&amp;: SSize @32 :|: SNil</span><span>
</span><span id="line-916"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; dims t</span><span>
</span><span id="line-917"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 32}]</span><span>
</span><span id="line-918"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 8 :|: SNil</span><span>
</span><span id="line-919"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; dims t</span><span>
</span><span id="line-920"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-921"></span><span>  </span><span id="dims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dims"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-922"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758272"><span class="annot"><a href="#local-6989586621679758272"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758271"><span class="annot"><a href="#local-6989586621679758271"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758270"><span class="annot"><a href="#local-6989586621679758270"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758269"><span class="annot"><a href="#local-6989586621679758269"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-923"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758272"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758271"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758270"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758269"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758289"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-924"></span><span>    </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span>
</span><span id="line-925"></span><span>  </span><span id="local-6989586621679757298"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dims"><span class="hs-identifier hs-var hs-var">dims</span></a></span><span> </span><span id="local-6989586621679757297"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757297"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Dim String Integer)
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim String Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(IsChecked String -&gt; String)
-&gt; (IsChecked Integer -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Dim String Integer
forall (p :: * -&gt; * -&gt; *) a b c d.
Bifunctor p =&gt;
(a -&gt; b) -&gt; (c -&gt; d) -&gt; p a c -&gt; p b d
</span><span class="hs-identifier hs-var">bimap</span></span><span> </span><span class="annot"><span class="annottext">IsChecked String -&gt; String
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">([Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim String Integer])
-&gt; (SShape shape -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; SShape shape
-&gt; [Dim String Integer]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked [Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; (SShape shape
    -&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)])
-&gt; SShape shape
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SShape shape
-&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)]
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; [Dim String Integer])
-&gt; SShape shape -&gt; [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sShape"><span class="hs-identifier hs-var">sShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757297"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-926"></span><span>
</span><span id="line-927"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757294"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-928"></span><span>  </span><span id="local-6989586621679757292"><span class="annot"><span class="annottext">sShape :: Tensor gradient layout device dataType 'UncheckedShape
-&gt; SShape 'UncheckedShape
</span><a href="#local-6989586621679757292"><span class="hs-identifier hs-var hs-var hs-var hs-var">sShape</span></a></span></span><span> </span><span id="local-6989586621679757291"><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679757291"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; SShape 'UncheckedShape
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedShape"><span class="hs-identifier hs-var">SUncheckedShape</span></a></span><span> </span><span class="annot"><span class="annottext">([Dim String Integer] -&gt; SShape 'UncheckedShape)
-&gt; (IO [Dim String Integer] -&gt; [Dim String Integer])
-&gt; IO [Dim String Integer]
-&gt; SShape 'UncheckedShape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IO [Dim String Integer] -&gt; [Dim String Integer]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO [Dim String Integer] -&gt; SShape 'UncheckedShape)
-&gt; IO [Dim String Integer] -&gt; SShape 'UncheckedShape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-929"></span><span>    </span><span id="local-6989586621679757289"><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679757289"><span class="hs-identifier hs-var">sizes</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray))
-&gt; Tensor gradient layout device dataType 'UncheckedShape
-&gt; IO [Integer]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_sizes</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679757291"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-930"></span><span>    </span><span class="annot"><span class="annottext">IO Bool
-&gt; IO [Dim String Integer]
-&gt; IO [Dim String Integer]
-&gt; IO [Dim String Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; m Bool -&gt; m a -&gt; m a -&gt; m a
</span><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier hs-var">ifM</span></a></span><span>
</span><span id="line-931"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout device dataType 'UncheckedShape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_has_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679757291"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-932"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-933"></span><span>          </span><span id="local-6989586621679757286"><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679757286"><span class="hs-identifier hs-var">names</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList))
-&gt; Tensor gradient layout device dataType 'UncheckedShape
-&gt; IO [String]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679757291"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-934"></span><span>          </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; IO [Dim String Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">([Dim String Integer] -&gt; IO [Dim String Integer])
-&gt; [Dim String Integer] -&gt; IO [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; Integer -&gt; Dim String Integer)
-&gt; [String] -&gt; [Integer] -&gt; [Dim String Integer]
forall a b c. (a -&gt; b -&gt; c) -&gt; [a] -&gt; [b] -&gt; [c]
</span><span class="hs-identifier hs-var">zipWith</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; Dim String Integer
forall name size. name -&gt; size -&gt; Dim name size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679757286"><span class="hs-identifier hs-var">names</span></a></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679757289"><span class="hs-identifier hs-var">sizes</span></a></span><span>
</span><span id="line-935"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-936"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; IO [Dim String Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">([Dim String Integer] -&gt; IO [Dim String Integer])
-&gt; [Dim String Integer] -&gt; IO [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; Dim String Integer
forall name size. name -&gt; size -&gt; Dim name size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Dim String Integer)
-&gt; [Integer] -&gt; [Dim String Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679757289"><span class="hs-identifier hs-var">sizes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-937"></span><span>
</span><span id="line-938"></span><span id="local-6989586621679757282"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757279"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757282"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757282"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-939"></span><span>  </span><span id="local-6989586621679757278"><span class="annot"><span class="annottext">sShape :: Tensor gradient layout device dataType ('Shape dims)
-&gt; SShape ('Shape dims)
</span><a href="#local-6989586621679757278"><span class="hs-identifier hs-var hs-var hs-var hs-var">sShape</span></a></span></span><span> </span><span id="local-6989586621679757277"><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679757277"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-940"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679757276"><span class="annot"><span class="annottext">sizes :: [Integer]
</span><a href="#local-6989586621679757276"><span class="hs-identifier hs-var hs-var">sizes</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-941"></span><span>          </span><span class="annot"><span class="annottext">IO [Integer] -&gt; [Integer]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO [Integer] -&gt; [Integer]) -&gt; IO [Integer] -&gt; [Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-942"></span><span>            </span><span class="annot"><span class="annottext">IO Bool -&gt; IO [Integer] -&gt; IO [Integer] -&gt; IO [Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; m Bool -&gt; m a -&gt; m a -&gt; m a
</span><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier hs-var">ifM</span></a></span><span>
</span><span id="line-943"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Bool) -&gt; IO Int -&gt; IO Bool
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor gradient layout device dataType ('Shape dims) -&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_dim</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679757277"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-944"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray))
-&gt; Tensor gradient layout device dataType ('Shape dims)
-&gt; IO [Integer]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_sizes</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679757277"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-945"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Integer] -&gt; IO [Integer]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-946"></span><span>        </span><span id="local-6989586621679757273"><span class="annot"><span class="annottext">names :: [String]
</span><a href="#local-6989586621679757273"><span class="hs-identifier hs-var hs-var">names</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-947"></span><span>          </span><span class="annot"><span class="annottext">IO [String] -&gt; [String]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO [String] -&gt; [String]) -&gt; IO [String] -&gt; [String]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-948"></span><span>            </span><span class="annot"><span class="annottext">IO Bool -&gt; IO [String] -&gt; IO [String] -&gt; IO [String]
forall (m :: * -&gt; *) a. Monad m =&gt; m Bool -&gt; m a -&gt; m a -&gt; m a
</span><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier hs-var">ifM</span></a></span><span>
</span><span id="line-949"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout device dataType ('Shape dims) -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_has_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679757277"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-950"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList))
-&gt; Tensor gradient layout device dataType ('Shape dims)
-&gt; IO [String]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679757277"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-951"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[String] -&gt; IO [String]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">([String] -&gt; IO [String]) -&gt; [String] -&gt; IO [String]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; String) -&gt; [Integer] -&gt; [String]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; String
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679757276"><span class="hs-identifier hs-var">sizes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-952"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SList dims -&gt; SShape ('Shape dims)
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList dims -&gt; SShape ('Shape dims))
-&gt; SList dims -&gt; SShape ('Shape dims)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[String] -&gt; [Integer] -&gt; SList dims
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SGetDims dims =&gt;
[String] -&gt; [Integer] -&gt; SList dims
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sDims"><span class="hs-identifier hs-var">sDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679757273"><span class="hs-identifier hs-var">names</span></a></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679757276"><span class="hs-identifier hs-var">sizes</span></a></span></span><span>
</span><span id="line-953"></span><span>
</span><span id="line-954"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-var">SGetDims</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758230"><span class="annot"><a href="#local-6989586621679758230"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-955"></span><span>  </span><span id="sDims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sDims"><span class="hs-identifier hs-type">sDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758230"><span class="hs-identifier hs-type">dims</span></a></span><span>
</span><span id="line-956"></span><span>
</span><span id="line-957"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-type">dimsError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758222"><span class="annot"><a href="#local-6989586621679758222"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="#local-6989586621679758222"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-958"></span><span id="dimsError"><span class="annot"><span class="annottext">dimsError :: a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-var hs-var">dimsError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; a
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; a) -&gt; String -&gt; a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The numbers of compile- and runtime dimensions are not the same. &quot;</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-959"></span><span>
</span><span id="line-960"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-type">dimNameError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758202"><span class="annot"><a href="#local-6989586621679758202"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758202"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-961"></span><span id="dimNameError"><span class="annot"><span class="annottext">dimNameError :: String -&gt; String -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-var hs-var">dimNameError</span></a></span></span><span> </span><span id="local-6989586621679757267"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757267"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679757266"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757266"><span class="hs-identifier hs-var">name'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-962"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; a
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; a) -&gt; String -&gt; a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-963"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The compile- and runtime dimension names are not the same, '&quot;</span></span><span>
</span><span id="line-964"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757267"><span class="hs-identifier hs-var">name</span></a></span><span>
</span><span id="line-965"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-966"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757266"><span class="hs-identifier hs-var">name'</span></a></span><span>
</span><span id="line-967"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;'. &quot;</span></span><span>
</span><span id="line-968"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-969"></span><span>
</span><span id="line-970"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-type">dimSizeError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758198"><span class="annot"><a href="#local-6989586621679758198"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679758197"><span class="annot"><a href="#local-6989586621679758197"><span class="hs-identifier hs-type">b</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679758198"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758198"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758198"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758197"><span class="hs-identifier hs-type">b</span></a></span><span>
</span><span id="line-971"></span><span id="dimSizeError"><span class="annot"><span class="annottext">dimSizeError :: a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-var hs-var">dimSizeError</span></a></span></span><span> </span><span id="local-6989586621679757264"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757264"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span id="local-6989586621679757263"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757263"><span class="hs-identifier hs-var">size'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-972"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; b
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; b) -&gt; String -&gt; b
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-973"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The compile- and runtime dimension sizes are not the same, '&quot;</span></span><span>
</span><span id="line-974"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757264"><span class="hs-identifier hs-var">size</span></a></span><span>
</span><span id="line-975"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-976"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757263"><span class="hs-identifier hs-var">size'</span></a></span><span>
</span><span id="line-977"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;'. &quot;</span></span><span>
</span><span id="line-978"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-979"></span><span>
</span><span id="line-980"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameSizeError"><span class="hs-identifier hs-type">dimNameSizeError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758194"><span class="annot"><a href="#local-6989586621679758194"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679758193"><span class="annot"><a href="#local-6989586621679758193"><span class="hs-identifier hs-type">b</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679758194"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758194"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758194"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758193"><span class="hs-identifier hs-type">b</span></a></span><span>
</span><span id="line-981"></span><span id="dimNameSizeError"><span class="annot"><span class="annottext">dimNameSizeError :: String -&gt; String -&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameSizeError"><span class="hs-identifier hs-var hs-var">dimNameSizeError</span></a></span></span><span> </span><span id="local-6989586621679757261"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757261"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679757260"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757260"><span class="hs-identifier hs-var">name'</span></a></span></span><span> </span><span id="local-6989586621679757259"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757259"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span id="local-6989586621679757258"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757258"><span class="hs-identifier hs-var">size'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-982"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; b
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; b) -&gt; String -&gt; b
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-983"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The compile- and runtime dimension names and sizes are not the same, '&quot;</span></span><span>
</span><span id="line-984"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757261"><span class="hs-identifier hs-var">name</span></a></span><span>
</span><span id="line-985"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-986"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757260"><span class="hs-identifier hs-var">name'</span></a></span><span>
</span><span id="line-987"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' and '&quot;</span></span><span>
</span><span id="line-988"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757259"><span class="hs-identifier hs-var">size</span></a></span><span>
</span><span id="line-989"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-990"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757258"><span class="hs-identifier hs-var">size'</span></a></span><span>
</span><span id="line-991"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;'. &quot;</span></span><span>
</span><span id="line-992"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-993"></span><span>
</span><span id="line-994"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-995"></span><span>  </span><span id="local-6989586621679757255"><span class="annot"><span class="annottext">sDims :: [String] -&gt; [Integer] -&gt; SList '[]
</span><a href="#local-6989586621679757255"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDims</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span>
</span><span id="line-996"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sDims"><span class="hs-identifier hs-var">sDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-var">dimsError</span></a></span><span>
</span><span id="line-997"></span><span>
</span><span id="line-998"></span><span id="local-6989586621679757252"><span id="local-6989586621679757253"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757253"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757252"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757253"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679757252"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-999"></span><span>  </span><span id="local-6989586621679757250"><span class="annot"><span class="annottext">sDims :: [String] -&gt; [Integer] -&gt; SList (dim : dims)
</span><a href="#local-6989586621679757250"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDims</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757249"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757249"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679757248"><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679757248"><span class="hs-identifier hs-var">names</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757247"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757247"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679757246"><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679757246"><span class="hs-identifier hs-var">sizes</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; SDim dim
forall (dim :: Dim (Name Symbol) (Size Nat)).
SGetDim dim =&gt;
String -&gt; Integer -&gt; SDim dim
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sDim"><span class="hs-identifier hs-var">sDim</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757249"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757247"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">SDim dim -&gt; SList dims -&gt; SList (dim : dims)
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">[String] -&gt; [Integer] -&gt; SList dims
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SGetDims dims =&gt;
[String] -&gt; [Integer] -&gt; SList dims
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sDims"><span class="hs-identifier hs-var">sDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679757248"><span class="hs-identifier hs-var">names</span></a></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679757246"><span class="hs-identifier hs-var">sizes</span></a></span><span>
</span><span id="line-1000"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sDims"><span class="hs-identifier hs-var">sDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SList (dim : dims)
forall a. a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-var">dimsError</span></a></span></span></span><span>
</span><span id="line-1001"></span><span>
</span><span id="line-1002"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDim"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-var">SGetDim</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758217"><span class="annot"><a href="#local-6989586621679758217"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1003"></span><span>  </span><span id="sDim"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sDim"><span class="hs-identifier hs-type">sDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758217"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-1004"></span><span>
</span><span id="line-1005"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedName"><span class="hs-identifier hs-type">UncheckedName</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1006"></span><span>  </span><span id="local-6989586621679757242"><span class="annot"><span class="annottext">sDim :: String -&gt; Integer -&gt; SDim ('Dim 'UncheckedName 'UncheckedSize)
</span><a href="#local-6989586621679757242"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDim</span></a></span></span><span> </span><span id="local-6989586621679757241"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757241"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679757240"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757240"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SName 'UncheckedName
-&gt; SSize 'UncheckedSize
-&gt; SDim ('Dim 'UncheckedName 'UncheckedSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">String -&gt; SName 'UncheckedName
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedName"><span class="hs-identifier hs-var">SUncheckedName</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757241"><span class="hs-identifier hs-var">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; SSize 'UncheckedSize
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedSize"><span class="hs-identifier hs-var">SUncheckedSize</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757240"><span class="hs-identifier hs-var">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1007"></span><span>
</span><span id="line-1008"></span><span id="local-6989586621679757236"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownSymbol</span></span><span> </span><span class="annot"><a href="#local-6989586621679757236"><span class="hs-identifier hs-type">name</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757236"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1009"></span><span>  </span><span id="local-6989586621679757234"><span class="annot"><span class="annottext">sDim :: String -&gt; Integer -&gt; SDim ('Dim ('Name name) 'UncheckedSize)
</span><a href="#local-6989586621679757234"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDim</span></a></span></span><span> </span><span id="local-6989586621679757233"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757233"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679757232"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757232"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Proxy name -&gt; String
forall (n :: Symbol) (proxy :: Symbol -&gt; *).
KnownSymbol n =&gt;
proxy n -&gt; String
</span><span class="hs-identifier hs-var">symbolVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy name -&gt; String) -&gt; Proxy name -&gt; String
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy name
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757236"><span class="hs-identifier hs-type">name</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-1010"></span><span>    </span><span id="local-6989586621679757231"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757231"><span class="hs-identifier hs-var">name'</span></a></span></span><span>
</span><span id="line-1011"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757233"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757231"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SName ('Name name)
-&gt; SSize 'UncheckedSize -&gt; SDim ('Dim ('Name name) 'UncheckedSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownSymbol name =&gt; SName ('Name name)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757236"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; SSize 'UncheckedSize
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedSize"><span class="hs-identifier hs-var">SUncheckedSize</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757232"><span class="hs-identifier hs-var">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1012"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; SDim ('Dim ('Name name) 'UncheckedSize)
forall a. String -&gt; String -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-var">dimNameError</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757233"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757231"><span class="hs-identifier hs-var">name'</span></a></span></span><span>
</span><span id="line-1013"></span><span>
</span><span id="line-1014"></span><span id="local-6989586621679757229"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679757229"><span class="hs-identifier hs-type">size</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedName"><span class="hs-identifier hs-type">UncheckedName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757229"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1015"></span><span>  </span><span id="local-6989586621679757227"><span class="annot"><span class="annottext">sDim :: String -&gt; Integer -&gt; SDim ('Dim 'UncheckedName ('Size size))
</span><a href="#local-6989586621679757227"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDim</span></a></span></span><span> </span><span id="local-6989586621679757226"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757226"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679757225"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757225"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Proxy size -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy size -&gt; Integer) -&gt; Proxy size -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy size
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757229"><span class="hs-identifier hs-type">size</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-1016"></span><span>    </span><span id="local-6989586621679757224"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757224"><span class="hs-identifier hs-var">size'</span></a></span></span><span>
</span><span id="line-1017"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757225"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757224"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SName 'UncheckedName
-&gt; SSize ('Size size) -&gt; SDim ('Dim 'UncheckedName ('Size size))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">String -&gt; SName 'UncheckedName
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedName"><span class="hs-identifier hs-var">SUncheckedName</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757226"><span class="hs-identifier hs-var">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat size =&gt; SSize ('Size size)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757229"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1018"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; SDim ('Dim 'UncheckedName ('Size size))
forall a b. Show a =&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-var">dimSizeError</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757225"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757224"><span class="hs-identifier hs-var">size'</span></a></span></span><span>
</span><span id="line-1019"></span><span>
</span><span id="line-1020"></span><span id="local-6989586621679757221"><span id="local-6989586621679757222"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownSymbol</span></span><span> </span><span class="annot"><a href="#local-6989586621679757222"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679757221"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757222"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757221"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1021"></span><span>  </span><span id="local-6989586621679757219"><span class="annot"><span class="annottext">sDim :: String -&gt; Integer -&gt; SDim ('Dim ('Name name) ('Size size))
</span><a href="#local-6989586621679757219"><span class="hs-identifier hs-var hs-var hs-var hs-var">sDim</span></a></span></span><span> </span><span id="local-6989586621679757218"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757218"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679757217"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757217"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy name -&gt; String
forall (n :: Symbol) (proxy :: Symbol -&gt; *).
KnownSymbol n =&gt;
proxy n -&gt; String
</span><span class="hs-identifier hs-var">symbolVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy name -&gt; String) -&gt; Proxy name -&gt; String
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy name
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757222"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Proxy size -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy size -&gt; Integer) -&gt; Proxy size -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy size
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757221"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-1022"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679757216"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757216"><span class="hs-identifier hs-var">name'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679757215"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757215"><span class="hs-identifier hs-var">size'</span></a></span></span><span class="hs-special">)</span><span>
</span><span id="line-1023"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757218"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757216"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757217"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757215"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SName ('Name name)
-&gt; SSize ('Size size) -&gt; SDim ('Dim ('Name name) ('Size size))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownSymbol name =&gt; SName ('Name name)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757222"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat size =&gt; SSize ('Size size)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757221"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1024"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757218"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">/=</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757216"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757217"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757215"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; SDim ('Dim ('Name name) ('Size size))
forall a. String -&gt; String -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-var">dimNameError</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757218"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757216"><span class="hs-identifier hs-var">name'</span></a></span><span>
</span><span id="line-1025"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757218"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757216"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757217"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">/=</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757215"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; SDim ('Dim ('Name name) ('Size size))
forall a b. Show a =&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-var">dimSizeError</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757217"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757215"><span class="hs-identifier hs-var">size'</span></a></span><span>
</span><span id="line-1026"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String
-&gt; String
-&gt; Integer
-&gt; Integer
-&gt; SDim ('Dim ('Name name) ('Size size))
forall a b. Show a =&gt; String -&gt; String -&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameSizeError"><span class="hs-identifier hs-var">dimNameSizeError</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757218"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679757216"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757217"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679757215"><span class="hs-identifier hs-var">size'</span></a></span></span></span><span>
</span><span id="line-1027"></span><span>
</span><span id="line-1028"></span><span class="hs-keyword">data</span><span> </span><span id="ShapeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-var">ShapeError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ShapeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-var">ShapeError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="seExpected"><span class="annot"><span class="annottext">ShapeError -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#seExpected"><span class="hs-identifier hs-var hs-var">seExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span id="seActual"><span class="annot"><span class="annottext">ShapeError -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#seActual"><span class="hs-identifier hs-var hs-var">seActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span class="hs-special">}</span><span>
</span><span id="line-1029"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757205"><span id="local-6989586621679757207"><span id="local-6989586621679757209"><span class="annot"><span class="annottext">Int -&gt; ShapeError -&gt; ShowS
[ShapeError] -&gt; ShowS
ShapeError -&gt; String
(Int -&gt; ShapeError -&gt; ShowS)
-&gt; (ShapeError -&gt; String)
-&gt; ([ShapeError] -&gt; ShowS)
-&gt; Show ShapeError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [ShapeError] -&gt; ShowS
$cshowList :: [ShapeError] -&gt; ShowS
show :: ShapeError -&gt; String
$cshow :: ShapeError -&gt; String
showsPrec :: Int -&gt; ShapeError -&gt; ShowS
$cshowsPrec :: Int -&gt; ShapeError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-1030"></span><span>
</span><span id="line-1031"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757199"><span id="local-6989586621679757201"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-type">ShapeError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1032"></span><span>  </span><span id="local-6989586621679757197"><span class="annot"><span class="annottext">displayException :: ShapeError -&gt; String
</span><a href="#local-6989586621679757197"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-type">ShapeError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679757195"><span id="local-6989586621679757196"><span class="annot"><span class="annottext">[Dim String Integer]
seActual :: [Dim String Integer]
seExpected :: [Dim String Integer]
seActual :: ShapeError -&gt; [Dim String Integer]
seExpected :: ShapeError -&gt; [Dim String Integer]
</span><a href="#local-6989586621679757195"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1033"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor does not have the shape `&quot;</span></span><span>
</span><span id="line-1034"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679757196"><span class="hs-identifier hs-var">seExpected</span></a></span><span>
</span><span id="line-1035"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-1036"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679757195"><span class="hs-identifier hs-var">seActual</span></a></span><span>
</span><span id="line-1037"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-1038"></span><span>
</span><span id="line-1039"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the shape 'shape'</span><span>
</span><span id="line-1040"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-1041"></span><span class="hs-comment">--</span><span>
</span><span id="line-1042"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the shape 'shape'.</span><span>
</span><span id="line-1043"></span><span class="hs-comment">-- If it is not, then the result will be 'Nothing'.</span><span>
</span><span id="line-1044"></span><span class="hs-comment">--</span><span>
</span><span id="line-1045"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-1046"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat) (SUncheckedShape [Dim &quot;batch&quot; 32, Dim &quot;feature&quot; 8])</span><span>
</span><span id="line-1047"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedShape (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil) t</span><span>
</span><span id="line-1048"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-1049"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-1050"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1051"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1052"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1053"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1054"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1055"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1056"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-1057"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1058"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedShape (SShape $ SUncheckedName &quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 8 :|: SNil) t</span><span>
</span><span id="line-1059"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-1060"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-1061"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1062"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1063"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1064"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1065"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1066"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1067"></span><span class="hs-comment">--           '[ 'Dim 'UncheckedName ('Size 32),</span><span>
</span><span id="line-1068"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) 'UncheckedSize])</span><span>
</span><span id="line-1069"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedShape (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 32 :|: SNil) t</span><span>
</span><span id="line-1070"></span><span class="hs-comment">-- *** Exception: ShapeError {seExpected = [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 32}], seActual = [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]}</span><span>
</span><span id="line-1071"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-type">sCheckedShape</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1072"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758174"><span class="annot"><a href="#local-6989586621679758174"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679758175"><span class="annot"><a href="#local-6989586621679758175"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679758173"><span class="annot"><a href="#local-6989586621679758173"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758172"><span class="annot"><a href="#local-6989586621679758172"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758171"><span class="annot"><a href="#local-6989586621679758171"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758170"><span class="annot"><a href="#local-6989586621679758170"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679758176"><span class="annot"><a href="#local-6989586621679758176"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1073"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758176"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758175"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1074"></span><span>  </span><span class="hs-comment">-- | shape</span><span>
</span><span id="line-1075"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758174"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1076"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1077"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758173"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758172"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758171"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758170"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758176"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1078"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-1079"></span><span>  </span><span class="annot"><a href="#local-6989586621679758175"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758173"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758172"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758171"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758170"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679758176"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758174"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679758174"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1080"></span><span id="sCheckedShape"><span class="annot"><span class="annottext">sCheckedShape :: SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var hs-var">sCheckedShape</span></a></span></span><span> </span><span id="local-6989586621679757193"><span class="annot"><span class="annottext">SShape shape'
</span><a href="#local-6989586621679757193"><span class="hs-identifier hs-var">shape'</span></a></span></span><span> </span><span id="local-6989586621679757192"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757192"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1081"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679757191"><span class="annot"><span class="annottext">f :: Sing a -&gt; [Dim String Integer]
</span><a href="#local-6989586621679757191"><span class="hs-identifier hs-var hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Dim String Integer)
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim String Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679757190"><span class="annot"><span class="annottext">IsChecked String
</span><a href="#local-6989586621679757190"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679757189"><span class="annot"><span class="annottext">IsChecked Integer
</span><a href="#local-6989586621679757189"><span class="hs-identifier hs-var">size</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; Dim String Integer
forall name size. name -&gt; size -&gt; Dim name size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IsChecked String -&gt; String
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">IsChecked String
</span><a href="#local-6989586621679757190"><span class="hs-identifier hs-var">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer
</span><a href="#local-6989586621679757189"><span class="hs-identifier hs-var">size</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">([Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim String Integer])
-&gt; (Sing a -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; Sing a
-&gt; [Dim String Integer]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked [Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; (Sing a
    -&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)])
-&gt; Sing a
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Sing a -&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)]
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span>
</span><span id="line-1082"></span><span>      </span><span id="local-6989586621679757188"><span class="annot"><span class="annottext">actualShape :: [Dim String Integer]
</span><a href="#local-6989586621679757188"><span class="hs-identifier hs-var hs-var">actualShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Sing shape -&gt; [Dim String Integer]
forall (a :: Shape [Dim (Name Symbol) (Size Nat)]).
Sing a -&gt; [Dim String Integer]
</span><a href="#local-6989586621679757191"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Sing shape -&gt; [Dim String Integer])
-&gt; Sing shape -&gt; [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sShape"><span class="hs-identifier hs-var">sShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757192"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-1083"></span><span>      </span><span id="local-6989586621679757187"><span class="annot"><span class="annottext">expectedShape :: [Dim String Integer]
</span><a href="#local-6989586621679757187"><span class="hs-identifier hs-var hs-var">expectedShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Sing shape' -&gt; [Dim String Integer]
forall (a :: Shape [Dim (Name Symbol) (Size Nat)]).
Sing a -&gt; [Dim String Integer]
</span><a href="#local-6989586621679757191"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">Sing shape'
SShape shape'
</span><a href="#local-6989586621679757193"><span class="hs-identifier hs-var">shape'</span></a></span><span>
</span><span id="line-1084"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679757188"><span class="hs-identifier hs-var">actualShape</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; [Dim String Integer] -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679757187"><span class="hs-identifier hs-var">expectedShape</span></a></span><span>
</span><span id="line-1085"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (Seq
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape') shape')
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   device
   dataType
   (Seq
      (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape') shape')
 -&gt; m (Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape')))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape'))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (Seq
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape') shape')
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape')))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757192"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-1086"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">ShapeError
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(ShapeError
 -&gt; m (Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape')))
-&gt; ShapeError
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; [Dim String Integer] -&gt; ShapeError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-var">ShapeError</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679757187"><span class="hs-identifier hs-var">expectedShape</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679757188"><span class="hs-identifier hs-var">actualShape</span></a></span><span>
</span><span id="line-1087"></span><span>
</span><span id="line-1088"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedShape"><span class="hs-identifier hs-type">checkedShape</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1089"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757185"><span class="annot"><a href="#local-6989586621679757185"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679757184"><span class="annot"><a href="#local-6989586621679757184"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679757183"><span class="annot"><a href="#local-6989586621679757183"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757182"><span class="annot"><a href="#local-6989586621679757182"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757181"><span class="annot"><a href="#local-6989586621679757181"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757180"><span class="annot"><a href="#local-6989586621679757180"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757179"><span class="annot"><a href="#local-6989586621679757179"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1090"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757185"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757179"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757184"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1091"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1092"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757183"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757182"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757181"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757180"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757179"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1093"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-1094"></span><span>  </span><span class="annot"><a href="#local-6989586621679757184"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757183"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757182"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757181"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757180"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757179"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757185"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757185"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1095"></span><span id="checkedShape"><span class="annot"><span class="annottext">checkedShape :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedShape"><span class="hs-identifier hs-var hs-var">checkedShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI shape' =&gt; Sing shape'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757185"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1096"></span><span>
</span><span id="line-1097"></span><span class="hs-comment">-- | Returns the input tensor but with the selected dimension replaces with 'UncheckedDim' as dimension type annotation.</span><span>
</span><span id="line-1098"></span><span class="hs-comment">-- The static information about the selected tensor dimension is thus erased.</span><span>
</span><span id="line-1099"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-1100"></span><span class="hs-comment">--</span><span>
</span><span id="line-1101"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1102"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDim @('SelectDim ('ByName &quot;batch&quot;)) t</span><span>
</span><span id="line-1103"></span><span class="hs-comment">-- uncheckedDim @('SelectDim ('ByName &quot;batch&quot;)) t</span><span>
</span><span id="line-1104"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1105"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1106"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1107"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1108"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1109"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1110"></span><span class="hs-comment">--           '[ 'Dim 'UncheckedName 'UncheckedSize,</span><span>
</span><span id="line-1111"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1112"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1113"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDim @('SelectDim ('ByIndex 1)) t</span><span>
</span><span id="line-1114"></span><span class="hs-comment">-- uncheckedDim @('SelectDim ('ByIndex 1)) t</span><span>
</span><span id="line-1115"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1116"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1117"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1118"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1119"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1120"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1121"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-1122"></span><span class="hs-comment">--              'Dim 'UncheckedName 'UncheckedSize])</span><span>
</span><span id="line-1123"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDim"><span class="hs-identifier hs-type">uncheckedDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1124"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757177"><span class="annot"><a href="#local-6989586621679757177"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span> </span><span id="local-6989586621679757176"><span class="annot"><a href="#local-6989586621679757176"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757175"><span class="annot"><a href="#local-6989586621679757175"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757174"><span class="annot"><a href="#local-6989586621679757174"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757173"><span class="annot"><a href="#local-6989586621679757173"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757172"><span class="annot"><a href="#local-6989586621679757172"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1125"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1126"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757176"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757175"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757174"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757173"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757172"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1127"></span><span>  </span><span class="hs-comment">-- | tensor with the selected dimensions unchecked</span><span>
</span><span id="line-1128"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757176"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757175"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757174"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757173"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier hs-type">ReplaceDimF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757177"><span class="hs-identifier hs-type">selectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757172"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedName"><span class="hs-identifier hs-type">UncheckedName</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1129"></span><span id="uncheckedDim"><span class="annot"><span class="annottext">uncheckedDim :: Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (ReplaceDimF selectDim shape ('Dim 'UncheckedName 'UncheckedSize))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDim"><span class="hs-identifier hs-var hs-var">uncheckedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (ReplaceDimF selectDim shape ('Dim 'UncheckedName 'UncheckedSize))
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-1130"></span><span>
</span><span id="line-1131"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedShape' as shape type annotation.</span><span>
</span><span id="line-1132"></span><span class="hs-comment">-- Any static information about the tensor's shape is thus erased.</span><span>
</span><span id="line-1133"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-1134"></span><span class="hs-comment">--</span><span>
</span><span id="line-1135"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1136"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedShape t</span><span>
</span><span id="line-1137"></span><span class="hs-comment">-- uncheckedShape t</span><span>
</span><span id="line-1138"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1139"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1140"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1141"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1142"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1143"></span><span class="hs-comment">--        'UncheckedShape</span><span>
</span><span id="line-1144"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedShape"><span class="hs-identifier hs-type">uncheckedShape</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1145"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757170"><span class="annot"><a href="#local-6989586621679757170"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757169"><span class="annot"><a href="#local-6989586621679757169"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757168"><span class="annot"><a href="#local-6989586621679757168"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757167"><span class="annot"><a href="#local-6989586621679757167"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757166"><span class="annot"><a href="#local-6989586621679757166"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1146"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1147"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757170"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757169"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757168"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757167"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757166"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1148"></span><span>  </span><span class="hs-comment">-- | tensor without checked shape</span><span>
</span><span id="line-1149"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757170"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757169"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757168"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757167"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-1150"></span><span id="uncheckedShape"><span class="annot"><span class="annottext">uncheckedShape :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType 'UncheckedShape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedShape"><span class="hs-identifier hs-var hs-var">uncheckedShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType 'UncheckedShape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-1151"></span><span>
</span><span id="line-1152"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-type">gitHubErrorMsg</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span>
</span><span id="line-1153"></span><span id="gitHubErrorMsg"><span class="annot"><span class="annottext">gitHubErrorMsg :: String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var hs-var">gitHubErrorMsg</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;Please open a ticket on GitHub.&quot;</span></span><span>
</span><span id="line-1154"></span><span>
</span><span id="line-1155"></span><span id="local-6989586621679758137"><span id="local-6989586621679758138"><span id="local-6989586621679758139"><span id="local-6989586621679758140"><span id="local-6989586621679758141"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#isContiguous"><span class="hs-identifier hs-type">isContiguous</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1156"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758141"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758140"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758139"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758138"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758137"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1157"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span></span></span></span></span></span><span>
</span><span id="line-1158"></span><span id="isContiguous"><span class="annot"><span class="annottext">isContiguous :: Tensor gradient layout device dataType shape -&gt; Bool
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#isContiguous"><span class="hs-identifier hs-var hs-var">isContiguous</span></a></span></span><span> </span><span id="local-6989586621679757164"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757164"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout device dataType shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_contiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757164"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1159"></span><span>
</span><span id="line-1160"></span><span id="local-6989586621679757158"><span id="local-6989586621679757159"><span id="local-6989586621679757160"><span id="local-6989586621679757161"><span id="local-6989586621679757162"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#contiguous"><span class="hs-identifier hs-type">contiguous</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1161"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757162"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757161"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757160"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757159"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757158"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1162"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757162"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757161"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757160"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757159"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757158"><span class="hs-identifier hs-type">shape</span></a></span></span></span></span></span></span><span>
</span><span id="line-1163"></span><span id="contiguous"><span class="annot"><span class="annottext">contiguous :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#contiguous"><span class="hs-identifier hs-var hs-var">contiguous</span></a></span></span><span> </span><span id="local-6989586621679757156"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757156"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_contiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757156"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1164"></span><span>
</span><span id="line-1165"></span><span id="local-6989586621679758090"><span id="local-6989586621679758091"><span id="local-6989586621679758092"><span id="local-6989586621679758093"><span id="local-6989586621679758094"><span id="local-6989586621679758095"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-type">withTensor</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758095"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758094"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758093"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758092"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758091"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Ptr</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="#local-6989586621679758090"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="#local-6989586621679758090"><span class="hs-identifier hs-type">a</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-1166"></span><span id="withTensor"><span class="annot"><span class="annottext">withTensor :: Tensor gradient layout device dataType shape
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-var hs-var">withTensor</span></a></span></span><span> </span><span id="local-6989586621679757153"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757153"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span id="local-6989586621679757152"><span class="annot"><span class="annottext">Ptr () -&gt; IO a
</span><a href="#local-6989586621679757152"><span class="hs-identifier hs-var">fn</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1167"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679757151"><span class="annot"><span class="annottext">contiguousTensor :: Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757151"><span class="hs-identifier hs-var hs-var">contiguousTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; Bool
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape -&gt; Bool
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#isContiguous"><span class="hs-identifier hs-var">isContiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757153"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757153"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#contiguous"><span class="hs-identifier hs-var">contiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757153"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1168"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO a) -&gt; IO a
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679757151"><span class="hs-identifier hs-var">contiguousTensor</span></a></span><span> </span><span class="annot"><span class="annottext">((ForeignPtr Tensor -&gt; IO a) -&gt; IO a)
-&gt; (ForeignPtr Tensor -&gt; IO a) -&gt; IO a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679757150"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757150"><span class="hs-identifier hs-var">ct</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; (Ptr Tensor -&gt; IO a) -&gt; IO a
forall a b. ForeignPtr a -&gt; (Ptr a -&gt; IO b) -&gt; IO b
</span><span class="hs-identifier hs-var">withForeignPtr</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679757150"><span class="hs-identifier hs-var">ct</span></a></span><span> </span><span class="annot"><span class="annottext">((Ptr Tensor -&gt; IO a) -&gt; IO a) -&gt; (Ptr Tensor -&gt; IO a) -&gt; IO a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Ptr Tensor -&gt; IO (Ptr ())
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">Unmanaged.tensor_data_ptr</span></a></span><span> </span><span class="annot"><span class="annottext">(Ptr Tensor -&gt; IO (Ptr ()))
-&gt; (Ptr () -&gt; IO a) -&gt; Ptr Tensor -&gt; IO a
forall (m :: * -&gt; *) a b c.
Monad m =&gt;
(a -&gt; m b) -&gt; (b -&gt; m c) -&gt; a -&gt; m c
</span><span class="hs-operator hs-var">&gt;=&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; IO a
</span><a href="#local-6989586621679757152"><span class="hs-identifier hs-var">fn</span></a></span><span>
</span><span id="line-1169"></span><span>
</span><span id="line-1170"></span><span class="hs-keyword">class</span><span> </span><span id="TensorLikeRaw"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-var">TensorLikeRaw</span></a></span></span><span> </span><span id="local-6989586621679758128"><span class="annot"><a href="#local-6989586621679758128"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1171"></span><span>  </span><span class="hs-comment">-- | Guesses outer dim.</span><span>
</span><span id="line-1172"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-1173"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; guessDim @[[Int]] $ pure [[1, 2], [3, 4], [5, 6]]</span><span>
</span><span id="line-1174"></span><span>  </span><span class="hs-comment">-- Just 3</span><span>
</span><span id="line-1175"></span><span>  </span><span id="guessDim"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDim"><span class="hs-identifier hs-type">guessDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1176"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1177"></span><span>    </span><span class="hs-comment">-- 'Nothing' if the data type wrapping 'a' is empty.</span><span>
</span><span id="line-1178"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679758128"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1179"></span><span>    </span><span class="hs-comment">-- | dimension</span><span>
</span><span id="line-1180"></span><span>    </span><span class="hs-comment">-- 'Nothing' if 'a' is a scalar.</span><span>
</span><span id="line-1181"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-1182"></span><span>
</span><span id="line-1183"></span><span>  </span><span class="hs-comment">-- | Guesses inner dims.</span><span>
</span><span id="line-1184"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-1185"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; guessInnerDims @[[Int]] $ pure [[1, 2], [3, 4], [5, 6]]</span><span>
</span><span id="line-1186"></span><span>  </span><span class="hs-comment">-- [2]</span><span>
</span><span id="line-1187"></span><span>  </span><span id="local-6989586621679758126"><span id="guessInnerDims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#guessInnerDims"><span class="hs-identifier hs-type">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1188"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758126"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1189"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1190"></span><span>    </span><span class="hs-comment">-- 'Nothing' if the data type wrapping 'a' is empty.</span><span>
</span><span id="line-1191"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679758128"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1192"></span><span>    </span><span class="hs-comment">-- | inner dimensions</span><span>
</span><span id="line-1193"></span><span>    </span><span class="annot"><a href="#local-6989586621679758126"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span></span><span>
</span><span id="line-1194"></span><span>
</span><span id="line-1195"></span><span>  </span><span class="hs-comment">-- | Reads a value from a tensor.</span><span>
</span><span id="line-1196"></span><span>  </span><span id="tensorPeekElemOff"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-type">tensorPeekElemOff</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1197"></span><span>    </span><span class="hs-comment">-- | pointer to tensor</span><span>
</span><span id="line-1198"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Ptr</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1199"></span><span>    </span><span class="hs-comment">-- | offset</span><span>
</span><span id="line-1200"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1201"></span><span>    </span><span class="hs-comment">-- | tensor dimensions</span><span>
</span><span id="line-1202"></span><span>    </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1203"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1204"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="#local-6989586621679758128"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1205"></span><span>
</span><span id="line-1206"></span><span>  </span><span class="hs-comment">-- | Writes a value to a tensor.</span><span>
</span><span id="line-1207"></span><span>  </span><span id="tensorPokeElemOff"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-type">tensorPokeElemOff</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1208"></span><span>    </span><span class="hs-comment">-- | pointer to tensor</span><span>
</span><span id="line-1209"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Ptr</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1210"></span><span>    </span><span class="hs-comment">-- | offset</span><span>
</span><span id="line-1211"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1212"></span><span>    </span><span class="hs-comment">-- | tensor dimensions</span><span>
</span><span id="line-1213"></span><span>    </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1214"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1215"></span><span>    </span><span class="annot"><a href="#local-6989586621679758128"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1216"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-1217"></span><span>
</span><span id="line-1218"></span><span class="hs-comment">-- | Guesses dims: concatenates 'guessDim' with 'guessInnerDims'.</span><span>
</span><span id="line-1219"></span><span class="hs-comment">--</span><span>
</span><span id="line-1220"></span><span class="hs-comment">-- &gt;&gt;&gt; guessDims @[[Int]] $ pure [[1, 2], [3, 4], [5, 6]]</span><span>
</span><span id="line-1221"></span><span class="hs-comment">-- [3,2]</span><span>
</span><span id="line-1222"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-type">guessDims</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758121"><span class="annot"><a href="#local-6989586621679758121"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679758120"><span class="annot"><a href="#local-6989586621679758120"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758121"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758120"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679758121"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758120"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-1223"></span><span id="guessDims"><span class="annot"><span class="annottext">guessDims :: Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var hs-var">guessDims</span></a></span></span><span> </span><span id="local-6989586621679757144"><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679757144"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757143"><span class="hs-identifier hs-var">outerDim</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; [Int]
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; [Int]) -&gt; m [Int] -&gt; m [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessInnerDims"><span class="hs-identifier hs-var">guessInnerDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679757144"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1224"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1225"></span><span>    </span><span id="local-6989586621679757143"><span class="annot"><span class="annottext">outerDim :: [Int]
</span><a href="#local-6989586621679757143"><span class="hs-identifier hs-var hs-var">outerDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; [Int]
forall a. Maybe a -&gt; [a]
</span><span class="hs-identifier hs-var">maybeToList</span></span><span> </span><span class="annot"><span class="annottext">(Maybe Int -&gt; [Int]) -&gt; Maybe Int -&gt; [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; Maybe Int
forall a. TensorLikeRaw a =&gt; Maybe a -&gt; Maybe Int
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDim"><span class="hs-identifier hs-var">guessDim</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679757144"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1226"></span><span>
</span><span id="line-1227"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-type">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758046"><span class="annot"><a href="#local-6989586621679758046"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679758045"><span class="annot"><a href="#local-6989586621679758045"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679758044"><span class="annot"><a href="#local-6989586621679758044"><span class="hs-identifier hs-type">b</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758046"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758045"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679758046"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758045"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758044"><span class="hs-identifier hs-type">b</span></a></span><span>
</span><span id="line-1228"></span><span id="unexpectedDimsError"><span class="annot"><span class="annottext">unexpectedDimsError :: [Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var hs-var">unexpectedDimsError</span></a></span></span><span> </span><span id="local-6989586621679757141"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757141"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679757140"><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679757140"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1229"></span><span>  </span><span id="local-6989586621679757139"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757139"><span class="hs-identifier hs-var">expected</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679757140"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1230"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; m b
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; m b) -&gt; String -&gt; m b
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;Expected shape to be &quot;</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757139"><span class="hs-identifier hs-var">expected</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; got: &quot;</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757141"><span class="hs-identifier hs-var">dims'</span></a></span><span>
</span><span id="line-1231"></span><span>
</span><span id="line-1232"></span><span class="hs-keyword">class</span><span> </span><span id="TensorLike"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-var">TensorLike</span></a></span></span><span> </span><span id="local-6989586621679758112"><span class="annot"><a href="#local-6989586621679758112"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758111"><span class="annot"><a href="#local-6989586621679758111"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679758110"><span class="annot"><a href="#local-6989586621679758110"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">|</span><span> </span><span class="annot"><a href="#local-6989586621679758112"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758110"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679758112"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679758111"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1233"></span><span>  </span><span class="hs-comment">-- | Creates a tensor from a 'TensorLike' value.</span><span>
</span><span id="line-1234"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-1235"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- sToTensor (SGradient SWithoutGradient) (SLayout SDense) (SDevice SCPU) ([(1, 2), (3, 4), (5, 6)] :: [(Int, Int)])</span><span>
</span><span id="line-1236"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t</span><span>
</span><span id="line-1237"></span><span>  </span><span class="hs-comment">-- Tensor Int64 [3,2] [[ 1,  2],</span><span>
</span><span id="line-1238"></span><span>  </span><span class="hs-comment">--                     [ 3,  4],</span><span>
</span><span id="line-1239"></span><span>  </span><span class="hs-comment">--                     [ 5,  6]]</span><span>
</span><span id="line-1240"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-1241"></span><span>  </span><span class="hs-comment">-- t :: Tensor</span><span>
</span><span id="line-1242"></span><span>  </span><span class="hs-comment">--        ('Gradient 'WithoutGradient)</span><span>
</span><span id="line-1243"></span><span>  </span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1244"></span><span>  </span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1245"></span><span>  </span><span class="hs-comment">--        ('DataType 'Int64)</span><span>
</span><span id="line-1246"></span><span>  </span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1247"></span><span>  </span><span class="hs-comment">--           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 2)])</span><span>
</span><span id="line-1248"></span><span>  </span><span id="sToTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-type">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1249"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758107"><span class="annot"><a href="#local-6989586621679758107"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758106"><span class="annot"><a href="#local-6989586621679758106"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758105"><span class="annot"><a href="#local-6989586621679758105"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758108"><span class="annot"><a href="#local-6989586621679758108"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1250"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758108"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1251"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758107"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1252"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758106"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1253"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758105"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1254"></span><span>    </span><span class="annot"><a href="#local-6989586621679758112"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1255"></span><span>    </span><span class="annot"><a href="#local-6989586621679758108"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758107"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758106"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758105"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758111"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758110"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1256"></span><span>
</span><span id="line-1257"></span><span>  </span><span class="hs-comment">-- | Creates a 'TensorLike' from a tensor.</span><span>
</span><span id="line-1258"></span><span>  </span><span id="fromTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensor"><span class="hs-identifier hs-type">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1259"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758081"><span class="annot"><a href="#local-6989586621679758081"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758080"><span class="annot"><a href="#local-6989586621679758080"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758079"><span class="annot"><a href="#local-6989586621679758079"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1260"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758081"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758080"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758079"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758111"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758110"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1261"></span><span>    </span><span class="annot"><a href="#local-6989586621679758112"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1262"></span><span>
</span><span id="line-1263"></span><span class="hs-comment">-- | Non-singleton version of 'sToTensor'.</span><span>
</span><span id="line-1264"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#toTensor"><span class="hs-identifier hs-type">toTensor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1265"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757135"><span class="annot"><a href="#local-6989586621679757135"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757134"><span class="annot"><a href="#local-6989586621679757134"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757133"><span class="annot"><a href="#local-6989586621679757133"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757132"><span class="annot"><a href="#local-6989586621679757132"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679757131"><span class="annot"><a href="#local-6989586621679757131"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span id="local-6989586621679757130"><span class="annot"><a href="#local-6989586621679757130"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span id="local-6989586621679757129"><span class="annot"><a href="#local-6989586621679757129"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1266"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757132"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757131"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757130"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1267"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757135"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1268"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757134"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1269"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757133"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1270"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757129"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1271"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1272"></span><span>  </span><span class="annot"><a href="#local-6989586621679757132"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1273"></span><span>  </span><span class="annot"><a href="#local-6989586621679757129"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757135"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757134"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757133"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757131"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757130"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1274"></span><span id="toTensor"><span class="annot"><span class="annottext">toTensor :: a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#toTensor"><span class="hs-identifier hs-var hs-var">toTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI gradient =&gt; Sing gradient
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757135"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI layout =&gt; Sing layout
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757134"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI device =&gt; Sing device
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757133"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1275"></span><span>
</span><span id="line-1276"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-type">sToTensorRaw</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1277"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758070"><span class="annot"><a href="#local-6989586621679758070"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758069"><span class="annot"><a href="#local-6989586621679758069"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758068"><span class="annot"><a href="#local-6989586621679758068"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758074"><span class="annot"><a href="#local-6989586621679758074"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679758073"><span class="annot"><a href="#local-6989586621679758073"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span id="local-6989586621679758072"><span class="annot"><a href="#local-6989586621679758072"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span id="local-6989586621679758071"><span class="annot"><a href="#local-6989586621679758071"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1278"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758074"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758073"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758072"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758074"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758073"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758071"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1279"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758070"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1280"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758069"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1281"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758068"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1282"></span><span>  </span><span class="annot"><a href="#local-6989586621679758074"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1283"></span><span>  </span><span class="annot"><a href="#local-6989586621679758071"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758070"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758069"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758068"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758073"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758072"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1284"></span><span id="sToTensorRaw"><span class="annot"><span class="annottext">sToTensorRaw :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var hs-var">sToTensorRaw</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier hs-type">Demoted'</span></a></span><span> </span><span id="local-6989586621679757127"><span class="annot"><a href="#local-6989586621679757127"><span class="hs-identifier hs-var">gradient'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier hs-type">Demoted'</span></a></span><span> </span><span id="local-6989586621679757126"><span class="annot"><a href="#local-6989586621679757126"><span class="hs-identifier hs-var">layout</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier hs-type">Demoted'</span></a></span><span> </span><span id="local-6989586621679757125"><span class="annot"><a href="#local-6989586621679757125"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679757124"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757124"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1285"></span><span>  </span><span id="local-6989586621679757123"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757123"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; Maybe a -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757124"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1286"></span><span>
</span><span id="line-1287"></span><span>  </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device ('DataType dType) ('Shape dims)
 -&gt; m (Tensor
         gradient layout device ('DataType dType) ('Shape dims)))
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1288"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType dType) ('Shape dims))
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType dType) ('Shape dims))
 -&gt; Tensor gradient layout device ('DataType dType) ('Shape dims))
-&gt; IO
     (Tensor gradient layout device ('DataType dType) ('Shape dims))
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1289"></span><span>      </span><span id="local-6989586621679757122"><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679757122"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Tensor gradient layout device ('DataType dType) ('Shape dims))
-&gt; IO (ForeignPtr Tensor)
-&gt; IO
     (Tensor gradient layout device ('DataType dType) ('Shape dims))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr IntArray
 -&gt; ForeignPtr TensorOptions -&gt; IO (ForeignPtr Tensor))
-&gt; [Int] -&gt; TensorOptions -&gt; IO (ForeignPtr Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr IntArray
-&gt; ForeignPtr TensorOptions -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.empty_lo</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757123"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">TensorOptions
</span><a href="#local-6989586621679757120"><span class="hs-identifier hs-var">opts</span></a></span><span>
</span><span id="line-1290"></span><span>      </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; (Ptr () -&gt; IO ()) -&gt; IO ()
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) a.
Tensor gradient layout device dataType shape
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-var">withTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679757122"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">((Ptr () -&gt; IO ()) -&gt; IO ()) -&gt; (Ptr () -&gt; IO ()) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679757119"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757119"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1291"></span><span>        </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757119"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757123"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679757124"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1292"></span><span>      </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; IO
     (Tensor gradient layout device ('DataType dType) ('Shape dims))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679757122"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1293"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1294"></span><span>    </span><span id="local-6989586621679757120"><span class="annot"><span class="annottext">opts :: TensorOptions
</span><a href="#local-6989586621679757120"><span class="hs-identifier hs-var hs-var">opts</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">RequiresGradient
-&gt; LayoutType -&gt; DeviceType Int16 -&gt; DType -&gt; TensorOptions
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorOptions"><span class="hs-identifier hs-var">tensorOptions</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679757127"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679757126"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679757125"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679757118"><span class="hs-identifier hs-var">dType'</span></a></span><span>
</span><span id="line-1295"></span><span>    </span><span id="local-6989586621679757118"><span class="annot"><span class="annottext">dType' :: DType
</span><a href="#local-6989586621679757118"><span class="hs-identifier hs-var hs-var">dType'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownDType dType =&gt; DType
forall (dType :: DType). KnownDType dType =&gt; DType
</span><a href="Torch.GraduallyTyped.DType.html#dTypeVal"><span class="hs-identifier hs-var">dTypeVal</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679758073"><span class="hs-identifier hs-type">dType</span></a></span><span>
</span><span id="line-1296"></span><span>
</span><span id="line-1297"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-type">fromTensorRaw</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1298"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679758061"><span class="annot"><a href="#local-6989586621679758061"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679758060"><span class="annot"><a href="#local-6989586621679758060"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679758059"><span class="annot"><a href="#local-6989586621679758059"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679758064"><span class="annot"><a href="#local-6989586621679758064"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679758063"><span class="annot"><a href="#local-6989586621679758063"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span id="local-6989586621679758062"><span class="annot"><a href="#local-6989586621679758062"><span class="hs-identifier hs-type">dims</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1299"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758064"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758063"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758062"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758064"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758062"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1300"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758061"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758060"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758059"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758063"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679758062"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1301"></span><span>  </span><span class="annot"><a href="#local-6989586621679758064"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1302"></span><span id="fromTensorRaw"><span class="annot"><span class="annottext">fromTensorRaw :: Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var hs-var">fromTensorRaw</span></a></span></span><span> </span><span id="local-6989586621679757116"><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679757116"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO a -&gt; a
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO a -&gt; a) -&gt; IO a -&gt; a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1303"></span><span>  </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) a.
Tensor gradient layout device dataType shape
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-var">withTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679757116"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">((Ptr () -&gt; IO a) -&gt; IO a) -&gt; (Ptr () -&gt; IO a) -&gt; IO a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679757115"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757115"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757115"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (Dim String Integer -&gt; Integer) -&gt; Dim String Integer -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim String Integer -&gt; Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim String Integer -&gt; Int) -&gt; [Dim String Integer] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape
-&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dims"><span class="hs-identifier hs-var">dims</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679757116"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1304"></span><span>
</span><span id="line-1305"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1306"></span><span>  </span><span id="local-6989586621679757110"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Bool
-&gt; m (Tensor gradient layout device ('DataType 'Bool) ('Shape '[]))
</span><a href="#local-6989586621679757110"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Bool
-&gt; m (Tensor gradient layout device ('DataType 'Bool) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1307"></span><span>  </span><span id="local-6989586621679757109"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Bool) ('Shape '[])
-&gt; Bool
</span><a href="#local-6989586621679757109"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Bool) ('Shape '[])
-&gt; Bool
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1308"></span><span>
</span><span id="line-1309"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1310"></span><span>  </span><span id="local-6989586621679757103"><span class="annot"><span class="annottext">guessDim :: Maybe Bool -&gt; Maybe Int
</span><a href="#local-6989586621679757103"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Bool -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1311"></span><span>
</span><span id="line-1312"></span><span>  </span><span id="local-6989586621679757102"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Bool -&gt; m [Int]
</span><a href="#local-6989586621679757102"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Bool -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Bool -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Bool -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall a. Monoid a =&gt; a
</span><span class="hs-identifier hs-var">mempty</span></span><span>
</span><span id="line-1313"></span><span>
</span><span id="line-1314"></span><span>  </span><span id="local-6989586621679757101"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Bool
</span><a href="#local-6989586621679757101"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679757100"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757100"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757099"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757099"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Word8 -&gt; Int -&gt; IO Word8
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Word8</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Word8
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757100"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757099"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">IO Word8 -&gt; (Word8 -&gt; Bool) -&gt; IO Bool
forall (f :: * -&gt; *) a b. Functor f =&gt; f a -&gt; (a -&gt; b) -&gt; f b
</span><span class="hs-operator hs-var">&lt;&amp;&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Word8 -&gt; Word8 -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Word8
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-1315"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757098"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757098"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Bool -&gt; IO Bool
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757098"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Bool
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1316"></span><span>
</span><span id="line-1317"></span><span>  </span><span id="local-6989586621679757097"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Bool -&gt; IO ()
</span><a href="#local-6989586621679757097"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679757096"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757096"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757095"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757095"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679757094"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679757094"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Word8 -&gt; Int -&gt; Word8 -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Word8</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Word8
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757096"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757095"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Bool -&gt; Word8
forall a. Num a =&gt; Bool -&gt; a
</span><span class="hs-identifier hs-var">fromBool</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679757094"><span class="hs-identifier hs-var">x</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1318"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757093"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757093"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679757092"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679757092"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Bool -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757093"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Bool -&gt; IO ()) -&gt; Maybe Bool -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Maybe Bool
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679757092"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1319"></span><span>
</span><span id="line-1320"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1321"></span><span>  </span><span id="local-6989586621679757089"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Int
-&gt; m (Tensor
        gradient layout device ('DataType 'Int64) ('Shape '[]))
</span><a href="#local-6989586621679757089"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Int
-&gt; m (Tensor
        gradient layout device ('DataType 'Int64) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1322"></span><span>  </span><span id="local-6989586621679757088"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Int64) ('Shape '[])
-&gt; Int
</span><a href="#local-6989586621679757088"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Int64) ('Shape '[])
-&gt; Int
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1323"></span><span>
</span><span id="line-1324"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1325"></span><span>  </span><span id="local-6989586621679757083"><span class="annot"><span class="annottext">guessDim :: Maybe Int -&gt; Maybe Int
</span><a href="#local-6989586621679757083"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Int -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1326"></span><span>
</span><span id="line-1327"></span><span>  </span><span id="local-6989586621679757082"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Int -&gt; m [Int]
</span><a href="#local-6989586621679757082"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Int -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Int -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Int -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1328"></span><span>
</span><span id="line-1329"></span><span>  </span><span id="local-6989586621679757081"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Int
</span><a href="#local-6989586621679757081"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679757080"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757080"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757079"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757079"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Int -&gt; Int -&gt; IO Int
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Int
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757080"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757079"><span class="hs-identifier hs-var">offset</span></a></span><span>
</span><span id="line-1330"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757078"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757078"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Int -&gt; IO Int
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757078"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1331"></span><span>
</span><span id="line-1332"></span><span>  </span><span id="local-6989586621679757077"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Int -&gt; IO ()
</span><a href="#local-6989586621679757077"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679757076"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757076"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757075"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757075"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679757074"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757074"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Int -&gt; Int -&gt; Int -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Int
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757076"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757075"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757074"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1333"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757073"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757073"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679757072"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757072"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Int -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757073"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Int -&gt; IO ()) -&gt; Maybe Int -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757072"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1334"></span><span>
</span><span id="line-1335"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-type">Float</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1336"></span><span>  </span><span id="local-6989586621679757069"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Float
-&gt; m (Tensor
        gradient layout device ('DataType 'Float) ('Shape '[]))
</span><a href="#local-6989586621679757069"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Float
-&gt; m (Tensor
        gradient layout device ('DataType 'Float) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1337"></span><span>  </span><span id="local-6989586621679757068"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Float) ('Shape '[])
-&gt; Float
</span><a href="#local-6989586621679757068"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Float) ('Shape '[])
-&gt; Float
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1338"></span><span>
</span><span id="line-1339"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1340"></span><span>  </span><span id="local-6989586621679757063"><span class="annot"><span class="annottext">guessDim :: Maybe Float -&gt; Maybe Int
</span><a href="#local-6989586621679757063"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Float -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1341"></span><span>
</span><span id="line-1342"></span><span>  </span><span id="local-6989586621679757062"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Float -&gt; m [Int]
</span><a href="#local-6989586621679757062"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Float -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Float -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Float -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1343"></span><span>
</span><span id="line-1344"></span><span>  </span><span id="local-6989586621679757061"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Float
</span><a href="#local-6989586621679757061"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679757060"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757060"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757059"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757059"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Float -&gt; Int -&gt; IO Float
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Float
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757060"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757059"><span class="hs-identifier hs-var">offset</span></a></span><span>
</span><span id="line-1345"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757058"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757058"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Float -&gt; IO Float
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757058"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Float
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1346"></span><span>
</span><span id="line-1347"></span><span>  </span><span id="local-6989586621679757057"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Float -&gt; IO ()
</span><a href="#local-6989586621679757057"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679757056"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757056"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757055"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757055"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679757054"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679757054"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Float -&gt; Int -&gt; Float -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Float
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757056"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757055"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679757054"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1348"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757053"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757053"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679757052"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679757052"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Float -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757053"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Float -&gt; IO ()) -&gt; Maybe Float -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Maybe Float
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679757052"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1349"></span><span>
</span><span id="line-1350"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Double"><span class="hs-identifier hs-type">Double</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1351"></span><span>  </span><span id="local-6989586621679757049"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Double
-&gt; m (Tensor
        gradient layout device ('DataType 'Double) ('Shape '[]))
</span><a href="#local-6989586621679757049"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Double
-&gt; m (Tensor
        gradient layout device ('DataType 'Double) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1352"></span><span>  </span><span id="local-6989586621679757048"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Double) ('Shape '[])
-&gt; Double
</span><a href="#local-6989586621679757048"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Double) ('Shape '[])
-&gt; Double
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1353"></span><span>
</span><span id="line-1354"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1355"></span><span>  </span><span id="local-6989586621679757043"><span class="annot"><span class="annottext">guessDim :: Maybe Double -&gt; Maybe Int
</span><a href="#local-6989586621679757043"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Double -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1356"></span><span>
</span><span id="line-1357"></span><span>  </span><span id="local-6989586621679757042"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Double -&gt; m [Int]
</span><a href="#local-6989586621679757042"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Double -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Double -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Double -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1358"></span><span>
</span><span id="line-1359"></span><span>  </span><span id="local-6989586621679757041"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Double
</span><a href="#local-6989586621679757041"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679757040"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757040"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757039"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757039"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Double -&gt; Int -&gt; IO Double
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Double
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757040"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757039"><span class="hs-identifier hs-var">offset</span></a></span><span>
</span><span id="line-1360"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757038"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757038"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Double -&gt; IO Double
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757038"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Double
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1361"></span><span>
</span><span id="line-1362"></span><span>  </span><span id="local-6989586621679757037"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Double -&gt; IO ()
</span><a href="#local-6989586621679757037"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679757036"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757036"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679757035"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757035"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679757034"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679757034"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Double -&gt; Int -&gt; Double -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Double
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679757036"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679757035"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679757034"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1363"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679757033"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757033"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679757032"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679757032"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Double -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757033"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Double -&gt; IO ()) -&gt; Maybe Double -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Maybe Double
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679757032"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1364"></span><span>
</span><span id="line-1365"></span><span class="hs-keyword">data</span><span> </span><span id="DimMismatchError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-var">DimMismatchError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="DimMismatchError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-var">DimMismatchError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="dmeFirst"><span class="annot"><span class="annottext">DimMismatchError -&gt; [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dmeFirst"><span class="hs-identifier hs-var hs-var">dmeFirst</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span id="dmeOther"><span class="annot"><span class="annottext">DimMismatchError -&gt; [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dmeOther"><span class="hs-identifier hs-var hs-var">dmeOther</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">}</span><span>
</span><span id="line-1366"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679757023"><span id="local-6989586621679757025"><span id="local-6989586621679757027"><span class="annot"><span class="annottext">Int -&gt; DimMismatchError -&gt; ShowS
[DimMismatchError] -&gt; ShowS
DimMismatchError -&gt; String
(Int -&gt; DimMismatchError -&gt; ShowS)
-&gt; (DimMismatchError -&gt; String)
-&gt; ([DimMismatchError] -&gt; ShowS)
-&gt; Show DimMismatchError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [DimMismatchError] -&gt; ShowS
$cshowList :: [DimMismatchError] -&gt; ShowS
show :: DimMismatchError -&gt; String
$cshow :: DimMismatchError -&gt; String
showsPrec :: Int -&gt; DimMismatchError -&gt; ShowS
$cshowsPrec :: Int -&gt; DimMismatchError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679757019"><span id="local-6989586621679757021"><span class="annot"><span class="annottext">DimMismatchError -&gt; DimMismatchError -&gt; Bool
(DimMismatchError -&gt; DimMismatchError -&gt; Bool)
-&gt; (DimMismatchError -&gt; DimMismatchError -&gt; Bool)
-&gt; Eq DimMismatchError
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
$c/= :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
== :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
$c== :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-1367"></span><span>
</span><span id="line-1368"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679757012"><span id="local-6989586621679757014"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-type">DimMismatchError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1369"></span><span>  </span><span id="local-6989586621679757010"><span class="annot"><span class="annottext">displayException :: DimMismatchError -&gt; String
</span><a href="#local-6989586621679757010"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-type">DimMismatchError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679757008"><span id="local-6989586621679757009"><span class="annot"><span class="annottext">[Int]
dmeOther :: [Int]
dmeFirst :: [Int]
dmeOther :: DimMismatchError -&gt; [Int]
dmeFirst :: DimMismatchError -&gt; [Int]
</span><a href="#local-6989586621679757008"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1370"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;When converting to a tensor, all elements on the same dimension must have the same shape, &quot;</span></span><span>
</span><span id="line-1371"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;but the first element has shape &quot;</span></span><span>
</span><span id="line-1372"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757009"><span class="hs-identifier hs-var">dmeFirst</span></a></span><span>
</span><span id="line-1373"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; while another element has shape &quot;</span></span><span>
</span><span id="line-1374"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757008"><span class="hs-identifier hs-var">dmeOther</span></a></span><span>
</span><span id="line-1375"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;.&quot;</span></span><span>
</span><span id="line-1376"></span><span>
</span><span id="line-1377"></span><span id="local-6989586621679757992"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-type">checkDims</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757992"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679757992"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-1378"></span><span id="checkDims"><span class="annot"><span class="annottext">checkDims :: [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var hs-var">checkDims</span></a></span></span><span> </span><span id="local-6989586621679757006"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757006"><span class="hs-identifier hs-var">firstDims</span></a></span></span><span> </span><span id="local-6989586621679757005"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757005"><span class="hs-identifier hs-var">otherDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; m () -&gt; m ()
forall (f :: * -&gt; *). Applicative f =&gt; Bool -&gt; f () -&gt; f ()
</span><span class="hs-identifier hs-var">when</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757006"><span class="hs-identifier hs-var">firstDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">/=</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757005"><span class="hs-identifier hs-var">otherDims</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(m () -&gt; m ()) -&gt; m () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DimMismatchError -&gt; m ()
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(DimMismatchError -&gt; m ()) -&gt; DimMismatchError -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; DimMismatchError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-var">DimMismatchError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757006"><span class="hs-identifier hs-var">firstDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679757005"><span class="hs-identifier hs-var">otherDims</span></a></span><span>
</span><span id="line-1379"></span><span>
</span><span id="line-1380"></span><span id="local-6989586621679756999"><span id="local-6989586621679757000"><span id="local-6989586621679757001"><span id="local-6989586621679757002"><span id="local-6989586621679757003"><span id="local-6989586621679757004"><span class="hs-keyword">instance</span><span>
</span><span id="line-1381"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757004"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757003"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757002"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1382"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757001"><span class="hs-identifier hs-type">b</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757003"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757000"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1383"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757004"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1384"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757001"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1385"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757003"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1386"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756999"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1387"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756999"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757002"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757000"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1388"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1389"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679757004"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679757001"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679757003"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756999"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1390"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1391"></span><span>  </span><span id="local-6989586621679756996"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; (a, b)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679756996"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; (a, b)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1392"></span><span>  </span><span id="local-6989586621679756995"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; (a, b)
</span><a href="#local-6989586621679756995"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; (a, b)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-1393"></span><span>
</span><span id="line-1394"></span><span id="local-6989586621679756993"><span id="local-6989586621679756994"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756994"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756993"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679756994"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679756993"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1395"></span><span>  </span><span id="local-6989586621679756988"><span class="annot"><span class="annottext">guessDim :: Maybe (a, b) -&gt; Maybe Int
</span><a href="#local-6989586621679756988"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe (a, b) -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(Maybe Int -&gt; Maybe (a, b) -&gt; Maybe Int)
-&gt; Maybe Int -&gt; Maybe (a, b) -&gt; Maybe Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-1396"></span><span>
</span><span id="line-1397"></span><span>  </span><span id="local-6989586621679756987"><span class="annot"><span class="annottext">guessInnerDims :: Maybe (a, b) -&gt; m [Int]
</span><a href="#local-6989586621679756987"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Maybe (a, b) -&gt; (Maybe a, Maybe b)
forall (f :: * -&gt; *) a b. Functor f =&gt; f (a, b) -&gt; (f a, f b)
</span><span class="hs-identifier hs-var">unzip</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756986"><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679756986"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679756985"><span class="annot"><span class="annottext">Maybe b
</span><a href="#local-6989586621679756985"><span class="hs-identifier hs-var">y</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1398"></span><span>    </span><span id="local-6989586621679756984"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756984"><span class="hs-identifier hs-var">xDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679756986"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1399"></span><span>    </span><span id="local-6989586621679756983"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756983"><span class="hs-identifier hs-var">yDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe b -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe b
</span><a href="#local-6989586621679756985"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-1400"></span><span>    </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; m ()
forall (m :: * -&gt; *). MonadThrow m =&gt; [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var">checkDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756984"><span class="hs-identifier hs-var">xDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756983"><span class="hs-identifier hs-var">yDims</span></a></span><span>
</span><span id="line-1401"></span><span>    </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756984"><span class="hs-identifier hs-var">xDims</span></a></span><span>
</span><span id="line-1402"></span><span>
</span><span id="line-1403"></span><span>  </span><span id="local-6989586621679756982"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO (a, b)
</span><a href="#local-6989586621679756982"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679756981"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756981"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756980"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756980"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679756979"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756979"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1404"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span>
</span><span id="line-1405"></span><span>      </span><span class="annot"><span class="annottext">(a -&gt; b -&gt; (a, b)) -&gt; IO a -&gt; IO (b -&gt; (a, b))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756981"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756980"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756979"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1406"></span><span>      </span><span class="annot"><span class="annottext">IO (b -&gt; (a, b)) -&gt; IO b -&gt; IO (a, b)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO b
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756981"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756980"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756978"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756979"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1407"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1408"></span><span>      </span><span id="local-6989586621679756978"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679756978"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756979"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1409"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679756976"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756976"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (a, b) -&gt; IO (a, b)
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679756994"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679756993"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756976"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (a, b)
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1410"></span><span>
</span><span id="line-1411"></span><span>  </span><span id="local-6989586621679756975"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; (a, b) -&gt; IO ()
</span><a href="#local-6989586621679756975"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679756974"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756974"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756973"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756973"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679756972"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756972"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756971"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756971"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679756970"><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679756970"><span class="hs-identifier hs-var">y</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1412"></span><span>    </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756974"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756973"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756972"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756971"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1413"></span><span>    </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; b -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756974"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756973"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756969"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756972"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679756970"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-1414"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1415"></span><span>      </span><span id="local-6989586621679756969"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679756969"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756972"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1416"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679756968"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756968"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679756967"><span class="annot"><span class="annottext">(a, b)
</span><a href="#local-6989586621679756967"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (a, b) -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756968"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe (a, b) -&gt; IO ()) -&gt; Maybe (a, b) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(a, b) -&gt; Maybe (a, b)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(a, b)
</span><a href="#local-6989586621679756967"><span class="hs-identifier hs-var">x</span></a></span></span></span><span>
</span><span id="line-1417"></span><span>
</span><span id="line-1418"></span><span id="local-6989586621679756963"><span id="local-6989586621679756964"><span id="local-6989586621679756965"><span id="local-6989586621679756966"><span class="hs-keyword">instance</span><span>
</span><span id="line-1419"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756966"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756965"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756964"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1420"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756966"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1421"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756965"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1422"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756963"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1423"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756963"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756964"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1424"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1425"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679756966"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679756965"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756963"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1426"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1427"></span><span>  </span><span id="local-6989586621679756960"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; [a]
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679756960"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; [a]
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1428"></span><span>  </span><span id="local-6989586621679756959"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; [a]
</span><a href="#local-6989586621679756959"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; [a]
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span><span>
</span><span id="line-1429"></span><span>
</span><span id="line-1430"></span><span id="local-6989586621679756958"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756958"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679756958"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1431"></span><span>  </span><span id="local-6989586621679756953"><span class="annot"><span class="annottext">guessDim :: Maybe [a] -&gt; Maybe Int
</span><a href="#local-6989586621679756953"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Maybe Int) -&gt; (Maybe [a] -&gt; Int) -&gt; Maybe [a] -&gt; Maybe Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; ([a] -&gt; Int) -&gt; Maybe [a] -&gt; Int
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><span class="hs-identifier hs-var">maybe</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span>
</span><span id="line-1432"></span><span>
</span><span id="line-1433"></span><span>  </span><span id="local-6989586621679756950"><span class="annot"><span class="annottext">guessInnerDims :: Maybe [a] -&gt; m [Int]
</span><a href="#local-6989586621679756950"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1434"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Maybe [a] -&gt; ([a] -&gt; Maybe (NonEmpty a)) -&gt; Maybe (NonEmpty a)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Maybe (NonEmpty a)
forall a. [a] -&gt; Maybe (NonEmpty a)
</span><span class="hs-identifier hs-var">nonEmpty</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Maybe [a] -&gt; Maybe (NonEmpty a))
-&gt; (Maybe (NonEmpty a) -&gt; m [Int]) -&gt; Maybe [a] -&gt; m [Int]
forall k (cat :: k -&gt; k -&gt; *) (a :: k) (b :: k) (c :: k).
Category cat =&gt;
cat a b -&gt; cat b c -&gt; cat a c
</span><span class="hs-operator hs-var">&gt;&gt;&gt;</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-1435"></span><span>      </span><span class="annot"><span class="annottext">Maybe (NonEmpty a)
</span><span class="hs-identifier hs-var">Nothing</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679756958"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1436"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756949"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756949"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="annot"><span class="hs-operator hs-type">:|</span></span><span> </span><span id="local-6989586621679756948"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679756948"><span class="hs-identifier hs-var">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1437"></span><span>        </span><span id="local-6989586621679756947"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756947"><span class="hs-identifier hs-var">xDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; Maybe a -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756949"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1438"></span><span>        </span><span class="annot"><span class="annottext">(a -&gt; m ()) -&gt; [a] -&gt; m ()
forall (t :: * -&gt; *) (f :: * -&gt; *) a b.
(Foldable t, Applicative f) =&gt;
(a -&gt; f b) -&gt; t a -&gt; f ()
</span><span class="hs-identifier hs-var">traverse_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; m ()
forall (m :: * -&gt; *). MonadThrow m =&gt; [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var">checkDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756947"><span class="hs-identifier hs-var">xDims</span></a></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; m ()) -&gt; (a -&gt; m [Int]) -&gt; a -&gt; m ()
forall (m :: * -&gt; *) b c a.
Monad m =&gt;
(b -&gt; m c) -&gt; (a -&gt; m b) -&gt; a -&gt; m c
</span><span class="hs-operator hs-var">&lt;=&lt;</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; (a -&gt; Maybe a) -&gt; a -&gt; m [Int]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679756948"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-1439"></span><span>        </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756947"><span class="hs-identifier hs-var">xDims</span></a></span><span>
</span><span id="line-1440"></span><span>
</span><span id="line-1441"></span><span>  </span><span id="local-6989586621679756946"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO [a]
</span><a href="#local-6989586621679756946"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679756945"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756945"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756944"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756944"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756943"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756943"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679756942"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756942"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1442"></span><span>    </span><span class="annot"><span class="annottext">[Int] -&gt; (Int -&gt; IO a) -&gt; IO [a]
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m (t b)
</span><span class="hs-identifier hs-var">forM</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756943"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">((Int -&gt; IO a) -&gt; IO [a]) -&gt; (Int -&gt; IO a) -&gt; IO [a]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679756941"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756941"><span class="hs-identifier hs-var">i</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1443"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756945"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756944"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756941"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756940"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756942"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1444"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1445"></span><span>      </span><span id="local-6989586621679756940"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679756940"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756942"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1446"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679756939"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756939"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe [a] -&gt; IO [a]
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679756958"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756939"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe [a]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1447"></span><span>
</span><span id="line-1448"></span><span>  </span><span id="local-6989586621679756938"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; [a] -&gt; IO ()
</span><a href="#local-6989586621679756938"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679756937"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756937"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756936"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756936"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756935"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756935"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679756934"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756934"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679756933"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679756933"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1449"></span><span>    </span><span class="annot"><span class="annottext">[(Int, a)] -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Foldable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m ()
</span><span class="hs-identifier hs-var">forM_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; [a] -&gt; [(Int, a)]
forall a b. [a] -&gt; [b] -&gt; [(a, b)]
</span><span class="hs-identifier hs-var">zip</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756935"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679756933"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(((Int, a) -&gt; IO ()) -&gt; IO ()) -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679756932"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756932"><span class="hs-identifier hs-var">i</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679756931"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756931"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1450"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756937"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756936"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756932"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756930"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756934"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756931"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1451"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1452"></span><span>      </span><span id="local-6989586621679756930"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679756930"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756934"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1453"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679756929"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756929"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679756928"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679756928"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe [a] -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756929"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe [a] -&gt; IO ()) -&gt; Maybe [a] -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Maybe [a]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679756928"><span class="hs-identifier hs-var">x</span></a></span></span><span>
</span><span id="line-1454"></span><span>
</span><span id="line-1455"></span><span id="local-6989586621679756924"><span id="local-6989586621679756925"><span id="local-6989586621679756926"><span id="local-6989586621679756927"><span class="hs-keyword">instance</span><span>
</span><span id="line-1456"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756927"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756926"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756925"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1457"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756927"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1458"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756926"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1459"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756924"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1460"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756924"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756925"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1461"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1462"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-type">V.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756927"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679756926"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756924"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1463"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1464"></span><span>  </span><span id="local-6989586621679756921"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679756921"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1465"></span><span>  </span><span id="local-6989586621679756920"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector a
</span><a href="#local-6989586621679756920"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector a
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span><span>
</span><span id="line-1466"></span><span>
</span><span id="line-1467"></span><span id="local-6989586621679756919"><span class="hs-keyword">instance</span><span>
</span><span id="line-1468"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756919"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1469"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-type">V.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756919"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1470"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1471"></span><span>  </span><span id="local-6989586621679756914"><span class="annot"><span class="annottext">guessDim :: Maybe (Vector a) -&gt; Maybe Int
</span><a href="#local-6989586621679756914"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Maybe Int)
-&gt; (Maybe (Vector a) -&gt; Int) -&gt; Maybe (Vector a) -&gt; Maybe Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; (Vector a -&gt; Int) -&gt; Maybe (Vector a) -&gt; Int
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><span class="hs-identifier hs-var">maybe</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span>
</span><span id="line-1472"></span><span>
</span><span id="line-1473"></span><span>  </span><span id="local-6989586621679756913"><span class="annot"><span class="annottext">guessInnerDims :: Maybe (Vector a) -&gt; m [Int]
</span><a href="#local-6989586621679756913"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1474"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Maybe (Vector a)
-&gt; (Vector a -&gt; Maybe (a, Vector a)) -&gt; Maybe (a, Vector a)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Maybe (a, Vector a)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.uncons</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Maybe (Vector a) -&gt; Maybe (a, Vector a))
-&gt; (Maybe (a, Vector a) -&gt; m [Int]) -&gt; Maybe (Vector a) -&gt; m [Int]
forall k (cat :: k -&gt; k -&gt; *) (a :: k) (b :: k) (c :: k).
Category cat =&gt;
cat a b -&gt; cat b c -&gt; cat a c
</span><span class="hs-operator hs-var">&gt;&gt;&gt;</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-1475"></span><span>      </span><span class="annot"><span class="annottext">Maybe (a, Vector a)
</span><span class="hs-identifier hs-var">Nothing</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679756919"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1476"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756911"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756911"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679756910"><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679756910"><span class="hs-identifier hs-var">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1477"></span><span>        </span><span id="local-6989586621679756909"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756909"><span class="hs-identifier hs-var">xDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; Maybe a -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756911"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1478"></span><span>        </span><span class="annot"><span class="annottext">(a -&gt; m ()) -&gt; Vector a -&gt; m ()
forall (t :: * -&gt; *) (f :: * -&gt; *) a b.
(Foldable t, Applicative f) =&gt;
(a -&gt; f b) -&gt; t a -&gt; f ()
</span><span class="hs-identifier hs-var">traverse_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; m ()
forall (m :: * -&gt; *). MonadThrow m =&gt; [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var">checkDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756909"><span class="hs-identifier hs-var">xDims</span></a></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; m ()) -&gt; (a -&gt; m [Int]) -&gt; a -&gt; m ()
forall (m :: * -&gt; *) b c a.
Monad m =&gt;
(b -&gt; m c) -&gt; (a -&gt; m b) -&gt; a -&gt; m c
</span><span class="hs-operator hs-var">&lt;=&lt;</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; (a -&gt; Maybe a) -&gt; a -&gt; m [Int]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679756910"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-1479"></span><span>        </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756909"><span class="hs-identifier hs-var">xDims</span></a></span><span>
</span><span id="line-1480"></span><span>
</span><span id="line-1481"></span><span>  </span><span id="local-6989586621679756908"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO (Vector a)
</span><a href="#local-6989586621679756908"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679756907"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756907"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756906"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756906"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756905"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756905"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679756904"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756904"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1482"></span><span>    </span><span class="annot"><span class="annottext">Vector Int -&gt; (Int -&gt; IO a) -&gt; IO (Vector a)
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m (t b)
</span><span class="hs-identifier hs-var">forM</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Vector Int
forall a. Enum a =&gt; a -&gt; a -&gt; Vector a
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.enumFromTo</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756905"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Int -&gt; IO a) -&gt; IO (Vector a)) -&gt; (Int -&gt; IO a) -&gt; IO (Vector a)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679756902"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756902"><span class="hs-identifier hs-var">i</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1483"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756907"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756906"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756902"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756901"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756904"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1484"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1485"></span><span>      </span><span id="local-6989586621679756901"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679756901"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756904"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1486"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679756900"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756900"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (Vector a) -&gt; IO (Vector a)
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-type">V.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756919"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756900"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Vector a)
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1487"></span><span>
</span><span id="line-1488"></span><span>  </span><span id="local-6989586621679756899"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Vector a -&gt; IO ()
</span><a href="#local-6989586621679756899"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679756898"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756898"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756897"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756897"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679756896"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756896"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679756895"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756895"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679756894"><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679756894"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1489"></span><span>    </span><span class="annot"><span class="annottext">Vector (Int, a) -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Foldable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m ()
</span><span class="hs-identifier hs-var">forM_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Vector Int -&gt; Vector a -&gt; Vector (Int, a)
forall a b. Vector a -&gt; Vector b -&gt; Vector (a, b)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.zip</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Vector Int
forall a. Enum a =&gt; a -&gt; a -&gt; Vector a
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.enumFromTo</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756896"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679756894"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(((Int, a) -&gt; IO ()) -&gt; IO ()) -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679756892"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756892"><span class="hs-identifier hs-var">i</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679756891"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756891"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1490"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756898"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756897"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756892"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756890"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756895"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679756891"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1491"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1492"></span><span>      </span><span id="local-6989586621679756890"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679756890"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756895"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1493"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679756889"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756889"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679756888"><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679756888"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (Vector a) -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756889"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe (Vector a) -&gt; IO ()) -&gt; Maybe (Vector a) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Maybe (Vector a)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679756888"><span class="hs-identifier hs-var">x</span></a></span></span><span>
</span><span id="line-1494"></span><span>
</span><span id="line-1495"></span><span id="local-6989586621679756883"><span id="local-6989586621679756884"><span id="local-6989586621679756885"><span id="local-6989586621679756886"><span id="local-6989586621679756887"><span class="hs-keyword">instance</span><span>
</span><span id="line-1496"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679756887"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1497"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756886"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756885"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756884"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1498"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756886"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1499"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#KnownDType"><span class="hs-identifier hs-type">KnownDType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756885"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1500"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756883"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1501"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756883"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756884"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756887"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1502"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1503"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">SV.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756887"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756886"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679756885"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756883"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1504"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1505"></span><span>  </span><span id="local-6989586621679756880"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector n a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679756880"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector n a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, KnownDType dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1506"></span><span>  </span><span id="local-6989586621679756879"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector n a
</span><a href="#local-6989586621679756879"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector n a
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span></span><span>
</span><span id="line-1507"></span><span>
</span><span id="line-1508"></span><span id="local-6989586621679756877"><span id="local-6989586621679756878"><span class="hs-keyword">instance</span><span>
</span><span id="line-1509"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679756878"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1510"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756877"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1511"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1512"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">SV.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756878"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756877"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1513"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1514"></span><span>  </span><span id="local-6989586621679756872"><span class="annot"><span class="annottext">guessDim :: Maybe (Vector n a) -&gt; Maybe Int
</span><a href="#local-6989586621679756872"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Maybe Int)
-&gt; (Maybe (Vector n a) -&gt; Int) -&gt; Maybe (Vector n a) -&gt; Maybe Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; (Vector n a -&gt; Int) -&gt; Maybe (Vector n a) -&gt; Int
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><span class="hs-identifier hs-var">maybe</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">Vector n a -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span>
</span><span id="line-1515"></span><span>
</span><span id="line-1516"></span><span>  </span><span id="local-6989586621679756871"><span class="annot"><span class="annottext">guessInnerDims :: Maybe (Vector n a) -&gt; m [Int]
</span><a href="#local-6989586621679756871"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe (Vector a) -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessInnerDims"><span class="hs-identifier hs-var">guessInnerDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe (Vector a) -&gt; m [Int])
-&gt; (Maybe (Vector n a) -&gt; Maybe (Vector a))
-&gt; Maybe (Vector n a)
-&gt; m [Int]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(Vector n a -&gt; Vector a) -&gt; Maybe (Vector n a) -&gt; Maybe (Vector a)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span> </span><span class="annot"><span class="annottext">Vector n a -&gt; Vector a
forall a (n :: Nat). KnownNat n =&gt; Vector n a -&gt; Vector a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">SV.SomeSized</span></a></span><span>
</span><span id="line-1517"></span><span>
</span><span id="line-1518"></span><span>  </span><span id="local-6989586621679756869"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO (Vector n a)
</span><a href="#local-6989586621679756869"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679756868"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756868"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756867"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756867"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span id="local-6989586621679756866"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756866"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Vector n a
forall (v :: * -&gt; *) (n :: Nat) a. v a -&gt; Vector v n a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">SVI.Vector</span></a></span><span> </span><span class="annot"><span class="annottext">(Vector a -&gt; Vector n a) -&gt; IO (Vector a) -&gt; IO (Vector n a)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO (Vector a)
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756868"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756867"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756866"><span class="hs-identifier hs-var">dims'</span></a></span><span>
</span><span id="line-1519"></span><span>
</span><span id="line-1520"></span><span>  </span><span id="local-6989586621679756864"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Vector n a -&gt; IO ()
</span><a href="#local-6989586621679756864"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679756863"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756863"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679756862"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756862"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span id="local-6989586621679756861"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756861"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; Vector a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679756863"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679756862"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679756861"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Vector a -&gt; IO ())
-&gt; (Vector n a -&gt; Vector a) -&gt; Vector n a -&gt; IO ()
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Vector n a -&gt; Vector a
forall a (n :: Nat). KnownNat n =&gt; Vector n a -&gt; Vector a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">SV.SomeSized</span></a></span></span></span><span>
</span><span id="line-1521"></span><span>
</span><span id="line-1522"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sChangeTensorOptions"><span class="hs-identifier hs-type">sChangeTensorOptions</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1523"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757875"><span class="annot"><a href="#local-6989586621679757875"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757874"><span class="annot"><a href="#local-6989586621679757874"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757873"><span class="annot"><a href="#local-6989586621679757873"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757872"><span class="annot"><a href="#local-6989586621679757872"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757871"><span class="annot"><a href="#local-6989586621679757871"><span class="hs-identifier hs-type">gradientFrom</span></a></span></span><span> </span><span id="local-6989586621679757870"><span class="annot"><a href="#local-6989586621679757870"><span class="hs-identifier hs-type">layoutFrom</span></a></span></span><span> </span><span id="local-6989586621679757869"><span class="annot"><a href="#local-6989586621679757869"><span class="hs-identifier hs-type">deviceFrom</span></a></span></span><span> </span><span id="local-6989586621679757868"><span class="annot"><a href="#local-6989586621679757868"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span></span><span> </span><span id="local-6989586621679757867"><span class="annot"><a href="#local-6989586621679757867"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1524"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757875"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1525"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757874"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1526"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757873"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1527"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757872"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1528"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757871"><span class="hs-identifier hs-type">gradientFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757870"><span class="hs-identifier hs-type">layoutFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757869"><span class="hs-identifier hs-type">deviceFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757868"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757867"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1529"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757875"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757874"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757873"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757872"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757867"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1530"></span><span id="sChangeTensorOptions"><span class="annot"><span class="annottext">sChangeTensorOptions :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sChangeTensorOptions"><span class="hs-identifier hs-var hs-var">sChangeTensorOptions</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier hs-type">Demoted'</span></a></span><span> </span><span id="local-6989586621679756859"><span class="annot"><a href="#local-6989586621679756859"><span class="hs-identifier hs-var">gradient'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier hs-type">Demoted'</span></a></span><span> </span><span id="local-6989586621679756858"><span class="annot"><a href="#local-6989586621679756858"><span class="hs-identifier hs-var">layout</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier hs-type">Demoted'</span></a></span><span> </span><span id="local-6989586621679756857"><span class="annot"><a href="#local-6989586621679756857"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Demoted%27"><span class="hs-identifier hs-type">Demoted'</span></a></span><span> </span><span id="local-6989586621679756856"><span class="annot"><a href="#local-6989586621679756856"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679756855"><span class="annot"><span class="annottext">Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
</span><a href="#local-6989586621679756855"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1531"></span><span>  </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape)
-&gt; ForeignPtr Tensor
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">IO (ForeignPtr Tensor) -&gt; ForeignPtr Tensor
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (ForeignPtr Tensor) -&gt; ForeignPtr Tensor)
-&gt; IO (ForeignPtr Tensor) -&gt; ForeignPtr Tensor
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorOptions
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; TensorOptions
-&gt; Bool
-&gt; Bool
-&gt; IO (ForeignPtr Tensor)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorOptions
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_obb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
</span><a href="#local-6989586621679756855"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">TensorOptions
</span><a href="#local-6989586621679756853"><span class="hs-identifier hs-var">opts</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679756852"><span class="hs-identifier hs-var">nonBlocking</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679756851"><span class="hs-identifier hs-var">copy</span></a></span><span>
</span><span id="line-1532"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1533"></span><span>    </span><span id="local-6989586621679756853"><span class="annot"><span class="annottext">opts :: TensorOptions
</span><a href="#local-6989586621679756853"><span class="hs-identifier hs-var hs-var">opts</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">RequiresGradient
-&gt; LayoutType -&gt; DeviceType Int16 -&gt; DType -&gt; TensorOptions
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorOptions"><span class="hs-identifier hs-var">tensorOptions</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679756859"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679756858"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679756857"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679756856"><span class="hs-identifier hs-var">dataType</span></a></span><span>
</span><span id="line-1534"></span><span>
</span><span id="line-1535"></span><span>    </span><span id="local-6989586621679756852"><span class="annot"><span class="annottext">nonBlocking :: Bool
</span><a href="#local-6989586621679756852"><span class="hs-identifier hs-var hs-var">nonBlocking</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1536"></span><span>    </span><span id="local-6989586621679756851"><span class="annot"><span class="annottext">copy :: Bool
</span><a href="#local-6989586621679756851"><span class="hs-identifier hs-var hs-var">copy</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1537"></span><span>
</span><span id="line-1538"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#changeTensorOptions"><span class="hs-identifier hs-type">changeTensorOptions</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1539"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679757854"><span class="annot"><a href="#local-6989586621679757854"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679757853"><span class="annot"><a href="#local-6989586621679757853"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679757852"><span class="annot"><a href="#local-6989586621679757852"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679757851"><span class="annot"><a href="#local-6989586621679757851"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679757850"><span class="annot"><a href="#local-6989586621679757850"><span class="hs-identifier hs-type">gradientFrom</span></a></span></span><span> </span><span id="local-6989586621679757849"><span class="annot"><a href="#local-6989586621679757849"><span class="hs-identifier hs-type">layoutFrom</span></a></span></span><span> </span><span id="local-6989586621679757848"><span class="annot"><a href="#local-6989586621679757848"><span class="hs-identifier hs-type">deviceFrom</span></a></span></span><span> </span><span id="local-6989586621679757847"><span class="annot"><a href="#local-6989586621679757847"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span></span><span> </span><span id="local-6989586621679757846"><span class="annot"><a href="#local-6989586621679757846"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1540"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757854"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1541"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757853"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1542"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757852"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1543"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757851"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-1544"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1545"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757850"><span class="hs-identifier hs-type">gradientFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757849"><span class="hs-identifier hs-type">layoutFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757848"><span class="hs-identifier hs-type">deviceFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757847"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757846"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1546"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757854"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757853"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757852"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757851"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679757846"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1547"></span><span id="changeTensorOptions"><span class="annot"><span class="annottext">changeTensorOptions :: Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#changeTensorOptions"><span class="hs-identifier hs-var hs-var">changeTensorOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (gradientFrom :: Gradient RequiresGradient)
       (layoutFrom :: Layout LayoutType)
       (deviceFrom :: Device (DeviceType Nat))
       (dataTypeFrom :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sChangeTensorOptions"><span class="hs-identifier hs-var">sChangeTensorOptions</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI gradient =&gt; Sing gradient
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757854"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI layout =&gt; Sing layout
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757853"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI device =&gt; Sing device
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757852"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI dataType =&gt; Sing dataType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679757851"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1548"></span><span>
</span><span id="line-1549"></span><span id="local-6989586621679756845"><span id="local-6989586621679756846"><span id="local-6989586621679756847"><span id="local-6989586621679756848"><span id="local-6989586621679756849"><span class="hs-keyword">instance</span><span>
</span><span id="line-1550"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756849"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1551"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756848"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1552"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756847"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1553"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756846"><span class="hs-identifier hs-type">dType</span></a></span><span>
</span><span id="line-1554"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1555"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756849"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756848"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756847"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756846"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756845"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679756846"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756845"><span class="hs-identifier hs-type">dims</span></a></span><span>
</span><span id="line-1556"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1557"></span><span>  </span><span id="local-6989586621679756842"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="#local-6989586621679756842"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span id="local-6989586621679756841"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679756841"><span class="hs-identifier hs-var">gradient'</span></a></span></span><span> </span><span id="local-6989586621679756840"><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679756840"><span class="hs-identifier hs-var">layout</span></a></span></span><span> </span><span id="local-6989586621679756839"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679756839"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679756838"><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679756838"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device ('DataType dType) ('Shape dims)
 -&gt; m (Tensor
         gradient layout device ('DataType dType) ('Shape dims)))
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType ('DataType dType)
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (gradientFrom :: Gradient RequiresGradient)
       (layoutFrom :: Layout LayoutType)
       (deviceFrom :: Device (DeviceType Nat))
       (dataTypeFrom :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sChangeTensorOptions"><span class="hs-identifier hs-var">sChangeTensorOptions</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679756841"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679756840"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679756839"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType dType)
</span><a href="#local-6989586621679756837"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679756838"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1558"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1559"></span><span>      </span><span id="local-6989586621679756837"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType dType)
</span><a href="#local-6989586621679756837"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType dType -&gt; SDataType ('DataType dType)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">(SDType dType -&gt; SDataType ('DataType dType))
-&gt; SDType dType -&gt; SDataType ('DataType dType)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SingI dType =&gt; Sing dType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679756846"><span class="hs-identifier hs-type">dType</span></a></span><span>
</span><span id="line-1560"></span><span>
</span><span id="line-1561"></span><span>  </span><span id="local-6989586621679756836"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679756836"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (gradientFrom :: Gradient RequiresGradient)
       (layoutFrom :: Layout LayoutType)
       (deviceFrom :: Device (DeviceType Nat))
       (dataTypeFrom :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SingI gradient, SingI layout, SingI device, SingI dataType) =&gt;
Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; Tensor gradient layout device dataType shape
forall (gradientFrom :: Gradient RequiresGradient)
       (layoutFrom :: Layout LayoutType)
       (deviceFrom :: Device (DeviceType Nat))
       (dataTypeFrom :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SingI gradient, SingI layout, SingI device,
 SingI ('DataType dType)) =&gt;
Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; Tensor gradient layout device ('DataType dType) shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#changeTensorOptions"><span class="hs-identifier hs-var">changeTensorOptions</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679756849"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679756848"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679756847"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679756846"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-1562"></span></pre></body></html>